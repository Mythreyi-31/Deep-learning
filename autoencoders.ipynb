{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SA RAVI\\anaconda3\\envs\\aimlsem1\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca doesn't work with categorical variables. Autoencoder is a non linear dimension reduction tool. \n",
    "\n",
    "## Load MNIST data\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]* X_test.shape[2])\n",
    "\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "#normalize the shapes\n",
    "xmax =  np.amax(X_train)\n",
    "xmin =  np.amin(X_train)\n",
    "X_train = (X_train -xmin)/ (xmax -xmin)\n",
    "X_test = (X_test -xmin)/ (xmax -xmin)\n",
    "\n",
    "print(num_samples)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of autoencoder\n",
    "batch_size = 256\n",
    "max_epochs = 50\n",
    "learning_rate = 1e-03\n",
    "latent_dim = 128\n",
    "hidden_dim = 256\n",
    "original_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train) #loads into numpy array onlyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert numpy to tf.data.dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(X_train).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layers\n",
    "#encoder\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    # define input independent model information\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__() #constructor is same for superclass\n",
    "        self.encoder_layer1 =  tf.keras.layers.Dense(units=hidden_dim, activation=tf.nn.relu)\n",
    "        self.encoder_layer2 = tf.keras.layers.Dense(units=latent_dim, activation=tf.nn.relu)    \n",
    "\n",
    "    # method for forward propagation\n",
    "    def call(self, input_features):\n",
    "        a = self.encoder_layer1(input_features)\n",
    "        a = self.encoder_layer2(a)\n",
    "        return (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, latent_dim, hidden_dim, original_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layer1 =  tf.keras.layers.Dense(units=hidden_dim, activation=tf.nn.relu)\n",
    "        self.decoder_layer2 = tf.keras.layers.Dense(units=original_dim, activation=tf.nn.relu) \n",
    "\n",
    "    def call(self, encoded_feature):\n",
    "        a = self.decoder_layer1(encoded_feature)\n",
    "        a = self.decoder_layer2(a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, hidden_dim, original_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.loss = []\n",
    "        self.encoder = Encoder(hidden_dim = hidden_dim, latent_dim = latent_dim) #calls constructor\n",
    "        self.decoder = Decoder(latent_dim = latent_dim, hidden_dim = hidden_dim, original_dim = original_dim)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        encoded = self.encoder(input_features)\n",
    "        reconstructed_features = self.decoder(encoded)\n",
    "        return reconstructed_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SA RAVI\\anaconda3\\envs\\aimlsem1\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "autoencoder = Autoencoder(latent_dim = latent_dim,\n",
    "                          hidden_dim = hidden_dim,\n",
    "                          original_dim = original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = learning_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom training\n",
    "def loss(true, pred):\n",
    "    #pred = tf.cast(pred, tf.float32)\n",
    "    #true = tf.cast(true, tf.float32)\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(true, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom training -  compute gradient of loss and update weights\n",
    "@tf.function\n",
    "def train(loss, model, opt , original_features):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = tf.cast(model(original_features), tf.float64)\n",
    "        reconstruction_error =  loss(original_features, pred)\n",
    "    \n",
    "    gradients = g.gradient(reconstruction_error, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss = 0.005336240865290165\n",
      "Epoch 1: time taken = 1.55s, train loss = 0.005336\n",
      "Epoch 2. loss = 0.005348077975213528\n",
      "Epoch 2: time taken = 1.51s, train loss = 0.005348\n",
      "Epoch 3. loss = 0.005384488496929407\n",
      "Epoch 3: time taken = 1.56s, train loss = 0.005384\n",
      "Epoch 4. loss = 0.005374573171138763\n",
      "Epoch 4: time taken = 1.55s, train loss = 0.005375\n",
      "Epoch 5. loss = 0.0053656091913580894\n",
      "Epoch 5: time taken = 1.50s, train loss = 0.005366\n",
      "Epoch 6. loss = 0.005366146098822355\n",
      "Epoch 6: time taken = 1.56s, train loss = 0.005366\n",
      "Epoch 7. loss = 0.0053571839816868305\n",
      "Epoch 7: time taken = 1.66s, train loss = 0.005357\n",
      "Epoch 8. loss = 0.005354090128093958\n",
      "Epoch 8: time taken = 1.58s, train loss = 0.005354\n",
      "Epoch 9. loss = 0.005342843011021614\n",
      "Epoch 9: time taken = 1.59s, train loss = 0.005343\n",
      "Epoch 10. loss = 0.005336232483386993\n",
      "Epoch 10: time taken = 1.59s, train loss = 0.005336\n",
      "Epoch 11. loss = 0.005334449931979179\n",
      "Epoch 11: time taken = 1.71s, train loss = 0.005334\n",
      "Epoch 12. loss = 0.0053399428725242615\n",
      "Epoch 12: time taken = 1.64s, train loss = 0.005340\n",
      "Epoch 13. loss = 0.005334910470992327\n",
      "Epoch 13: time taken = 1.69s, train loss = 0.005335\n",
      "Epoch 14. loss = 0.00533377006649971\n",
      "Epoch 14: time taken = 1.69s, train loss = 0.005334\n",
      "Epoch 15. loss = 0.0053390273824334145\n",
      "Epoch 15: time taken = 1.79s, train loss = 0.005339\n",
      "Epoch 16. loss = 0.005341948010027409\n",
      "Epoch 16: time taken = 1.57s, train loss = 0.005342\n",
      "Epoch 17. loss = 0.005341301206499338\n",
      "Epoch 17: time taken = 1.71s, train loss = 0.005341\n",
      "Epoch 18. loss = 0.005339520517736673\n",
      "Epoch 18: time taken = 1.62s, train loss = 0.005340\n",
      "Epoch 19. loss = 0.0053346892818808556\n",
      "Epoch 19: time taken = 1.65s, train loss = 0.005335\n",
      "Epoch 20. loss = 0.005334134213626385\n",
      "Epoch 20: time taken = 1.73s, train loss = 0.005334\n",
      "Epoch 21. loss = 0.005335546564310789\n",
      "Epoch 21: time taken = 1.74s, train loss = 0.005336\n",
      "Epoch 22. loss = 0.005335396155714989\n",
      "Epoch 22: time taken = 1.76s, train loss = 0.005335\n",
      "Epoch 23. loss = 0.005333207547664642\n",
      "Epoch 23: time taken = 1.75s, train loss = 0.005333\n",
      "Epoch 24. loss = 0.005330102052539587\n",
      "Epoch 24: time taken = 1.93s, train loss = 0.005330\n",
      "Epoch 25. loss = 0.005328087601810694\n",
      "Epoch 25: time taken = 1.88s, train loss = 0.005328\n",
      "Epoch 26. loss = 0.005329486448317766\n",
      "Epoch 26: time taken = 1.88s, train loss = 0.005329\n",
      "Epoch 27. loss = 0.0053284685127437115\n",
      "Epoch 27: time taken = 1.90s, train loss = 0.005328\n",
      "Epoch 28. loss = 0.005326807498931885\n",
      "Epoch 28: time taken = 1.85s, train loss = 0.005327\n",
      "Epoch 29. loss = 0.005325490143150091\n",
      "Epoch 29: time taken = 1.87s, train loss = 0.005325\n",
      "Epoch 30. loss = 0.0053249383345246315\n",
      "Epoch 30: time taken = 1.88s, train loss = 0.005325\n",
      "Epoch 31. loss = 0.005326427053660154\n",
      "Epoch 31: time taken = 1.87s, train loss = 0.005326\n",
      "Epoch 32. loss = 0.005327689927071333\n",
      "Epoch 32: time taken = 1.88s, train loss = 0.005328\n",
      "Epoch 33. loss = 0.005334652028977871\n",
      "Epoch 33: time taken = 1.87s, train loss = 0.005335\n",
      "Epoch 34. loss = 0.005333229899406433\n",
      "Epoch 34: time taken = 1.85s, train loss = 0.005333\n",
      "Epoch 35. loss = 0.005334076471626759\n",
      "Epoch 35: time taken = 1.83s, train loss = 0.005334\n",
      "Epoch 36. loss = 0.005335214082151651\n",
      "Epoch 36: time taken = 1.83s, train loss = 0.005335\n",
      "Epoch 37. loss = 0.005340650212019682\n",
      "Epoch 37: time taken = 1.88s, train loss = 0.005341\n",
      "Epoch 38. loss = 0.005339764058589935\n",
      "Epoch 38: time taken = 1.86s, train loss = 0.005340\n",
      "Epoch 39. loss = 0.005337601061910391\n",
      "Epoch 39: time taken = 1.86s, train loss = 0.005338\n",
      "Epoch 40. loss = 0.005335637368261814\n",
      "Epoch 40: time taken = 1.85s, train loss = 0.005336\n",
      "Epoch 41. loss = 0.005333462730050087\n",
      "Epoch 41: time taken = 1.92s, train loss = 0.005333\n",
      "Epoch 42. loss = 0.0053306384943425655\n",
      "Epoch 42: time taken = 1.93s, train loss = 0.005331\n",
      "Epoch 43. loss = 0.005330038256943226\n",
      "Epoch 43: time taken = 1.90s, train loss = 0.005330\n",
      "Epoch 44. loss = 0.005329102743417025\n",
      "Epoch 44: time taken = 1.99s, train loss = 0.005329\n",
      "Epoch 45. loss = 0.0053353519178926945\n",
      "Epoch 45: time taken = 1.83s, train loss = 0.005335\n",
      "Epoch 46. loss = 0.005333251785486937\n",
      "Epoch 46: time taken = 1.71s, train loss = 0.005333\n",
      "Epoch 47. loss = 0.005334061104804277\n",
      "Epoch 47: time taken = 1.69s, train loss = 0.005334\n",
      "Epoch 48. loss = 0.005331784952431917\n",
      "Epoch 48: time taken = 1.74s, train loss = 0.005332\n",
      "Epoch 49. loss = 0.005331752821803093\n",
      "Epoch 49: time taken = 1.73s, train loss = 0.005332\n",
      "Epoch 50. loss = 0.005330950487405062\n",
      "Epoch 50: time taken = 1.70s, train loss = 0.005331\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# train network by iterating over epochs\n",
    "# Varible to store training loss per epoch\n",
    "loss_train_epoch = tf.keras.metrics.Mean()\n",
    "\n",
    "#iterate over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0\n",
    "    for step, train_batch_features in enumerate(training_dataset):\n",
    "        loss_batch = train(loss, autoencoder, opt, train_batch_features)\n",
    "   #append loss per epoch\n",
    "    loss_train_epoch(loss_batch)\n",
    "    print(f'Epoch {epoch+1}. loss = {loss_train_epoch.result()}' )\n",
    "    print('Epoch %d: time taken = %.2fs, train loss = %f'%(epoch+1, time.time() - start_time, loss_train_epoch.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(4, 4))\n",
    "fig.tight_layout(pad=5.0)\n",
    "pd.Series(loss_train_epoch).plot(ax=ax[0], color='b')\n",
    "ax[0].set_xlabel('Epochs', fontsize=15)\n",
    "ax[0].set_ylabel('Loss', fontsize=15)\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Loss vs. Epoch', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(autoencoder, opt, loss, training_dataset, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SA RAVI\\AppData\\Local\\Temp\\ipykernel_17784\\3907480142.py:4: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  ax = plt.subplot(2, nimages, ind + 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nimages = 5\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "for ind in range(nimages):\n",
    "    ax = plt.subplot(2, nimages, ind + 1)\n",
    "    plt.imshow(X_train[ind].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    #reconstructed images\n",
    "    ax = plt.subplot(2, nimages, ind + 1 + nimages)\n",
    "    plt.imshow(autoencoder(X_test)[ind].numpy().reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimlsem1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

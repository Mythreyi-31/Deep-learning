{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dEgRpy3952M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\SA RAVI\\anaconda3\\envs\\aimlsem1\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4T7eUtw7Mh0z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q1e2N5S8MlCU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbaFOIn_CDuN"
      },
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive if running in Colab\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02xk1yt7CE1D"
      },
      "outputs": [],
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR + '/Data/'\n",
        "    os.chdir(DIR)\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BpVeIWIOks"
      },
      "source": [
        "---\n",
        "\n",
        "Load diabetes data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E5kaKFKSIQgu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diabetes dataset\n",
            "-----------\n",
            "Initial number of samples = 442\n",
            "Initial number of features = 11\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>BMILEVEL</th>\n",
              "      <th>BP</th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>101.0</td>\n",
              "      <td>157</td>\n",
              "      <td>93.2</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.8598</td>\n",
              "      <td>87</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>healthy</td>\n",
              "      <td>87.0</td>\n",
              "      <td>183</td>\n",
              "      <td>103.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.8918</td>\n",
              "      <td>69</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>93.0</td>\n",
              "      <td>156</td>\n",
              "      <td>93.6</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.6728</td>\n",
              "      <td>85</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>overweight</td>\n",
              "      <td>84.0</td>\n",
              "      <td>198</td>\n",
              "      <td>131.4</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.8903</td>\n",
              "      <td>89</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>healthy</td>\n",
              "      <td>101.0</td>\n",
              "      <td>192</td>\n",
              "      <td>125.4</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2905</td>\n",
              "      <td>80</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   AGE  GENDER    BMILEVEL     BP   S1     S2    S3   S4      S5  S6    Y\n",
              "0   59       2   unhealthy  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
              "1   48       1     healthy   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
              "2   72       2   unhealthy   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
              "3   24       1  overweight   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
              "4   50       1     healthy  101.0  192  125.4  52.0  4.0  4.2905  80  135"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Load Bengaluru house price data\n",
        "file = 'diabetes_regression.csv'\n",
        "df= pd.read_csv(file, header = 0)\n",
        "\n",
        "print('Diabetes dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(df.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(df.shape[1]))\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AJE5ehBOClXW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BMILEVEL', 'GENDER']\n",
            "['AGE', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'Y']\n"
          ]
        }
      ],
      "source": [
        "## Create lists of ordinal, categorical, and continuous features\n",
        "categorical_features = (['BMILEVEL', 'GENDER'])\n",
        "continuous_features = df.drop(categorical_features, axis = 1).columns.tolist()\n",
        "print(categorical_features)\n",
        "print(continuous_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3NyP_EoDG1i"
      },
      "source": [
        "---\n",
        "\n",
        "Assign 'category' datatype to categorical columns\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-dVFfOBlDJ5n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AGE           int64\n",
            "GENDER        int64\n",
            "BMILEVEL     object\n",
            "BP          float64\n",
            "S1            int64\n",
            "S2          float64\n",
            "S3          float64\n",
            "S4          float64\n",
            "S5          float64\n",
            "S6            int64\n",
            "Y             int64\n",
            "dtype: object\n",
            "----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AGE            int64\n",
              "GENDER      category\n",
              "BMILEVEL    category\n",
              "BP           float64\n",
              "S1             int64\n",
              "S2           float64\n",
              "S3           float64\n",
              "S4           float64\n",
              "S5           float64\n",
              "S6             int64\n",
              "Y              int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Assign 'category' datatype to ordinal and categorical columns\n",
        "print(df.dtypes)\n",
        "df[categorical_features] = df[categorical_features].astype('category')\n",
        "print('----')\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95YNt2eDUJ8"
      },
      "source": [
        "---\n",
        "\n",
        "Remove the target variable column from the list of continuous features\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XuQGzpefDUqE"
      },
      "outputs": [],
      "source": [
        "## Remove the target variable column from the list of continuous features\n",
        "continuous_features.remove('Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tn-qjRocE8Lj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diabetes data set\n",
            "---------------------\n",
            "Number of training samples = 10\n",
            "Number of features = 353\n"
          ]
        }
      ],
      "source": [
        "## Train and test split of the data\n",
        "X = df.drop('Y', axis = 1)\n",
        "y = df['Y']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "num_features = X_train.shape[0]\n",
        "num_samples = X_train.shape[1]\n",
        "\n",
        "print('Diabetes data set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqSu9e7G-fh"
      },
      "source": [
        "---\n",
        "\n",
        "Build pipeline for categorical and continuous features\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FKAqkz1GHGvm"
      },
      "outputs": [],
      "source": [
        "## Build pipeline for categorical and continuous features\n",
        "\n",
        "# Pipeline object for categorical (features\n",
        "categorical_transformer = Pipeline(steps = [('onehotenc', OneHotEncoder(handle_unknown = 'ignore'))])\n",
        "\n",
        "# Pipeline object for continuous features\n",
        "continuous_transformer = Pipeline(steps = [('scaler', StandardScaler())])\n",
        "\n",
        "# Create a preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('continuous',continuous_transformer, continuous_features),\n",
        "                                                 ('categorical', categorical_transformer, categorical_features)\n",
        "                                                ],\n",
        "                                 remainder = 'passthrough'\n",
        "                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUWtfRseHv2O"
      },
      "source": [
        "---\n",
        "\n",
        "Fit and transform train data using preprocessor followed by transforming test data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RvrUIw4SHzO_"
      },
      "outputs": [],
      "source": [
        "## Fit and transform train data using preprocessor\n",
        "X_train_transformed = preprocessor.fit_transform(X_train).T\n",
        "\n",
        "# Update number of features\n",
        "num_features = X_train_transformed.shape[0]\n",
        "# Transform training data using preprocessor\n",
        "X_test_transformed = preprocessor.transform(X_test).T\n",
        "# Convert Y_train and Y_test to numpy arrays\n",
        "Y_train = Y_train.to_numpy()\n",
        "Y_test = Y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYn_hOccDa3M"
      },
      "source": [
        "---\n",
        "\n",
        "A generic layer class with forward and backward methods\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N4pKUhCyMrWm"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  def forward(self, input):\n",
        "    pass\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMt81Faf9-bf"
      },
      "source": [
        "---\n",
        "\n",
        "Mean squared error (MSE) loss and its gradient\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hdXSGW2s7zKd"
      },
      "outputs": [],
      "source": [
        "## Define the loss function and its gradient\n",
        "def mse(Y, Yhat):\n",
        "  return(np.mean((Y - Yhat)**2))\n",
        "  #TensorFlow in-built function for mean squared error loss\n",
        "  #mse = tf.keras.losses.MeanSquaredError()\n",
        "  #mse(Y, Yhat).numpy()\n",
        "\n",
        "def mse_gradient(Y, Yhat):\n",
        "  return(Yhat - Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmcNJTjS-BaW"
      },
      "source": [
        "---\n",
        "\n",
        "Generic activation layer class\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C21FcWIEwGCN"
      },
      "outputs": [],
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_gradient):\n",
        "        self.activation = activation\n",
        "        self.activation_gradient = activation_gradient\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = self.activation(self.input)\n",
        "        return(self.output)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate = None):\n",
        "        return(output_gradient[:-1, :] * self.activation_gradient(self.input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JheGWSoKxYWu"
      },
      "source": [
        "---\n",
        "\n",
        "Specific activation layer classes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PQ5ybz_Yxbef"
      },
      "outputs": [],
      "source": [
        "class Sigmoid(Activation):\n",
        "    def __init__(self):\n",
        "        def sigmoid(z):\n",
        "            return 1 / (1 + np.exp(-z))\n",
        "\n",
        "        def sigmoid_gradient(z):\n",
        "            a = sigmoid(z)\n",
        "            return a * (1 - a)\n",
        "\n",
        "        super().__init__(sigmoid, sigmoid_gradient)\n",
        "\n",
        "class Tanh(Activation):\n",
        "    def __init__(self):\n",
        "        def tanh(z):\n",
        "            return np.tanh(z)\n",
        "\n",
        "        def tanh_gradient(z):\n",
        "            a = np.tanh(z)\n",
        "            return 1 - a**2\n",
        "\n",
        "        super().__init__(tanh, tanh_gradient)\n",
        "\n",
        "class ReLU(Activation):\n",
        "    def __init__(self):\n",
        "        def relu(z):\n",
        "            return z * (z > 0)\n",
        "\n",
        "        def relu_gradient(z):\n",
        "            return 1. * (z > 0)\n",
        "\n",
        "        super().__init__(relu, relu_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKnqi7rf-MBn"
      },
      "source": [
        "---\n",
        "\n",
        "Dense layer class\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8ctXhZYCTmHK"
      },
      "outputs": [],
      "source": [
        "## Dense layer class\n",
        "class Dense(Layer):\n",
        "    def __init__(self, input_size, output_size, reg_strength):\n",
        "        self.weights = 0.01*np.random.randn(output_size, input_size+1) # bias trick\n",
        "        self.weights[:, -1] = 0.01 # set all bias values to the same nonzero constant\n",
        "        self.reg_strength = reg_strength\n",
        "        self.reg_loss = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = np.vstack([input, np.ones((1, input.shape[1]))]) # bias trick\n",
        "        self.output= np.dot(self.weights, self.input)\n",
        "        # Calculate regularization loss\n",
        "        self.reg_loss = self.reg_strength * np.sum(self.weights[:, :-1] * self.weights[:, :-1])\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        ## Following is the inefficient way of calculating the backward gradient\n",
        "        #weights_gradient = np.zeros((self.output.shape[0], self.input.shape[0]), dtype = np.float64)\n",
        "        #for b in range(output_gradient.shape[1]):\n",
        "        #  weights_gradient += np.dot(output_gradient[:, b].reshape(-1, 1), self.input[:, b].reshape(-1, 1).T)\n",
        "        #weights_gradient = (1/output_gradient.shape[1])*weights_gradient\n",
        "\n",
        "        ## Following is the efficient way of calculating the weights gradient w.r.t. data\n",
        "        weights_gradient = (1/output_gradient.shape[1])*np.dot(np.atleast_2d(output_gradient), np.atleast_2d(self.input).T)\n",
        "        # Add the regularization gradient here\n",
        "        weights_gradient += 2 * self.reg_strength * np.hstack([self.weights[:, :-1], np.zeros((self.weights.shape[0], 1))])\n",
        "\n",
        "\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "        self.weights = self.weights + learning_rate * (-weights_gradient)\n",
        "\n",
        "        return(input_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W1howeOJegI"
      },
      "source": [
        "---\n",
        "\n",
        "Function to generate sample indices for batch processing according to batch size\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MHyjEf22IRpc"
      },
      "outputs": [],
      "source": [
        "## Function to generate sample indices for batch processing according to batch size\n",
        "def generate_batch_indices(num_samples, batch_size):\n",
        "  # Reorder sample indices\n",
        "  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n",
        "  # Generate batch indices for batch processing\n",
        "  batch_indices = np.split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n",
        "  return(batch_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_Gms9fJqbs"
      },
      "source": [
        "---\n",
        "\n",
        "Train the 1-hidden layer neural network (128 nodes) using batch training with batch size = 16\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LGIzrN-rPuI4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 25006.592098, test loss = 26951.593589\n",
            "Epoch 2: train loss = 24963.896749, test loss = 26908.592798\n",
            "Epoch 3: train loss = 24921.284867, test loss = 26865.654206\n",
            "Epoch 4: train loss = 24878.724171, test loss = 26822.745696\n",
            "Epoch 5: train loss = 24836.168405, test loss = 26779.834900\n",
            "Epoch 6: train loss = 24793.579059, test loss = 26736.870399\n",
            "Epoch 7: train loss = 24750.876388, test loss = 26693.774422\n",
            "Epoch 8: train loss = 24707.950703, test loss = 26650.442419\n",
            "Epoch 9: train loss = 24664.658532, test loss = 26606.724132\n",
            "Epoch 10: train loss = 24620.793232, test loss = 26562.380615\n",
            "Epoch 11: train loss = 24576.027963, test loss = 26517.084479\n",
            "Epoch 12: train loss = 24529.902410, test loss = 26470.340589\n",
            "Epoch 13: train loss = 24481.729431, test loss = 26421.419360\n",
            "Epoch 14: train loss = 24430.497108, test loss = 26369.258154\n",
            "Epoch 15: train loss = 24374.716351, test loss = 26312.281289\n",
            "Epoch 16: train loss = 24312.198582, test loss = 26248.190689\n",
            "Epoch 17: train loss = 24239.726420, test loss = 26173.425013\n",
            "Epoch 18: train loss = 24152.304258, test loss = 26083.064644\n",
            "Epoch 19: train loss = 24043.102013, test loss = 25969.872440\n",
            "Epoch 20: train loss = 23901.989474, test loss = 25822.928006\n",
            "Epoch 21: train loss = 23713.834341, test loss = 25627.440283\n",
            "Epoch 22: train loss = 23457.984164, test loss = 25362.346153\n",
            "Epoch 23: train loss = 23105.224717, test loss = 24999.099774\n",
            "Epoch 24: train loss = 22615.944063, test loss = 24500.641625\n",
            "Epoch 25: train loss = 21938.841229, test loss = 23822.249937\n",
            "Epoch 26: train loss = 21012.294236, test loss = 22916.562439\n",
            "Epoch 27: train loss = 19771.764664, test loss = 21745.539524\n",
            "Epoch 28: train loss = 18167.244199, test loss = 20301.272044\n",
            "Epoch 29: train loss = 16193.494685, test loss = 18630.927340\n",
            "Epoch 30: train loss = 13926.504890, test loss = 16849.503083\n",
            "Epoch 31: train loss = 11541.414087, test loss = 15067.732717\n",
            "Epoch 32: train loss = 9221.071177, test loss = 13461.785935\n",
            "Epoch 33: train loss = 7246.091919, test loss = 12118.390987\n",
            "Epoch 34: train loss = 5733.214607, test loss = 11038.931730\n",
            "Epoch 35: train loss = 4658.407816, test loss = 10175.568558\n",
            "Epoch 36: train loss = 3918.273402, test loss = 9489.168111\n",
            "Epoch 37: train loss = 3404.555683, test loss = 8938.125870\n",
            "Epoch 38: train loss = 3038.579712, test loss = 8499.872252\n",
            "Epoch 39: train loss = 2768.435823, test loss = 8151.315376\n",
            "Epoch 40: train loss = 2561.503467, test loss = 7873.126346\n",
            "Epoch 41: train loss = 2396.978634, test loss = 7649.804626\n",
            "Epoch 42: train loss = 2261.410798, test loss = 7469.231088\n",
            "Epoch 43: train loss = 2146.718665, test loss = 7322.586076\n",
            "Epoch 44: train loss = 2047.722797, test loss = 7202.514647\n",
            "Epoch 45: train loss = 1959.648557, test loss = 7103.788650\n",
            "Epoch 46: train loss = 1880.125281, test loss = 7022.467432\n",
            "Epoch 47: train loss = 1808.161068, test loss = 6955.706196\n",
            "Epoch 48: train loss = 1741.973534, test loss = 6901.255987\n",
            "Epoch 49: train loss = 1680.950710, test loss = 6857.222801\n",
            "Epoch 50: train loss = 1624.624489, test loss = 6822.105059\n",
            "Epoch 51: train loss = 1572.262963, test loss = 6794.553219\n",
            "Epoch 52: train loss = 1523.449304, test loss = 6773.743484\n",
            "Epoch 53: train loss = 1477.920651, test loss = 6758.823505\n",
            "Epoch 54: train loss = 1435.501295, test loss = 6748.671571\n",
            "Epoch 55: train loss = 1395.767573, test loss = 6739.170557\n",
            "Epoch 56: train loss = 1358.377005, test loss = 6732.407001\n",
            "Epoch 57: train loss = 1323.219141, test loss = 6729.480724\n",
            "Epoch 58: train loss = 1290.214928, test loss = 6730.046457\n",
            "Epoch 59: train loss = 1259.060469, test loss = 6733.446456\n",
            "Epoch 60: train loss = 1229.457912, test loss = 6738.857561\n",
            "Epoch 61: train loss = 1201.378607, test loss = 6746.631315\n",
            "Epoch 62: train loss = 1174.860754, test loss = 6756.584595\n",
            "Epoch 63: train loss = 1149.509783, test loss = 6766.141948\n",
            "Epoch 64: train loss = 1125.228073, test loss = 6775.439865\n",
            "Epoch 65: train loss = 1102.022618, test loss = 6786.587701\n",
            "Epoch 66: train loss = 1079.965685, test loss = 6798.884748\n",
            "Epoch 67: train loss = 1058.554784, test loss = 6812.560950\n",
            "Epoch 68: train loss = 1037.940580, test loss = 6827.484806\n",
            "Epoch 69: train loss = 1018.234964, test loss = 6843.995992\n",
            "Epoch 70: train loss = 999.089307, test loss = 6861.112757\n",
            "Epoch 71: train loss = 980.489149, test loss = 6878.112203\n",
            "Epoch 72: train loss = 962.573550, test loss = 6891.831757\n",
            "Epoch 73: train loss = 945.196838, test loss = 6903.343411\n",
            "Epoch 74: train loss = 928.175772, test loss = 6915.094177\n",
            "Epoch 75: train loss = 911.686537, test loss = 6927.974296\n",
            "Epoch 76: train loss = 895.701932, test loss = 6940.375349\n",
            "Epoch 77: train loss = 879.949233, test loss = 6953.004203\n",
            "Epoch 78: train loss = 864.629268, test loss = 6966.809890\n",
            "Epoch 79: train loss = 849.768023, test loss = 6980.706870\n",
            "Epoch 80: train loss = 835.062549, test loss = 6995.326891\n",
            "Epoch 81: train loss = 820.728651, test loss = 7011.098840\n",
            "Epoch 82: train loss = 806.798371, test loss = 7026.716083\n",
            "Epoch 83: train loss = 792.981976, test loss = 7042.957268\n",
            "Epoch 84: train loss = 779.502836, test loss = 7060.346160\n",
            "Epoch 85: train loss = 766.366147, test loss = 7077.720837\n",
            "Epoch 86: train loss = 753.325232, test loss = 7095.748848\n",
            "Epoch 87: train loss = 740.604919, test loss = 7114.926504\n",
            "Epoch 88: train loss = 728.162666, test loss = 7134.047321\n",
            "Epoch 89: train loss = 715.814041, test loss = 7153.803719\n",
            "Epoch 90: train loss = 703.780691, test loss = 7174.716240\n",
            "Epoch 91: train loss = 691.960652, test loss = 7195.534467\n",
            "Epoch 92: train loss = 680.242175, test loss = 7216.460135\n",
            "Epoch 93: train loss = 668.840166, test loss = 7237.858390\n",
            "Epoch 94: train loss = 657.588972, test loss = 7259.116542\n",
            "Epoch 95: train loss = 646.452959, test loss = 7280.826803\n",
            "Epoch 96: train loss = 635.778873, test loss = 7303.321536\n",
            "Epoch 97: train loss = 625.116622, test loss = 7325.119235\n",
            "Epoch 98: train loss = 614.531863, test loss = 7347.389408\n",
            "Epoch 99: train loss = 604.171298, test loss = 7370.772741\n",
            "Epoch 100: train loss = 594.101974, test loss = 7394.154351\n",
            "Epoch 101: train loss = 584.191715, test loss = 7417.410601\n",
            "Epoch 102: train loss = 574.291778, test loss = 7441.112194\n",
            "Epoch 103: train loss = 564.680733, test loss = 7465.496640\n",
            "Epoch 104: train loss = 555.253405, test loss = 7488.750502\n",
            "Epoch 105: train loss = 545.928213, test loss = 7508.374740\n",
            "Epoch 106: train loss = 536.710469, test loss = 7529.036083\n",
            "Epoch 107: train loss = 527.733524, test loss = 7549.807311\n",
            "Epoch 108: train loss = 518.966558, test loss = 7570.773994\n",
            "Epoch 109: train loss = 510.161169, test loss = 7592.133187\n",
            "Epoch 110: train loss = 501.654043, test loss = 7613.979858\n",
            "Epoch 111: train loss = 493.340680, test loss = 7634.182017\n",
            "Epoch 112: train loss = 484.969707, test loss = 7653.795331\n",
            "Epoch 113: train loss = 476.783180, test loss = 7674.872610\n",
            "Epoch 114: train loss = 468.993097, test loss = 7695.303561\n",
            "Epoch 115: train loss = 461.037421, test loss = 7716.072187\n",
            "Epoch 116: train loss = 453.260134, test loss = 7737.671421\n",
            "Epoch 117: train loss = 445.759493, test loss = 7759.289439\n",
            "Epoch 118: train loss = 438.276330, test loss = 7781.790560\n",
            "Epoch 119: train loss = 430.968149, test loss = 7804.421793\n",
            "Epoch 120: train loss = 423.814363, test loss = 7827.051454\n",
            "Epoch 121: train loss = 416.641144, test loss = 7849.952955\n",
            "Epoch 122: train loss = 409.894223, test loss = 7874.238236\n",
            "Epoch 123: train loss = 402.989420, test loss = 7897.814917\n",
            "Epoch 124: train loss = 396.261266, test loss = 7922.159155\n",
            "Epoch 125: train loss = 389.729919, test loss = 7946.379358\n",
            "Epoch 126: train loss = 383.190146, test loss = 7971.412757\n",
            "Epoch 127: train loss = 377.021099, test loss = 7995.532132\n",
            "Epoch 128: train loss = 370.679956, test loss = 8019.440514\n",
            "Epoch 129: train loss = 364.596853, test loss = 8042.877293\n",
            "Epoch 130: train loss = 358.567543, test loss = 8065.939766\n",
            "Epoch 131: train loss = 352.683641, test loss = 8090.169010\n",
            "Epoch 132: train loss = 346.957675, test loss = 8113.629759\n",
            "Epoch 133: train loss = 341.204762, test loss = 8137.783504\n",
            "Epoch 134: train loss = 335.702559, test loss = 8161.766231\n",
            "Epoch 135: train loss = 330.153521, test loss = 8186.410619\n",
            "Epoch 136: train loss = 324.858336, test loss = 8210.835638\n",
            "Epoch 137: train loss = 319.518812, test loss = 8235.902179\n",
            "Epoch 138: train loss = 314.412539, test loss = 8260.700504\n",
            "Epoch 139: train loss = 309.324447, test loss = 8286.671246\n",
            "Epoch 140: train loss = 304.396364, test loss = 8311.766478\n",
            "Epoch 141: train loss = 299.436758, test loss = 8337.523852\n",
            "Epoch 142: train loss = 294.703321, test loss = 8362.125456\n",
            "Epoch 143: train loss = 289.961937, test loss = 8386.303644\n",
            "Epoch 144: train loss = 285.369333, test loss = 8409.597851\n",
            "Epoch 145: train loss = 280.849459, test loss = 8432.465709\n",
            "Epoch 146: train loss = 276.382450, test loss = 8454.928173\n",
            "Epoch 147: train loss = 272.094718, test loss = 8478.421934\n",
            "Epoch 148: train loss = 267.759732, test loss = 8501.042879\n",
            "Epoch 149: train loss = 263.647232, test loss = 8524.224044\n",
            "Epoch 150: train loss = 259.477137, test loss = 8547.326493\n",
            "Epoch 151: train loss = 255.490375, test loss = 8569.193632\n",
            "Epoch 152: train loss = 251.533207, test loss = 8591.058295\n",
            "Epoch 153: train loss = 247.620463, test loss = 8612.562140\n",
            "Epoch 154: train loss = 243.894358, test loss = 8634.393827\n",
            "Epoch 155: train loss = 240.118539, test loss = 8656.385573\n",
            "Epoch 156: train loss = 236.477259, test loss = 8677.750694\n",
            "Epoch 157: train loss = 232.921210, test loss = 8699.308331\n",
            "Epoch 158: train loss = 229.368547, test loss = 8720.891685\n",
            "Epoch 159: train loss = 225.955742, test loss = 8741.694527\n",
            "Epoch 160: train loss = 222.585898, test loss = 8762.534409\n",
            "Epoch 161: train loss = 219.237929, test loss = 8783.478823\n",
            "Epoch 162: train loss = 216.024811, test loss = 8803.966261\n",
            "Epoch 163: train loss = 212.844858, test loss = 8824.728748\n",
            "Epoch 164: train loss = 209.693527, test loss = 8845.597654\n",
            "Epoch 165: train loss = 206.644369, test loss = 8865.979747\n",
            "Epoch 166: train loss = 203.666540, test loss = 8886.732736\n",
            "Epoch 167: train loss = 200.694605, test loss = 8907.623780\n",
            "Epoch 168: train loss = 197.786104, test loss = 8928.385888\n",
            "Epoch 169: train loss = 195.010963, test loss = 8948.284112\n",
            "Epoch 170: train loss = 192.213115, test loss = 8968.600657\n",
            "Epoch 171: train loss = 189.468411, test loss = 8989.037229\n",
            "Epoch 172: train loss = 186.795724, test loss = 9008.818060\n",
            "Epoch 173: train loss = 184.209014, test loss = 9029.075246\n",
            "Epoch 174: train loss = 181.621645, test loss = 9049.436688\n",
            "Epoch 175: train loss = 179.084714, test loss = 9069.834046\n",
            "Epoch 176: train loss = 176.599076, test loss = 9090.201129\n",
            "Epoch 177: train loss = 174.212386, test loss = 9109.876453\n",
            "Epoch 178: train loss = 171.821266, test loss = 9129.976524\n",
            "Epoch 179: train loss = 169.473640, test loss = 9150.179521\n",
            "Epoch 180: train loss = 167.171446, test loss = 9170.367025\n",
            "Epoch 181: train loss = 164.914726, test loss = 9190.534318\n",
            "Epoch 182: train loss = 162.738831, test loss = 9209.988747\n",
            "Epoch 183: train loss = 160.566379, test loss = 9229.867276\n",
            "Epoch 184: train loss = 158.430973, test loss = 9249.800135\n",
            "Epoch 185: train loss = 156.338636, test loss = 9269.741987\n",
            "Epoch 186: train loss = 154.283470, test loss = 9289.638013\n",
            "Epoch 187: train loss = 152.269472, test loss = 9309.458071\n",
            "Epoch 188: train loss = 150.304788, test loss = 9328.613233\n",
            "Epoch 189: train loss = 148.374349, test loss = 9348.111395\n",
            "Epoch 190: train loss = 146.464838, test loss = 9367.455670\n",
            "Epoch 191: train loss = 144.591412, test loss = 9386.726288\n",
            "Epoch 192: train loss = 142.752028, test loss = 9405.950917\n",
            "Epoch 193: train loss = 140.945786, test loss = 9425.083735\n",
            "Epoch 194: train loss = 139.172933, test loss = 9444.100777\n",
            "Epoch 195: train loss = 137.430547, test loss = 9463.016020\n",
            "Epoch 196: train loss = 135.721222, test loss = 9481.861349\n",
            "Epoch 197: train loss = 134.039614, test loss = 9500.494257\n",
            "Epoch 198: train loss = 132.389869, test loss = 9518.925531\n",
            "Epoch 199: train loss = 130.767113, test loss = 9537.066216\n",
            "Epoch 200: train loss = 129.173413, test loss = 9555.088520\n",
            "Epoch 201: train loss = 127.607740, test loss = 9572.474432\n",
            "Epoch 202: train loss = 126.068152, test loss = 9590.121526\n",
            "Epoch 203: train loss = 124.551814, test loss = 9607.702168\n",
            "Epoch 204: train loss = 123.059895, test loss = 9625.246390\n",
            "Epoch 205: train loss = 121.594703, test loss = 9642.695692\n",
            "Epoch 206: train loss = 120.151878, test loss = 9660.028502\n",
            "Epoch 207: train loss = 118.734374, test loss = 9677.260541\n",
            "Epoch 208: train loss = 117.338735, test loss = 9694.413920\n",
            "Epoch 209: train loss = 115.966397, test loss = 9711.470409\n",
            "Epoch 210: train loss = 114.615930, test loss = 9728.446555\n",
            "Epoch 211: train loss = 113.286339, test loss = 9745.315405\n",
            "Epoch 212: train loss = 111.979150, test loss = 9762.111962\n",
            "Epoch 213: train loss = 110.690480, test loss = 9778.815224\n",
            "Epoch 214: train loss = 109.423879, test loss = 9795.404730\n",
            "Epoch 215: train loss = 108.175073, test loss = 9811.858321\n",
            "Epoch 216: train loss = 106.946193, test loss = 9828.207884\n",
            "Epoch 217: train loss = 105.735764, test loss = 9844.479666\n",
            "Epoch 218: train loss = 104.542884, test loss = 9860.648345\n",
            "Epoch 219: train loss = 103.369138, test loss = 9876.735587\n",
            "Epoch 220: train loss = 102.211094, test loss = 9892.739579\n",
            "Epoch 221: train loss = 101.072173, test loss = 9908.646457\n",
            "Epoch 222: train loss = 99.948304, test loss = 9924.467459\n",
            "Epoch 223: train loss = 98.841353, test loss = 9940.189653\n",
            "Epoch 224: train loss = 97.750256, test loss = 9955.822269\n",
            "Epoch 225: train loss = 96.673707, test loss = 9971.362409\n",
            "Epoch 226: train loss = 95.614208, test loss = 9986.829744\n",
            "Epoch 227: train loss = 94.567202, test loss = 10002.205209\n",
            "Epoch 228: train loss = 93.535969, test loss = 10017.474938\n",
            "Epoch 229: train loss = 92.518690, test loss = 10032.666534\n",
            "Epoch 230: train loss = 91.514450, test loss = 10047.768777\n",
            "Epoch 231: train loss = 90.525242, test loss = 10062.789457\n",
            "Epoch 232: train loss = 89.547579, test loss = 10077.729226\n",
            "Epoch 233: train loss = 88.584028, test loss = 10092.566471\n",
            "Epoch 234: train loss = 87.632590, test loss = 10107.325374\n",
            "Epoch 235: train loss = 86.693415, test loss = 10121.984002\n",
            "Epoch 236: train loss = 85.767378, test loss = 10136.579914\n",
            "Epoch 237: train loss = 84.851751, test loss = 10151.070186\n",
            "Epoch 238: train loss = 83.949280, test loss = 10165.417808\n",
            "Epoch 239: train loss = 83.057122, test loss = 10179.691064\n",
            "Epoch 240: train loss = 82.176272, test loss = 10193.864465\n",
            "Epoch 241: train loss = 81.307389, test loss = 10207.973833\n",
            "Epoch 242: train loss = 80.447720, test loss = 10221.990851\n",
            "Epoch 243: train loss = 79.600163, test loss = 10235.903501\n",
            "Epoch 244: train loss = 78.761922, test loss = 10249.734902\n",
            "Epoch 245: train loss = 77.933785, test loss = 10263.469671\n",
            "Epoch 246: train loss = 77.116536, test loss = 10277.131192\n",
            "Epoch 247: train loss = 76.307784, test loss = 10290.658671\n",
            "Epoch 248: train loss = 75.509874, test loss = 10304.026949\n",
            "Epoch 249: train loss = 74.720500, test loss = 10317.269622\n",
            "Epoch 250: train loss = 73.940473, test loss = 10330.429240\n",
            "Epoch 251: train loss = 73.170289, test loss = 10343.521100\n",
            "Epoch 252: train loss = 72.471132, test loss = 10355.783361\n",
            "Epoch 253: train loss = 71.768420, test loss = 10368.979518\n",
            "Epoch 254: train loss = 71.023924, test loss = 10381.901400\n",
            "Epoch 255: train loss = 70.379608, test loss = 10393.707157\n",
            "Epoch 256: train loss = 69.677273, test loss = 10406.520402\n",
            "Epoch 257: train loss = 68.970104, test loss = 10418.360517\n",
            "Epoch 258: train loss = 68.364321, test loss = 10430.904395\n",
            "Epoch 259: train loss = 67.661430, test loss = 10443.156957\n",
            "Epoch 260: train loss = 67.024280, test loss = 10454.493737\n",
            "Epoch 261: train loss = 66.398834, test loss = 10466.759815\n",
            "Epoch 262: train loss = 65.718299, test loss = 10478.739258\n",
            "Epoch 263: train loss = 65.155344, test loss = 10489.702152\n",
            "Epoch 264: train loss = 64.502088, test loss = 10501.758045\n",
            "Epoch 265: train loss = 63.888161, test loss = 10512.763389\n",
            "Epoch 266: train loss = 63.314530, test loss = 10524.606229\n",
            "Epoch 267: train loss = 62.669442, test loss = 10536.155138\n",
            "Epoch 268: train loss = 62.140941, test loss = 10546.686584\n",
            "Epoch 269: train loss = 61.524388, test loss = 10558.306790\n",
            "Epoch 270: train loss = 60.952620, test loss = 10568.886743\n",
            "Epoch 271: train loss = 60.405378, test loss = 10580.311091\n",
            "Epoch 272: train loss = 59.796273, test loss = 10590.790826\n",
            "Epoch 273: train loss = 59.311219, test loss = 10601.981471\n",
            "Epoch 274: train loss = 58.711456, test loss = 10612.900951\n",
            "Epoch 275: train loss = 58.199332, test loss = 10622.881638\n",
            "Epoch 276: train loss = 57.655408, test loss = 10633.879771\n",
            "Epoch 277: train loss = 57.110389, test loss = 10643.896892\n",
            "Epoch 278: train loss = 56.621343, test loss = 10654.737186\n",
            "Epoch 279: train loss = 56.050552, test loss = 10665.291368\n",
            "Epoch 280: train loss = 55.608046, test loss = 10674.511051\n",
            "Epoch 281: train loss = 55.051253, test loss = 10684.814276\n",
            "Epoch 282: train loss = 54.580939, test loss = 10693.979848\n",
            "Epoch 283: train loss = 54.072320, test loss = 10704.117663\n",
            "Epoch 284: train loss = 53.579068, test loss = 10713.134239\n",
            "Epoch 285: train loss = 53.114399, test loss = 10723.035628\n",
            "Epoch 286: train loss = 52.600253, test loss = 10731.931172\n",
            "Epoch 287: train loss = 52.176835, test loss = 10741.643592\n",
            "Epoch 288: train loss = 51.650931, test loss = 10751.056137\n",
            "Epoch 289: train loss = 51.251063, test loss = 10759.450928\n",
            "Epoch 290: train loss = 50.743428, test loss = 10769.058103\n",
            "Epoch 291: train loss = 50.323609, test loss = 10777.507702\n",
            "Epoch 292: train loss = 49.853468, test loss = 10787.000963\n",
            "Epoch 293: train loss = 49.418136, test loss = 10795.359780\n",
            "Epoch 294: train loss = 48.981098, test loss = 10804.645805\n",
            "Epoch 295: train loss = 48.533522, test loss = 10812.883685\n",
            "Epoch 296: train loss = 48.125494, test loss = 10822.009435\n",
            "Epoch 297: train loss = 47.668459, test loss = 10830.148434\n",
            "Epoch 298: train loss = 47.286967, test loss = 10839.121273\n",
            "Epoch 299: train loss = 46.821979, test loss = 10847.149522\n",
            "Epoch 300: train loss = 46.465368, test loss = 10855.976902\n",
            "Epoch 301: train loss = 45.996964, test loss = 10864.519346\n",
            "Epoch 302: train loss = 45.655719, test loss = 10872.052452\n",
            "Epoch 303: train loss = 45.200340, test loss = 10880.839544\n",
            "Epoch 304: train loss = 44.850305, test loss = 10888.425287\n",
            "Epoch 305: train loss = 44.418502, test loss = 10897.146144\n",
            "Epoch 306: train loss = 44.062612, test loss = 10904.668732\n",
            "Epoch 307: train loss = 43.651153, test loss = 10913.260069\n",
            "Epoch 308: train loss = 43.292281, test loss = 10920.700253\n",
            "Epoch 309: train loss = 42.897730, test loss = 10929.158584\n",
            "Epoch 310: train loss = 42.537980, test loss = 10936.492441\n",
            "Epoch 311: train loss = 42.158443, test loss = 10944.838483\n",
            "Epoch 312: train loss = 41.799277, test loss = 10952.069027\n",
            "Epoch 313: train loss = 41.433493, test loss = 10960.295550\n",
            "Epoch 314: train loss = 41.074961, test loss = 10967.423987\n",
            "Epoch 315: train loss = 40.722129, test loss = 10975.532444\n",
            "Epoch 316: train loss = 40.365612, test loss = 10982.548540\n",
            "Epoch 317: train loss = 40.023564, test loss = 10990.437465\n",
            "Epoch 318: train loss = 39.671069, test loss = 10997.234131\n",
            "Epoch 319: train loss = 39.337483, test loss = 11004.966917\n",
            "Epoch 320: train loss = 38.990315, test loss = 11011.668715\n",
            "Epoch 321: train loss = 38.664271, test loss = 11019.283971\n",
            "Epoch 322: train loss = 38.322830, test loss = 11025.853853\n",
            "Epoch 323: train loss = 38.003652, test loss = 11033.374880\n",
            "Epoch 324: train loss = 37.668165, test loss = 11039.835564\n",
            "Epoch 325: train loss = 37.355093, test loss = 11047.253492\n",
            "Epoch 326: train loss = 37.026944, test loss = 11053.634630\n",
            "Epoch 327: train loss = 36.717666, test loss = 11060.957563\n",
            "Epoch 328: train loss = 36.398393, test loss = 11067.243311\n",
            "Epoch 329: train loss = 36.095364, test loss = 11074.311588\n",
            "Epoch 330: train loss = 35.805991, test loss = 11080.311855\n",
            "Epoch 331: train loss = 35.459148, test loss = 11087.532310\n",
            "Epoch 332: train loss = 35.199813, test loss = 11093.556927\n",
            "Epoch 333: train loss = 34.858768, test loss = 11100.572418\n",
            "Epoch 334: train loss = 34.628453, test loss = 11106.350606\n",
            "Epoch 335: train loss = 34.280387, test loss = 11112.809470\n",
            "Epoch 336: train loss = 34.028635, test loss = 11119.687993\n",
            "Epoch 337: train loss = 33.726437, test loss = 11125.532458\n",
            "Epoch 338: train loss = 33.427662, test loss = 11132.247209\n",
            "Epoch 339: train loss = 33.181849, test loss = 11137.867031\n",
            "Epoch 340: train loss = 32.855783, test loss = 11143.952357\n",
            "Epoch 341: train loss = 32.607954, test loss = 11150.508964\n",
            "Epoch 342: train loss = 32.341513, test loss = 11156.077649\n",
            "Epoch 343: train loss = 32.034069, test loss = 11162.645535\n",
            "Epoch 344: train loss = 31.821673, test loss = 11168.063463\n",
            "Epoch 345: train loss = 31.509485, test loss = 11173.957559\n",
            "Epoch 346: train loss = 31.252470, test loss = 11180.404871\n",
            "Epoch 347: train loss = 31.018758, test loss = 11185.786079\n",
            "Epoch 348: train loss = 30.720907, test loss = 11191.593426\n",
            "Epoch 349: train loss = 30.491209, test loss = 11197.837446\n",
            "Epoch 350: train loss = 30.238487, test loss = 11203.134892\n",
            "Epoch 351: train loss = 29.955981, test loss = 11209.374864\n",
            "Epoch 352: train loss = 29.756164, test loss = 11214.500535\n",
            "Epoch 353: train loss = 29.470362, test loss = 11220.021396\n",
            "Epoch 354: train loss = 29.229597, test loss = 11226.083484\n",
            "Epoch 355: train loss = 29.009961, test loss = 11231.114290\n",
            "Epoch 356: train loss = 28.736671, test loss = 11236.575723\n",
            "Epoch 357: train loss = 28.522045, test loss = 11242.478442\n",
            "Epoch 358: train loss = 28.285962, test loss = 11247.337389\n",
            "Epoch 359: train loss = 28.031833, test loss = 11252.553331\n",
            "Epoch 360: train loss = 27.813870, test loss = 11258.376634\n",
            "Epoch 361: train loss = 27.594525, test loss = 11263.235396\n",
            "Epoch 362: train loss = 27.337376, test loss = 11268.483005\n",
            "Epoch 363: train loss = 27.143816, test loss = 11274.204523\n",
            "Epoch 364: train loss = 26.911301, test loss = 11278.908980\n",
            "Epoch 365: train loss = 26.670198, test loss = 11283.966452\n",
            "Epoch 366: train loss = 26.473280, test loss = 11289.571083\n",
            "Epoch 367: train loss = 26.255151, test loss = 11294.181636\n",
            "Epoch 368: train loss = 26.020777, test loss = 11299.179947\n",
            "Epoch 369: train loss = 25.821737, test loss = 11304.711861\n",
            "Epoch 370: train loss = 25.617120, test loss = 11309.232651\n",
            "Epoch 371: train loss = 25.388452, test loss = 11314.151319\n",
            "Epoch 372: train loss = 25.188448, test loss = 11319.632527\n",
            "Epoch 373: train loss = 24.997159, test loss = 11324.166708\n",
            "Epoch 374: train loss = 24.765564, test loss = 11329.108673\n",
            "Epoch 375: train loss = 24.589235, test loss = 11334.519267\n",
            "Epoch 376: train loss = 24.384243, test loss = 11338.921806\n",
            "Epoch 377: train loss = 24.167246, test loss = 11343.688428\n",
            "Epoch 378: train loss = 23.989732, test loss = 11349.004699\n",
            "Epoch 379: train loss = 23.796340, test loss = 11353.312890\n",
            "Epoch 380: train loss = 23.584957, test loss = 11357.999926\n",
            "Epoch 381: train loss = 23.407115, test loss = 11363.237452\n",
            "Epoch 382: train loss = 23.223727, test loss = 11367.504520\n",
            "Epoch 383: train loss = 23.018343, test loss = 11372.108416\n",
            "Epoch 384: train loss = 22.841116, test loss = 11377.293365\n",
            "Epoch 385: train loss = 22.667469, test loss = 11381.575969\n",
            "Epoch 386: train loss = 22.460427, test loss = 11386.216579\n",
            "Epoch 387: train loss = 22.304669, test loss = 11391.307046\n",
            "Epoch 388: train loss = 22.118542, test loss = 11395.473962\n",
            "Epoch 389: train loss = 21.924188, test loss = 11399.959295\n",
            "Epoch 390: train loss = 21.769320, test loss = 11404.959416\n",
            "Epoch 391: train loss = 21.591605, test loss = 11409.025105\n",
            "Epoch 392: train loss = 21.401903, test loss = 11413.468810\n",
            "Epoch 393: train loss = 21.249047, test loss = 11418.406468\n",
            "Epoch 394: train loss = 21.079313, test loss = 11422.421616\n",
            "Epoch 395: train loss = 20.894306, test loss = 11426.812743\n",
            "Epoch 396: train loss = 20.743147, test loss = 11431.667692\n",
            "Epoch 397: train loss = 20.580219, test loss = 11435.607168\n",
            "Epoch 398: train loss = 20.400538, test loss = 11439.920105\n",
            "Epoch 399: train loss = 20.251509, test loss = 11444.714625\n",
            "Epoch 400: train loss = 20.095067, test loss = 11448.592158\n",
            "Epoch 401: train loss = 19.920235, test loss = 11452.843761\n",
            "Epoch 402: train loss = 19.773847, test loss = 11457.560226\n",
            "Epoch 403: train loss = 19.623388, test loss = 11461.406764\n",
            "Epoch 404: train loss = 19.453071, test loss = 11465.593795\n",
            "Epoch 405: train loss = 19.309693, test loss = 11470.252422\n",
            "Epoch 406: train loss = 19.164201, test loss = 11474.035163\n",
            "Epoch 407: train loss = 18.998712, test loss = 11478.163539\n",
            "Epoch 408: train loss = 18.858650, test loss = 11482.762050\n",
            "Epoch 409: train loss = 18.717622, test loss = 11486.557948\n",
            "Epoch 410: train loss = 18.551582, test loss = 11490.745369\n",
            "Epoch 411: train loss = 18.430194, test loss = 11495.247979\n",
            "Epoch 412: train loss = 18.278583, test loss = 11498.943442\n",
            "Epoch 413: train loss = 18.121955, test loss = 11502.984456\n",
            "Epoch 414: train loss = 18.003802, test loss = 11507.428445\n",
            "Epoch 415: train loss = 17.856633, test loss = 11511.060386\n",
            "Epoch 416: train loss = 17.704280, test loss = 11515.035301\n",
            "Epoch 417: train loss = 17.589471, test loss = 11519.419226\n",
            "Epoch 418: train loss = 17.446333, test loss = 11523.000205\n",
            "Epoch 419: train loss = 17.298156, test loss = 11526.922432\n",
            "Epoch 420: train loss = 17.186926, test loss = 11531.247733\n",
            "Epoch 421: train loss = 17.047468, test loss = 11534.786529\n",
            "Epoch 422: train loss = 16.903262, test loss = 11538.651013\n",
            "Epoch 423: train loss = 16.795839, test loss = 11542.917118\n",
            "Epoch 424: train loss = 16.659715, test loss = 11546.407494\n",
            "Epoch 425: train loss = 16.519360, test loss = 11550.207979\n",
            "Epoch 426: train loss = 16.416024, test loss = 11554.382794\n",
            "Epoch 427: train loss = 16.282777, test loss = 11557.834361\n",
            "Epoch 428: train loss = 16.146384, test loss = 11561.591069\n",
            "Epoch 429: train loss = 16.047052, test loss = 11565.698586\n",
            "Epoch 430: train loss = 15.916194, test loss = 11569.106342\n",
            "Epoch 431: train loss = 15.783750, test loss = 11572.814216\n",
            "Epoch 432: train loss = 15.688628, test loss = 11576.861685\n",
            "Epoch 433: train loss = 15.559920, test loss = 11580.233001\n",
            "Epoch 434: train loss = 15.431355, test loss = 11584.278875\n",
            "Epoch 435: train loss = 15.342294, test loss = 11587.509759\n",
            "Epoch 436: train loss = 15.209520, test loss = 11591.186626\n",
            "Epoch 437: train loss = 15.098329, test loss = 11595.287703\n",
            "Epoch 438: train loss = 14.996999, test loss = 11598.510649\n",
            "Epoch 439: train loss = 14.873246, test loss = 11602.084170\n",
            "Epoch 440: train loss = 14.767056, test loss = 11606.098370\n",
            "Epoch 441: train loss = 14.666801, test loss = 11609.273292\n",
            "Epoch 442: train loss = 14.546493, test loss = 11612.789063\n",
            "Epoch 443: train loss = 14.445335, test loss = 11616.737491\n",
            "Epoch 444: train loss = 14.345974, test loss = 11619.871449\n",
            "Epoch 445: train loss = 14.229029, test loss = 11623.340910\n",
            "Epoch 446: train loss = 14.132883, test loss = 11627.225902\n",
            "Epoch 447: train loss = 14.034283, test loss = 11630.321408\n",
            "Epoch 448: train loss = 13.920618, test loss = 11633.746409\n",
            "Epoch 449: train loss = 13.829481, test loss = 11637.551846\n",
            "Epoch 450: train loss = 13.731193, test loss = 11640.637577\n",
            "Epoch 451: train loss = 13.621031, test loss = 11644.014416\n",
            "Epoch 452: train loss = 13.534907, test loss = 11647.755331\n",
            "Epoch 453: train loss = 13.437010, test loss = 11650.787985\n",
            "Epoch 454: train loss = 13.330023, test loss = 11654.147200\n",
            "Epoch 455: train loss = 13.248863, test loss = 11657.822136\n",
            "Epoch 456: train loss = 13.151345, test loss = 11660.818524\n",
            "Epoch 457: train loss = 13.047321, test loss = 11664.139573\n",
            "Epoch 458: train loss = 12.971136, test loss = 11667.753028\n",
            "Epoch 459: train loss = 12.873971, test loss = 11670.727542\n",
            "Epoch 460: train loss = 12.772923, test loss = 11673.983217\n",
            "Epoch 461: train loss = 12.701544, test loss = 11677.539712\n",
            "Epoch 462: train loss = 12.604411, test loss = 11680.484500\n",
            "Epoch 463: train loss = 12.507789, test loss = 11684.042691\n",
            "Epoch 464: train loss = 12.439313, test loss = 11686.872011\n",
            "Epoch 465: train loss = 12.339672, test loss = 11690.086936\n",
            "Epoch 466: train loss = 12.256663, test loss = 11693.690791\n",
            "Epoch 467: train loss = 12.179317, test loss = 11696.511096\n",
            "Epoch 468: train loss = 12.085613, test loss = 11699.648115\n",
            "Epoch 469: train loss = 12.007980, test loss = 11703.155778\n",
            "Epoch 470: train loss = 11.930005, test loss = 11705.956588\n",
            "Epoch 471: train loss = 11.839130, test loss = 11709.051047\n",
            "Epoch 472: train loss = 11.766621, test loss = 11712.490991\n",
            "Epoch 473: train loss = 11.687853, test loss = 11715.264133\n",
            "Epoch 474: train loss = 11.599727, test loss = 11718.314098\n",
            "Epoch 475: train loss = 11.532339, test loss = 11721.690961\n",
            "Epoch 476: train loss = 11.452834, test loss = 11724.440619\n",
            "Epoch 477: train loss = 11.367102, test loss = 11727.448526\n",
            "Epoch 478: train loss = 11.304938, test loss = 11730.762739\n",
            "Epoch 479: train loss = 11.224724, test loss = 11733.484456\n",
            "Epoch 480: train loss = 11.141510, test loss = 11736.455704\n",
            "Epoch 481: train loss = 11.084237, test loss = 11739.708318\n",
            "Epoch 482: train loss = 11.003326, test loss = 11742.403334\n",
            "Epoch 483: train loss = 10.925112, test loss = 11745.643264\n",
            "Epoch 484: train loss = 10.867959, test loss = 11748.187914\n",
            "Epoch 485: train loss = 10.788064, test loss = 11751.077148\n",
            "Epoch 486: train loss = 10.716146, test loss = 11754.371218\n",
            "Epoch 487: train loss = 10.656947, test loss = 11756.927509\n",
            "Epoch 488: train loss = 10.579515, test loss = 11759.793894\n",
            "Epoch 489: train loss = 10.512908, test loss = 11763.026679\n",
            "Epoch 490: train loss = 10.452313, test loss = 11765.557380\n",
            "Epoch 491: train loss = 10.377189, test loss = 11768.386927\n",
            "Epoch 492: train loss = 10.315656, test loss = 11771.554608\n",
            "Epoch 493: train loss = 10.253782, test loss = 11774.059056\n",
            "Epoch 494: train loss = 10.180892, test loss = 11776.852783\n",
            "Epoch 495: train loss = 10.124250, test loss = 11779.957064\n",
            "Epoch 496: train loss = 10.061175, test loss = 11782.436761\n",
            "Epoch 497: train loss = 9.990455, test loss = 11785.196127\n",
            "Epoch 498: train loss = 9.938535, test loss = 11788.241831\n",
            "Epoch 499: train loss = 9.874325, test loss = 11790.693472\n",
            "Epoch 500: train loss = 9.805714, test loss = 11793.420199\n",
            "Epoch 501: train loss = 9.758358, test loss = 11796.405420\n",
            "Epoch 502: train loss = 9.693066, test loss = 11798.834621\n",
            "Epoch 503: train loss = 9.628568, test loss = 11801.807309\n",
            "Epoch 504: train loss = 9.581930, test loss = 11804.126444\n",
            "Epoch 505: train loss = 9.516857, test loss = 11806.770637\n",
            "Epoch 506: train loss = 9.458035, test loss = 11809.765820\n",
            "Epoch 507: train loss = 9.409285, test loss = 11812.099497\n",
            "Epoch 508: train loss = 9.346203, test loss = 11814.724145\n",
            "Epoch 509: train loss = 9.292406, test loss = 11817.659029\n",
            "Epoch 510: train loss = 9.241950, test loss = 11819.971328\n",
            "Epoch 511: train loss = 9.180730, test loss = 11822.562921\n",
            "Epoch 512: train loss = 9.131708, test loss = 11825.433966\n",
            "Epoch 513: train loss = 9.079693, test loss = 11827.724112\n",
            "Epoch 514: train loss = 9.020273, test loss = 11830.283490\n",
            "Epoch 515: train loss = 8.975826, test loss = 11833.093363\n",
            "Epoch 516: train loss = 8.922358, test loss = 11835.377005\n",
            "Epoch 517: train loss = 8.864688, test loss = 11837.920626\n",
            "Epoch 518: train loss = 8.824629, test loss = 11840.712956\n",
            "Epoch 519: train loss = 8.769804, test loss = 11842.976586\n",
            "Epoch 520: train loss = 8.715290, test loss = 11845.777723\n",
            "Epoch 521: train loss = 8.676877, test loss = 11847.923022\n",
            "Epoch 522: train loss = 8.621577, test loss = 11850.374655\n",
            "Epoch 523: train loss = 8.572186, test loss = 11853.198407\n",
            "Epoch 524: train loss = 8.531639, test loss = 11855.360387\n",
            "Epoch 525: train loss = 8.478114, test loss = 11857.794628\n",
            "Epoch 526: train loss = 8.433232, test loss = 11860.546408\n",
            "Epoch 527: train loss = 8.390792, test loss = 11862.711089\n",
            "Epoch 528: train loss = 8.339070, test loss = 11865.110107\n",
            "Epoch 529: train loss = 8.298466, test loss = 11867.798089\n",
            "Epoch 530: train loss = 8.254394, test loss = 11869.942454\n",
            "Epoch 531: train loss = 8.204295, test loss = 11872.310852\n",
            "Epoch 532: train loss = 8.167777, test loss = 11874.937995\n",
            "Epoch 533: train loss = 8.122200, test loss = 11877.050595\n",
            "Epoch 534: train loss = 8.073656, test loss = 11879.409622\n",
            "Epoch 535: train loss = 8.041052, test loss = 11881.977035\n",
            "Epoch 536: train loss = 7.994168, test loss = 11884.080916\n",
            "Epoch 537: train loss = 7.949584, test loss = 11886.646596\n",
            "Epoch 538: train loss = 7.915950, test loss = 11888.633856\n",
            "Epoch 539: train loss = 7.869707, test loss = 11890.908797\n",
            "Epoch 540: train loss = 7.829748, test loss = 11893.492871\n",
            "Epoch 541: train loss = 7.794065, test loss = 11895.497100\n",
            "Epoch 542: train loss = 7.749290, test loss = 11897.756157\n",
            "Epoch 543: train loss = 7.713411, test loss = 11900.283102\n",
            "Epoch 544: train loss = 7.676033, test loss = 11902.271014\n",
            "Epoch 545: train loss = 7.632625, test loss = 11904.501626\n",
            "Epoch 546: train loss = 7.600603, test loss = 11906.967094\n",
            "Epoch 547: train loss = 7.561667, test loss = 11908.938460\n",
            "Epoch 548: train loss = 7.519608, test loss = 11911.141403\n",
            "Epoch 549: train loss = 7.491225, test loss = 11913.548701\n",
            "Epoch 550: train loss = 7.450861, test loss = 11915.504062\n",
            "Epoch 551: train loss = 7.411996, test loss = 11917.912711\n",
            "Epoch 552: train loss = 7.383562, test loss = 11919.751381\n",
            "Epoch 553: train loss = 7.343268, test loss = 11921.859590\n",
            "Epoch 554: train loss = 7.308613, test loss = 11924.280142\n",
            "Epoch 555: train loss = 7.278172, test loss = 11926.135726\n",
            "Epoch 556: train loss = 7.239207, test loss = 11928.228898\n",
            "Epoch 557: train loss = 7.208260, test loss = 11930.593592\n",
            "Epoch 558: train loss = 7.176148, test loss = 11932.434750\n",
            "Epoch 559: train loss = 7.138420, test loss = 11934.501185\n",
            "Epoch 560: train loss = 7.110965, test loss = 11936.806645\n",
            "Epoch 561: train loss = 7.077332, test loss = 11938.630376\n",
            "Epoch 562: train loss = 7.040796, test loss = 11940.668647\n",
            "Epoch 563: train loss = 7.016653, test loss = 11942.916090\n",
            "Epoch 564: train loss = 6.981619, test loss = 11944.725551\n",
            "Epoch 565: train loss = 6.948279, test loss = 11946.971647\n",
            "Epoch 566: train loss = 6.923385, test loss = 11948.684640\n",
            "Epoch 567: train loss = 6.888649, test loss = 11950.652300\n",
            "Epoch 568: train loss = 6.859185, test loss = 11952.911683\n",
            "Epoch 569: train loss = 6.832393, test loss = 11954.641497\n",
            "Epoch 570: train loss = 6.798847, test loss = 11956.606135\n",
            "Epoch 571: train loss = 6.772761, test loss = 11958.793692\n",
            "Epoch 572: train loss = 6.744332, test loss = 11960.514239\n",
            "Epoch 573: train loss = 6.711903, test loss = 11962.454919\n",
            "Epoch 574: train loss = 6.688895, test loss = 11964.587669\n",
            "Epoch 575: train loss = 6.659066, test loss = 11966.294809\n",
            "Epoch 576: train loss = 6.628158, test loss = 11968.434541\n",
            "Epoch 577: train loss = 6.607376, test loss = 11970.051399\n",
            "Epoch 578: train loss = 6.576340, test loss = 11971.922646\n",
            "Epoch 579: train loss = 6.548874, test loss = 11974.059454\n",
            "Epoch 580: train loss = 6.526340, test loss = 11975.704942\n",
            "Epoch 581: train loss = 6.496454, test loss = 11977.545980\n",
            "Epoch 582: train loss = 6.471993, test loss = 11979.634353\n",
            "Epoch 583: train loss = 6.447973, test loss = 11981.269029\n",
            "Epoch 584: train loss = 6.419021, test loss = 11983.087215\n",
            "Epoch 585: train loss = 6.397475, test loss = 11985.121414\n",
            "Epoch 586: train loss = 6.372108, test loss = 11986.742856\n",
            "Epoch 587: train loss = 6.344055, test loss = 11988.538106\n",
            "Epoch 588: train loss = 6.325265, test loss = 11990.530145\n",
            "Epoch 589: train loss = 6.298593, test loss = 11992.122902\n",
            "Epoch 590: train loss = 6.272991, test loss = 11994.095203\n",
            "Epoch 591: train loss = 6.253995, test loss = 11995.624525\n",
            "Epoch 592: train loss = 6.227291, test loss = 11997.359278\n",
            "Epoch 593: train loss = 6.204794, test loss = 11999.341267\n",
            "Epoch 594: train loss = 6.184231, test loss = 12000.885225\n",
            "Epoch 595: train loss = 6.158391, test loss = 12002.607493\n",
            "Epoch 596: train loss = 6.138627, test loss = 12004.539531\n",
            "Epoch 597: train loss = 6.116746, test loss = 12006.071868\n",
            "Epoch 598: train loss = 6.091709, test loss = 12007.771935\n",
            "Epoch 599: train loss = 6.074531, test loss = 12009.661828\n",
            "Epoch 600: train loss = 6.051408, test loss = 12011.166779\n",
            "Epoch 601: train loss = 6.027972, test loss = 12013.051719\n",
            "Epoch 602: train loss = 6.011797, test loss = 12014.473177\n",
            "Epoch 603: train loss = 5.988004, test loss = 12016.118384\n",
            "Epoch 604: train loss = 5.967466, test loss = 12018.012871\n",
            "Epoch 605: train loss = 5.949730, test loss = 12019.450299\n",
            "Epoch 606: train loss = 5.926754, test loss = 12021.083642\n",
            "Epoch 607: train loss = 5.908761, test loss = 12022.929061\n",
            "Epoch 608: train loss = 5.889706, test loss = 12024.356532\n",
            "Epoch 609: train loss = 5.867492, test loss = 12025.977919\n",
            "Epoch 610: train loss = 5.851871, test loss = 12027.757800\n",
            "Epoch 611: train loss = 5.831622, test loss = 12029.177246\n",
            "Epoch 612: train loss = 5.810568, test loss = 12030.964367\n",
            "Epoch 613: train loss = 5.796481, test loss = 12032.309199\n",
            "Epoch 614: train loss = 5.775304, test loss = 12033.869384\n",
            "Epoch 615: train loss = 5.756901, test loss = 12035.649300\n",
            "Epoch 616: train loss = 5.741334, test loss = 12037.011952\n",
            "Epoch 617: train loss = 5.720911, test loss = 12038.561509\n",
            "Epoch 618: train loss = 5.704779, test loss = 12040.295275\n",
            "Epoch 619: train loss = 5.688013, test loss = 12041.648715\n",
            "Epoch 620: train loss = 5.668289, test loss = 12043.177493\n",
            "Epoch 621: train loss = 5.654281, test loss = 12044.862928\n",
            "Epoch 622: train loss = 5.636438, test loss = 12046.215166\n",
            "Epoch 623: train loss = 5.617578, test loss = 12047.888846\n",
            "Epoch 624: train loss = 5.605230, test loss = 12049.168240\n",
            "Epoch 625: train loss = 5.586475, test loss = 12050.632012\n",
            "Epoch 626: train loss = 5.569925, test loss = 12052.316263\n",
            "Epoch 627: train loss = 5.556280, test loss = 12053.611084\n",
            "Epoch 628: train loss = 5.538153, test loss = 12055.064835\n",
            "Epoch 629: train loss = 5.523698, test loss = 12056.704201\n",
            "Epoch 630: train loss = 5.508957, test loss = 12057.989896\n",
            "Epoch 631: train loss = 5.491412, test loss = 12059.424476\n",
            "Epoch 632: train loss = 5.478915, test loss = 12061.017179\n",
            "Epoch 633: train loss = 5.463180, test loss = 12062.292992\n",
            "Epoch 634: train loss = 5.446418, test loss = 12063.876453\n",
            "Epoch 635: train loss = 5.435441, test loss = 12065.082706\n",
            "Epoch 636: train loss = 5.418742, test loss = 12066.465894\n",
            "Epoch 637: train loss = 5.404155, test loss = 12068.056910\n",
            "Epoch 638: train loss = 5.391998, test loss = 12069.277511\n",
            "Epoch 639: train loss = 5.375859, test loss = 12070.650798\n",
            "Epoch 640: train loss = 5.363186, test loss = 12072.206512\n",
            "Epoch 641: train loss = 5.350030, test loss = 12073.405455\n",
            "Epoch 642: train loss = 5.334384, test loss = 12074.763190\n",
            "Epoch 643: train loss = 5.323501, test loss = 12076.274914\n",
            "Epoch 644: train loss = 5.309393, test loss = 12077.465896\n",
            "Epoch 645: train loss = 5.294584, test loss = 12078.962581\n",
            "Epoch 646: train loss = 5.284853, test loss = 12080.102399\n",
            "Epoch 647: train loss = 5.269987, test loss = 12081.406737\n",
            "Epoch 648: train loss = 5.257138, test loss = 12082.916507\n",
            "Epoch 649: train loss = 5.246267, test loss = 12084.056851\n",
            "Epoch 650: train loss = 5.231946, test loss = 12085.353618\n",
            "Epoch 651: train loss = 5.220829, test loss = 12086.822266\n",
            "Epoch 652: train loss = 5.209001, test loss = 12087.955644\n",
            "Epoch 653: train loss = 5.195160, test loss = 12089.235172\n",
            "Epoch 654: train loss = 5.185660, test loss = 12090.660516\n",
            "Epoch 655: train loss = 5.172962, test loss = 12091.785917\n",
            "Epoch 656: train loss = 5.160054, test loss = 12093.201061\n",
            "Epoch 657: train loss = 5.151225, test loss = 12094.266462\n",
            "Epoch 658: train loss = 5.138019, test loss = 12095.500843\n",
            "Epoch 659: train loss = 5.126882, test loss = 12096.920796\n",
            "Epoch 660: train loss = 5.117033, test loss = 12097.999218\n",
            "Epoch 661: train loss = 5.104301, test loss = 12099.231611\n",
            "Epoch 662: train loss = 5.094731, test loss = 12100.599373\n",
            "Epoch 663: train loss = 5.083993, test loss = 12101.673188\n",
            "Epoch 664: train loss = 5.071704, test loss = 12102.889701\n",
            "Epoch 665: train loss = 5.063554, test loss = 12104.217118\n",
            "Epoch 666: train loss = 5.052045, test loss = 12105.283528\n",
            "Epoch 667: train loss = 5.040833, test loss = 12106.616478\n",
            "Epoch 668: train loss = 5.032799, test loss = 12107.621049\n",
            "Epoch 669: train loss = 5.021074, test loss = 12108.794673\n",
            "Epoch 670: train loss = 5.011433, test loss = 12110.120371\n",
            "Epoch 671: train loss = 5.002473, test loss = 12111.137915\n",
            "Epoch 672: train loss = 4.991195, test loss = 12112.302735\n",
            "Epoch 673: train loss = 4.982919, test loss = 12113.590620\n",
            "Epoch 674: train loss = 4.973200, test loss = 12114.608526\n",
            "Epoch 675: train loss = 4.962327, test loss = 12115.746028\n",
            "Epoch 676: train loss = 4.955308, test loss = 12116.997088\n",
            "Epoch 677: train loss = 4.944900, test loss = 12118.008616\n",
            "Epoch 678: train loss = 4.935224, test loss = 12119.252102\n",
            "Epoch 679: train loss = 4.927801, test loss = 12120.205089\n",
            "Epoch 680: train loss = 4.917471, test loss = 12121.309762\n",
            "Epoch 681: train loss = 4.909183, test loss = 12122.555606\n",
            "Epoch 682: train loss = 4.900949, test loss = 12123.519351\n",
            "Epoch 683: train loss = 4.890997, test loss = 12124.614777\n",
            "Epoch 684: train loss = 4.883932, test loss = 12125.824176\n",
            "Epoch 685: train loss = 4.875018, test loss = 12126.788044\n",
            "Epoch 686: train loss = 4.865516, test loss = 12127.986009\n",
            "Epoch 687: train loss = 4.859404, test loss = 12128.890484\n",
            "Epoch 688: train loss = 4.849886, test loss = 12129.946772\n",
            "Epoch 689: train loss = 4.841705, test loss = 12131.150035\n",
            "Epoch 690: train loss = 4.834803, test loss = 12132.065366\n",
            "Epoch 691: train loss = 4.825634, test loss = 12133.112717\n",
            "Epoch 692: train loss = 4.818613, test loss = 12134.280226\n",
            "Epoch 693: train loss = 4.811041, test loss = 12135.195845\n",
            "Epoch 694: train loss = 4.802189, test loss = 12136.218398\n",
            "Epoch 695: train loss = 4.796254, test loss = 12137.351172\n",
            "Epoch 696: train loss = 4.788079, test loss = 12138.260920\n",
            "Epoch 697: train loss = 4.779960, test loss = 12139.384287\n",
            "Epoch 698: train loss = 4.774229, test loss = 12140.243608\n",
            "Epoch 699: train loss = 4.765839, test loss = 12141.230053\n",
            "Epoch 700: train loss = 4.758880, test loss = 12142.357594\n",
            "Epoch 701: train loss = 4.752455, test loss = 12143.227916\n",
            "Epoch 702: train loss = 4.744354, test loss = 12144.206957\n",
            "Epoch 703: train loss = 4.738437, test loss = 12145.300826\n",
            "Epoch 704: train loss = 4.731423, test loss = 12146.165389\n",
            "Epoch 705: train loss = 4.723588, test loss = 12147.130931\n",
            "Epoch 706: train loss = 4.718642, test loss = 12148.190220\n",
            "Epoch 707: train loss = 4.711094, test loss = 12149.048560\n",
            "Epoch 708: train loss = 4.704215, test loss = 12150.102309\n",
            "Epoch 709: train loss = 4.698837, test loss = 12150.913222\n",
            "Epoch 710: train loss = 4.691378, test loss = 12151.843454\n",
            "Epoch 711: train loss = 4.685542, test loss = 12152.905156\n",
            "Epoch 712: train loss = 4.679582, test loss = 12153.716316\n",
            "Epoch 713: train loss = 4.672357, test loss = 12154.641186\n",
            "Epoch 714: train loss = 4.667457, test loss = 12155.671413\n",
            "Epoch 715: train loss = 4.660953, test loss = 12156.478008\n",
            "Epoch 716: train loss = 4.654232, test loss = 12157.496155\n",
            "Epoch 717: train loss = 4.649741, test loss = 12158.267346\n",
            "Epoch 718: train loss = 4.642899, test loss = 12159.154006\n",
            "Epoch 719: train loss = 4.637173, test loss = 12160.173519\n",
            "Epoch 720: train loss = 4.632090, test loss = 12160.953881\n",
            "Epoch 721: train loss = 4.625484, test loss = 12161.833220\n",
            "Epoch 722: train loss = 4.620631, test loss = 12162.826742\n",
            "Epoch 723: train loss = 4.615026, test loss = 12163.593197\n",
            "Epoch 724: train loss = 4.608654, test loss = 12164.461702\n",
            "Epoch 725: train loss = 4.604621, test loss = 12165.423643\n",
            "Epoch 726: train loss = 4.598544, test loss = 12166.185273\n",
            "Epoch 727: train loss = 4.592924, test loss = 12167.134534\n",
            "Epoch 728: train loss = 4.588631, test loss = 12167.863547\n",
            "Epoch 729: train loss = 4.582570, test loss = 12168.699028\n",
            "Epoch 730: train loss = 4.577826, test loss = 12169.648938\n",
            "Epoch 731: train loss = 4.573011, test loss = 12170.386432\n",
            "Epoch 732: train loss = 4.567161, test loss = 12171.214999\n",
            "Epoch 733: train loss = 4.563187, test loss = 12172.140457\n",
            "Epoch 734: train loss = 4.557925, test loss = 12172.864845\n",
            "Epoch 735: train loss = 4.552477, test loss = 12173.779363\n",
            "Epoch 736: train loss = 4.548856, test loss = 12174.469743\n",
            "Epoch 737: train loss = 4.543299, test loss = 12175.262057\n",
            "Epoch 738: train loss = 4.538681, test loss = 12176.188222\n",
            "Epoch 739: train loss = 4.534569, test loss = 12176.875613\n",
            "Epoch 740: train loss = 4.529191, test loss = 12177.657150\n",
            "Epoch 741: train loss = 4.525306, test loss = 12178.562056\n",
            "Epoch 742: train loss = 4.520752, test loss = 12179.238845\n",
            "Epoch 743: train loss = 4.515559, test loss = 12180.009168\n",
            "Epoch 744: train loss = 4.512356, test loss = 12180.884176\n",
            "Epoch 745: train loss = 4.507400, test loss = 12181.556584\n",
            "Epoch 746: train loss = 4.502860, test loss = 12182.423454\n",
            "Epoch 747: train loss = 4.499382, test loss = 12183.063305\n",
            "Epoch 748: train loss = 4.494461, test loss = 12183.803138\n",
            "Epoch 749: train loss = 4.490649, test loss = 12184.674856\n",
            "Epoch 750: train loss = 4.486717, test loss = 12185.315297\n",
            "Epoch 751: train loss = 4.481980, test loss = 12186.050456\n",
            "Epoch 752: train loss = 4.478813, test loss = 12186.895154\n",
            "Epoch 753: train loss = 4.474496, test loss = 12187.532176\n",
            "Epoch 754: train loss = 4.470146, test loss = 12188.365918\n",
            "Epoch 755: train loss = 4.467163, test loss = 12188.974924\n",
            "Epoch 756: train loss = 4.462653, test loss = 12189.678478\n",
            "Epoch 757: train loss = 4.458983, test loss = 12190.512541\n",
            "Epoch 758: train loss = 4.455582, test loss = 12191.127757\n",
            "Epoch 759: train loss = 4.451231, test loss = 12191.821713\n",
            "Epoch 760: train loss = 4.448160, test loss = 12192.629874\n",
            "Epoch 761: train loss = 4.444399, test loss = 12193.232013\n",
            "Epoch 762: train loss = 4.440223, test loss = 12194.027119\n",
            "Epoch 763: train loss = 4.437690, test loss = 12194.600954\n",
            "Epoch 764: train loss = 4.433558, test loss = 12195.269101\n",
            "Epoch 765: train loss = 4.430024, test loss = 12196.069601\n",
            "Epoch 766: train loss = 4.427101, test loss = 12196.644361\n",
            "Epoch 767: train loss = 4.423102, test loss = 12197.308649\n",
            "Epoch 768: train loss = 4.420136, test loss = 12198.083847\n",
            "Epoch 769: train loss = 4.416861, test loss = 12198.655666\n",
            "Epoch 770: train loss = 4.413000, test loss = 12199.310479\n",
            "Epoch 771: train loss = 4.410562, test loss = 12200.059336\n",
            "Epoch 772: train loss = 4.406967, test loss = 12200.627646\n",
            "Epoch 773: train loss = 4.403522, test loss = 12201.368926\n",
            "Epoch 774: train loss = 4.401038, test loss = 12201.908760\n",
            "Epoch 775: train loss = 4.397378, test loss = 12202.537131\n",
            "Epoch 776: train loss = 4.394493, test loss = 12203.282810\n",
            "Epoch 777: train loss = 4.391655, test loss = 12203.823532\n",
            "Epoch 778: train loss = 4.388129, test loss = 12204.448058\n",
            "Epoch 779: train loss = 4.385742, test loss = 12205.169933\n",
            "Epoch 780: train loss = 4.382600, test loss = 12205.707961\n",
            "Epoch 781: train loss = 4.379319, test loss = 12206.419916\n",
            "Epoch 782: train loss = 4.377171, test loss = 12206.933667\n",
            "Epoch 783: train loss = 4.373824, test loss = 12207.530691\n",
            "Epoch 784: train loss = 4.371066, test loss = 12208.242982\n",
            "Epoch 785: train loss = 4.368590, test loss = 12208.762706\n",
            "Epoch 786: train loss = 4.365369, test loss = 12209.356441\n",
            "Epoch 787: train loss = 4.363063, test loss = 12210.045121\n",
            "Epoch 788: train loss = 4.360306, test loss = 12210.561710\n",
            "Epoch 789: train loss = 4.357191, test loss = 12211.146826\n",
            "Epoch 790: train loss = 4.355314, test loss = 12211.815575\n",
            "Epoch 791: train loss = 4.352295, test loss = 12212.323167\n",
            "Epoch 792: train loss = 4.349622, test loss = 12212.983963\n",
            "Epoch 793: train loss = 4.347501, test loss = 12213.468995\n",
            "Epoch 794: train loss = 4.344533, test loss = 12214.030422\n",
            "Epoch 795: train loss = 4.342322, test loss = 12214.694738\n",
            "Epoch 796: train loss = 4.339916, test loss = 12215.180241\n",
            "Epoch 797: train loss = 4.337045, test loss = 12215.738338\n",
            "Epoch 798: train loss = 4.335243, test loss = 12216.381027\n",
            "Epoch 799: train loss = 4.332583, test loss = 12216.864196\n",
            "Epoch 800: train loss = 4.330023, test loss = 12217.497381\n",
            "Epoch 801: train loss = 4.328193, test loss = 12217.953879\n",
            "Epoch 802: train loss = 4.325477, test loss = 12218.495450\n",
            "Epoch 803: train loss = 4.323347, test loss = 12219.127344\n",
            "Epoch 804: train loss = 4.321245, test loss = 12219.593723\n",
            "Epoch 805: train loss = 4.318623, test loss = 12220.124623\n",
            "Epoch 806: train loss = 4.316874, test loss = 12220.736007\n",
            "Epoch 807: train loss = 4.314535, test loss = 12221.200059\n",
            "Epoch 808: train loss = 4.312109, test loss = 12221.806800\n",
            "Epoch 809: train loss = 4.310522, test loss = 12222.240750\n",
            "Epoch 810: train loss = 4.308038, test loss = 12222.750381\n",
            "Epoch 811: train loss = 4.306006, test loss = 12223.358421\n",
            "Epoch 812: train loss = 4.304163, test loss = 12223.799559\n",
            "Epoch 813: train loss = 4.301764, test loss = 12224.305210\n",
            "Epoch 814: train loss = 4.300085, test loss = 12224.892634\n",
            "Epoch 815: train loss = 4.298023, test loss = 12225.331237\n",
            "Epoch 816: train loss = 4.295729, test loss = 12225.912443\n",
            "Epoch 817: train loss = 4.294347, test loss = 12226.321263\n",
            "Epoch 818: train loss = 4.292073, test loss = 12226.810204\n",
            "Epoch 819: train loss = 4.290148, test loss = 12227.391845\n",
            "Epoch 820: train loss = 4.288522, test loss = 12227.807428\n",
            "Epoch 821: train loss = 4.286334, test loss = 12228.292180\n",
            "Epoch 822: train loss = 4.284734, test loss = 12228.853901\n",
            "Epoch 823: train loss = 4.282901, test loss = 12229.269381\n",
            "Epoch 824: train loss = 4.280786, test loss = 12229.743033\n",
            "Epoch 825: train loss = 4.279491, test loss = 12230.285398\n",
            "Epoch 826: train loss = 4.277470, test loss = 12230.698777\n",
            "Epoch 827: train loss = 4.275629, test loss = 12231.236811\n",
            "Epoch 828: train loss = 4.274228, test loss = 12231.622600\n",
            "Epoch 829: train loss = 4.272207, test loss = 12232.081627\n",
            "Epoch 830: train loss = 4.270687, test loss = 12232.619523\n",
            "Epoch 831: train loss = 4.269074, test loss = 12233.011449\n",
            "Epoch 832: train loss = 4.267129, test loss = 12233.466527\n",
            "Epoch 833: train loss = 4.265893, test loss = 12233.985814\n",
            "Epoch 834: train loss = 4.264098, test loss = 12234.375703\n",
            "Epoch 835: train loss = 4.262354, test loss = 12234.894632\n",
            "Epoch 836: train loss = 4.261137, test loss = 12235.259150\n",
            "Epoch 837: train loss = 4.259276, test loss = 12235.696820\n",
            "Epoch 838: train loss = 4.257831, test loss = 12236.210687\n",
            "Epoch 839: train loss = 4.256417, test loss = 12236.582106\n",
            "Epoch 840: train loss = 4.254625, test loss = 12237.016005\n",
            "Epoch 841: train loss = 4.253454, test loss = 12237.512261\n",
            "Epoch 842: train loss = 4.251860, test loss = 12237.881889\n",
            "Epoch 843: train loss = 4.250206, test loss = 12238.379353\n",
            "Epoch 844: train loss = 4.249151, test loss = 12238.723350\n",
            "Epoch 845: train loss = 4.247443, test loss = 12239.136711\n",
            "Epoch 846: train loss = 4.246076, test loss = 12239.634053\n",
            "Epoch 847: train loss = 4.244829, test loss = 12239.984045\n",
            "Epoch 848: train loss = 4.243183, test loss = 12240.396916\n",
            "Epoch 849: train loss = 4.242064, test loss = 12240.872347\n",
            "Epoch 850: train loss = 4.240656, test loss = 12241.221119\n",
            "Epoch 851: train loss = 4.239094, test loss = 12241.697267\n",
            "Epoch 852: train loss = 4.238170, test loss = 12242.022992\n",
            "Epoch 853: train loss = 4.236611, test loss = 12242.414841\n",
            "Epoch 854: train loss = 4.235315, test loss = 12242.891158\n",
            "Epoch 855: train loss = 4.234213, test loss = 12243.222897\n",
            "Epoch 856: train loss = 4.232709, test loss = 12243.611560\n",
            "Epoch 857: train loss = 4.231648, test loss = 12244.070560\n",
            "Epoch 858: train loss = 4.230396, test loss = 12244.400271\n",
            "Epoch 859: train loss = 4.228938, test loss = 12244.783999\n",
            "Epoch 860: train loss = 4.228097, test loss = 12245.225748\n",
            "Epoch 861: train loss = 4.226703, test loss = 12245.553646\n",
            "Epoch 862: train loss = 4.225460, test loss = 12245.990258\n",
            "Epoch 863: train loss = 4.224505, test loss = 12246.301778\n",
            "Epoch 864: train loss = 4.223121, test loss = 12246.668213\n",
            "Epoch 865: train loss = 4.222110, test loss = 12247.107192\n",
            "Epoch 866: train loss = 4.220999, test loss = 12247.419661\n",
            "Epoch 867: train loss = 4.219666, test loss = 12247.783864\n",
            "Epoch 868: train loss = 4.218860, test loss = 12248.207370\n",
            "Epoch 869: train loss = 4.217616, test loss = 12248.518538\n",
            "Epoch 870: train loss = 4.216449, test loss = 12248.935303\n",
            "Epoch 871: train loss = 4.215603, test loss = 12249.230454\n",
            "Epoch 872: train loss = 4.214339, test loss = 12249.579354\n",
            "Epoch 873: train loss = 4.213383, test loss = 12249.995879\n",
            "Epoch 874: train loss = 4.212395, test loss = 12250.296125\n",
            "Epoch 875: train loss = 4.211173, test loss = 12250.642108\n",
            "Epoch 876: train loss = 4.210407, test loss = 12251.043363\n",
            "Epoch 877: train loss = 4.209296, test loss = 12251.342034\n",
            "Epoch 878: train loss = 4.208199, test loss = 12251.739917\n",
            "Epoch 879: train loss = 4.207451, test loss = 12252.015678\n",
            "Epoch 880: train loss = 4.206291, test loss = 12252.350742\n",
            "Epoch 881: train loss = 4.205393, test loss = 12252.748511\n",
            "Epoch 882: train loss = 4.204509, test loss = 12253.031896\n",
            "Epoch 883: train loss = 4.203388, test loss = 12253.360134\n",
            "Epoch 884: train loss = 4.202669, test loss = 12253.743890\n",
            "Epoch 885: train loss = 4.201669, test loss = 12254.025883\n",
            "Epoch 886: train loss = 4.200645, test loss = 12254.405685\n",
            "Epoch 887: train loss = 4.199984, test loss = 12254.666283\n",
            "Epoch 888: train loss = 4.198915, test loss = 12254.984615\n",
            "Epoch 889: train loss = 4.198076, test loss = 12255.364388\n",
            "Epoch 890: train loss = 4.197287, test loss = 12255.629992\n",
            "Epoch 891: train loss = 4.196258, test loss = 12255.945557\n",
            "Epoch 892: train loss = 4.195582, test loss = 12256.311159\n",
            "Epoch 893: train loss = 4.194682, test loss = 12256.575518\n",
            "Epoch 894: train loss = 4.193724, test loss = 12256.941315\n",
            "Epoch 895: train loss = 4.193142, test loss = 12257.187093\n",
            "Epoch 896: train loss = 4.192156, test loss = 12257.485888\n",
            "Epoch 897: train loss = 4.191370, test loss = 12257.852117\n",
            "Epoch 898: train loss = 4.190669, test loss = 12258.102842\n",
            "Epoch 899: train loss = 4.189720, test loss = 12258.401495\n",
            "Epoch 900: train loss = 4.189090, test loss = 12258.750169\n",
            "Epoch 901: train loss = 4.188281, test loss = 12259.000569\n",
            "Epoch 902: train loss = 4.187382, test loss = 12259.348918\n",
            "Epoch 903: train loss = 4.186870, test loss = 12259.580935\n",
            "Epoch 904: train loss = 4.185964, test loss = 12259.865213\n",
            "Epoch 905: train loss = 4.185229, test loss = 12260.213746\n",
            "Epoch 906: train loss = 4.184602, test loss = 12260.450742\n",
            "Epoch 907: train loss = 4.183729, test loss = 12260.732464\n",
            "Epoch 908: train loss = 4.183136, test loss = 12261.065880\n",
            "Epoch 909: train loss = 4.182412, test loss = 12261.305410\n",
            "Epoch 910: train loss = 4.181571, test loss = 12261.634878\n",
            "Epoch 911: train loss = 4.181115, test loss = 12261.856417\n",
            "Epoch 912: train loss = 4.180287, test loss = 12262.125075\n",
            "Epoch 913: train loss = 4.179599, test loss = 12262.455482\n",
            "Epoch 914: train loss = 4.179036, test loss = 12262.682089\n",
            "Epoch 915: train loss = 4.178237, test loss = 12262.948758\n",
            "Epoch 916: train loss = 4.177683, test loss = 12263.266076\n",
            "Epoch 917: train loss = 4.177028, test loss = 12263.492395\n",
            "Epoch 918: train loss = 4.176256, test loss = 12263.754592\n",
            "Epoch 919: train loss = 4.175825, test loss = 12264.059287\n",
            "Epoch 920: train loss = 4.175086, test loss = 12264.284507\n",
            "Epoch 921: train loss = 4.174433, test loss = 12264.586886\n",
            "Epoch 922: train loss = 4.173939, test loss = 12264.793482\n",
            "Epoch 923: train loss = 4.173203, test loss = 12265.047862\n",
            "Epoch 924: train loss = 4.172682, test loss = 12265.350345\n",
            "Epoch 925: train loss = 4.172093, test loss = 12265.561349\n",
            "Epoch 926: train loss = 4.171385, test loss = 12265.813648\n",
            "Epoch 927: train loss = 4.170978, test loss = 12266.104386\n",
            "Epoch 928: train loss = 4.170310, test loss = 12266.314585\n",
            "Epoch 929: train loss = 4.169702, test loss = 12266.606204\n",
            "Epoch 930: train loss = 4.169260, test loss = 12266.801039\n",
            "Epoch 931: train loss = 4.168580, test loss = 12267.039615\n",
            "Epoch 932: train loss = 4.168093, test loss = 12267.331353\n",
            "Epoch 933: train loss = 4.167566, test loss = 12267.530362\n",
            "Epoch 934: train loss = 4.166911, test loss = 12267.768923\n",
            "Epoch 935: train loss = 4.166534, test loss = 12268.045892\n",
            "Epoch 936: train loss = 4.165929, test loss = 12268.244796\n",
            "Epoch 937: train loss = 4.165359, test loss = 12268.522167\n",
            "Epoch 938: train loss = 4.164966, test loss = 12268.705818\n",
            "Epoch 939: train loss = 4.164340, test loss = 12268.932367\n",
            "Epoch 940: train loss = 4.163884, test loss = 12269.207914\n",
            "Epoch 941: train loss = 4.163408, test loss = 12269.398867\n",
            "Epoch 942: train loss = 4.162807, test loss = 12269.622483\n",
            "Epoch 943: train loss = 4.162452, test loss = 12269.887280\n",
            "Epoch 944: train loss = 4.161906, test loss = 12270.076999\n",
            "Epoch 945: train loss = 4.161376, test loss = 12270.338422\n",
            "Epoch 946: train loss = 4.161020, test loss = 12270.512257\n",
            "Epoch 947: train loss = 4.160448, test loss = 12270.728912\n",
            "Epoch 948: train loss = 4.160023, test loss = 12270.990353\n",
            "Epoch 949: train loss = 4.159591, test loss = 12271.168244\n",
            "Epoch 950: train loss = 4.159041, test loss = 12271.383058\n",
            "Epoch 951: train loss = 4.158708, test loss = 12271.633868\n",
            "Epoch 952: train loss = 4.158211, test loss = 12271.812731\n",
            "Epoch 953: train loss = 4.157719, test loss = 12272.061649\n",
            "Epoch 954: train loss = 4.157399, test loss = 12272.224649\n",
            "Epoch 955: train loss = 4.156871, test loss = 12272.429971\n",
            "Epoch 956: train loss = 4.156478, test loss = 12272.679113\n",
            "Epoch 957: train loss = 4.156086, test loss = 12272.846171\n",
            "Epoch 958: train loss = 4.155578, test loss = 12273.049809\n",
            "Epoch 959: train loss = 4.155271, test loss = 12273.288727\n",
            "Epoch 960: train loss = 4.154818, test loss = 12273.455007\n",
            "Epoch 961: train loss = 4.154359, test loss = 12273.693003\n",
            "Epoch 962: train loss = 4.154073, test loss = 12273.848781\n",
            "Epoch 963: train loss = 4.153588, test loss = 12274.040151\n",
            "Epoch 964: train loss = 4.153219, test loss = 12274.278037\n",
            "Epoch 965: train loss = 4.152867, test loss = 12274.437592\n",
            "Epoch 966: train loss = 4.152397, test loss = 12274.627405\n",
            "Epoch 967: train loss = 4.152111, test loss = 12274.855377\n",
            "Epoch 968: train loss = 4.151701, test loss = 12275.013974\n",
            "Epoch 969: train loss = 4.151274, test loss = 12275.239304\n",
            "Epoch 970: train loss = 4.151014, test loss = 12275.383807\n",
            "Epoch 971: train loss = 4.150567, test loss = 12275.567338\n",
            "Epoch 972: train loss = 4.150227, test loss = 12275.792791\n",
            "Epoch 973: train loss = 4.149905, test loss = 12275.942818\n",
            "Epoch 974: train loss = 4.149474, test loss = 12276.122126\n",
            "Epoch 975: train loss = 4.149209, test loss = 12276.338625\n",
            "Epoch 976: train loss = 4.148833, test loss = 12276.488438\n",
            "Epoch 977: train loss = 4.148439, test loss = 12276.701896\n",
            "Epoch 978: train loss = 4.148204, test loss = 12276.837650\n",
            "Epoch 979: train loss = 4.147790, test loss = 12277.010001\n",
            "Epoch 980: train loss = 4.147476, test loss = 12277.226165\n",
            "Epoch 981: train loss = 4.147184, test loss = 12277.365349\n",
            "Epoch 982: train loss = 4.146783, test loss = 12277.536173\n",
            "Epoch 983: train loss = 4.146542, test loss = 12277.743042\n",
            "Epoch 984: train loss = 4.146197, test loss = 12277.881841\n",
            "Epoch 985: train loss = 4.145829, test loss = 12278.085468\n",
            "Epoch 986: train loss = 4.145618, test loss = 12278.214529\n",
            "Epoch 987: train loss = 4.145237, test loss = 12278.376567\n",
            "Epoch 988: train loss = 4.144946, test loss = 12278.580073\n",
            "Epoch 989: train loss = 4.144678, test loss = 12278.713297\n",
            "Epoch 990: train loss = 4.144310, test loss = 12278.874034\n",
            "Epoch 991: train loss = 4.144087, test loss = 12279.068656\n",
            "Epoch 992: train loss = 4.143769, test loss = 12279.201531\n",
            "Epoch 993: train loss = 4.143431, test loss = 12279.394110\n",
            "Epoch 994: train loss = 4.143239, test loss = 12279.513364\n",
            "Epoch 995: train loss = 4.142886, test loss = 12279.668611\n",
            "Epoch 996: train loss = 4.142620, test loss = 12279.861649\n",
            "Epoch 997: train loss = 4.142373, test loss = 12279.984599\n",
            "Epoch 998: train loss = 4.142033, test loss = 12280.138681\n",
            "Epoch 999: train loss = 4.141828, test loss = 12280.323255\n",
            "Epoch 1000: train loss = 4.141535, test loss = 12280.445785\n",
            "Epoch 1001: train loss = 4.141223, test loss = 12280.629561\n",
            "Epoch 1002: train loss = 4.141047, test loss = 12280.743532\n",
            "Epoch 1003: train loss = 4.140722, test loss = 12280.887469\n",
            "Epoch 1004: train loss = 4.140475, test loss = 12281.071344\n",
            "Epoch 1005: train loss = 4.140250, test loss = 12281.188559\n",
            "Epoch 1006: train loss = 4.139936, test loss = 12281.331513\n",
            "Epoch 1007: train loss = 4.139746, test loss = 12281.507195\n",
            "Epoch 1008: train loss = 4.139479, test loss = 12281.624189\n",
            "Epoch 1009: train loss = 4.139190, test loss = 12281.797222\n",
            "Epoch 1010: train loss = 4.139028, test loss = 12281.902141\n",
            "Epoch 1011: train loss = 4.138728, test loss = 12282.040233\n",
            "Epoch 1012: train loss = 4.138501, test loss = 12282.214010\n",
            "Epoch 1013: train loss = 4.138293, test loss = 12282.322344\n",
            "Epoch 1014: train loss = 4.138002, test loss = 12282.459396\n",
            "Epoch 1015: train loss = 4.137830, test loss = 12282.625110\n",
            "Epoch 1016: train loss = 4.137582, test loss = 12282.733414\n",
            "Epoch 1017: train loss = 4.137315, test loss = 12282.899369\n",
            "Epoch 1018: train loss = 4.137169, test loss = 12282.997021\n",
            "Epoch 1019: train loss = 4.136890, test loss = 12283.125944\n",
            "Epoch 1020: train loss = 4.136681, test loss = 12283.292230\n",
            "Epoch 1021: train loss = 4.136490, test loss = 12283.393336\n",
            "Epoch 1022: train loss = 4.136220, test loss = 12283.521184\n",
            "Epoch 1023: train loss = 4.136063, test loss = 12283.678629\n",
            "Epoch 1024: train loss = 4.135833, test loss = 12283.781711\n",
            "Epoch 1025: train loss = 4.135589, test loss = 12283.937315\n",
            "Epoch 1026: train loss = 4.135451, test loss = 12284.028737\n",
            "Epoch 1027: train loss = 4.135195, test loss = 12284.151620\n",
            "Epoch 1028: train loss = 4.135003, test loss = 12284.307570\n",
            "Epoch 1029: train loss = 4.134825, test loss = 12284.402317\n",
            "Epoch 1030: train loss = 4.134578, test loss = 12284.524298\n",
            "Epoch 1031: train loss = 4.134433, test loss = 12284.672631\n",
            "Epoch 1032: train loss = 4.134219, test loss = 12284.767554\n",
            "Epoch 1033: train loss = 4.133993, test loss = 12284.915513\n",
            "Epoch 1034: train loss = 4.133868, test loss = 12285.002127\n",
            "Epoch 1035: train loss = 4.133630, test loss = 12285.116059\n",
            "Epoch 1036: train loss = 4.133453, test loss = 12285.264214\n",
            "Epoch 1037: train loss = 4.133290, test loss = 12285.354005\n",
            "Epoch 1038: train loss = 4.133059, test loss = 12285.467129\n",
            "Epoch 1039: train loss = 4.132928, test loss = 12285.608027\n",
            "Epoch 1040: train loss = 4.132729, test loss = 12285.697998\n",
            "Epoch 1041: train loss = 4.132521, test loss = 12285.837269\n",
            "Epoch 1042: train loss = 4.132406, test loss = 12285.916821\n",
            "Epoch 1043: train loss = 4.132184, test loss = 12286.025472\n",
            "Epoch 1044: train loss = 4.132024, test loss = 12286.164961\n",
            "Epoch 1045: train loss = 4.131871, test loss = 12286.247841\n",
            "Epoch 1046: train loss = 4.131657, test loss = 12286.355606\n",
            "Epoch 1047: train loss = 4.131539, test loss = 12286.488413\n",
            "Epoch 1048: train loss = 4.131353, test loss = 12286.571351\n",
            "Epoch 1049: train loss = 4.131162, test loss = 12286.704362\n",
            "Epoch 1050: train loss = 4.131054, test loss = 12286.778050\n",
            "Epoch 1051: train loss = 4.130849, test loss = 12286.878954\n",
            "Epoch 1052: train loss = 4.130701, test loss = 12287.011265\n",
            "Epoch 1053: train loss = 4.130559, test loss = 12287.089909\n",
            "Epoch 1054: train loss = 4.130361, test loss = 12287.189588\n",
            "Epoch 1055: train loss = 4.130253, test loss = 12287.315387\n",
            "Epoch 1056: train loss = 4.130080, test loss = 12287.392937\n",
            "Epoch 1057: train loss = 4.129904, test loss = 12287.518628\n",
            "Epoch 1058: train loss = 4.129805, test loss = 12287.587118\n",
            "Epoch 1059: train loss = 4.129613, test loss = 12287.682060\n",
            "Epoch 1060: train loss = 4.129480, test loss = 12287.808014\n",
            "Epoch 1061: train loss = 4.129346, test loss = 12287.879545\n",
            "Epoch 1062: train loss = 4.129161, test loss = 12287.973707\n",
            "Epoch 1063: train loss = 4.129065, test loss = 12288.093471\n",
            "Epoch 1064: train loss = 4.128903, test loss = 12288.165058\n",
            "Epoch 1065: train loss = 4.128741, test loss = 12288.282614\n",
            "Epoch 1066: train loss = 4.128647, test loss = 12288.347455\n",
            "Epoch 1067: train loss = 4.128470, test loss = 12288.435889\n",
            "Epoch 1068: train loss = 4.128348, test loss = 12288.553895\n",
            "Epoch 1069: train loss = 4.128223, test loss = 12288.621599\n",
            "Epoch 1070: train loss = 4.128053, test loss = 12288.709576\n",
            "Epoch 1071: train loss = 4.127964, test loss = 12288.821225\n",
            "Epoch 1072: train loss = 4.127812, test loss = 12288.889405\n",
            "Epoch 1073: train loss = 4.127664, test loss = 12288.999885\n",
            "Epoch 1074: train loss = 4.127576, test loss = 12289.058458\n",
            "Epoch 1075: train loss = 4.127411, test loss = 12289.142060\n",
            "Epoch 1076: train loss = 4.127300, test loss = 12289.254592\n",
            "Epoch 1077: train loss = 4.127183, test loss = 12289.315832\n",
            "Epoch 1078: train loss = 4.127023, test loss = 12289.398644\n",
            "Epoch 1079: train loss = 4.126945, test loss = 12289.504215\n",
            "Epoch 1080: train loss = 4.126801, test loss = 12289.567240\n",
            "Epoch 1081: train loss = 4.126667, test loss = 12289.671424\n",
            "Epoch 1082: train loss = 4.126603, test loss = 12289.731004\n",
            "Epoch 1083: train loss = 4.126440, test loss = 12289.845435\n",
            "Epoch 1084: train loss = 4.126355, test loss = 12289.910435\n",
            "Epoch 1085: train loss = 4.126216, test loss = 12290.022161\n",
            "Epoch 1086: train loss = 4.126111, test loss = 12290.088914\n",
            "Epoch 1087: train loss = 4.125997, test loss = 12290.198493\n",
            "Epoch 1088: train loss = 4.125875, test loss = 12290.257660\n",
            "Epoch 1089: train loss = 4.125736, test loss = 12290.358863\n",
            "Epoch 1090: train loss = 4.125693, test loss = 12290.414849\n",
            "Epoch 1091: train loss = 4.125528, test loss = 12290.523510\n",
            "Epoch 1092: train loss = 4.125459, test loss = 12290.583813\n",
            "Epoch 1093: train loss = 4.125322, test loss = 12290.692089\n",
            "Epoch 1094: train loss = 4.125232, test loss = 12290.753174\n",
            "Epoch 1095: train loss = 4.125120, test loss = 12290.856567\n",
            "Epoch 1096: train loss = 4.125012, test loss = 12290.911144\n",
            "Epoch 1097: train loss = 4.124878, test loss = 12290.984198\n",
            "Epoch 1098: train loss = 4.124821, test loss = 12291.075119\n",
            "Epoch 1099: train loss = 4.124693, test loss = 12291.127128\n",
            "Epoch 1100: train loss = 4.124586, test loss = 12291.218292\n",
            "Epoch 1101: train loss = 4.124529, test loss = 12291.267971\n",
            "Epoch 1102: train loss = 4.124400, test loss = 12291.366856\n",
            "Epoch 1103: train loss = 4.124317, test loss = 12291.424030\n",
            "Epoch 1104: train loss = 4.124216, test loss = 12291.520471\n",
            "Epoch 1105: train loss = 4.124109, test loss = 12291.578618\n",
            "Epoch 1106: train loss = 4.124034, test loss = 12291.671663\n",
            "Epoch 1107: train loss = 4.123912, test loss = 12291.723673\n",
            "Epoch 1108: train loss = 4.123813, test loss = 12291.809392\n",
            "Epoch 1109: train loss = 4.123757, test loss = 12291.856826\n",
            "Epoch 1110: train loss = 4.123641, test loss = 12291.951469\n",
            "Epoch 1111: train loss = 4.123559, test loss = 12292.003982\n",
            "Epoch 1112: train loss = 4.123471, test loss = 12292.095038\n",
            "Epoch 1113: train loss = 4.123367, test loss = 12292.142189\n",
            "Epoch 1114: train loss = 4.123261, test loss = 12292.226992\n",
            "Epoch 1115: train loss = 4.123225, test loss = 12292.269705\n",
            "Epoch 1116: train loss = 4.123099, test loss = 12292.361058\n",
            "Epoch 1117: train loss = 4.123035, test loss = 12292.410047\n",
            "Epoch 1118: train loss = 4.122939, test loss = 12292.499969\n",
            "Epoch 1119: train loss = 4.122849, test loss = 12292.550761\n",
            "Epoch 1120: train loss = 4.122781, test loss = 12292.635299\n",
            "Epoch 1121: train loss = 4.122675, test loss = 12292.679221\n",
            "Epoch 1122: train loss = 4.122585, test loss = 12292.758155\n",
            "Epoch 1123: train loss = 4.122539, test loss = 12292.798438\n",
            "Epoch 1124: train loss = 4.122435, test loss = 12292.883399\n",
            "Epoch 1125: train loss = 4.122361, test loss = 12292.931166\n",
            "Epoch 1126: train loss = 4.122287, test loss = 12293.012756\n",
            "Epoch 1127: train loss = 4.122193, test loss = 12293.053163\n",
            "Epoch 1128: train loss = 4.122101, test loss = 12293.129211\n",
            "Epoch 1129: train loss = 4.122065, test loss = 12293.166195\n",
            "Epoch 1130: train loss = 4.121961, test loss = 12293.248348\n",
            "Epoch 1131: train loss = 4.121895, test loss = 12293.291803\n",
            "Epoch 1132: train loss = 4.121820, test loss = 12293.372340\n",
            "Epoch 1133: train loss = 4.121733, test loss = 12293.409487\n",
            "Epoch 1134: train loss = 4.121643, test loss = 12293.481435\n",
            "Epoch 1135: train loss = 4.121614, test loss = 12293.516871\n",
            "Epoch 1136: train loss = 4.121511, test loss = 12293.595655\n",
            "Epoch 1137: train loss = 4.121451, test loss = 12293.636094\n",
            "Epoch 1138: train loss = 4.121379, test loss = 12293.712595\n",
            "Epoch 1139: train loss = 4.121296, test loss = 12293.748549\n",
            "Epoch 1140: train loss = 4.121210, test loss = 12293.816962\n",
            "Epoch 1141: train loss = 4.121184, test loss = 12293.848816\n",
            "Epoch 1142: train loss = 4.121085, test loss = 12293.925695\n",
            "Epoch 1143: train loss = 4.121029, test loss = 12293.963382\n",
            "Epoch 1144: train loss = 4.120960, test loss = 12294.036338\n",
            "Epoch 1145: train loss = 4.120880, test loss = 12294.068854\n",
            "Epoch 1146: train loss = 4.120800, test loss = 12294.135488\n",
            "Epoch 1147: train loss = 4.120775, test loss = 12294.164712\n",
            "Epoch 1148: train loss = 4.120682, test loss = 12294.236935\n",
            "Epoch 1149: train loss = 4.120626, test loss = 12294.273262\n",
            "Epoch 1150: train loss = 4.120564, test loss = 12294.343752\n",
            "Epoch 1151: train loss = 4.120485, test loss = 12294.373674\n",
            "Epoch 1152: train loss = 4.120411, test loss = 12294.435790\n",
            "Epoch 1153: train loss = 4.120384, test loss = 12294.463599\n",
            "Epoch 1154: train loss = 4.120299, test loss = 12294.533255\n",
            "Epoch 1155: train loss = 4.120242, test loss = 12294.567320\n",
            "Epoch 1156: train loss = 4.120188, test loss = 12294.633169\n",
            "Epoch 1157: train loss = 4.120108, test loss = 12294.661682\n",
            "Epoch 1158: train loss = 4.120042, test loss = 12294.721214\n",
            "Epoch 1159: train loss = 4.120012, test loss = 12294.747024\n",
            "Epoch 1160: train loss = 4.119936, test loss = 12294.811993\n",
            "Epoch 1161: train loss = 4.119874, test loss = 12294.845005\n",
            "Epoch 1162: train loss = 4.119831, test loss = 12294.907856\n",
            "Epoch 1163: train loss = 4.119749, test loss = 12294.934554\n",
            "Epoch 1164: train loss = 4.119691, test loss = 12294.989445\n",
            "Epoch 1165: train loss = 4.119656, test loss = 12295.015062\n",
            "Epoch 1166: train loss = 4.119592, test loss = 12295.076192\n",
            "Epoch 1167: train loss = 4.119524, test loss = 12295.107689\n",
            "Epoch 1168: train loss = 4.119492, test loss = 12295.165820\n",
            "Epoch 1169: train loss = 4.119406, test loss = 12295.192350\n",
            "Epoch 1170: train loss = 4.119359, test loss = 12295.243277\n",
            "Epoch 1171: train loss = 4.119316, test loss = 12295.266864\n",
            "Epoch 1172: train loss = 4.119264, test loss = 12295.325287\n",
            "Epoch 1173: train loss = 4.119192, test loss = 12295.347619\n",
            "Epoch 1174: train loss = 4.119135, test loss = 12295.398429\n",
            "Epoch 1175: train loss = 4.119113, test loss = 12295.418862\n",
            "Epoch 1176: train loss = 4.119045, test loss = 12295.477851\n",
            "Epoch 1177: train loss = 4.118989, test loss = 12295.504776\n",
            "Epoch 1178: train loss = 4.118954, test loss = 12295.559606\n",
            "Epoch 1179: train loss = 4.118874, test loss = 12295.581917\n",
            "Epoch 1180: train loss = 4.118830, test loss = 12295.629874\n",
            "Epoch 1181: train loss = 4.118796, test loss = 12295.649473\n",
            "Epoch 1182: train loss = 4.118744, test loss = 12295.702984\n",
            "Epoch 1183: train loss = 4.118678, test loss = 12295.730871\n",
            "Epoch 1184: train loss = 4.118658, test loss = 12295.780955\n",
            "Epoch 1185: train loss = 4.118571, test loss = 12295.801993\n",
            "Epoch 1186: train loss = 4.118539, test loss = 12295.845278\n",
            "Epoch 1187: train loss = 4.118493, test loss = 12295.865888\n",
            "Epoch 1188: train loss = 4.118458, test loss = 12295.914763\n",
            "Epoch 1189: train loss = 4.118381, test loss = 12295.933571\n",
            "Epoch 1190: train loss = 4.118343, test loss = 12295.976443\n",
            "Epoch 1191: train loss = 4.118314, test loss = 12295.993793\n",
            "Epoch 1192: train loss = 4.118265, test loss = 12296.043153\n",
            "Epoch 1193: train loss = 4.118202, test loss = 12296.067147\n",
            "Epoch 1194: train loss = 4.118186, test loss = 12296.113413\n",
            "Epoch 1195: train loss = 4.118099, test loss = 12296.133244\n",
            "Epoch 1196: train loss = 4.118075, test loss = 12296.171659\n",
            "Epoch 1197: train loss = 4.118031, test loss = 12296.188350\n",
            "Epoch 1198: train loss = 4.118001, test loss = 12296.233559\n",
            "Epoch 1199: train loss = 4.117924, test loss = 12296.258446\n",
            "Epoch 1200: train loss = 4.117926, test loss = 12296.299885\n",
            "Epoch 1201: train loss = 4.117839, test loss = 12296.334083\n",
            "Epoch 1202: train loss = 4.117834, test loss = 12296.342663\n",
            "Epoch 1203: train loss = 4.117769, test loss = 12296.390967\n",
            "Epoch 1204: train loss = 4.117728, test loss = 12296.409582\n",
            "Epoch 1205: train loss = 4.117697, test loss = 12296.454145\n",
            "Epoch 1206: train loss = 4.117627, test loss = 12296.468999\n",
            "Epoch 1207: train loss = 4.117595, test loss = 12296.505830\n",
            "Epoch 1208: train loss = 4.117569, test loss = 12296.518657\n",
            "Epoch 1209: train loss = 4.117528, test loss = 12296.561490\n",
            "Epoch 1210: train loss = 4.117468, test loss = 12296.581081\n",
            "Epoch 1211: train loss = 4.117460, test loss = 12296.620558\n",
            "Epoch 1212: train loss = 4.117378, test loss = 12296.652685\n",
            "Epoch 1213: train loss = 4.117385, test loss = 12296.656698\n",
            "Epoch 1214: train loss = 4.117315, test loss = 12296.701096\n",
            "Epoch 1215: train loss = 4.117285, test loss = 12296.716074\n",
            "Epoch 1216: train loss = 4.117250, test loss = 12296.758643\n",
            "Epoch 1217: train loss = 4.117189, test loss = 12296.769522\n",
            "Epoch 1218: train loss = 4.117154, test loss = 12296.803009\n",
            "Epoch 1219: train loss = 4.117137, test loss = 12296.811348\n",
            "Epoch 1220: train loss = 4.117094, test loss = 12296.852070\n",
            "Epoch 1221: train loss = 4.117042, test loss = 12296.867865\n",
            "Epoch 1222: train loss = 4.117032, test loss = 12296.903961\n",
            "Epoch 1223: train loss = 4.116956, test loss = 12296.915253\n",
            "Epoch 1224: train loss = 4.116941, test loss = 12296.944545\n",
            "Epoch 1225: train loss = 4.116901, test loss = 12296.953789\n",
            "Epoch 1226: train loss = 4.116883, test loss = 12296.988325\n",
            "Epoch 1227: train loss = 4.116811, test loss = 12296.997810\n",
            "Epoch 1228: train loss = 4.116794, test loss = 12297.026050\n",
            "Epoch 1229: train loss = 4.116763, test loss = 12297.033488\n",
            "Epoch 1230: train loss = 4.116738, test loss = 12297.067684\n",
            "Epoch 1231: train loss = 4.116673, test loss = 12297.083138\n",
            "Epoch 1232: train loss = 4.116681, test loss = 12297.114620\n",
            "Epoch 1233: train loss = 4.116609, test loss = 12297.137940\n",
            "Epoch 1234: train loss = 4.116603, test loss = 12297.139638\n",
            "Epoch 1235: train loss = 4.116555, test loss = 12297.175196\n",
            "Epoch 1236: train loss = 4.116514, test loss = 12297.187730\n",
            "Epoch 1237: train loss = 4.116501, test loss = 12297.219994\n",
            "Epoch 1238: train loss = 4.116431, test loss = 12297.243826\n",
            "Epoch 1239: train loss = 4.116445, test loss = 12297.241512\n",
            "Epoch 1240: train loss = 4.116380, test loss = 12297.279006\n",
            "Epoch 1241: train loss = 4.116358, test loss = 12297.287134\n",
            "Epoch 1242: train loss = 4.116328, test loss = 12297.320618\n",
            "Epoch 1243: train loss = 4.116273, test loss = 12297.333357\n",
            "Epoch 1244: train loss = 4.116276, test loss = 12297.362672\n",
            "Epoch 1245: train loss = 4.116209, test loss = 12297.383032\n",
            "Epoch 1246: train loss = 4.116208, test loss = 12297.381488\n",
            "Epoch 1247: train loss = 4.116161, test loss = 12297.413952\n",
            "Epoch 1248: train loss = 4.116124, test loss = 12297.423254\n",
            "Epoch 1249: train loss = 4.116112, test loss = 12297.452246\n",
            "Epoch 1250: train loss = 4.116049, test loss = 12297.456347\n",
            "Epoch 1251: train loss = 4.116034, test loss = 12297.477724\n",
            "Epoch 1252: train loss = 4.116004, test loss = 12297.480909\n",
            "Epoch 1253: train loss = 4.115988, test loss = 12297.508603\n",
            "Epoch 1254: train loss = 4.115927, test loss = 12297.511144\n",
            "Epoch 1255: train loss = 4.115912, test loss = 12297.531171\n",
            "Epoch 1256: train loss = 4.115888, test loss = 12297.532671\n",
            "Epoch 1257: train loss = 4.115868, test loss = 12297.559778\n",
            "Epoch 1258: train loss = 4.115808, test loss = 12297.569135\n",
            "Epoch 1259: train loss = 4.115822, test loss = 12297.591479\n",
            "Epoch 1260: train loss = 4.115760, test loss = 12297.607559\n",
            "Epoch 1261: train loss = 4.115750, test loss = 12297.605620\n",
            "Epoch 1262: train loss = 4.115718, test loss = 12297.631772\n",
            "Epoch 1263: train loss = 4.115672, test loss = 12297.638972\n",
            "Epoch 1264: train loss = 4.115674, test loss = 12297.662190\n",
            "Epoch 1265: train loss = 4.115613, test loss = 12297.678826\n",
            "Epoch 1266: train loss = 4.115615, test loss = 12297.673222\n",
            "Epoch 1267: train loss = 4.115572, test loss = 12297.699997\n",
            "Epoch 1268: train loss = 4.115537, test loss = 12297.705034\n",
            "Epoch 1269: train loss = 4.115530, test loss = 12297.728806\n",
            "Epoch 1270: train loss = 4.115470, test loss = 12297.744879\n",
            "Epoch 1271: train loss = 4.115482, test loss = 12297.736854\n",
            "Epoch 1272: train loss = 4.115432, test loss = 12297.763842\n",
            "Epoch 1273: train loss = 4.115406, test loss = 12297.766493\n",
            "Epoch 1274: train loss = 4.115391, test loss = 12297.790996\n",
            "Epoch 1275: train loss = 4.115338, test loss = 12297.789601\n",
            "Epoch 1276: train loss = 4.115324, test loss = 12297.804769\n",
            "Epoch 1277: train loss = 4.115302, test loss = 12297.802436\n",
            "Epoch 1278: train loss = 4.115286, test loss = 12297.824156\n",
            "Epoch 1279: train loss = 4.115232, test loss = 12297.821511\n",
            "Epoch 1280: train loss = 4.115220, test loss = 12297.835238\n",
            "Epoch 1281: train loss = 4.115200, test loss = 12297.831819\n",
            "Epoch 1282: train loss = 4.115184, test loss = 12297.851873\n",
            "Epoch 1283: train loss = 4.115129, test loss = 12297.857597\n",
            "Epoch 1284: train loss = 4.115146, test loss = 12297.873206\n",
            "Epoch 1285: train loss = 4.115091, test loss = 12297.883139\n",
            "Epoch 1286: train loss = 4.115079, test loss = 12297.876745\n",
            "Epoch 1287: train loss = 4.115056, test loss = 12297.896965\n",
            "Epoch 1288: train loss = 4.115008, test loss = 12297.900124\n",
            "Epoch 1289: train loss = 4.115020, test loss = 12297.916195\n",
            "Epoch 1290: train loss = 4.114966, test loss = 12297.925650\n",
            "Epoch 1291: train loss = 4.114959, test loss = 12297.917848\n",
            "Epoch 1292: train loss = 4.114932, test loss = 12297.938053\n",
            "Epoch 1293: train loss = 4.114889, test loss = 12297.939623\n",
            "Epoch 1294: train loss = 4.114897, test loss = 12297.955495\n",
            "Epoch 1295: train loss = 4.114844, test loss = 12297.964258\n",
            "Epoch 1296: train loss = 4.114842, test loss = 12297.955669\n",
            "Epoch 1297: train loss = 4.114812, test loss = 12297.974313\n",
            "Epoch 1298: train loss = 4.114773, test loss = 12297.974831\n",
            "Epoch 1299: train loss = 4.114779, test loss = 12297.990241\n",
            "Epoch 1300: train loss = 4.114727, test loss = 12297.998410\n",
            "Epoch 1301: train loss = 4.114726, test loss = 12297.988502\n",
            "Epoch 1302: train loss = 4.114696, test loss = 12298.006414\n",
            "Epoch 1303: train loss = 4.114659, test loss = 12298.006016\n",
            "Epoch 1304: train loss = 4.114663, test loss = 12298.020452\n",
            "Epoch 1305: train loss = 4.114612, test loss = 12298.028374\n",
            "Epoch 1306: train loss = 4.114614, test loss = 12298.016570\n",
            "Epoch 1307: train loss = 4.114583, test loss = 12298.033656\n",
            "Epoch 1308: train loss = 4.114548, test loss = 12298.032419\n",
            "Epoch 1309: train loss = 4.114552, test loss = 12298.046172\n",
            "Epoch 1310: train loss = 4.114502, test loss = 12298.053070\n",
            "Epoch 1311: train loss = 4.114503, test loss = 12298.040438\n",
            "Epoch 1312: train loss = 4.114473, test loss = 12298.056619\n",
            "Epoch 1313: train loss = 4.114438, test loss = 12298.054514\n",
            "Epoch 1314: train loss = 4.114443, test loss = 12298.067251\n",
            "Epoch 1315: train loss = 4.114394, test loss = 12298.073166\n",
            "Epoch 1316: train loss = 4.114395, test loss = 12298.059895\n",
            "Epoch 1317: train loss = 4.114367, test loss = 12298.075114\n",
            "Epoch 1318: train loss = 4.114332, test loss = 12298.064511\n",
            "Epoch 1319: train loss = 4.114312, test loss = 12298.073409\n",
            "Epoch 1320: train loss = 4.114309, test loss = 12298.061713\n",
            "Epoch 1321: train loss = 4.114285, test loss = 12298.075653\n",
            "Epoch 1322: train loss = 4.114247, test loss = 12298.072894\n",
            "Epoch 1323: train loss = 4.114256, test loss = 12298.082879\n",
            "Epoch 1324: train loss = 4.114210, test loss = 12298.086547\n",
            "Epoch 1325: train loss = 4.114206, test loss = 12298.072946\n",
            "Epoch 1326: train loss = 4.114184, test loss = 12298.085307\n",
            "Epoch 1327: train loss = 4.114145, test loss = 12298.074368\n",
            "Epoch 1328: train loss = 4.114131, test loss = 12298.079838\n",
            "Epoch 1329: train loss = 4.114123, test loss = 12298.068594\n",
            "Epoch 1330: train loss = 4.114106, test loss = 12298.079675\n",
            "Epoch 1331: train loss = 4.114063, test loss = 12298.076493\n",
            "Epoch 1332: train loss = 4.114079, test loss = 12298.083547\n",
            "Epoch 1333: train loss = 4.114033, test loss = 12298.084718\n",
            "Epoch 1334: train loss = 4.114023, test loss = 12298.072165\n",
            "Epoch 1335: train loss = 4.114009, test loss = 12298.081621\n",
            "Epoch 1336: train loss = 4.113965, test loss = 12298.070425\n",
            "Epoch 1337: train loss = 4.113958, test loss = 12298.073098\n",
            "Epoch 1338: train loss = 4.113944, test loss = 12298.061224\n",
            "Epoch 1339: train loss = 4.113934, test loss = 12298.070365\n",
            "Epoch 1340: train loss = 4.113890, test loss = 12298.071304\n",
            "Epoch 1341: train loss = 4.113905, test loss = 12298.053122\n",
            "Epoch 1342: train loss = 4.113867, test loss = 12298.065230\n",
            "Epoch 1343: train loss = 4.113846, test loss = 12298.058485\n",
            "Epoch 1344: train loss = 4.113842, test loss = 12298.066673\n",
            "Epoch 1345: train loss = 4.113799, test loss = 12298.067363\n",
            "Epoch 1346: train loss = 4.113808, test loss = 12298.049789\n",
            "Epoch 1347: train loss = 4.113776, test loss = 12298.060379\n",
            "Epoch 1348: train loss = 4.113749, test loss = 12298.053896\n",
            "Epoch 1349: train loss = 4.113752, test loss = 12298.060197\n",
            "Epoch 1350: train loss = 4.113709, test loss = 12298.059593\n",
            "Epoch 1351: train loss = 4.113712, test loss = 12298.042645\n",
            "Epoch 1352: train loss = 4.113688, test loss = 12298.051294\n",
            "Epoch 1353: train loss = 4.113654, test loss = 12298.045109\n",
            "Epoch 1354: train loss = 4.113664, test loss = 12298.049712\n",
            "Epoch 1355: train loss = 4.113623, test loss = 12298.047705\n",
            "Epoch 1356: train loss = 4.113618, test loss = 12298.031403\n",
            "Epoch 1357: train loss = 4.113601, test loss = 12298.038306\n",
            "Epoch 1358: train loss = 4.113561, test loss = 12298.032514\n",
            "Epoch 1359: train loss = 4.113579, test loss = 12298.035269\n",
            "Epoch 1360: train loss = 4.113538, test loss = 12298.032054\n",
            "Epoch 1361: train loss = 4.113526, test loss = 12298.016480\n",
            "Epoch 1362: train loss = 4.113517, test loss = 12298.021727\n",
            "Epoch 1363: train loss = 4.113476, test loss = 12298.020261\n",
            "Epoch 1364: train loss = 4.113490, test loss = 12297.999663\n",
            "Epoch 1365: train loss = 4.113456, test loss = 12298.008124\n",
            "Epoch 1366: train loss = 4.113434, test loss = 12297.998460\n",
            "Epoch 1367: train loss = 4.113435, test loss = 12298.003777\n",
            "Epoch 1368: train loss = 4.113394, test loss = 12298.000801\n",
            "Epoch 1369: train loss = 4.113399, test loss = 12297.981426\n",
            "Epoch 1370: train loss = 4.113375, test loss = 12297.987846\n",
            "Epoch 1371: train loss = 4.113344, test loss = 12297.978876\n",
            "Epoch 1372: train loss = 4.113354, test loss = 12297.981904\n",
            "Epoch 1373: train loss = 4.113315, test loss = 12297.977530\n",
            "Epoch 1374: train loss = 4.113310, test loss = 12297.959160\n",
            "Epoch 1375: train loss = 4.113296, test loss = 12297.963439\n",
            "Epoch 1376: train loss = 4.113257, test loss = 12297.947514\n",
            "Epoch 1377: train loss = 4.113252, test loss = 12297.944884\n",
            "Epoch 1378: train loss = 4.113241, test loss = 12297.928183\n",
            "Epoch 1379: train loss = 4.113234, test loss = 12297.930704\n",
            "Epoch 1380: train loss = 4.113195, test loss = 12297.926133\n",
            "Epoch 1381: train loss = 4.113208, test loss = 12297.904391\n",
            "Epoch 1382: train loss = 4.113177, test loss = 12297.910583\n",
            "Epoch 1383: train loss = 4.113154, test loss = 12297.899143\n",
            "Epoch 1384: train loss = 4.113158, test loss = 12297.900867\n",
            "Epoch 1385: train loss = 4.113119, test loss = 12297.895497\n",
            "Epoch 1386: train loss = 4.113121, test loss = 12297.875474\n",
            "Epoch 1387: train loss = 4.113102, test loss = 12297.879427\n",
            "Epoch 1388: train loss = 4.113068, test loss = 12297.869060\n",
            "Epoch 1389: train loss = 4.113083, test loss = 12297.868324\n",
            "Epoch 1390: train loss = 4.113045, test loss = 12297.861598\n",
            "Epoch 1391: train loss = 4.113036, test loss = 12297.842897\n",
            "Epoch 1392: train loss = 4.113028, test loss = 12297.844592\n",
            "Epoch 1393: train loss = 4.112991, test loss = 12297.838563\n",
            "Epoch 1394: train loss = 4.113004, test loss = 12297.815440\n",
            "Epoch 1395: train loss = 4.112974, test loss = 12297.819584\n",
            "Epoch 1396: train loss = 4.112951, test loss = 12297.807533\n",
            "Epoch 1397: train loss = 4.112956, test loss = 12297.808161\n",
            "Epoch 1398: train loss = 4.112919, test loss = 12297.801201\n",
            "Epoch 1399: train loss = 4.112920, test loss = 12297.780135\n",
            "Epoch 1400: train loss = 4.112903, test loss = 12297.781599\n",
            "Epoch 1401: train loss = 4.112868, test loss = 12297.770796\n",
            "Epoch 1402: train loss = 4.112885, test loss = 12297.768731\n",
            "Epoch 1403: train loss = 4.112849, test loss = 12297.760180\n",
            "Epoch 1404: train loss = 4.112838, test loss = 12297.740833\n",
            "Epoch 1405: train loss = 4.112833, test loss = 12297.739835\n",
            "Epoch 1406: train loss = 4.112797, test loss = 12297.732472\n",
            "Epoch 1407: train loss = 4.112806, test loss = 12297.709243\n",
            "Epoch 1408: train loss = 4.112782, test loss = 12297.711770\n",
            "Epoch 1409: train loss = 4.112755, test loss = 12297.698847\n",
            "Epoch 1410: train loss = 4.112765, test loss = 12297.696822\n",
            "Epoch 1411: train loss = 4.112729, test loss = 12297.688179\n",
            "Epoch 1412: train loss = 4.112725, test loss = 12297.667110\n",
            "Epoch 1413: train loss = 4.112714, test loss = 12297.666983\n",
            "Epoch 1414: train loss = 4.112679, test loss = 12297.658938\n",
            "Epoch 1415: train loss = 4.112694, test loss = 12297.633827\n",
            "Epoch 1416: train loss = 4.112664, test loss = 12297.635788\n",
            "Epoch 1417: train loss = 4.112643, test loss = 12297.621626\n",
            "Epoch 1418: train loss = 4.112648, test loss = 12297.619840\n",
            "Epoch 1419: train loss = 4.112613, test loss = 12297.611345\n",
            "Epoch 1420: train loss = 4.112614, test loss = 12297.588443\n",
            "Epoch 1421: train loss = 4.112598, test loss = 12297.587633\n",
            "Epoch 1422: train loss = 4.112564, test loss = 12297.586739\n",
            "Epoch 1423: train loss = 4.112552, test loss = 12297.580016\n",
            "Epoch 1424: train loss = 4.112565, test loss = 12297.555177\n",
            "Epoch 1425: train loss = 4.112538, test loss = 12297.555914\n",
            "Epoch 1426: train loss = 4.112515, test loss = 12297.541018\n",
            "Epoch 1427: train loss = 4.112522, test loss = 12297.537940\n",
            "Epoch 1428: train loss = 4.112488, test loss = 12297.528222\n",
            "Epoch 1429: train loss = 4.112486, test loss = 12297.505532\n",
            "Epoch 1430: train loss = 4.112474, test loss = 12297.503285\n",
            "Epoch 1431: train loss = 4.112441, test loss = 12297.481981\n",
            "Epoch 1432: train loss = 4.112437, test loss = 12297.472811\n",
            "Epoch 1433: train loss = 4.112427, test loss = 12297.451626\n",
            "Epoch 1434: train loss = 4.112423, test loss = 12297.448370\n",
            "Epoch 1435: train loss = 4.112389, test loss = 12297.437606\n",
            "Epoch 1436: train loss = 4.112399, test loss = 12297.411894\n",
            "Epoch 1437: train loss = 4.112377, test loss = 12297.410572\n",
            "Epoch 1438: train loss = 4.112349, test loss = 12297.395719\n",
            "Epoch 1439: train loss = 4.112362, test loss = 12297.390295\n",
            "Epoch 1440: train loss = 4.112328, test loss = 12297.379267\n",
            "Epoch 1441: train loss = 4.112322, test loss = 12297.356197\n",
            "Epoch 1442: train loss = 4.112316, test loss = 12297.351965\n",
            "Epoch 1443: train loss = 4.112282, test loss = 12297.341065\n",
            "Epoch 1444: train loss = 4.112293, test loss = 12297.314767\n",
            "Epoch 1445: train loss = 4.112270, test loss = 12297.313666\n",
            "Epoch 1446: train loss = 4.112245, test loss = 12297.297892\n",
            "Epoch 1447: train loss = 4.112256, test loss = 12297.291919\n",
            "Epoch 1448: train loss = 4.112223, test loss = 12297.279848\n",
            "Epoch 1449: train loss = 4.112217, test loss = 12297.256521\n",
            "Epoch 1450: train loss = 4.112210, test loss = 12297.252246\n",
            "Epoch 1451: train loss = 4.112178, test loss = 12297.240576\n",
            "Epoch 1452: train loss = 4.112190, test loss = 12297.213644\n",
            "Epoch 1453: train loss = 4.112166, test loss = 12297.211252\n",
            "Epoch 1454: train loss = 4.112141, test loss = 12297.195226\n",
            "Epoch 1455: train loss = 4.112152, test loss = 12297.188774\n",
            "Epoch 1456: train loss = 4.112120, test loss = 12297.176625\n",
            "Epoch 1457: train loss = 4.112115, test loss = 12297.152526\n",
            "Epoch 1458: train loss = 4.112108, test loss = 12297.146936\n",
            "Epoch 1459: train loss = 4.112076, test loss = 12297.134867\n",
            "Epoch 1460: train loss = 4.112087, test loss = 12297.107685\n",
            "Epoch 1461: train loss = 4.112064, test loss = 12297.105075\n",
            "Epoch 1462: train loss = 4.112039, test loss = 12297.088343\n",
            "Epoch 1463: train loss = 4.112051, test loss = 12297.081069\n",
            "Epoch 1464: train loss = 4.112019, test loss = 12297.067579\n",
            "Epoch 1465: train loss = 4.112013, test loss = 12297.043493\n",
            "Epoch 1466: train loss = 4.112008, test loss = 12297.037324\n",
            "Epoch 1467: train loss = 4.111976, test loss = 12297.024945\n",
            "Epoch 1468: train loss = 4.111986, test loss = 12296.997306\n",
            "Epoch 1469: train loss = 4.111965, test loss = 12296.993255\n",
            "Epoch 1470: train loss = 4.111939, test loss = 12296.976518\n",
            "Epoch 1471: train loss = 4.111952, test loss = 12296.968446\n",
            "Epoch 1472: train loss = 4.111921, test loss = 12296.954275\n",
            "Epoch 1473: train loss = 4.111913, test loss = 12296.930589\n",
            "Epoch 1474: train loss = 4.111910, test loss = 12296.923188\n",
            "Epoch 1475: train loss = 4.111878, test loss = 12296.909444\n",
            "Epoch 1476: train loss = 4.111886, test loss = 12296.882087\n",
            "Epoch 1477: train loss = 4.111867, test loss = 12296.877239\n",
            "Epoch 1478: train loss = 4.111840, test loss = 12296.860390\n",
            "Epoch 1479: train loss = 4.111855, test loss = 12296.851796\n",
            "Epoch 1480: train loss = 4.111824, test loss = 12296.836693\n",
            "Epoch 1481: train loss = 4.111814, test loss = 12296.812383\n",
            "Epoch 1482: train loss = 4.111814, test loss = 12296.804232\n",
            "Epoch 1483: train loss = 4.111783, test loss = 12296.789861\n",
            "Epoch 1484: train loss = 4.111788, test loss = 12296.763209\n",
            "Epoch 1485: train loss = 4.111772, test loss = 12296.757069\n",
            "Epoch 1486: train loss = 4.111743, test loss = 12296.750856\n",
            "Epoch 1487: train loss = 4.111733, test loss = 12296.739095\n",
            "Epoch 1488: train loss = 4.111743, test loss = 12296.711006\n",
            "Epoch 1489: train loss = 4.111722, test loss = 12296.706448\n",
            "Epoch 1490: train loss = 4.111697, test loss = 12296.688300\n",
            "Epoch 1491: train loss = 4.111711, test loss = 12296.678899\n",
            "Epoch 1492: train loss = 4.111680, test loss = 12296.663370\n",
            "Epoch 1493: train loss = 4.111672, test loss = 12296.638190\n",
            "Epoch 1494: train loss = 4.111670, test loss = 12296.630154\n",
            "Epoch 1495: train loss = 4.111640, test loss = 12296.614844\n",
            "Epoch 1496: train loss = 4.111646, test loss = 12296.586559\n",
            "Epoch 1497: train loss = 4.111630, test loss = 12296.580011\n",
            "Epoch 1498: train loss = 4.111601, test loss = 12296.554722\n",
            "Epoch 1499: train loss = 4.111597, test loss = 12296.540696\n",
            "Epoch 1500: train loss = 4.111593, test loss = 12296.515472\n",
            "Epoch 1501: train loss = 4.111587, test loss = 12296.506631\n",
            "Epoch 1502: train loss = 4.111558, test loss = 12296.491196\n",
            "Epoch 1503: train loss = 4.111568, test loss = 12296.461908\n",
            "Epoch 1504: train loss = 4.111548, test loss = 12296.455328\n",
            "Epoch 1505: train loss = 4.111523, test loss = 12296.447922\n",
            "Epoch 1506: train loss = 4.111510, test loss = 12296.435183\n",
            "Epoch 1507: train loss = 4.111524, test loss = 12296.406098\n",
            "Epoch 1508: train loss = 4.111500, test loss = 12296.400031\n",
            "Epoch 1509: train loss = 4.111478, test loss = 12296.380493\n",
            "Epoch 1510: train loss = 4.111489, test loss = 12296.370334\n",
            "Epoch 1511: train loss = 4.111460, test loss = 12296.353812\n",
            "Epoch 1512: train loss = 4.111454, test loss = 12296.327360\n",
            "Epoch 1513: train loss = 4.111451, test loss = 12296.318298\n",
            "Epoch 1514: train loss = 4.111421, test loss = 12296.301930\n",
            "Epoch 1515: train loss = 4.111429, test loss = 12296.272544\n",
            "Epoch 1516: train loss = 4.111412, test loss = 12296.265009\n",
            "Epoch 1517: train loss = 4.111384, test loss = 12296.246141\n",
            "Epoch 1518: train loss = 4.111401, test loss = 12296.234420\n",
            "Epoch 1519: train loss = 4.111372, test loss = 12296.217460\n",
            "Epoch 1520: train loss = 4.111360, test loss = 12296.191531\n",
            "Epoch 1521: train loss = 4.111363, test loss = 12296.180396\n",
            "Epoch 1522: train loss = 4.111334, test loss = 12296.163340\n",
            "Epoch 1523: train loss = 4.111335, test loss = 12296.135099\n",
            "Epoch 1524: train loss = 4.111325, test loss = 12296.126542\n",
            "Epoch 1525: train loss = 4.111296, test loss = 12296.110220\n",
            "Epoch 1526: train loss = 4.111311, test loss = 12296.079325\n",
            "Epoch 1527: train loss = 4.111287, test loss = 12296.072197\n",
            "Epoch 1528: train loss = 4.111266, test loss = 12296.052136\n",
            "Epoch 1529: train loss = 4.111277, test loss = 12296.041246\n",
            "Epoch 1530: train loss = 4.111248, test loss = 12296.023454\n",
            "Epoch 1531: train loss = 4.111242, test loss = 12295.996317\n",
            "Epoch 1532: train loss = 4.111240, test loss = 12295.985472\n",
            "Epoch 1533: train loss = 4.111211, test loss = 12295.968359\n",
            "Epoch 1534: train loss = 4.111218, test loss = 12295.938701\n",
            "Epoch 1535: train loss = 4.111202, test loss = 12295.930296\n",
            "Epoch 1536: train loss = 4.111175, test loss = 12295.921061\n",
            "Epoch 1537: train loss = 4.111167, test loss = 12295.906308\n",
            "Epoch 1538: train loss = 4.111175, test loss = 12295.876465\n",
            "Epoch 1539: train loss = 4.111158, test loss = 12295.867999\n",
            "Epoch 1540: train loss = 4.111131, test loss = 12295.840737\n",
            "Epoch 1541: train loss = 4.111127, test loss = 12295.824924\n",
            "Epoch 1542: train loss = 4.111125, test loss = 12295.796971\n",
            "Epoch 1543: train loss = 4.111119, test loss = 12295.785986\n",
            "Epoch 1544: train loss = 4.111090, test loss = 12295.768399\n",
            "Epoch 1545: train loss = 4.111101, test loss = 12295.737577\n",
            "Epoch 1546: train loss = 4.111082, test loss = 12295.728475\n",
            "Epoch 1547: train loss = 4.111058, test loss = 12295.718842\n",
            "Epoch 1548: train loss = 4.111047, test loss = 12295.704275\n",
            "Epoch 1549: train loss = 4.111058, test loss = 12295.673327\n",
            "Epoch 1550: train loss = 4.111039, test loss = 12295.664523\n",
            "Epoch 1551: train loss = 4.111014, test loss = 12295.643980\n",
            "Epoch 1552: train loss = 4.111029, test loss = 12295.630868\n",
            "Epoch 1553: train loss = 4.111001, test loss = 12295.611891\n",
            "Epoch 1554: train loss = 4.110991, test loss = 12295.585138\n",
            "Epoch 1555: train loss = 4.110993, test loss = 12295.572336\n",
            "Epoch 1556: train loss = 4.110965, test loss = 12295.553583\n",
            "Epoch 1557: train loss = 4.110967, test loss = 12295.523863\n",
            "Epoch 1558: train loss = 4.110957, test loss = 12295.513126\n",
            "Epoch 1559: train loss = 4.110930, test loss = 12295.495415\n",
            "Epoch 1560: train loss = 4.110943, test loss = 12295.463952\n",
            "Epoch 1561: train loss = 4.110922, test loss = 12295.454777\n",
            "Epoch 1562: train loss = 4.110900, test loss = 12295.433400\n",
            "Epoch 1563: train loss = 4.110912, test loss = 12295.420092\n",
            "Epoch 1564: train loss = 4.110885, test loss = 12295.400794\n",
            "Epoch 1565: train loss = 4.110877, test loss = 12295.373498\n",
            "Epoch 1566: train loss = 4.110877, test loss = 12295.360418\n",
            "Epoch 1567: train loss = 4.110850, test loss = 12295.341302\n",
            "Epoch 1568: train loss = 4.110853, test loss = 12295.311076\n",
            "Epoch 1569: train loss = 4.110842, test loss = 12295.300057\n",
            "Epoch 1570: train loss = 4.110815, test loss = 12295.281907\n",
            "Epoch 1571: train loss = 4.110829, test loss = 12295.250023\n",
            "Epoch 1572: train loss = 4.110807, test loss = 12295.240441\n",
            "Epoch 1573: train loss = 4.110786, test loss = 12295.218646\n",
            "Epoch 1574: train loss = 4.110798, test loss = 12295.204940\n",
            "Epoch 1575: train loss = 4.110771, test loss = 12295.185325\n",
            "Epoch 1576: train loss = 4.110763, test loss = 12295.157090\n",
            "Epoch 1577: train loss = 4.110763, test loss = 12295.143841\n",
            "Epoch 1578: train loss = 4.110736, test loss = 12295.124942\n",
            "Epoch 1579: train loss = 4.110740, test loss = 12295.094197\n",
            "Epoch 1580: train loss = 4.110728, test loss = 12295.082590\n",
            "Epoch 1581: train loss = 4.110702, test loss = 12295.071340\n",
            "Epoch 1582: train loss = 4.110695, test loss = 12295.054543\n",
            "Epoch 1583: train loss = 4.110698, test loss = 12295.024422\n",
            "Epoch 1584: train loss = 4.110687, test loss = 12295.013512\n",
            "Epoch 1585: train loss = 4.110660, test loss = 12294.994793\n",
            "Epoch 1586: train loss = 4.110675, test loss = 12294.961849\n",
            "Epoch 1587: train loss = 4.110653, test loss = 12294.951840\n",
            "Epoch 1588: train loss = 4.110632, test loss = 12294.929796\n",
            "Epoch 1589: train loss = 4.110644, test loss = 12294.915525\n",
            "Epoch 1590: train loss = 4.110618, test loss = 12294.895793\n",
            "Epoch 1591: train loss = 4.110609, test loss = 12294.866972\n",
            "Epoch 1592: train loss = 4.110610, test loss = 12294.852886\n",
            "Epoch 1593: train loss = 4.110583, test loss = 12294.832976\n",
            "Epoch 1594: train loss = 4.110586, test loss = 12294.802141\n",
            "Epoch 1595: train loss = 4.110576, test loss = 12294.789865\n",
            "Epoch 1596: train loss = 4.110550, test loss = 12294.771242\n",
            "Epoch 1597: train loss = 4.110563, test loss = 12294.738152\n",
            "Epoch 1598: train loss = 4.110543, test loss = 12294.727328\n",
            "Epoch 1599: train loss = 4.110520, test loss = 12294.705219\n",
            "Epoch 1600: train loss = 4.110534, test loss = 12294.690274\n",
            "Epoch 1601: train loss = 4.110507, test loss = 12294.669854\n",
            "Epoch 1602: train loss = 4.110498, test loss = 12294.641148\n",
            "Epoch 1603: train loss = 4.110500, test loss = 12294.626328\n",
            "Epoch 1604: train loss = 4.110474, test loss = 12294.605873\n",
            "Epoch 1605: train loss = 4.110475, test loss = 12294.575213\n",
            "Epoch 1606: train loss = 4.110467, test loss = 12294.562187\n",
            "Epoch 1607: train loss = 4.110440, test loss = 12294.542589\n",
            "Epoch 1608: train loss = 4.110452, test loss = 12294.510420\n",
            "Epoch 1609: train loss = 4.110434, test loss = 12294.498709\n",
            "Epoch 1610: train loss = 4.110411, test loss = 12294.486655\n",
            "Epoch 1611: train loss = 4.110402, test loss = 12294.469451\n",
            "Epoch 1612: train loss = 4.110411, test loss = 12294.437306\n",
            "Epoch 1613: train loss = 4.110394, test loss = 12294.425941\n",
            "Epoch 1614: train loss = 4.110369, test loss = 12294.414224\n",
            "Epoch 1615: train loss = 4.110362, test loss = 12294.397115\n",
            "Epoch 1616: train loss = 4.110369, test loss = 12294.364659\n",
            "Epoch 1617: train loss = 4.110355, test loss = 12294.352798\n",
            "Epoch 1618: train loss = 4.110329, test loss = 12294.322873\n",
            "Epoch 1619: train loss = 4.110327, test loss = 12294.303361\n",
            "Epoch 1620: train loss = 4.110323, test loss = 12294.273548\n",
            "Epoch 1621: train loss = 4.110320, test loss = 12294.259691\n",
            "Epoch 1622: train loss = 4.110294, test loss = 12294.238741\n",
            "Epoch 1623: train loss = 4.110301, test loss = 12294.206154\n",
            "Epoch 1624: train loss = 4.110287, test loss = 12294.193328\n",
            "Epoch 1625: train loss = 4.110262, test loss = 12294.180843\n",
            "Epoch 1626: train loss = 4.110256, test loss = 12294.162471\n",
            "Epoch 1627: train loss = 4.110260, test loss = 12294.131307\n",
            "Epoch 1628: train loss = 4.110249, test loss = 12294.118211\n",
            "Epoch 1629: train loss = 4.110223, test loss = 12294.098178\n",
            "Epoch 1630: train loss = 4.110237, test loss = 12294.064031\n",
            "Epoch 1631: train loss = 4.110216, test loss = 12294.052535\n",
            "Epoch 1632: train loss = 4.110195, test loss = 12294.029742\n",
            "Epoch 1633: train loss = 4.110208, test loss = 12294.013639\n",
            "Epoch 1634: train loss = 4.110183, test loss = 12293.991759\n",
            "Epoch 1635: train loss = 4.110173, test loss = 12293.962252\n",
            "Epoch 1636: train loss = 4.110176, test loss = 12293.946648\n",
            "Epoch 1637: train loss = 4.110150, test loss = 12293.925178\n",
            "Epoch 1638: train loss = 4.110151, test loss = 12293.893667\n",
            "Epoch 1639: train loss = 4.110144, test loss = 12293.880111\n",
            "Epoch 1640: train loss = 4.110118, test loss = 12293.859118\n",
            "Epoch 1641: train loss = 4.110128, test loss = 12293.825645\n",
            "Epoch 1642: train loss = 4.110112, test loss = 12293.813014\n",
            "Epoch 1643: train loss = 4.110087, test loss = 12293.800434\n",
            "Epoch 1644: train loss = 4.110081, test loss = 12293.781987\n",
            "Epoch 1645: train loss = 4.110087, test loss = 12293.749306\n",
            "Epoch 1646: train loss = 4.110074, test loss = 12293.737113\n",
            "Epoch 1647: train loss = 4.110048, test loss = 12293.716709\n",
            "Epoch 1648: train loss = 4.110065, test loss = 12293.681526\n",
            "Epoch 1649: train loss = 4.110042, test loss = 12293.670046\n",
            "Epoch 1650: train loss = 4.110023, test loss = 12293.645998\n",
            "Epoch 1651: train loss = 4.110034, test loss = 12293.630095\n",
            "Epoch 1652: train loss = 4.110009, test loss = 12293.608599\n",
            "Epoch 1653: train loss = 4.110001, test loss = 12293.578053\n",
            "Epoch 1654: train loss = 4.110002, test loss = 12293.562139\n",
            "Epoch 1655: train loss = 4.109977, test loss = 12293.540399\n",
            "Epoch 1656: train loss = 4.109979, test loss = 12293.508011\n",
            "Epoch 1657: train loss = 4.109971, test loss = 12293.493865\n",
            "Epoch 1658: train loss = 4.109945, test loss = 12293.473320\n",
            "Epoch 1659: train loss = 4.109957, test loss = 12293.438900\n",
            "Epoch 1660: train loss = 4.109939, test loss = 12293.426090\n",
            "Epoch 1661: train loss = 4.109915, test loss = 12293.402754\n",
            "Epoch 1662: train loss = 4.109932, test loss = 12293.385431\n",
            "Epoch 1663: train loss = 4.109906, test loss = 12293.362791\n",
            "Epoch 1664: train loss = 4.109894, test loss = 12293.333966\n",
            "Epoch 1665: train loss = 4.109900, test loss = 12293.316662\n",
            "Epoch 1666: train loss = 4.109875, test loss = 12293.294144\n",
            "Epoch 1667: train loss = 4.109872, test loss = 12293.262770\n",
            "Epoch 1668: train loss = 4.109869, test loss = 12293.247399\n",
            "Epoch 1669: train loss = 4.109844, test loss = 12293.225739\n",
            "Epoch 1670: train loss = 4.109850, test loss = 12293.192676\n",
            "Epoch 1671: train loss = 4.109837, test loss = 12293.179191\n",
            "Epoch 1672: train loss = 4.109813, test loss = 12293.165458\n",
            "Epoch 1673: train loss = 4.109807, test loss = 12293.145830\n",
            "Epoch 1674: train loss = 4.109809, test loss = 12293.113877\n",
            "Epoch 1675: train loss = 4.109801, test loss = 12293.099631\n",
            "Epoch 1676: train loss = 4.109775, test loss = 12293.078349\n",
            "Epoch 1677: train loss = 4.109787, test loss = 12293.044074\n",
            "Epoch 1678: train loss = 4.109770, test loss = 12293.031452\n",
            "Epoch 1679: train loss = 4.109746, test loss = 12293.007463\n",
            "Epoch 1680: train loss = 4.109762, test loss = 12292.989903\n",
            "Epoch 1681: train loss = 4.109737, test loss = 12292.966725\n",
            "Epoch 1682: train loss = 4.109725, test loss = 12292.937177\n",
            "Epoch 1683: train loss = 4.109731, test loss = 12292.919889\n",
            "Epoch 1684: train loss = 4.109706, test loss = 12292.897423\n",
            "Epoch 1685: train loss = 4.109703, test loss = 12292.865707\n",
            "Epoch 1686: train loss = 4.109700, test loss = 12292.849781\n",
            "Epoch 1687: train loss = 4.109675, test loss = 12292.827578\n",
            "Epoch 1688: train loss = 4.109681, test loss = 12292.794433\n",
            "Epoch 1689: train loss = 4.109669, test loss = 12292.780062\n",
            "Epoch 1690: train loss = 4.109644, test loss = 12292.758992\n",
            "Epoch 1691: train loss = 4.109659, test loss = 12292.723951\n",
            "Epoch 1692: train loss = 4.109639, test loss = 12292.710744\n",
            "Epoch 1693: train loss = 4.109618, test loss = 12292.686561\n",
            "Epoch 1694: train loss = 4.109631, test loss = 12292.669056\n",
            "Epoch 1695: train loss = 4.109607, test loss = 12292.646184\n",
            "Epoch 1696: train loss = 4.109596, test loss = 12292.615956\n",
            "Epoch 1697: train loss = 4.109601, test loss = 12292.598436\n",
            "Epoch 1698: train loss = 4.109576, test loss = 12292.575299\n",
            "Epoch 1699: train loss = 4.109575, test loss = 12292.543473\n",
            "Epoch 1700: train loss = 4.109570, test loss = 12292.527531\n",
            "Epoch 1701: train loss = 4.109545, test loss = 12292.505167\n",
            "Epoch 1702: train loss = 4.109553, test loss = 12292.471725\n",
            "Epoch 1703: train loss = 4.109539, test loss = 12292.457631\n",
            "Epoch 1704: train loss = 4.109517, test loss = 12292.442882\n",
            "Epoch 1705: train loss = 4.109510, test loss = 12292.422902\n",
            "Epoch 1706: train loss = 4.109513, test loss = 12292.390556\n",
            "Epoch 1707: train loss = 4.109504, test loss = 12292.375604\n",
            "Epoch 1708: train loss = 4.109479, test loss = 12292.353764\n",
            "Epoch 1709: train loss = 4.109491, test loss = 12292.319110\n",
            "Epoch 1710: train loss = 4.109473, test loss = 12292.305693\n",
            "Epoch 1711: train loss = 4.109451, test loss = 12292.291356\n",
            "Epoch 1712: train loss = 4.109444, test loss = 12292.271373\n",
            "Epoch 1713: train loss = 4.109450, test loss = 12292.237884\n",
            "Epoch 1714: train loss = 4.109438, test loss = 12292.223527\n",
            "Epoch 1715: train loss = 4.109413, test loss = 12292.201828\n",
            "Epoch 1716: train loss = 4.109428, test loss = 12292.166558\n",
            "Epoch 1717: train loss = 4.109408, test loss = 12292.153095\n",
            "Epoch 1718: train loss = 4.109387, test loss = 12292.128047\n",
            "Epoch 1719: train loss = 4.109401, test loss = 12292.110317\n",
            "Epoch 1720: train loss = 4.109376, test loss = 12292.086679\n",
            "Epoch 1721: train loss = 4.109366, test loss = 12292.056001\n",
            "Epoch 1722: train loss = 4.109371, test loss = 12292.038765\n",
            "Epoch 1723: train loss = 4.109346, test loss = 12292.015113\n",
            "Epoch 1724: train loss = 4.109345, test loss = 12291.982469\n",
            "Epoch 1725: train loss = 4.109340, test loss = 12291.966158\n",
            "Epoch 1726: train loss = 4.109316, test loss = 12291.943450\n",
            "Epoch 1727: train loss = 4.109323, test loss = 12291.909357\n",
            "Epoch 1728: train loss = 4.109310, test loss = 12291.894888\n",
            "Epoch 1729: train loss = 4.109286, test loss = 12291.872549\n",
            "Epoch 1730: train loss = 4.109301, test loss = 12291.836766\n",
            "Epoch 1731: train loss = 4.109280, test loss = 12291.823078\n",
            "Epoch 1732: train loss = 4.109260, test loss = 12291.798201\n",
            "Epoch 1733: train loss = 4.109274, test loss = 12291.780114\n",
            "Epoch 1734: train loss = 4.109249, test loss = 12291.756201\n",
            "Epoch 1735: train loss = 4.109240, test loss = 12291.726067\n",
            "Epoch 1736: train loss = 4.109244, test loss = 12291.707725\n",
            "Epoch 1737: train loss = 4.109219, test loss = 12291.683873\n",
            "Epoch 1738: train loss = 4.109218, test loss = 12291.651468\n",
            "Epoch 1739: train loss = 4.109214, test loss = 12291.634780\n",
            "Epoch 1740: train loss = 4.109189, test loss = 12291.611746\n",
            "Epoch 1741: train loss = 4.109197, test loss = 12291.577861\n",
            "Epoch 1742: train loss = 4.109184, test loss = 12291.562949\n",
            "Epoch 1743: train loss = 4.109161, test loss = 12291.547590\n",
            "Epoch 1744: train loss = 4.109155, test loss = 12291.526952\n",
            "Epoch 1745: train loss = 4.109157, test loss = 12291.494250\n",
            "Epoch 1746: train loss = 4.109149, test loss = 12291.478466\n",
            "Epoch 1747: train loss = 4.109125, test loss = 12291.455943\n",
            "Epoch 1748: train loss = 4.109135, test loss = 12291.421435\n",
            "Epoch 1749: train loss = 4.109120, test loss = 12291.406505\n",
            "Epoch 1750: train loss = 4.109096, test loss = 12291.391673\n",
            "Epoch 1751: train loss = 4.109091, test loss = 12291.370965\n",
            "Epoch 1752: train loss = 4.109095, test loss = 12291.337430\n",
            "Epoch 1753: train loss = 4.109085, test loss = 12291.322152\n",
            "Epoch 1754: train loss = 4.109061, test loss = 12291.300073\n",
            "Epoch 1755: train loss = 4.109073, test loss = 12291.264166\n",
            "Epoch 1756: train loss = 4.109055, test loss = 12291.249784\n",
            "Epoch 1757: train loss = 4.109033, test loss = 12291.224735\n",
            "Epoch 1758: train loss = 4.109049, test loss = 12291.205975\n",
            "Epoch 1759: train loss = 4.109025, test loss = 12291.181606\n",
            "Epoch 1760: train loss = 4.109012, test loss = 12291.151006\n",
            "Epoch 1761: train loss = 4.109019, test loss = 12291.132734\n",
            "Epoch 1762: train loss = 4.108995, test loss = 12291.108288\n",
            "Epoch 1763: train loss = 4.108991, test loss = 12291.075842\n",
            "Epoch 1764: train loss = 4.108990, test loss = 12291.058495\n",
            "Epoch 1765: train loss = 4.108966, test loss = 12291.034952\n",
            "Epoch 1766: train loss = 4.108970, test loss = 12291.001133\n",
            "Epoch 1767: train loss = 4.108960, test loss = 12290.985115\n",
            "Epoch 1768: train loss = 4.108936, test loss = 12290.962266\n",
            "Epoch 1769: train loss = 4.108948, test loss = 12290.927358\n",
            "Epoch 1770: train loss = 4.108931, test loss = 12290.912361\n",
            "Epoch 1771: train loss = 4.108909, test loss = 12290.897127\n",
            "Epoch 1772: train loss = 4.108903, test loss = 12290.876418\n",
            "Epoch 1773: train loss = 4.108908, test loss = 12290.842429\n",
            "Epoch 1774: train loss = 4.108897, test loss = 12290.827426\n",
            "Epoch 1775: train loss = 4.108873, test loss = 12290.804564\n",
            "Epoch 1776: train loss = 4.108887, test loss = 12290.768313\n",
            "Epoch 1777: train loss = 4.108868, test loss = 12290.753871\n",
            "Epoch 1778: train loss = 4.108846, test loss = 12290.728639\n",
            "Epoch 1779: train loss = 4.108861, test loss = 12290.709670\n",
            "Epoch 1780: train loss = 4.108837, test loss = 12290.685597\n",
            "Epoch 1781: train loss = 4.108826, test loss = 12290.654382\n",
            "Epoch 1782: train loss = 4.108832, test loss = 12290.635290\n",
            "Epoch 1783: train loss = 4.108808, test loss = 12290.610931\n",
            "Epoch 1784: train loss = 4.108805, test loss = 12290.578209\n",
            "Epoch 1785: train loss = 4.108803, test loss = 12290.560712\n",
            "Epoch 1786: train loss = 4.108779, test loss = 12290.537070\n",
            "Epoch 1787: train loss = 4.108783, test loss = 12290.503339\n",
            "Epoch 1788: train loss = 4.108774, test loss = 12290.486860\n",
            "Epoch 1789: train loss = 4.108749, test loss = 12290.463703\n",
            "Epoch 1790: train loss = 4.108762, test loss = 12290.428018\n",
            "Epoch 1791: train loss = 4.108745, test loss = 12290.413012\n",
            "Epoch 1792: train loss = 4.108723, test loss = 12290.397700\n",
            "Epoch 1793: train loss = 4.108716, test loss = 12290.376708\n",
            "Epoch 1794: train loss = 4.108722, test loss = 12290.342756\n",
            "Epoch 1795: train loss = 4.108711, test loss = 12290.327438\n",
            "Epoch 1796: train loss = 4.108687, test loss = 12290.304223\n",
            "Epoch 1797: train loss = 4.108700, test loss = 12290.268014\n",
            "Epoch 1798: train loss = 4.108682, test loss = 12290.253150\n",
            "Epoch 1799: train loss = 4.108660, test loss = 12290.227833\n",
            "Epoch 1800: train loss = 4.108675, test loss = 12290.208647\n",
            "Epoch 1801: train loss = 4.108651, test loss = 12290.184160\n",
            "Epoch 1802: train loss = 4.108640, test loss = 12290.152969\n",
            "Epoch 1803: train loss = 4.108646, test loss = 12290.133610\n",
            "Epoch 1804: train loss = 4.108623, test loss = 12290.108852\n",
            "Epoch 1805: train loss = 4.108619, test loss = 12290.076217\n",
            "Epoch 1806: train loss = 4.108617, test loss = 12290.058343\n",
            "Epoch 1807: train loss = 4.108594, test loss = 12290.034727\n",
            "Epoch 1808: train loss = 4.108598, test loss = 12290.000466\n",
            "Epoch 1809: train loss = 4.108589, test loss = 12289.983716\n",
            "Epoch 1810: train loss = 4.108565, test loss = 12289.960238\n",
            "Epoch 1811: train loss = 4.108576, test loss = 12289.924754\n",
            "Epoch 1812: train loss = 4.108560, test loss = 12289.909263\n",
            "Epoch 1813: train loss = 4.108538, test loss = 12289.894117\n",
            "Epoch 1814: train loss = 4.108532, test loss = 12289.872752\n",
            "Epoch 1815: train loss = 4.108537, test loss = 12289.838610\n",
            "Epoch 1816: train loss = 4.108526, test loss = 12289.822454\n",
            "Epoch 1817: train loss = 4.108502, test loss = 12289.799331\n",
            "Epoch 1818: train loss = 4.108515, test loss = 12289.763183\n",
            "Epoch 1819: train loss = 4.108498, test loss = 12289.748058\n",
            "Epoch 1820: train loss = 4.108475, test loss = 12289.732697\n",
            "Epoch 1821: train loss = 4.108470, test loss = 12289.711825\n",
            "Epoch 1822: train loss = 4.108475, test loss = 12289.677028\n",
            "Epoch 1823: train loss = 4.108464, test loss = 12289.661052\n",
            "Epoch 1824: train loss = 4.108440, test loss = 12289.637795\n",
            "Epoch 1825: train loss = 4.108454, test loss = 12289.601234\n",
            "Epoch 1826: train loss = 4.108436, test loss = 12289.586217\n",
            "Epoch 1827: train loss = 4.108414, test loss = 12289.560589\n",
            "Epoch 1828: train loss = 4.108429, test loss = 12289.541578\n",
            "Epoch 1829: train loss = 4.108406, test loss = 12289.516240\n",
            "Epoch 1830: train loss = 4.108394, test loss = 12289.484807\n",
            "Epoch 1831: train loss = 4.108401, test loss = 12289.465304\n",
            "Epoch 1832: train loss = 4.108377, test loss = 12289.440331\n",
            "Epoch 1833: train loss = 4.108373, test loss = 12289.407456\n",
            "Epoch 1834: train loss = 4.108372, test loss = 12289.389714\n",
            "Epoch 1835: train loss = 4.108348, test loss = 12289.365207\n",
            "Epoch 1836: train loss = 4.108352, test loss = 12289.330792\n",
            "Epoch 1837: train loss = 4.108343, test loss = 12289.313755\n",
            "Epoch 1838: train loss = 4.108320, test loss = 12289.290227\n",
            "Epoch 1839: train loss = 4.108330, test loss = 12289.254520\n",
            "Epoch 1840: train loss = 4.108315, test loss = 12289.239117\n",
            "Epoch 1841: train loss = 4.108292, test loss = 12289.223248\n",
            "Epoch 1842: train loss = 4.108287, test loss = 12289.201588\n",
            "Epoch 1843: train loss = 4.108291, test loss = 12289.167306\n",
            "Epoch 1844: train loss = 4.108282, test loss = 12289.150881\n",
            "Epoch 1845: train loss = 4.108258, test loss = 12289.127438\n",
            "Epoch 1846: train loss = 4.108270, test loss = 12289.091181\n",
            "Epoch 1847: train loss = 4.108253, test loss = 12289.076136\n",
            "Epoch 1848: train loss = 4.108230, test loss = 12289.042959\n",
            "Epoch 1849: train loss = 4.108228, test loss = 12289.019269\n",
            "Epoch 1850: train loss = 4.108227, test loss = 12288.986317\n",
            "Epoch 1851: train loss = 4.108223, test loss = 12288.968025\n",
            "Epoch 1852: train loss = 4.108199, test loss = 12288.943608\n",
            "Epoch 1853: train loss = 4.108206, test loss = 12288.908749\n",
            "Epoch 1854: train loss = 4.108195, test loss = 12288.892052\n",
            "Epoch 1855: train loss = 4.108172, test loss = 12288.875393\n",
            "Epoch 1856: train loss = 4.108167, test loss = 12288.853318\n",
            "Epoch 1857: train loss = 4.108167, test loss = 12288.820078\n",
            "Epoch 1858: train loss = 4.108162, test loss = 12288.802561\n",
            "Epoch 1859: train loss = 4.108138, test loss = 12288.778583\n",
            "Epoch 1860: train loss = 4.108146, test loss = 12288.743721\n",
            "Epoch 1861: train loss = 4.108134, test loss = 12288.726961\n",
            "Epoch 1862: train loss = 4.108110, test loss = 12288.710786\n",
            "Epoch 1863: train loss = 4.108106, test loss = 12288.688801\n",
            "Epoch 1864: train loss = 4.108107, test loss = 12288.655256\n",
            "Epoch 1865: train loss = 4.108101, test loss = 12288.637971\n",
            "Epoch 1866: train loss = 4.108077, test loss = 12288.614534\n",
            "Epoch 1867: train loss = 4.108086, test loss = 12288.578692\n",
            "Epoch 1868: train loss = 4.108072, test loss = 12288.562267\n",
            "Epoch 1869: train loss = 4.108049, test loss = 12288.538839\n",
            "Epoch 1870: train loss = 4.108064, test loss = 12288.501885\n",
            "Epoch 1871: train loss = 4.108044, test loss = 12288.486674\n",
            "Epoch 1872: train loss = 4.108024, test loss = 12288.460672\n",
            "Epoch 1873: train loss = 4.108038, test loss = 12288.441038\n",
            "Epoch 1874: train loss = 4.108014, test loss = 12288.416101\n",
            "Epoch 1875: train loss = 4.108004, test loss = 12288.384211\n",
            "Epoch 1876: train loss = 4.108010, test loss = 12288.364264\n",
            "Epoch 1877: train loss = 4.107986, test loss = 12288.339127\n",
            "Epoch 1878: train loss = 4.107983, test loss = 12288.305925\n",
            "Epoch 1879: train loss = 4.107982, test loss = 12288.287348\n",
            "Epoch 1880: train loss = 4.107958, test loss = 12288.262916\n",
            "Epoch 1881: train loss = 4.107963, test loss = 12288.228799\n",
            "Epoch 1882: train loss = 4.107953, test loss = 12288.211193\n",
            "Epoch 1883: train loss = 4.107930, test loss = 12288.187227\n",
            "Epoch 1884: train loss = 4.107941, test loss = 12288.151312\n",
            "Epoch 1885: train loss = 4.107925, test loss = 12288.135091\n",
            "Epoch 1886: train loss = 4.107904, test loss = 12288.118919\n",
            "Epoch 1887: train loss = 4.107898, test loss = 12288.097531\n",
            "Epoch 1888: train loss = 4.107902, test loss = 12288.063166\n",
            "Epoch 1889: train loss = 4.107893, test loss = 12288.046226\n",
            "Epoch 1890: train loss = 4.107869, test loss = 12288.022283\n",
            "Epoch 1891: train loss = 4.107881, test loss = 12287.986101\n",
            "Epoch 1892: train loss = 4.107864, test loss = 12287.970197\n",
            "Epoch 1893: train loss = 4.107842, test loss = 12287.954516\n",
            "Epoch 1894: train loss = 4.107837, test loss = 12287.932416\n",
            "Epoch 1895: train loss = 4.107841, test loss = 12287.897798\n",
            "Epoch 1896: train loss = 4.107832, test loss = 12287.880867\n",
            "Epoch 1897: train loss = 4.107808, test loss = 12287.857099\n",
            "Epoch 1898: train loss = 4.107820, test loss = 12287.820628\n",
            "Epoch 1899: train loss = 4.107804, test loss = 12287.804695\n",
            "Epoch 1900: train loss = 4.107780, test loss = 12287.771880\n",
            "Epoch 1901: train loss = 4.107779, test loss = 12287.747744\n",
            "Epoch 1902: train loss = 4.107778, test loss = 12287.714343\n",
            "Epoch 1903: train loss = 4.107774, test loss = 12287.695774\n",
            "Epoch 1904: train loss = 4.107751, test loss = 12287.670911\n",
            "Epoch 1905: train loss = 4.107757, test loss = 12287.635747\n",
            "Epoch 1906: train loss = 4.107746, test loss = 12287.618393\n",
            "Epoch 1907: train loss = 4.107724, test loss = 12287.601580\n",
            "Epoch 1908: train loss = 4.107719, test loss = 12287.579648\n",
            "Epoch 1909: train loss = 4.107718, test loss = 12287.546134\n",
            "Epoch 1910: train loss = 4.107714, test loss = 12287.528008\n",
            "Epoch 1911: train loss = 4.107690, test loss = 12287.503587\n",
            "Epoch 1912: train loss = 4.107697, test loss = 12287.468180\n",
            "Epoch 1913: train loss = 4.107686, test loss = 12287.451282\n",
            "Epoch 1914: train loss = 4.107662, test loss = 12287.427801\n",
            "Epoch 1915: train loss = 4.107676, test loss = 12287.390801\n",
            "Epoch 1916: train loss = 4.107658, test loss = 12287.374882\n",
            "Epoch 1917: train loss = 4.107638, test loss = 12287.358517\n",
            "Epoch 1918: train loss = 4.107631, test loss = 12287.336641\n",
            "Epoch 1919: train loss = 4.107637, test loss = 12287.301856\n",
            "Epoch 1920: train loss = 4.107626, test loss = 12287.285595\n",
            "Epoch 1921: train loss = 4.107602, test loss = 12287.261457\n",
            "Epoch 1922: train loss = 4.107616, test loss = 12287.224495\n",
            "Epoch 1923: train loss = 4.107598, test loss = 12287.208669\n",
            "Epoch 1924: train loss = 4.107576, test loss = 12287.182519\n",
            "Epoch 1925: train loss = 4.107592, test loss = 12287.162273\n",
            "Epoch 1926: train loss = 4.107568, test loss = 12287.136408\n",
            "Epoch 1927: train loss = 4.107556, test loss = 12287.105359\n",
            "Epoch 1928: train loss = 4.107564, test loss = 12287.084760\n",
            "Epoch 1929: train loss = 4.107540, test loss = 12287.058932\n",
            "Epoch 1930: train loss = 4.107536, test loss = 12287.025887\n",
            "Epoch 1931: train loss = 4.107536, test loss = 12287.006802\n",
            "Epoch 1932: train loss = 4.107512, test loss = 12286.981746\n",
            "Epoch 1933: train loss = 4.107515, test loss = 12286.947463\n",
            "Epoch 1934: train loss = 4.107508, test loss = 12286.929629\n",
            "Epoch 1935: train loss = 4.107485, test loss = 12286.905566\n",
            "Epoch 1936: train loss = 4.107494, test loss = 12286.869715\n",
            "Epoch 1937: train loss = 4.107480, test loss = 12286.852792\n",
            "Epoch 1938: train loss = 4.107459, test loss = 12286.836216\n",
            "Epoch 1939: train loss = 4.107453, test loss = 12286.814062\n",
            "Epoch 1940: train loss = 4.107455, test loss = 12286.780200\n",
            "Epoch 1941: train loss = 4.107448, test loss = 12286.763073\n",
            "Epoch 1942: train loss = 4.107424, test loss = 12286.738572\n",
            "Epoch 1943: train loss = 4.107434, test loss = 12286.702541\n",
            "Epoch 1944: train loss = 4.107420, test loss = 12286.685867\n",
            "Epoch 1945: train loss = 4.107397, test loss = 12286.669552\n",
            "Epoch 1946: train loss = 4.107393, test loss = 12286.647194\n",
            "Epoch 1947: train loss = 4.107395, test loss = 12286.613508\n",
            "Epoch 1948: train loss = 4.107388, test loss = 12286.595791\n",
            "Epoch 1949: train loss = 4.107365, test loss = 12286.571322\n",
            "Epoch 1950: train loss = 4.107374, test loss = 12286.535198\n",
            "Epoch 1951: train loss = 4.107360, test loss = 12286.518522\n",
            "Epoch 1952: train loss = 4.107337, test loss = 12286.494806\n",
            "Epoch 1953: train loss = 4.107353, test loss = 12286.457413\n",
            "Epoch 1954: train loss = 4.107332, test loss = 12286.442219\n",
            "Epoch 1955: train loss = 4.107313, test loss = 12286.415548\n",
            "Epoch 1956: train loss = 4.107327, test loss = 12286.395400\n",
            "Epoch 1957: train loss = 4.107303, test loss = 12286.369538\n",
            "Epoch 1958: train loss = 4.107293, test loss = 12286.337582\n",
            "Epoch 1959: train loss = 4.107299, test loss = 12286.317414\n",
            "Epoch 1960: train loss = 4.107276, test loss = 12286.291741\n",
            "Epoch 1961: train loss = 4.107272, test loss = 12286.258322\n",
            "Epoch 1962: train loss = 4.107271, test loss = 12286.239680\n",
            "Epoch 1963: train loss = 4.107248, test loss = 12286.214510\n",
            "Epoch 1964: train loss = 4.107252, test loss = 12286.179672\n",
            "Epoch 1965: train loss = 4.107243, test loss = 12286.161768\n",
            "Epoch 1966: train loss = 4.107220, test loss = 12286.137411\n",
            "Epoch 1967: train loss = 4.107231, test loss = 12286.101408\n",
            "Epoch 1968: train loss = 4.107216, test loss = 12286.085059\n",
            "Epoch 1969: train loss = 4.107194, test loss = 12286.068278\n",
            "Epoch 1970: train loss = 4.107189, test loss = 12286.045950\n",
            "Epoch 1971: train loss = 4.107192, test loss = 12286.011584\n",
            "Epoch 1972: train loss = 4.107184, test loss = 12285.994100\n",
            "Epoch 1973: train loss = 4.107160, test loss = 12285.969861\n",
            "Epoch 1974: train loss = 4.107171, test loss = 12285.933963\n",
            "Epoch 1975: train loss = 4.107156, test loss = 12285.917174\n",
            "Epoch 1976: train loss = 4.107133, test loss = 12285.900608\n",
            "Epoch 1977: train loss = 4.107129, test loss = 12285.878201\n",
            "Epoch 1978: train loss = 4.107131, test loss = 12285.843709\n",
            "Epoch 1979: train loss = 4.107124, test loss = 12285.826175\n",
            "Epoch 1980: train loss = 4.107101, test loss = 12285.801910\n",
            "Epoch 1981: train loss = 4.107111, test loss = 12285.765957\n",
            "Epoch 1982: train loss = 4.107097, test loss = 12285.749070\n",
            "Epoch 1983: train loss = 4.107073, test loss = 12285.725136\n",
            "Epoch 1984: train loss = 4.107089, test loss = 12285.687411\n",
            "Epoch 1985: train loss = 4.107069, test loss = 12285.671809\n",
            "Epoch 1986: train loss = 4.107050, test loss = 12285.645136\n",
            "Epoch 1987: train loss = 4.107063, test loss = 12285.625034\n",
            "Epoch 1988: train loss = 4.107040, test loss = 12285.599342\n",
            "Epoch 1989: train loss = 4.107030, test loss = 12285.567501\n",
            "Epoch 1990: train loss = 4.107035, test loss = 12285.546965\n",
            "Epoch 1991: train loss = 4.107012, test loss = 12285.521267\n",
            "Epoch 1992: train loss = 4.107010, test loss = 12285.487500\n",
            "Epoch 1993: train loss = 4.107008, test loss = 12285.468408\n",
            "Epoch 1994: train loss = 4.106985, test loss = 12285.443456\n",
            "Epoch 1995: train loss = 4.106989, test loss = 12285.408895\n",
            "Epoch 1996: train loss = 4.106980, test loss = 12285.390779\n",
            "Epoch 1997: train loss = 4.106957, test loss = 12285.366235\n",
            "Epoch 1998: train loss = 4.106968, test loss = 12285.329948\n",
            "Epoch 1999: train loss = 4.106953, test loss = 12285.313122\n",
            "Epoch 2000: train loss = 4.106931, test loss = 12285.296551\n",
            "Epoch 2001: train loss = 4.106926, test loss = 12285.274553\n",
            "Epoch 2002: train loss = 4.106929, test loss = 12285.239965\n",
            "Epoch 2003: train loss = 4.106921, test loss = 12285.222287\n",
            "Epoch 2004: train loss = 4.106898, test loss = 12285.197763\n",
            "Epoch 2005: train loss = 4.106908, test loss = 12285.161408\n",
            "Epoch 2006: train loss = 4.106893, test loss = 12285.144783\n",
            "Epoch 2007: train loss = 4.106870, test loss = 12285.128295\n",
            "Epoch 2008: train loss = 4.106867, test loss = 12285.105822\n",
            "Epoch 2009: train loss = 4.106869, test loss = 12285.071700\n",
            "Epoch 2010: train loss = 4.106862, test loss = 12285.053750\n",
            "Epoch 2011: train loss = 4.106838, test loss = 12285.029263\n",
            "Epoch 2012: train loss = 4.106848, test loss = 12284.992671\n",
            "Epoch 2013: train loss = 4.106834, test loss = 12284.976027\n",
            "Epoch 2014: train loss = 4.106811, test loss = 12284.952102\n",
            "Epoch 2015: train loss = 4.106827, test loss = 12284.914291\n",
            "Epoch 2016: train loss = 4.106807, test loss = 12284.899077\n",
            "Epoch 2017: train loss = 4.106787, test loss = 12284.872055\n",
            "Epoch 2018: train loss = 4.106801, test loss = 12284.851746\n",
            "Epoch 2019: train loss = 4.106778, test loss = 12284.825850\n",
            "Epoch 2020: train loss = 4.106767, test loss = 12284.793537\n",
            "Epoch 2021: train loss = 4.106773, test loss = 12284.773172\n",
            "Epoch 2022: train loss = 4.106750, test loss = 12284.747857\n",
            "Epoch 2023: train loss = 4.106747, test loss = 12284.713831\n",
            "Epoch 2024: train loss = 4.106746, test loss = 12284.694542\n",
            "Epoch 2025: train loss = 4.106723, test loss = 12284.669392\n",
            "Epoch 2026: train loss = 4.106727, test loss = 12284.634286\n",
            "Epoch 2027: train loss = 4.106718, test loss = 12284.616420\n",
            "Epoch 2028: train loss = 4.106695, test loss = 12284.592299\n",
            "Epoch 2029: train loss = 4.106706, test loss = 12284.555721\n",
            "Epoch 2030: train loss = 4.106691, test loss = 12284.538773\n",
            "Epoch 2031: train loss = 4.106669, test loss = 12284.522059\n",
            "Epoch 2032: train loss = 4.106664, test loss = 12284.499457\n",
            "Epoch 2033: train loss = 4.106667, test loss = 12284.465125\n",
            "Epoch 2034: train loss = 4.106659, test loss = 12284.447410\n",
            "Epoch 2035: train loss = 4.106636, test loss = 12284.422829\n",
            "Epoch 2036: train loss = 4.106646, test loss = 12284.386995\n",
            "Epoch 2037: train loss = 4.106632, test loss = 12284.369896\n",
            "Epoch 2038: train loss = 4.106609, test loss = 12284.345626\n",
            "Epoch 2039: train loss = 4.106625, test loss = 12284.308036\n",
            "Epoch 2040: train loss = 4.106605, test loss = 12284.292114\n",
            "Epoch 2041: train loss = 4.106585, test loss = 12284.265489\n",
            "Epoch 2042: train loss = 4.106599, test loss = 12284.245217\n",
            "Epoch 2043: train loss = 4.106576, test loss = 12284.219530\n",
            "Epoch 2044: train loss = 4.106565, test loss = 12284.187144\n",
            "Epoch 2045: train loss = 4.106571, test loss = 12284.166587\n",
            "Epoch 2046: train loss = 4.106548, test loss = 12284.140574\n",
            "Epoch 2047: train loss = 4.106545, test loss = 12284.106981\n",
            "Epoch 2048: train loss = 4.106544, test loss = 12284.087739\n",
            "Epoch 2049: train loss = 4.106521, test loss = 12284.062811\n",
            "Epoch 2050: train loss = 4.106525, test loss = 12284.027729\n",
            "Epoch 2051: train loss = 4.106517, test loss = 12284.009443\n",
            "Epoch 2052: train loss = 4.106493, test loss = 12283.984753\n",
            "Epoch 2053: train loss = 4.106504, test loss = 12283.948664\n",
            "Epoch 2054: train loss = 4.106489, test loss = 12283.931575\n",
            "Epoch 2055: train loss = 4.106468, test loss = 12283.915087\n",
            "Epoch 2056: train loss = 4.106463, test loss = 12283.892367\n",
            "Epoch 2057: train loss = 4.106465, test loss = 12283.858030\n",
            "Epoch 2058: train loss = 4.106458, test loss = 12283.840111\n",
            "Epoch 2059: train loss = 4.106434, test loss = 12283.815505\n",
            "Epoch 2060: train loss = 4.106444, test loss = 12283.779294\n",
            "Epoch 2061: train loss = 4.106430, test loss = 12283.762297\n",
            "Epoch 2062: train loss = 4.106407, test loss = 12283.745627\n",
            "Epoch 2063: train loss = 4.106404, test loss = 12283.723357\n",
            "Epoch 2064: train loss = 4.106405, test loss = 12283.688783\n",
            "Epoch 2065: train loss = 4.106399, test loss = 12283.670646\n",
            "Epoch 2066: train loss = 4.106376, test loss = 12283.646039\n",
            "Epoch 2067: train loss = 4.106384, test loss = 12283.609786\n",
            "Epoch 2068: train loss = 4.106371, test loss = 12283.592655\n",
            "Epoch 2069: train loss = 4.106348, test loss = 12283.568552\n",
            "Epoch 2070: train loss = 4.106363, test loss = 12283.531463\n",
            "Epoch 2071: train loss = 4.106344, test loss = 12283.515081\n",
            "Epoch 2072: train loss = 4.106324, test loss = 12283.488446\n",
            "Epoch 2073: train loss = 4.106338, test loss = 12283.467854\n",
            "Epoch 2074: train loss = 4.106315, test loss = 12283.441611\n",
            "Epoch 2075: train loss = 4.106304, test loss = 12283.409638\n",
            "Epoch 2076: train loss = 4.106311, test loss = 12283.389269\n",
            "Epoch 2077: train loss = 4.106288, test loss = 12283.363038\n",
            "Epoch 2078: train loss = 4.106284, test loss = 12283.329481\n",
            "Epoch 2079: train loss = 4.106284, test loss = 12283.309834\n",
            "Epoch 2080: train loss = 4.106261, test loss = 12283.284478\n",
            "Epoch 2081: train loss = 4.106263, test loss = 12283.249815\n",
            "Epoch 2082: train loss = 4.106256, test loss = 12283.231391\n",
            "Epoch 2083: train loss = 4.106233, test loss = 12283.207052\n",
            "Epoch 2084: train loss = 4.106243, test loss = 12283.170877\n",
            "Epoch 2085: train loss = 4.106229, test loss = 12283.153412\n",
            "Epoch 2086: train loss = 4.106207, test loss = 12283.136438\n",
            "Epoch 2087: train loss = 4.106203, test loss = 12283.113760\n",
            "Epoch 2088: train loss = 4.106204, test loss = 12283.079766\n",
            "Epoch 2089: train loss = 4.106198, test loss = 12283.061669\n",
            "Epoch 2090: train loss = 4.106174, test loss = 12283.036900\n",
            "Epoch 2091: train loss = 4.106183, test loss = 12283.001321\n",
            "Epoch 2092: train loss = 4.106170, test loss = 12282.983834\n",
            "Epoch 2093: train loss = 4.106147, test loss = 12282.959371\n",
            "Epoch 2094: train loss = 4.106162, test loss = 12282.922082\n",
            "Epoch 2095: train loss = 4.106143, test loss = 12282.905844\n",
            "Epoch 2096: train loss = 4.106123, test loss = 12282.889074\n",
            "Epoch 2097: train loss = 4.106117, test loss = 12282.867229\n",
            "Epoch 2098: train loss = 4.106123, test loss = 12282.831606\n",
            "Epoch 2099: train loss = 4.106112, test loss = 12282.814241\n",
            "Epoch 2100: train loss = 4.106088, test loss = 12282.789893\n",
            "Epoch 2101: train loss = 4.106102, test loss = 12282.752511\n",
            "Epoch 2102: train loss = 4.106084, test loss = 12282.736242\n",
            "Epoch 2103: train loss = 4.106063, test loss = 12282.710236\n",
            "Epoch 2104: train loss = 4.106079, test loss = 12282.688988\n",
            "Epoch 2105: train loss = 4.106056, test loss = 12282.662616\n",
            "Epoch 2106: train loss = 4.106043, test loss = 12282.630742\n",
            "Epoch 2107: train loss = 4.106051, test loss = 12282.609633\n",
            "Epoch 2108: train loss = 4.106029, test loss = 12282.583539\n",
            "Epoch 2109: train loss = 4.106023, test loss = 12282.550292\n",
            "Epoch 2110: train loss = 4.106024, test loss = 12282.530835\n",
            "Epoch 2111: train loss = 4.106001, test loss = 12282.505105\n",
            "Epoch 2112: train loss = 4.106002, test loss = 12282.470416\n",
            "Epoch 2113: train loss = 4.105997, test loss = 12282.451785\n",
            "Epoch 2114: train loss = 4.105974, test loss = 12282.426872\n",
            "Epoch 2115: train loss = 4.105982, test loss = 12282.391060\n",
            "Epoch 2116: train loss = 4.105970, test loss = 12282.373574\n",
            "Epoch 2117: train loss = 4.105947, test loss = 12282.356621\n",
            "Epoch 2118: train loss = 4.105943, test loss = 12282.334193\n",
            "Epoch 2119: train loss = 4.105943, test loss = 12282.300161\n",
            "Epoch 2120: train loss = 4.105938, test loss = 12282.281706\n",
            "Epoch 2121: train loss = 4.105915, test loss = 12282.256678\n",
            "Epoch 2122: train loss = 4.105922, test loss = 12282.220938\n",
            "Epoch 2123: train loss = 4.105911, test loss = 12282.203474\n",
            "Epoch 2124: train loss = 4.105888, test loss = 12282.179338\n",
            "Epoch 2125: train loss = 4.105901, test loss = 12282.142088\n",
            "Epoch 2126: train loss = 4.105884, test loss = 12282.125425\n",
            "Epoch 2127: train loss = 4.105863, test loss = 12282.108678\n",
            "Epoch 2128: train loss = 4.105857, test loss = 12282.086222\n",
            "Epoch 2129: train loss = 4.105862, test loss = 12282.051046\n",
            "Epoch 2130: train loss = 4.105853, test loss = 12282.034018\n",
            "Epoch 2131: train loss = 4.105830, test loss = 12282.009288\n",
            "Epoch 2132: train loss = 4.105842, test loss = 12281.972087\n",
            "Epoch 2133: train loss = 4.105826, test loss = 12281.955450\n",
            "Epoch 2134: train loss = 4.105803, test loss = 12281.938929\n",
            "Epoch 2135: train loss = 4.105799, test loss = 12281.916180\n",
            "Epoch 2136: train loss = 4.105803, test loss = 12281.880991\n",
            "Epoch 2137: train loss = 4.105794, test loss = 12281.863837\n",
            "Epoch 2138: train loss = 4.105771, test loss = 12281.838967\n",
            "Epoch 2139: train loss = 4.105782, test loss = 12281.801833\n",
            "Epoch 2140: train loss = 4.105767, test loss = 12281.785007\n",
            "Epoch 2141: train loss = 4.105744, test loss = 12281.751013\n",
            "Epoch 2142: train loss = 4.105742, test loss = 12281.726494\n",
            "Epoch 2143: train loss = 4.105740, test loss = 12281.692685\n",
            "Epoch 2144: train loss = 4.105738, test loss = 12281.673336\n",
            "Epoch 2145: train loss = 4.105715, test loss = 12281.648272\n",
            "Epoch 2146: train loss = 4.105720, test loss = 12281.612388\n",
            "Epoch 2147: train loss = 4.105711, test loss = 12281.594050\n",
            "Epoch 2148: train loss = 4.105688, test loss = 12281.569088\n",
            "Epoch 2149: train loss = 4.105700, test loss = 12281.532325\n",
            "Epoch 2150: train loss = 4.105684, test loss = 12281.515217\n",
            "Epoch 2151: train loss = 4.105664, test loss = 12281.498123\n",
            "Epoch 2152: train loss = 4.105658, test loss = 12281.475780\n",
            "Epoch 2153: train loss = 4.105661, test loss = 12281.440991\n",
            "Epoch 2154: train loss = 4.105653, test loss = 12281.422824\n",
            "Epoch 2155: train loss = 4.105630, test loss = 12281.398058\n",
            "Epoch 2156: train loss = 4.105640, test loss = 12281.361505\n",
            "Epoch 2157: train loss = 4.105626, test loss = 12281.344358\n",
            "Epoch 2158: train loss = 4.105603, test loss = 12281.327964\n",
            "Epoch 2159: train loss = 4.105599, test loss = 12281.304957\n",
            "Epoch 2160: train loss = 4.105602, test loss = 12281.270075\n",
            "Epoch 2161: train loss = 4.105595, test loss = 12281.252046\n",
            "Epoch 2162: train loss = 4.105572, test loss = 12281.227279\n",
            "Epoch 2163: train loss = 4.105581, test loss = 12281.190676\n",
            "Epoch 2164: train loss = 4.105568, test loss = 12281.174018\n",
            "Epoch 2165: train loss = 4.105544, test loss = 12281.149407\n",
            "Epoch 2166: train loss = 4.105560, test loss = 12281.111545\n",
            "Epoch 2167: train loss = 4.105540, test loss = 12281.095398\n",
            "Epoch 2168: train loss = 4.105521, test loss = 12281.068517\n",
            "Epoch 2169: train loss = 4.105535, test loss = 12281.047910\n",
            "Epoch 2170: train loss = 4.105512, test loss = 12281.021680\n",
            "Epoch 2171: train loss = 4.105501, test loss = 12280.989326\n",
            "Epoch 2172: train loss = 4.105508, test loss = 12280.969037\n",
            "Epoch 2173: train loss = 4.105485, test loss = 12280.942659\n",
            "Epoch 2174: train loss = 4.105481, test loss = 12280.908804\n",
            "Epoch 2175: train loss = 4.105481, test loss = 12280.889175\n",
            "Epoch 2176: train loss = 4.105458, test loss = 12280.863678\n",
            "Epoch 2177: train loss = 4.105461, test loss = 12280.828686\n",
            "Epoch 2178: train loss = 4.105453, test loss = 12280.810318\n",
            "Epoch 2179: train loss = 4.105430, test loss = 12280.785719\n",
            "Epoch 2180: train loss = 4.105440, test loss = 12280.749437\n",
            "Epoch 2181: train loss = 4.105426, test loss = 12280.731961\n",
            "Epoch 2182: train loss = 4.105405, test loss = 12280.714769\n",
            "Epoch 2183: train loss = 4.105400, test loss = 12280.692006\n",
            "Epoch 2184: train loss = 4.105401, test loss = 12280.657915\n",
            "Epoch 2185: train loss = 4.105395, test loss = 12280.639969\n",
            "Epoch 2186: train loss = 4.105372, test loss = 12280.614911\n",
            "Epoch 2187: train loss = 4.105381, test loss = 12280.578704\n",
            "Epoch 2188: train loss = 4.105368, test loss = 12280.561157\n",
            "Epoch 2189: train loss = 4.105345, test loss = 12280.536733\n",
            "Epoch 2190: train loss = 4.105360, test loss = 12280.499348\n",
            "Epoch 2191: train loss = 4.105341, test loss = 12280.482987\n",
            "Epoch 2192: train loss = 4.105321, test loss = 12280.466623\n",
            "Epoch 2193: train loss = 4.105315, test loss = 12280.443864\n",
            "Epoch 2194: train loss = 4.105321, test loss = 12280.408357\n",
            "Epoch 2195: train loss = 4.105310, test loss = 12280.390943\n",
            "Epoch 2196: train loss = 4.105287, test loss = 12280.366397\n",
            "Epoch 2197: train loss = 4.105300, test loss = 12280.329120\n",
            "Epoch 2198: train loss = 4.105283, test loss = 12280.312609\n",
            "Epoch 2199: train loss = 4.105261, test loss = 12280.286099\n",
            "Epoch 2200: train loss = 4.105277, test loss = 12280.265444\n",
            "Epoch 2201: train loss = 4.105254, test loss = 12280.238736\n",
            "Epoch 2202: train loss = 4.105241, test loss = 12280.206733\n",
            "Epoch 2203: train loss = 4.105250, test loss = 12280.185523\n",
            "Epoch 2204: train loss = 4.105227, test loss = 12280.159113\n",
            "Epoch 2205: train loss = 4.105221, test loss = 12280.125945\n",
            "Epoch 2206: train loss = 4.105223, test loss = 12280.106368\n",
            "Epoch 2207: train loss = 4.105200, test loss = 12280.080335\n",
            "Epoch 2208: train loss = 4.105201, test loss = 12280.045837\n",
            "Epoch 2209: train loss = 4.105196, test loss = 12280.026974\n",
            "Epoch 2210: train loss = 4.105173, test loss = 12280.001762\n",
            "Epoch 2211: train loss = 4.105180, test loss = 12279.966167\n",
            "Epoch 2212: train loss = 4.105169, test loss = 12279.948853\n",
            "Epoch 2213: train loss = 4.105146, test loss = 12279.931485\n",
            "Epoch 2214: train loss = 4.105143, test loss = 12279.908412\n",
            "Epoch 2215: train loss = 4.105142, test loss = 12279.874558\n",
            "Epoch 2216: train loss = 4.105138, test loss = 12279.855934\n",
            "Epoch 2217: train loss = 4.105115, test loss = 12279.830940\n",
            "Epoch 2218: train loss = 4.105121, test loss = 12279.795185\n",
            "Epoch 2219: train loss = 4.105111, test loss = 12279.777886\n",
            "Epoch 2220: train loss = 4.105088, test loss = 12279.753067\n",
            "Epoch 2221: train loss = 4.105100, test loss = 12279.715936\n",
            "Epoch 2222: train loss = 4.105084, test loss = 12279.699170\n",
            "Epoch 2223: train loss = 4.105062, test loss = 12279.682407\n",
            "Epoch 2224: train loss = 4.105057, test loss = 12279.659679\n",
            "Epoch 2225: train loss = 4.105061, test loss = 12279.624710\n",
            "Epoch 2226: train loss = 4.105053, test loss = 12279.607051\n",
            "Epoch 2227: train loss = 4.105030, test loss = 12279.582713\n",
            "Epoch 2228: train loss = 4.105041, test loss = 12279.545598\n",
            "Epoch 2229: train loss = 4.105026, test loss = 12279.528577\n",
            "Epoch 2230: train loss = 4.105003, test loss = 12279.504349\n",
            "Epoch 2231: train loss = 4.105020, test loss = 12279.466237\n",
            "Epoch 2232: train loss = 4.104999, test loss = 12279.450295\n",
            "Epoch 2233: train loss = 4.104980, test loss = 12279.423636\n",
            "Epoch 2234: train loss = 4.104993, test loss = 12279.402989\n",
            "Epoch 2235: train loss = 4.104970, test loss = 12279.376650\n",
            "Epoch 2236: train loss = 4.104961, test loss = 12279.344040\n",
            "Epoch 2237: train loss = 4.104966, test loss = 12279.323430\n",
            "Epoch 2238: train loss = 4.104943, test loss = 12279.297315\n",
            "Epoch 2239: train loss = 4.104941, test loss = 12279.263764\n",
            "Epoch 2240: train loss = 4.104939, test loss = 12279.244065\n",
            "Epoch 2241: train loss = 4.104916, test loss = 12279.218438\n",
            "Epoch 2242: train loss = 4.104920, test loss = 12279.183222\n",
            "Epoch 2243: train loss = 4.104912, test loss = 12279.164829\n",
            "Epoch 2244: train loss = 4.104889, test loss = 12279.140019\n",
            "Epoch 2245: train loss = 4.104900, test loss = 12279.103640\n",
            "Epoch 2246: train loss = 4.104885, test loss = 12279.086747\n",
            "Epoch 2247: train loss = 4.104864, test loss = 12279.069439\n",
            "Epoch 2248: train loss = 4.104859, test loss = 12279.046604\n",
            "Epoch 2249: train loss = 4.104861, test loss = 12279.012053\n",
            "Epoch 2250: train loss = 4.104854, test loss = 12278.993966\n",
            "Epoch 2251: train loss = 4.104831, test loss = 12278.969131\n",
            "Epoch 2252: train loss = 4.104840, test loss = 12278.932688\n",
            "Epoch 2253: train loss = 4.104827, test loss = 12278.915484\n",
            "Epoch 2254: train loss = 4.104804, test loss = 12278.898943\n",
            "Epoch 2255: train loss = 4.104801, test loss = 12278.875790\n",
            "Epoch 2256: train loss = 4.104802, test loss = 12278.841258\n",
            "Epoch 2257: train loss = 4.104796, test loss = 12278.822876\n",
            "Epoch 2258: train loss = 4.104773, test loss = 12278.797999\n",
            "Epoch 2259: train loss = 4.104781, test loss = 12278.761712\n",
            "Epoch 2260: train loss = 4.104769, test loss = 12278.744665\n",
            "Epoch 2261: train loss = 4.104746, test loss = 12278.719989\n",
            "Epoch 2262: train loss = 4.104760, test loss = 12278.682358\n",
            "Epoch 2263: train loss = 4.104742, test loss = 12278.665850\n",
            "Epoch 2264: train loss = 4.104721, test loss = 12278.639207\n",
            "Epoch 2265: train loss = 4.104736, test loss = 12278.618364\n",
            "Epoch 2266: train loss = 4.104714, test loss = 12278.592287\n",
            "Epoch 2267: train loss = 4.104702, test loss = 12278.559984\n",
            "Epoch 2268: train loss = 4.104710, test loss = 12278.538770\n",
            "Epoch 2269: train loss = 4.104687, test loss = 12278.512482\n",
            "Epoch 2270: train loss = 4.104682, test loss = 12278.479011\n",
            "Epoch 2271: train loss = 4.104683, test loss = 12278.459092\n",
            "Epoch 2272: train loss = 4.104660, test loss = 12278.433479\n",
            "Epoch 2273: train loss = 4.104661, test loss = 12278.398835\n",
            "Epoch 2274: train loss = 4.104655, test loss = 12278.380454\n",
            "Epoch 2275: train loss = 4.104633, test loss = 12278.355176\n",
            "Epoch 2276: train loss = 4.104641, test loss = 12278.319196\n",
            "Epoch 2277: train loss = 4.104628, test loss = 12278.301461\n",
            "Epoch 2278: train loss = 4.104606, test loss = 12278.284375\n",
            "Epoch 2279: train loss = 4.104602, test loss = 12278.261357\n",
            "Epoch 2280: train loss = 4.104602, test loss = 12278.227487\n",
            "Epoch 2281: train loss = 4.104598, test loss = 12278.209006\n",
            "Epoch 2282: train loss = 4.104575, test loss = 12278.184288\n",
            "Epoch 2283: train loss = 4.104582, test loss = 12278.148261\n",
            "Epoch 2284: train loss = 4.104571, test loss = 12278.130479\n",
            "Epoch 2285: train loss = 4.104548, test loss = 12278.105751\n",
            "Epoch 2286: train loss = 4.104561, test loss = 12278.068674\n",
            "Epoch 2287: train loss = 4.104544, test loss = 12278.052043\n",
            "Epoch 2288: train loss = 4.104523, test loss = 12278.035502\n",
            "Epoch 2289: train loss = 4.104517, test loss = 12278.012714\n",
            "Epoch 2290: train loss = 4.104522, test loss = 12277.977450\n",
            "Epoch 2291: train loss = 4.104513, test loss = 12277.959636\n",
            "Epoch 2292: train loss = 4.104490, test loss = 12277.935014\n",
            "Epoch 2293: train loss = 4.104501, test loss = 12277.897928\n",
            "Epoch 2294: train loss = 4.104486, test loss = 12277.881556\n",
            "Epoch 2295: train loss = 4.104463, test loss = 12277.857140\n",
            "Epoch 2296: train loss = 4.104481, test loss = 12277.818672\n",
            "Epoch 2297: train loss = 4.104459, test loss = 12277.802800\n",
            "Epoch 2298: train loss = 4.104441, test loss = 12277.775588\n",
            "Epoch 2299: train loss = 4.104453, test loss = 12277.755182\n",
            "Epoch 2300: train loss = 4.104430, test loss = 12277.729053\n",
            "Epoch 2301: train loss = 4.104422, test loss = 12277.696790\n",
            "Epoch 2302: train loss = 4.104426, test loss = 12277.675887\n",
            "Epoch 2303: train loss = 4.104404, test loss = 12277.649730\n",
            "Epoch 2304: train loss = 4.104402, test loss = 12277.615528\n",
            "Epoch 2305: train loss = 4.104399, test loss = 12277.596126\n",
            "Epoch 2306: train loss = 4.104377, test loss = 12277.570684\n",
            "Epoch 2307: train loss = 4.104381, test loss = 12277.535290\n",
            "Epoch 2308: train loss = 4.104372, test loss = 12277.517096\n",
            "Epoch 2309: train loss = 4.104350, test loss = 12277.492615\n",
            "Epoch 2310: train loss = 4.104361, test loss = 12277.455817\n",
            "Epoch 2311: train loss = 4.104346, test loss = 12277.438515\n",
            "Epoch 2312: train loss = 4.104325, test loss = 12277.421322\n",
            "Epoch 2313: train loss = 4.104319, test loss = 12277.398489\n",
            "Epoch 2314: train loss = 4.104322, test loss = 12277.364075\n",
            "Epoch 2315: train loss = 4.104315, test loss = 12277.346362\n",
            "Epoch 2316: train loss = 4.104292, test loss = 12277.321194\n",
            "Epoch 2317: train loss = 4.104302, test loss = 12277.284673\n",
            "Epoch 2318: train loss = 4.104288, test loss = 12277.267255\n",
            "Epoch 2319: train loss = 4.104265, test loss = 12277.250356\n",
            "Epoch 2320: train loss = 4.104262, test loss = 12277.227474\n",
            "Epoch 2321: train loss = 4.104263, test loss = 12277.193279\n",
            "Epoch 2322: train loss = 4.104257, test loss = 12277.174842\n",
            "Epoch 2323: train loss = 4.104234, test loss = 12277.149817\n",
            "Epoch 2324: train loss = 4.104242, test loss = 12277.113267\n",
            "Epoch 2325: train loss = 4.104230, test loss = 12277.095912\n",
            "Epoch 2326: train loss = 4.104207, test loss = 12277.071497\n",
            "Epoch 2327: train loss = 4.104222, test loss = 12277.033785\n",
            "Epoch 2328: train loss = 4.104203, test loss = 12277.017460\n",
            "Epoch 2329: train loss = 4.104182, test loss = 12276.991240\n",
            "Epoch 2330: train loss = 4.104198, test loss = 12276.969968\n",
            "Epoch 2331: train loss = 4.104175, test loss = 12276.943461\n",
            "Epoch 2332: train loss = 4.104163, test loss = 12276.911262\n",
            "Epoch 2333: train loss = 4.104171, test loss = 12276.890214\n",
            "Epoch 2334: train loss = 4.104148, test loss = 12276.863941\n",
            "Epoch 2335: train loss = 4.104143, test loss = 12276.830384\n",
            "Epoch 2336: train loss = 4.104144, test loss = 12276.810931\n",
            "Epoch 2337: train loss = 4.104121, test loss = 12276.785023\n",
            "Epoch 2338: train loss = 4.104123, test loss = 12276.750146\n",
            "Epoch 2339: train loss = 4.104117, test loss = 12276.731397\n",
            "Epoch 2340: train loss = 4.104094, test loss = 12276.706298\n",
            "Epoch 2341: train loss = 4.104102, test loss = 12276.670334\n",
            "Epoch 2342: train loss = 4.104090, test loss = 12276.653113\n",
            "Epoch 2343: train loss = 4.104068, test loss = 12276.635715\n",
            "Epoch 2344: train loss = 4.104064, test loss = 12276.612594\n",
            "Epoch 2345: train loss = 4.104064, test loss = 12276.578656\n",
            "Epoch 2346: train loss = 4.104059, test loss = 12276.559991\n",
            "Epoch 2347: train loss = 4.104036, test loss = 12276.535013\n",
            "Epoch 2348: train loss = 4.104043, test loss = 12276.499586\n",
            "Epoch 2349: train loss = 4.104032, test loss = 12276.481510\n",
            "Epoch 2350: train loss = 4.104009, test loss = 12276.456838\n",
            "Epoch 2351: train loss = 4.104023, test loss = 12276.419693\n",
            "Epoch 2352: train loss = 4.104005, test loss = 12276.402871\n",
            "Epoch 2353: train loss = 4.103984, test loss = 12276.386041\n",
            "Epoch 2354: train loss = 4.103979, test loss = 12276.363442\n",
            "Epoch 2355: train loss = 4.103984, test loss = 12276.328200\n",
            "Epoch 2356: train loss = 4.103974, test loss = 12276.311007\n",
            "Epoch 2357: train loss = 4.103951, test loss = 12276.285990\n",
            "Epoch 2358: train loss = 4.103963, test loss = 12276.248858\n",
            "Epoch 2359: train loss = 4.103947, test loss = 12276.232005\n",
            "Epoch 2360: train loss = 4.103925, test loss = 12276.215202\n",
            "Epoch 2361: train loss = 4.103921, test loss = 12276.192360\n",
            "Epoch 2362: train loss = 4.103924, test loss = 12276.157242\n",
            "Epoch 2363: train loss = 4.103917, test loss = 12276.139684\n",
            "Epoch 2364: train loss = 4.103894, test loss = 12276.114712\n",
            "Epoch 2365: train loss = 4.103904, test loss = 12276.077661\n",
            "Epoch 2366: train loss = 4.103890, test loss = 12276.060535\n",
            "Epoch 2367: train loss = 4.103867, test loss = 12276.036251\n",
            "Epoch 2368: train loss = 4.103883, test loss = 12275.998122\n",
            "Epoch 2369: train loss = 4.103863, test loss = 12275.982433\n",
            "Epoch 2370: train loss = 4.103844, test loss = 12275.955040\n",
            "Epoch 2371: train loss = 4.103858, test loss = 12275.934379\n",
            "Epoch 2372: train loss = 4.103835, test loss = 12275.908110\n",
            "Epoch 2373: train loss = 4.103824, test loss = 12275.875474\n",
            "Epoch 2374: train loss = 4.103831, test loss = 12275.854710\n",
            "Epoch 2375: train loss = 4.103808, test loss = 12275.828599\n",
            "Epoch 2376: train loss = 4.103804, test loss = 12275.795005\n",
            "Epoch 2377: train loss = 4.103804, test loss = 12275.775130\n",
            "Epoch 2378: train loss = 4.103781, test loss = 12275.749508\n",
            "Epoch 2379: train loss = 4.103784, test loss = 12275.714253\n",
            "Epoch 2380: train loss = 4.103777, test loss = 12275.695775\n",
            "Epoch 2381: train loss = 4.103754, test loss = 12275.670838\n",
            "Epoch 2382: train loss = 4.103764, test loss = 12275.634356\n",
            "Epoch 2383: train loss = 4.103750, test loss = 12275.617052\n",
            "Epoch 2384: train loss = 4.103728, test loss = 12275.600579\n",
            "Epoch 2385: train loss = 4.103724, test loss = 12275.577283\n",
            "Epoch 2386: train loss = 4.103725, test loss = 12275.542781\n",
            "Epoch 2387: train loss = 4.103719, test loss = 12275.524453\n",
            "Epoch 2388: train loss = 4.103696, test loss = 12275.499407\n",
            "Epoch 2389: train loss = 4.103705, test loss = 12275.463091\n",
            "Epoch 2390: train loss = 4.103692, test loss = 12275.445731\n",
            "Epoch 2391: train loss = 4.103669, test loss = 12275.421545\n",
            "Epoch 2392: train loss = 4.103684, test loss = 12275.383808\n",
            "Epoch 2393: train loss = 4.103666, test loss = 12275.367279\n",
            "Epoch 2394: train loss = 4.103645, test loss = 12275.340482\n",
            "Epoch 2395: train loss = 4.103660, test loss = 12275.319529\n",
            "Epoch 2396: train loss = 4.103637, test loss = 12275.293029\n",
            "Epoch 2397: train loss = 4.103625, test loss = 12275.261435\n",
            "Epoch 2398: train loss = 4.103633, test loss = 12275.240108\n",
            "Epoch 2399: train loss = 4.103611, test loss = 12275.213571\n",
            "Epoch 2400: train loss = 4.103605, test loss = 12275.180102\n",
            "Epoch 2401: train loss = 4.103606, test loss = 12275.160197\n",
            "Epoch 2402: train loss = 4.103584, test loss = 12275.134395\n",
            "Epoch 2403: train loss = 4.103585, test loss = 12275.100213\n",
            "Epoch 2404: train loss = 4.103580, test loss = 12275.081199\n",
            "Epoch 2405: train loss = 4.103557, test loss = 12275.055842\n",
            "Epoch 2406: train loss = 4.103565, test loss = 12275.019974\n",
            "Epoch 2407: train loss = 4.103553, test loss = 12275.002198\n",
            "Epoch 2408: train loss = 4.103531, test loss = 12274.985033\n",
            "Epoch 2409: train loss = 4.103527, test loss = 12274.962096\n",
            "Epoch 2410: train loss = 4.103526, test loss = 12274.928169\n",
            "Epoch 2411: train loss = 4.103522, test loss = 12274.910043\n",
            "Epoch 2412: train loss = 4.103499, test loss = 12274.884702\n",
            "Epoch 2413: train loss = 4.103506, test loss = 12274.848735\n",
            "Epoch 2414: train loss = 4.103495, test loss = 12274.830939\n",
            "Epoch 2415: train loss = 4.103472, test loss = 12274.806285\n",
            "Epoch 2416: train loss = 4.103485, test loss = 12274.769150\n",
            "Epoch 2417: train loss = 4.103468, test loss = 12274.752450\n",
            "Epoch 2418: train loss = 4.103448, test loss = 12274.735927\n",
            "Epoch 2419: train loss = 4.103442, test loss = 12274.712992\n",
            "Epoch 2420: train loss = 4.103447, test loss = 12274.677834\n",
            "Epoch 2421: train loss = 4.103437, test loss = 12274.659941\n",
            "Epoch 2422: train loss = 4.103414, test loss = 12274.635257\n",
            "Epoch 2423: train loss = 4.103426, test loss = 12274.598342\n",
            "Epoch 2424: train loss = 4.103411, test loss = 12274.581736\n",
            "Epoch 2425: train loss = 4.103388, test loss = 12274.564817\n",
            "Epoch 2426: train loss = 4.103384, test loss = 12274.541819\n",
            "Epoch 2427: train loss = 4.103387, test loss = 12274.506583\n",
            "Epoch 2428: train loss = 4.103380, test loss = 12274.488661\n",
            "Epoch 2429: train loss = 4.103357, test loss = 12274.463929\n",
            "Epoch 2430: train loss = 4.103367, test loss = 12274.426931\n",
            "Epoch 2431: train loss = 4.103353, test loss = 12274.410338\n",
            "Epoch 2432: train loss = 4.103330, test loss = 12274.385693\n",
            "Epoch 2433: train loss = 4.103346, test loss = 12274.347499\n",
            "Epoch 2434: train loss = 4.103326, test loss = 12274.331396\n",
            "Epoch 2435: train loss = 4.103307, test loss = 12274.304236\n",
            "Epoch 2436: train loss = 4.103321, test loss = 12274.283685\n",
            "Epoch 2437: train loss = 4.103298, test loss = 12274.257419\n",
            "Epoch 2438: train loss = 4.103287, test loss = 12274.224819\n",
            "Epoch 2439: train loss = 4.103294, test loss = 12274.204461\n",
            "Epoch 2440: train loss = 4.103271, test loss = 12274.178046\n",
            "Epoch 2441: train loss = 4.103268, test loss = 12274.143918\n",
            "Epoch 2442: train loss = 4.103267, test loss = 12274.124283\n",
            "Epoch 2443: train loss = 4.103244, test loss = 12274.098721\n",
            "Epoch 2444: train loss = 4.103247, test loss = 12274.063528\n",
            "Epoch 2445: train loss = 4.103240, test loss = 12274.045485\n",
            "Epoch 2446: train loss = 4.103217, test loss = 12274.020148\n",
            "Epoch 2447: train loss = 4.103227, test loss = 12273.983774\n",
            "Epoch 2448: train loss = 4.103214, test loss = 12273.966323\n",
            "Epoch 2449: train loss = 4.103191, test loss = 12273.949222\n",
            "Epoch 2450: train loss = 4.103188, test loss = 12273.926341\n",
            "Epoch 2451: train loss = 4.103188, test loss = 12273.892409\n",
            "Epoch 2452: train loss = 4.103183, test loss = 12273.873688\n",
            "Epoch 2453: train loss = 4.103160, test loss = 12273.848662\n",
            "Epoch 2454: train loss = 4.103168, test loss = 12273.812365\n",
            "Epoch 2455: train loss = 4.103156, test loss = 12273.794765\n",
            "Epoch 2456: train loss = 4.103133, test loss = 12273.770307\n",
            "Epoch 2457: train loss = 4.103147, test loss = 12273.732847\n",
            "Epoch 2458: train loss = 4.103129, test loss = 12273.716682\n",
            "Epoch 2459: train loss = 4.103108, test loss = 12273.689894\n",
            "Epoch 2460: train loss = 4.103124, test loss = 12273.668650\n",
            "Epoch 2461: train loss = 4.103101, test loss = 12273.642142\n",
            "Epoch 2462: train loss = 4.103089, test loss = 12273.610218\n",
            "Epoch 2463: train loss = 4.103097, test loss = 12273.588929\n",
            "Epoch 2464: train loss = 4.103074, test loss = 12273.562611\n",
            "Epoch 2465: train loss = 4.103069, test loss = 12273.529311\n",
            "Epoch 2466: train loss = 4.103070, test loss = 12273.509600\n",
            "Epoch 2467: train loss = 4.103047, test loss = 12273.483646\n",
            "Epoch 2468: train loss = 4.103049, test loss = 12273.449027\n",
            "Epoch 2469: train loss = 4.103043, test loss = 12273.430021\n",
            "Epoch 2470: train loss = 4.103020, test loss = 12273.404873\n",
            "Epoch 2471: train loss = 4.103028, test loss = 12273.369073\n",
            "Epoch 2472: train loss = 4.103017, test loss = 12273.351719\n",
            "Epoch 2473: train loss = 4.102995, test loss = 12273.334245\n",
            "Epoch 2474: train loss = 4.102991, test loss = 12273.311106\n",
            "Epoch 2475: train loss = 4.102990, test loss = 12273.277341\n",
            "Epoch 2476: train loss = 4.102986, test loss = 12273.258643\n",
            "Epoch 2477: train loss = 4.102963, test loss = 12273.233475\n",
            "Epoch 2478: train loss = 4.102970, test loss = 12273.198216\n",
            "Epoch 2479: train loss = 4.102959, test loss = 12273.180111\n",
            "Epoch 2480: train loss = 4.102936, test loss = 12273.155248\n",
            "Epoch 2481: train loss = 4.102949, test loss = 12273.118275\n",
            "Epoch 2482: train loss = 4.102932, test loss = 12273.101426\n",
            "Epoch 2483: train loss = 4.102912, test loss = 12273.084391\n",
            "Epoch 2484: train loss = 4.102906, test loss = 12273.061783\n",
            "Epoch 2485: train loss = 4.102910, test loss = 12273.026739\n",
            "Epoch 2486: train loss = 4.102901, test loss = 12273.009368\n",
            "Epoch 2487: train loss = 4.102879, test loss = 12272.984420\n",
            "Epoch 2488: train loss = 4.102890, test loss = 12272.947332\n",
            "Epoch 2489: train loss = 4.102875, test loss = 12272.930367\n",
            "Epoch 2490: train loss = 4.102852, test loss = 12272.913593\n",
            "Epoch 2491: train loss = 4.102849, test loss = 12272.890600\n",
            "Epoch 2492: train loss = 4.102851, test loss = 12272.855643\n",
            "Epoch 2493: train loss = 4.102844, test loss = 12272.837708\n",
            "Epoch 2494: train loss = 4.102821, test loss = 12272.813197\n",
            "Epoch 2495: train loss = 4.102831, test loss = 12272.776206\n",
            "Epoch 2496: train loss = 4.102817, test loss = 12272.758891\n",
            "Epoch 2497: train loss = 4.102794, test loss = 12272.734507\n",
            "Epoch 2498: train loss = 4.102810, test loss = 12272.696485\n",
            "Epoch 2499: train loss = 4.102791, test loss = 12272.680291\n",
            "Epoch 2500: train loss = 4.102771, test loss = 12272.653706\n",
            "Epoch 2501: train loss = 4.102785, test loss = 12272.632852\n",
            "Epoch 2502: train loss = 4.102762, test loss = 12272.606313\n",
            "Epoch 2503: train loss = 4.102752, test loss = 12272.573822\n",
            "Epoch 2504: train loss = 4.102758, test loss = 12272.552962\n",
            "Epoch 2505: train loss = 4.102736, test loss = 12272.526691\n",
            "Epoch 2506: train loss = 4.102732, test loss = 12272.493275\n",
            "Epoch 2507: train loss = 4.102732, test loss = 12272.473378\n",
            "Epoch 2508: train loss = 4.102709, test loss = 12272.447562\n",
            "Epoch 2509: train loss = 4.102712, test loss = 12272.412491\n",
            "Epoch 2510: train loss = 4.102705, test loss = 12272.393894\n",
            "Epoch 2511: train loss = 4.102682, test loss = 12272.368888\n",
            "Epoch 2512: train loss = 4.102691, test loss = 12272.332664\n",
            "Epoch 2513: train loss = 4.102678, test loss = 12272.315517\n",
            "Epoch 2514: train loss = 4.102656, test loss = 12272.298281\n",
            "Epoch 2515: train loss = 4.102652, test loss = 12272.275214\n",
            "Epoch 2516: train loss = 4.102653, test loss = 12272.240851\n",
            "Epoch 2517: train loss = 4.102648, test loss = 12272.222442\n",
            "Epoch 2518: train loss = 4.102625, test loss = 12272.197455\n",
            "Epoch 2519: train loss = 4.102632, test loss = 12272.161190\n",
            "Epoch 2520: train loss = 4.102621, test loss = 12272.143718\n",
            "Epoch 2521: train loss = 4.102598, test loss = 12272.119479\n",
            "Epoch 2522: train loss = 4.102612, test loss = 12272.081915\n",
            "Epoch 2523: train loss = 4.102594, test loss = 12272.065251\n",
            "Epoch 2524: train loss = 4.102573, test loss = 12272.048332\n",
            "Epoch 2525: train loss = 4.102568, test loss = 12272.025698\n",
            "Epoch 2526: train loss = 4.102573, test loss = 12271.990294\n",
            "Epoch 2527: train loss = 4.102563, test loss = 12271.973026\n",
            "Epoch 2528: train loss = 4.102540, test loss = 12271.948220\n",
            "Epoch 2529: train loss = 4.102553, test loss = 12271.910814\n",
            "Epoch 2530: train loss = 4.102537, test loss = 12271.893937\n",
            "Epoch 2531: train loss = 4.102514, test loss = 12271.859862\n",
            "Epoch 2532: train loss = 4.102512, test loss = 12271.835212\n",
            "Epoch 2533: train loss = 4.102512, test loss = 12271.801528\n",
            "Epoch 2534: train loss = 4.102508, test loss = 12271.781890\n",
            "Epoch 2535: train loss = 4.102485, test loss = 12271.756020\n",
            "Epoch 2536: train loss = 4.102492, test loss = 12271.720255\n",
            "Epoch 2537: train loss = 4.102482, test loss = 12271.701881\n",
            "Epoch 2538: train loss = 4.102459, test loss = 12271.684283\n",
            "Epoch 2539: train loss = 4.102456, test loss = 12271.661034\n",
            "Epoch 2540: train loss = 4.102454, test loss = 12271.627478\n",
            "Epoch 2541: train loss = 4.102451, test loss = 12271.608760\n",
            "Epoch 2542: train loss = 4.102428, test loss = 12271.583157\n",
            "Epoch 2543: train loss = 4.102433, test loss = 12271.547541\n",
            "Epoch 2544: train loss = 4.102424, test loss = 12271.529254\n",
            "Epoch 2545: train loss = 4.102401, test loss = 12271.504388\n",
            "Epoch 2546: train loss = 4.102413, test loss = 12271.467588\n",
            "Epoch 2547: train loss = 4.102397, test loss = 12271.450529\n",
            "Epoch 2548: train loss = 4.102377, test loss = 12271.433856\n",
            "Epoch 2549: train loss = 4.102371, test loss = 12271.410739\n",
            "Epoch 2550: train loss = 4.102375, test loss = 12271.375980\n",
            "Epoch 2551: train loss = 4.102367, test loss = 12271.357860\n",
            "Epoch 2552: train loss = 4.102344, test loss = 12271.332892\n",
            "Epoch 2553: train loss = 4.102354, test loss = 12271.296340\n",
            "Epoch 2554: train loss = 4.102340, test loss = 12271.279526\n",
            "Epoch 2555: train loss = 4.102317, test loss = 12271.254741\n",
            "Epoch 2556: train loss = 4.102334, test loss = 12271.216856\n",
            "Epoch 2557: train loss = 4.102313, test loss = 12271.200567\n",
            "Epoch 2558: train loss = 4.102294, test loss = 12271.173588\n",
            "Epoch 2559: train loss = 4.102308, test loss = 12271.152892\n",
            "Epoch 2560: train loss = 4.102285, test loss = 12271.126852\n",
            "Epoch 2561: train loss = 4.102275, test loss = 12271.094311\n",
            "Epoch 2562: train loss = 4.102281, test loss = 12271.073288\n",
            "Epoch 2563: train loss = 4.102259, test loss = 12271.046880\n",
            "Epoch 2564: train loss = 4.102255, test loss = 12271.013196\n",
            "Epoch 2565: train loss = 4.102255, test loss = 12270.993465\n",
            "Epoch 2566: train loss = 4.102232, test loss = 12270.967730\n",
            "Epoch 2567: train loss = 4.102235, test loss = 12270.932889\n",
            "Epoch 2568: train loss = 4.102228, test loss = 12270.914740\n",
            "Epoch 2569: train loss = 4.102205, test loss = 12270.889293\n",
            "Epoch 2570: train loss = 4.102215, test loss = 12270.853124\n",
            "Epoch 2571: train loss = 4.102201, test loss = 12270.835556\n",
            "Epoch 2572: train loss = 4.102181, test loss = 12270.818115\n",
            "Epoch 2573: train loss = 4.102175, test loss = 12270.795334\n",
            "Epoch 2574: train loss = 4.102176, test loss = 12270.761286\n",
            "Epoch 2575: train loss = 4.102171, test loss = 12270.743247\n",
            "Epoch 2576: train loss = 4.102148, test loss = 12270.717979\n",
            "Epoch 2577: train loss = 4.102156, test loss = 12270.681805\n",
            "Epoch 2578: train loss = 4.102144, test loss = 12270.664145\n",
            "Epoch 2579: train loss = 4.102121, test loss = 12270.647072\n",
            "Epoch 2580: train loss = 4.102118, test loss = 12270.623997\n",
            "Epoch 2581: train loss = 4.102118, test loss = 12270.590387\n",
            "Epoch 2582: train loss = 4.102113, test loss = 12270.571551\n",
            "Epoch 2583: train loss = 4.102090, test loss = 12270.546297\n",
            "Epoch 2584: train loss = 4.102097, test loss = 12270.510302\n",
            "Epoch 2585: train loss = 4.102086, test loss = 12270.492492\n",
            "Epoch 2586: train loss = 4.102063, test loss = 12270.467932\n",
            "Epoch 2587: train loss = 4.102077, test loss = 12270.430751\n",
            "Epoch 2588: train loss = 4.102060, test loss = 12270.414369\n",
            "Epoch 2589: train loss = 4.102038, test loss = 12270.397348\n",
            "Epoch 2590: train loss = 4.102034, test loss = 12270.374540\n",
            "Epoch 2591: train loss = 4.102038, test loss = 12270.339142\n",
            "Epoch 2592: train loss = 4.102029, test loss = 12270.321473\n",
            "Epoch 2593: train loss = 4.102006, test loss = 12270.296791\n",
            "Epoch 2594: train loss = 4.102018, test loss = 12270.259592\n",
            "Epoch 2595: train loss = 4.102002, test loss = 12270.243176\n",
            "Epoch 2596: train loss = 4.101980, test loss = 12270.218692\n",
            "Epoch 2597: train loss = 4.101997, test loss = 12270.180167\n",
            "Epoch 2598: train loss = 4.101976, test loss = 12270.164291\n",
            "Epoch 2599: train loss = 4.101958, test loss = 12270.136945\n",
            "Epoch 2600: train loss = 4.101970, test loss = 12270.116577\n",
            "Epoch 2601: train loss = 4.101948, test loss = 12270.090380\n",
            "Epoch 2602: train loss = 4.101939, test loss = 12270.057586\n",
            "Epoch 2603: train loss = 4.101944, test loss = 12270.037388\n",
            "Epoch 2604: train loss = 4.101921, test loss = 12270.011077\n",
            "Epoch 2605: train loss = 4.101919, test loss = 12269.976716\n",
            "Epoch 2606: train loss = 4.101917, test loss = 12269.957224\n",
            "Epoch 2607: train loss = 4.101894, test loss = 12269.931711\n",
            "Epoch 2608: train loss = 4.101899, test loss = 12269.896329\n",
            "Epoch 2609: train loss = 4.101890, test loss = 12269.878431\n",
            "Epoch 2610: train loss = 4.101867, test loss = 12269.853284\n",
            "Epoch 2611: train loss = 4.101879, test loss = 12269.816557\n",
            "Epoch 2612: train loss = 4.101864, test loss = 12269.799256\n",
            "Epoch 2613: train loss = 4.101843, test loss = 12269.782037\n",
            "Epoch 2614: train loss = 4.101838, test loss = 12269.759295\n",
            "Epoch 2615: train loss = 4.101840, test loss = 12269.725249\n",
            "Epoch 2616: train loss = 4.101833, test loss = 12269.706711\n",
            "Epoch 2617: train loss = 4.101810, test loss = 12269.681697\n",
            "Epoch 2618: train loss = 4.101820, test loss = 12269.645240\n",
            "Epoch 2619: train loss = 4.101806, test loss = 12269.627754\n",
            "Epoch 2620: train loss = 4.101784, test loss = 12269.603335\n",
            "Epoch 2621: train loss = 4.101799, test loss = 12269.565721\n",
            "Epoch 2622: train loss = 4.101780, test loss = 12269.549255\n",
            "Epoch 2623: train loss = 4.101760, test loss = 12269.523057\n",
            "Epoch 2624: train loss = 4.101774, test loss = 12269.501789\n",
            "Epoch 2625: train loss = 4.101752, test loss = 12269.475259\n",
            "Epoch 2626: train loss = 4.101741, test loss = 12269.443154\n",
            "Epoch 2627: train loss = 4.101748, test loss = 12269.421962\n",
            "Epoch 2628: train loss = 4.101725, test loss = 12269.395677\n",
            "Epoch 2629: train loss = 4.101721, test loss = 12269.362228\n",
            "Epoch 2630: train loss = 4.101721, test loss = 12269.342630\n",
            "Epoch 2631: train loss = 4.101698, test loss = 12269.316756\n",
            "Epoch 2632: train loss = 4.101701, test loss = 12269.281949\n",
            "Epoch 2633: train loss = 4.101694, test loss = 12269.263044\n",
            "Epoch 2634: train loss = 4.101671, test loss = 12269.237926\n",
            "Epoch 2635: train loss = 4.101681, test loss = 12269.202079\n",
            "Epoch 2636: train loss = 4.101668, test loss = 12269.184701\n",
            "Epoch 2637: train loss = 4.101647, test loss = 12269.167165\n",
            "Epoch 2638: train loss = 4.101642, test loss = 12269.144115\n",
            "Epoch 2639: train loss = 4.101642, test loss = 12269.110271\n",
            "Epoch 2640: train loss = 4.101637, test loss = 12269.091676\n",
            "Epoch 2641: train loss = 4.101614, test loss = 12269.066546\n",
            "Epoch 2642: train loss = 4.101622, test loss = 12269.030752\n",
            "Epoch 2643: train loss = 4.101610, test loss = 12269.013436\n",
            "Epoch 2644: train loss = 4.101588, test loss = 12268.996013\n",
            "Epoch 2645: train loss = 4.101584, test loss = 12268.972872\n",
            "Epoch 2646: train loss = 4.101584, test loss = 12268.938965\n",
            "Epoch 2647: train loss = 4.101580, test loss = 12268.920202\n",
            "Epoch 2648: train loss = 4.101557, test loss = 12268.895109\n",
            "Epoch 2649: train loss = 4.101563, test loss = 12268.859235\n",
            "Epoch 2650: train loss = 4.101553, test loss = 12268.841916\n",
            "Epoch 2651: train loss = 4.101530, test loss = 12268.816973\n",
            "Epoch 2652: train loss = 4.101543, test loss = 12268.779731\n",
            "Epoch 2653: train loss = 4.101526, test loss = 12268.762923\n",
            "Epoch 2654: train loss = 4.101505, test loss = 12268.746065\n",
            "Epoch 2655: train loss = 4.101500, test loss = 12268.723249\n",
            "Epoch 2656: train loss = 4.101504, test loss = 12268.688251\n",
            "Epoch 2657: train loss = 4.101496, test loss = 12268.670834\n",
            "Epoch 2658: train loss = 4.101473, test loss = 12268.645748\n",
            "Epoch 2659: train loss = 4.101484, test loss = 12268.608757\n",
            "Epoch 2660: train loss = 4.101469, test loss = 12268.591736\n",
            "Epoch 2661: train loss = 4.101446, test loss = 12268.567318\n",
            "Epoch 2662: train loss = 4.101464, test loss = 12268.529244\n",
            "Epoch 2663: train loss = 4.101443, test loss = 12268.513558\n",
            "Epoch 2664: train loss = 4.101424, test loss = 12268.486209\n",
            "Epoch 2665: train loss = 4.101437, test loss = 12268.465627\n",
            "Epoch 2666: train loss = 4.101415, test loss = 12268.439217\n",
            "Epoch 2667: train loss = 4.101405, test loss = 12268.406639\n",
            "Epoch 2668: train loss = 4.101411, test loss = 12268.385955\n",
            "Epoch 2669: train loss = 4.101388, test loss = 12268.359700\n",
            "Epoch 2670: train loss = 4.101385, test loss = 12268.326169\n",
            "Epoch 2671: train loss = 4.101384, test loss = 12268.306371\n",
            "Epoch 2672: train loss = 4.101361, test loss = 12268.280600\n",
            "Epoch 2673: train loss = 4.101365, test loss = 12268.245410\n",
            "Epoch 2674: train loss = 4.101357, test loss = 12268.226915\n",
            "Epoch 2675: train loss = 4.101334, test loss = 12268.201956\n",
            "Epoch 2676: train loss = 4.101345, test loss = 12268.165618\n",
            "Epoch 2677: train loss = 4.101331, test loss = 12268.148154\n",
            "Epoch 2678: train loss = 4.101310, test loss = 12268.131508\n",
            "Epoch 2679: train loss = 4.101305, test loss = 12268.108422\n",
            "Epoch 2680: train loss = 4.101306, test loss = 12268.073922\n",
            "Epoch 2681: train loss = 4.101300, test loss = 12268.055590\n",
            "Epoch 2682: train loss = 4.101277, test loss = 12268.030633\n",
            "Epoch 2683: train loss = 4.101286, test loss = 12267.994309\n",
            "Epoch 2684: train loss = 4.101274, test loss = 12267.977274\n",
            "Epoch 2685: train loss = 4.101251, test loss = 12267.952502\n",
            "Epoch 2686: train loss = 4.101266, test loss = 12267.914836\n",
            "Epoch 2687: train loss = 4.101247, test loss = 12267.898337\n",
            "Epoch 2688: train loss = 4.101227, test loss = 12267.881341\n",
            "Epoch 2689: train loss = 4.101221, test loss = 12267.858896\n",
            "Epoch 2690: train loss = 4.101227, test loss = 12267.823825\n",
            "Epoch 2691: train loss = 4.101216, test loss = 12267.805975\n",
            "Epoch 2692: train loss = 4.101193, test loss = 12267.781338\n",
            "Epoch 2693: train loss = 4.101207, test loss = 12267.743911\n",
            "Epoch 2694: train loss = 4.101190, test loss = 12267.727145\n",
            "Epoch 2695: train loss = 4.101168, test loss = 12267.700692\n",
            "Epoch 2696: train loss = 4.101184, test loss = 12267.679503\n",
            "Epoch 2697: train loss = 4.101162, test loss = 12267.652835\n",
            "Epoch 2698: train loss = 4.101149, test loss = 12267.621419\n",
            "Epoch 2699: train loss = 4.101158, test loss = 12267.599868\n",
            "Epoch 2700: train loss = 4.101135, test loss = 12267.573221\n",
            "Epoch 2701: train loss = 4.101129, test loss = 12267.539985\n",
            "Epoch 2702: train loss = 4.101131, test loss = 12267.519746\n",
            "Epoch 2703: train loss = 4.101108, test loss = 12267.493980\n",
            "Epoch 2704: train loss = 4.101109, test loss = 12267.459542\n",
            "Epoch 2705: train loss = 4.101104, test loss = 12267.440522\n",
            "Epoch 2706: train loss = 4.101082, test loss = 12267.415728\n",
            "Epoch 2707: train loss = 4.101089, test loss = 12267.379881\n",
            "Epoch 2708: train loss = 4.101078, test loss = 12267.361769\n",
            "Epoch 2709: train loss = 4.101055, test loss = 12267.344618\n",
            "Epoch 2710: train loss = 4.101052, test loss = 12267.321528\n",
            "Epoch 2711: train loss = 4.101050, test loss = 12267.287813\n",
            "Epoch 2712: train loss = 4.101047, test loss = 12267.269432\n",
            "Epoch 2713: train loss = 4.101025, test loss = 12267.243966\n",
            "Epoch 2714: train loss = 4.101030, test loss = 12267.208281\n",
            "Epoch 2715: train loss = 4.101021, test loss = 12267.190293\n",
            "Epoch 2716: train loss = 4.100998, test loss = 12267.165449\n",
            "Epoch 2717: train loss = 4.101010, test loss = 12267.128686\n",
            "Epoch 2718: train loss = 4.100994, test loss = 12267.112163\n",
            "Epoch 2719: train loss = 4.100973, test loss = 12267.094972\n",
            "Epoch 2720: train loss = 4.100968, test loss = 12267.072130\n",
            "Epoch 2721: train loss = 4.100971, test loss = 12267.037220\n",
            "Epoch 2722: train loss = 4.100964, test loss = 12267.019156\n",
            "Epoch 2723: train loss = 4.100941, test loss = 12266.994445\n",
            "Epoch 2724: train loss = 4.100951, test loss = 12266.957709\n",
            "Epoch 2725: train loss = 4.100937, test loss = 12266.940941\n",
            "Epoch 2726: train loss = 4.100914, test loss = 12266.916391\n",
            "Epoch 2727: train loss = 4.100931, test loss = 12266.878224\n",
            "Epoch 2728: train loss = 4.100910, test loss = 12266.862081\n",
            "Epoch 2729: train loss = 4.100891, test loss = 12266.835156\n",
            "Epoch 2730: train loss = 4.100905, test loss = 12266.814420\n",
            "Epoch 2731: train loss = 4.100882, test loss = 12266.788144\n",
            "Epoch 2732: train loss = 4.100872, test loss = 12266.755789\n",
            "Epoch 2733: train loss = 4.100879, test loss = 12266.735244\n",
            "Epoch 2734: train loss = 4.100856, test loss = 12266.708819\n",
            "Epoch 2735: train loss = 4.100853, test loss = 12266.674935\n",
            "Epoch 2736: train loss = 4.100852, test loss = 12266.655106\n",
            "Epoch 2737: train loss = 4.100829, test loss = 12266.629534\n",
            "Epoch 2738: train loss = 4.100832, test loss = 12266.594491\n",
            "Epoch 2739: train loss = 4.100825, test loss = 12266.576384\n",
            "Epoch 2740: train loss = 4.100802, test loss = 12266.551112\n",
            "Epoch 2741: train loss = 4.100812, test loss = 12266.514745\n",
            "Epoch 2742: train loss = 4.100799, test loss = 12266.497241\n",
            "Epoch 2743: train loss = 4.100777, test loss = 12266.480068\n",
            "Epoch 2744: train loss = 4.100773, test loss = 12266.457165\n",
            "Epoch 2745: train loss = 4.100774, test loss = 12266.423459\n",
            "Epoch 2746: train loss = 4.100768, test loss = 12266.404792\n",
            "Epoch 2747: train loss = 4.100745, test loss = 12266.379619\n",
            "Epoch 2748: train loss = 4.100754, test loss = 12266.343485\n",
            "Epoch 2749: train loss = 4.100741, test loss = 12266.325919\n",
            "Epoch 2750: train loss = 4.100719, test loss = 12266.301299\n",
            "Epoch 2751: train loss = 4.100733, test loss = 12266.263999\n",
            "Epoch 2752: train loss = 4.100715, test loss = 12266.247776\n",
            "Epoch 2753: train loss = 4.100695, test loss = 12266.230650\n",
            "Epoch 2754: train loss = 4.100689, test loss = 12266.208004\n",
            "Epoch 2755: train loss = 4.100695, test loss = 12266.172518\n",
            "Epoch 2756: train loss = 4.100684, test loss = 12266.154997\n",
            "Epoch 2757: train loss = 4.100662, test loss = 12266.130388\n",
            "Epoch 2758: train loss = 4.100674, test loss = 12266.093065\n",
            "Epoch 2759: train loss = 4.100658, test loss = 12266.076403\n",
            "Epoch 2760: train loss = 4.100636, test loss = 12266.060098\n",
            "Epoch 2761: train loss = 4.100632, test loss = 12266.036945\n",
            "Epoch 2762: train loss = 4.100636, test loss = 12266.001569\n",
            "Epoch 2763: train loss = 4.100628, test loss = 12265.983768\n",
            "Epoch 2764: train loss = 4.100605, test loss = 12265.958944\n",
            "Epoch 2765: train loss = 4.100616, test loss = 12265.921874\n",
            "Epoch 2766: train loss = 4.100601, test loss = 12265.905305\n",
            "Epoch 2767: train loss = 4.100578, test loss = 12265.870956\n",
            "Epoch 2768: train loss = 4.100576, test loss = 12265.846125\n",
            "Epoch 2769: train loss = 4.100575, test loss = 12265.812130\n",
            "Epoch 2770: train loss = 4.100573, test loss = 12265.792559\n",
            "Epoch 2771: train loss = 4.100550, test loss = 12265.766889\n",
            "Epoch 2772: train loss = 4.100555, test loss = 12265.731632\n",
            "Epoch 2773: train loss = 4.100546, test loss = 12265.712887\n",
            "Epoch 2774: train loss = 4.100523, test loss = 12265.687719\n",
            "Epoch 2775: train loss = 4.100535, test loss = 12265.650874\n",
            "Epoch 2776: train loss = 4.100520, test loss = 12265.633537\n",
            "Epoch 2777: train loss = 4.100500, test loss = 12265.616160\n",
            "Epoch 2778: train loss = 4.100494, test loss = 12265.593416\n",
            "Epoch 2779: train loss = 4.100497, test loss = 12265.558880\n",
            "Epoch 2780: train loss = 4.100489, test loss = 12265.541005\n",
            "Epoch 2781: train loss = 4.100467, test loss = 12265.515862\n",
            "Epoch 2782: train loss = 4.100477, test loss = 12265.479253\n",
            "Epoch 2783: train loss = 4.100463, test loss = 12265.461804\n",
            "Epoch 2784: train loss = 4.100441, test loss = 12265.444796\n",
            "Epoch 2785: train loss = 4.100437, test loss = 12265.421866\n",
            "Epoch 2786: train loss = 4.100438, test loss = 12265.387238\n",
            "Epoch 2787: train loss = 4.100432, test loss = 12265.369022\n",
            "Epoch 2788: train loss = 4.100410, test loss = 12265.344476\n",
            "Epoch 2789: train loss = 4.100418, test loss = 12265.307753\n",
            "Epoch 2790: train loss = 4.100406, test loss = 12265.290248\n",
            "Epoch 2791: train loss = 4.100383, test loss = 12265.265607\n",
            "Epoch 2792: train loss = 4.100398, test loss = 12265.227997\n",
            "Epoch 2793: train loss = 4.100379, test loss = 12265.211620\n",
            "Epoch 2794: train loss = 4.100359, test loss = 12265.185243\n",
            "Epoch 2795: train loss = 4.100374, test loss = 12265.164102\n",
            "Epoch 2796: train loss = 4.100351, test loss = 12265.137530\n",
            "Epoch 2797: train loss = 4.100340, test loss = 12265.105293\n",
            "Epoch 2798: train loss = 4.100347, test loss = 12265.084185\n",
            "Epoch 2799: train loss = 4.100325, test loss = 12265.057904\n",
            "Epoch 2800: train loss = 4.100320, test loss = 12265.024741\n",
            "Epoch 2801: train loss = 4.100321, test loss = 12265.004609\n",
            "Epoch 2802: train loss = 4.100298, test loss = 12264.978697\n",
            "Epoch 2803: train loss = 4.100300, test loss = 12264.943998\n",
            "Epoch 2804: train loss = 4.100294, test loss = 12264.925205\n",
            "Epoch 2805: train loss = 4.100271, test loss = 12264.900016\n",
            "Epoch 2806: train loss = 4.100280, test loss = 12264.864174\n",
            "Epoch 2807: train loss = 4.100267, test loss = 12264.846906\n",
            "Epoch 2808: train loss = 4.100246, test loss = 12264.829365\n",
            "Epoch 2809: train loss = 4.100242, test loss = 12264.806346\n",
            "Epoch 2810: train loss = 4.100242, test loss = 12264.772518\n",
            "Epoch 2811: train loss = 4.100237, test loss = 12264.753778\n",
            "Epoch 2812: train loss = 4.100214, test loss = 12264.728720\n",
            "Epoch 2813: train loss = 4.100221, test loss = 12264.692926\n",
            "Epoch 2814: train loss = 4.100211, test loss = 12264.675103\n",
            "Epoch 2815: train loss = 4.100188, test loss = 12264.650883\n",
            "Epoch 2816: train loss = 4.100201, test loss = 12264.613551\n",
            "Epoch 2817: train loss = 4.100184, test loss = 12264.596687\n",
            "Epoch 2818: train loss = 4.100164, test loss = 12264.579692\n",
            "Epoch 2819: train loss = 4.100158, test loss = 12264.556976\n",
            "Epoch 2820: train loss = 4.100163, test loss = 12264.522002\n",
            "Epoch 2821: train loss = 4.100154, test loss = 12264.504651\n",
            "Epoch 2822: train loss = 4.100131, test loss = 12264.479642\n",
            "Epoch 2823: train loss = 4.100143, test loss = 12264.442597\n",
            "Epoch 2824: train loss = 4.100127, test loss = 12264.425620\n",
            "Epoch 2825: train loss = 4.100105, test loss = 12264.408753\n",
            "Epoch 2826: train loss = 4.100101, test loss = 12264.385957\n",
            "Epoch 2827: train loss = 4.100104, test loss = 12264.351354\n",
            "Epoch 2828: train loss = 4.100097, test loss = 12264.333083\n",
            "Epoch 2829: train loss = 4.100074, test loss = 12264.308198\n",
            "Epoch 2830: train loss = 4.100084, test loss = 12264.271187\n",
            "Epoch 2831: train loss = 4.100070, test loss = 12264.254126\n",
            "Epoch 2832: train loss = 4.100047, test loss = 12264.229833\n",
            "Epoch 2833: train loss = 4.100064, test loss = 12264.191672\n",
            "Epoch 2834: train loss = 4.100044, test loss = 12264.175623\n",
            "Epoch 2835: train loss = 4.100024, test loss = 12264.149061\n",
            "Epoch 2836: train loss = 4.100038, test loss = 12264.128098\n",
            "Epoch 2837: train loss = 4.100016, test loss = 12264.101714\n",
            "Epoch 2838: train loss = 4.100005, test loss = 12264.069199\n",
            "Epoch 2839: train loss = 4.100012, test loss = 12264.048281\n",
            "Epoch 2840: train loss = 4.099989, test loss = 12264.022128\n",
            "Epoch 2841: train loss = 4.099986, test loss = 12263.988179\n",
            "Epoch 2842: train loss = 4.099985, test loss = 12263.968975\n",
            "Epoch 2843: train loss = 4.099963, test loss = 12263.943165\n",
            "Epoch 2844: train loss = 4.099966, test loss = 12263.907901\n",
            "Epoch 2845: train loss = 4.099959, test loss = 12263.889386\n",
            "Epoch 2846: train loss = 4.099936, test loss = 12263.864380\n",
            "Epoch 2847: train loss = 4.099946, test loss = 12263.828045\n",
            "Epoch 2848: train loss = 4.099932, test loss = 12263.811051\n",
            "Epoch 2849: train loss = 4.099910, test loss = 12263.793794\n",
            "Epoch 2850: train loss = 4.099906, test loss = 12263.770692\n",
            "Epoch 2851: train loss = 4.099907, test loss = 12263.736382\n",
            "Epoch 2852: train loss = 4.099902, test loss = 12263.718000\n",
            "Epoch 2853: train loss = 4.099879, test loss = 12263.692968\n",
            "Epoch 2854: train loss = 4.099887, test loss = 12263.656805\n",
            "Epoch 2855: train loss = 4.099875, test loss = 12263.639634\n",
            "Epoch 2856: train loss = 4.099852, test loss = 12263.614903\n",
            "Epoch 2857: train loss = 4.099867, test loss = 12263.577376\n",
            "Epoch 2858: train loss = 4.099849, test loss = 12263.560712\n",
            "Epoch 2859: train loss = 4.099828, test loss = 12263.544010\n",
            "Epoch 2860: train loss = 4.099823, test loss = 12263.521408\n",
            "Epoch 2861: train loss = 4.099828, test loss = 12263.485854\n",
            "Epoch 2862: train loss = 4.099818, test loss = 12263.468814\n",
            "Epoch 2863: train loss = 4.099796, test loss = 12263.443950\n",
            "Epoch 2864: train loss = 4.099808, test loss = 12263.406417\n",
            "Epoch 2865: train loss = 4.099792, test loss = 12263.389740\n",
            "Epoch 2866: train loss = 4.099769, test loss = 12263.355646\n",
            "Epoch 2867: train loss = 4.099767, test loss = 12263.330869\n",
            "Epoch 2868: train loss = 4.099767, test loss = 12263.296923\n",
            "Epoch 2869: train loss = 4.099764, test loss = 12263.277836\n",
            "Epoch 2870: train loss = 4.099741, test loss = 12263.251975\n",
            "Epoch 2871: train loss = 4.099748, test loss = 12263.216148\n",
            "Epoch 2872: train loss = 4.099737, test loss = 12263.197675\n",
            "Epoch 2873: train loss = 4.099715, test loss = 12263.180174\n",
            "Epoch 2874: train loss = 4.099712, test loss = 12263.156979\n",
            "Epoch 2875: train loss = 4.099710, test loss = 12263.123717\n",
            "Epoch 2876: train loss = 4.099707, test loss = 12263.104412\n",
            "Epoch 2877: train loss = 4.099684, test loss = 12263.079003\n",
            "Epoch 2878: train loss = 4.099690, test loss = 12263.043334\n",
            "Epoch 2879: train loss = 4.099681, test loss = 12263.025196\n",
            "Epoch 2880: train loss = 4.099658, test loss = 12263.000301\n",
            "Epoch 2881: train loss = 4.099670, test loss = 12262.963608\n",
            "Epoch 2882: train loss = 4.099654, test loss = 12262.946939\n",
            "Epoch 2883: train loss = 4.099633, test loss = 12262.929560\n",
            "Epoch 2884: train loss = 4.099628, test loss = 12262.906724\n",
            "Epoch 2885: train loss = 4.099631, test loss = 12262.871982\n",
            "Epoch 2886: train loss = 4.099624, test loss = 12262.853859\n",
            "Epoch 2887: train loss = 4.099601, test loss = 12262.829044\n",
            "Epoch 2888: train loss = 4.099611, test loss = 12262.792442\n",
            "Epoch 2889: train loss = 4.099597, test loss = 12262.775147\n",
            "Epoch 2890: train loss = 4.099574, test loss = 12262.758839\n",
            "Epoch 2891: train loss = 4.099571, test loss = 12262.735621\n",
            "Epoch 2892: train loss = 4.099573, test loss = 12262.700746\n",
            "Epoch 2893: train loss = 4.099567, test loss = 12262.682535\n",
            "Epoch 2894: train loss = 4.099544, test loss = 12262.657541\n",
            "Epoch 2895: train loss = 4.099553, test loss = 12262.621019\n",
            "Epoch 2896: train loss = 4.099540, test loss = 12262.603772\n",
            "Epoch 2897: train loss = 4.099518, test loss = 12262.579637\n",
            "Epoch 2898: train loss = 4.099533, test loss = 12262.541703\n",
            "Epoch 2899: train loss = 4.099514, test loss = 12262.525280\n",
            "Epoch 2900: train loss = 4.099493, test loss = 12262.498346\n",
            "Epoch 2901: train loss = 4.099509, test loss = 12262.477515\n",
            "Epoch 2902: train loss = 4.099486, test loss = 12262.451165\n",
            "Epoch 2903: train loss = 4.099474, test loss = 12262.419272\n",
            "Epoch 2904: train loss = 4.099482, test loss = 12262.398066\n",
            "Epoch 2905: train loss = 4.099459, test loss = 12262.371584\n",
            "Epoch 2906: train loss = 4.099455, test loss = 12262.337950\n",
            "Epoch 2907: train loss = 4.099456, test loss = 12262.318099\n",
            "Epoch 2908: train loss = 4.099433, test loss = 12262.292391\n",
            "Epoch 2909: train loss = 4.099435, test loss = 12262.257626\n",
            "Epoch 2910: train loss = 4.099429, test loss = 12262.239374\n",
            "Epoch 2911: train loss = 4.099406, test loss = 12262.213967\n",
            "Epoch 2912: train loss = 4.099415, test loss = 12262.177880\n",
            "Epoch 2913: train loss = 4.099403, test loss = 12262.160221\n",
            "Epoch 2914: train loss = 4.099380, test loss = 12262.143113\n",
            "Epoch 2915: train loss = 4.099377, test loss = 12262.120160\n",
            "Epoch 2916: train loss = 4.099377, test loss = 12262.086184\n",
            "Epoch 2917: train loss = 4.099372, test loss = 12262.068005\n",
            "Epoch 2918: train loss = 4.099349, test loss = 12262.042714\n",
            "Epoch 2919: train loss = 4.099356, test loss = 12262.006586\n",
            "Epoch 2920: train loss = 4.099346, test loss = 12261.988915\n",
            "Epoch 2921: train loss = 4.099323, test loss = 12261.964303\n",
            "Epoch 2922: train loss = 4.099336, test loss = 12261.927062\n",
            "Epoch 2923: train loss = 4.099319, test loss = 12261.910444\n",
            "Epoch 2924: train loss = 4.099298, test loss = 12261.894075\n",
            "Epoch 2925: train loss = 4.099293, test loss = 12261.871065\n",
            "Epoch 2926: train loss = 4.099298, test loss = 12261.835824\n",
            "Epoch 2927: train loss = 4.099289, test loss = 12261.818076\n",
            "Epoch 2928: train loss = 4.099266, test loss = 12261.793301\n",
            "Epoch 2929: train loss = 4.099278, test loss = 12261.756315\n",
            "Epoch 2930: train loss = 4.099262, test loss = 12261.739877\n",
            "Epoch 2931: train loss = 4.099239, test loss = 12261.715277\n",
            "Epoch 2932: train loss = 4.099257, test loss = 12261.676967\n",
            "Epoch 2933: train loss = 4.099236, test loss = 12261.660938\n",
            "Epoch 2934: train loss = 4.099218, test loss = 12261.633765\n",
            "Epoch 2935: train loss = 4.099231, test loss = 12261.613433\n",
            "Epoch 2936: train loss = 4.099208, test loss = 12261.587149\n",
            "Epoch 2937: train loss = 4.099199, test loss = 12261.554914\n",
            "Epoch 2938: train loss = 4.099204, test loss = 12261.534072\n",
            "Epoch 2939: train loss = 4.099182, test loss = 12261.507753\n",
            "Epoch 2940: train loss = 4.099179, test loss = 12261.473632\n",
            "Epoch 2941: train loss = 4.099178, test loss = 12261.454205\n",
            "Epoch 2942: train loss = 4.099155, test loss = 12261.428618\n",
            "Epoch 2943: train loss = 4.099160, test loss = 12261.393380\n",
            "Epoch 2944: train loss = 4.099151, test loss = 12261.375027\n",
            "Epoch 2945: train loss = 4.099128, test loss = 12261.350533\n",
            "Epoch 2946: train loss = 4.099139, test loss = 12261.313828\n",
            "Epoch 2947: train loss = 4.099125, test loss = 12261.296395\n",
            "Epoch 2948: train loss = 4.099104, test loss = 12261.279289\n",
            "Epoch 2949: train loss = 4.099099, test loss = 12261.256509\n",
            "Epoch 2950: train loss = 4.099101, test loss = 12261.222027\n",
            "Epoch 2951: train loss = 4.099095, test loss = 12261.204250\n",
            "Epoch 2952: train loss = 4.099072, test loss = 12261.179105\n",
            "Epoch 2953: train loss = 4.099081, test loss = 12261.142564\n",
            "Epoch 2954: train loss = 4.099068, test loss = 12261.125181\n",
            "Epoch 2955: train loss = 4.099045, test loss = 12261.100713\n",
            "Epoch 2956: train loss = 4.099061, test loss = 12261.063075\n",
            "Epoch 2957: train loss = 4.099041, test loss = 12261.047144\n",
            "Epoch 2958: train loss = 4.099022, test loss = 12261.029956\n",
            "Epoch 2959: train loss = 4.099016, test loss = 12261.007437\n",
            "Epoch 2960: train loss = 4.099022, test loss = 12260.971806\n",
            "Epoch 2961: train loss = 4.099011, test loss = 12260.954305\n",
            "Epoch 2962: train loss = 4.098988, test loss = 12260.929848\n",
            "Epoch 2963: train loss = 4.099002, test loss = 12260.892395\n",
            "Epoch 2964: train loss = 4.098985, test loss = 12260.876168\n",
            "Epoch 2965: train loss = 4.098963, test loss = 12260.849387\n",
            "Epoch 2966: train loss = 4.098980, test loss = 12260.828178\n",
            "Epoch 2967: train loss = 4.098957, test loss = 12260.801506\n",
            "Epoch 2968: train loss = 4.098944, test loss = 12260.769616\n",
            "Epoch 2969: train loss = 4.098953, test loss = 12260.748290\n",
            "Epoch 2970: train loss = 4.098930, test loss = 12260.721950\n",
            "Epoch 2971: train loss = 4.098925, test loss = 12260.688627\n",
            "Epoch 2972: train loss = 4.098927, test loss = 12260.668959\n",
            "Epoch 2973: train loss = 4.098904, test loss = 12260.642972\n",
            "Epoch 2974: train loss = 4.098905, test loss = 12260.608380\n",
            "Epoch 2975: train loss = 4.098900, test loss = 12260.589345\n",
            "Epoch 2976: train loss = 4.098877, test loss = 12260.564188\n",
            "Epoch 2977: train loss = 4.098885, test loss = 12260.528466\n",
            "Epoch 2978: train loss = 4.098874, test loss = 12260.510602\n",
            "Epoch 2979: train loss = 4.098851, test loss = 12260.493965\n",
            "Epoch 2980: train loss = 4.098848, test loss = 12260.470727\n",
            "Epoch 2981: train loss = 4.098847, test loss = 12260.436784\n",
            "Epoch 2982: train loss = 4.098843, test loss = 12260.418034\n",
            "Epoch 2983: train loss = 4.098820, test loss = 12260.392809\n",
            "Epoch 2984: train loss = 4.098827, test loss = 12260.357213\n",
            "Epoch 2985: train loss = 4.098817, test loss = 12260.339774\n",
            "Epoch 2986: train loss = 4.098794, test loss = 12260.314782\n",
            "Epoch 2987: train loss = 4.098807, test loss = 12260.277791\n",
            "Epoch 2988: train loss = 4.098790, test loss = 12260.260887\n",
            "Epoch 2989: train loss = 4.098769, test loss = 12260.243952\n",
            "Epoch 2990: train loss = 4.098764, test loss = 12260.221312\n",
            "Epoch 2991: train loss = 4.098768, test loss = 12260.186396\n",
            "Epoch 2992: train loss = 4.098760, test loss = 12260.168860\n",
            "Epoch 2993: train loss = 4.098737, test loss = 12260.143930\n",
            "Epoch 2994: train loss = 4.098748, test loss = 12260.106912\n",
            "Epoch 2995: train loss = 4.098734, test loss = 12260.089877\n",
            "Epoch 2996: train loss = 4.098711, test loss = 12260.065612\n",
            "Epoch 2997: train loss = 4.098728, test loss = 12260.027495\n",
            "Epoch 2998: train loss = 4.098707, test loss = 12260.011484\n",
            "Epoch 2999: train loss = 4.098689, test loss = 12259.984549\n",
            "Epoch 3000: train loss = 4.098702, test loss = 12259.964298\n",
            "Epoch 3001: train loss = 4.098679, test loss = 12259.937862\n",
            "Epoch 3002: train loss = 4.098670, test loss = 12259.905279\n",
            "Epoch 3003: train loss = 4.098676, test loss = 12259.884367\n",
            "Epoch 3004: train loss = 4.098653, test loss = 12259.858218\n",
            "Epoch 3005: train loss = 4.098650, test loss = 12259.824388\n",
            "Epoch 3006: train loss = 4.098649, test loss = 12259.805088\n",
            "Epoch 3007: train loss = 4.098626, test loss = 12259.779364\n",
            "Epoch 3008: train loss = 4.098630, test loss = 12259.744098\n",
            "Epoch 3009: train loss = 4.098623, test loss = 12259.725615\n",
            "Epoch 3010: train loss = 4.098600, test loss = 12259.700629\n",
            "Epoch 3011: train loss = 4.098610, test loss = 12259.664323\n",
            "Epoch 3012: train loss = 4.098596, test loss = 12259.647362\n",
            "Epoch 3013: train loss = 4.098575, test loss = 12259.630043\n",
            "Epoch 3014: train loss = 4.098570, test loss = 12259.607014\n",
            "Epoch 3015: train loss = 4.098572, test loss = 12259.572781\n",
            "Epoch 3016: train loss = 4.098566, test loss = 12259.554436\n",
            "Epoch 3017: train loss = 4.098543, test loss = 12259.529430\n",
            "Epoch 3018: train loss = 4.098552, test loss = 12259.493304\n",
            "Epoch 3019: train loss = 4.098539, test loss = 12259.476257\n",
            "Epoch 3020: train loss = 4.098517, test loss = 12259.451414\n",
            "Epoch 3021: train loss = 4.098532, test loss = 12259.413938\n",
            "Epoch 3022: train loss = 4.098513, test loss = 12259.397309\n",
            "Epoch 3023: train loss = 4.098493, test loss = 12259.380500\n",
            "Epoch 3024: train loss = 4.098487, test loss = 12259.358014\n",
            "Epoch 3025: train loss = 4.098493, test loss = 12259.322541\n",
            "Epoch 3026: train loss = 4.098483, test loss = 12259.305118\n",
            "Epoch 3027: train loss = 4.098460, test loss = 12259.280954\n",
            "Epoch 3028: train loss = 4.098473, test loss = 12259.243326\n",
            "Epoch 3029: train loss = 4.098456, test loss = 12259.226607\n",
            "Epoch 3030: train loss = 4.098434, test loss = 12259.209914\n",
            "Epoch 3031: train loss = 4.098430, test loss = 12259.187036\n",
            "Epoch 3032: train loss = 4.098435, test loss = 12259.151740\n",
            "Epoch 3033: train loss = 4.098426, test loss = 12259.134453\n",
            "Epoch 3034: train loss = 4.098403, test loss = 12259.109425\n",
            "Epoch 3035: train loss = 4.098415, test loss = 12259.072197\n",
            "Epoch 3036: train loss = 4.098400, test loss = 12259.055236\n",
            "Epoch 3037: train loss = 4.098377, test loss = 12259.021104\n",
            "Epoch 3038: train loss = 4.098375, test loss = 12258.996459\n",
            "Epoch 3039: train loss = 4.098374, test loss = 12258.962910\n",
            "Epoch 3040: train loss = 4.098372, test loss = 12258.943156\n",
            "Epoch 3041: train loss = 4.098349, test loss = 12258.917408\n",
            "Epoch 3042: train loss = 4.098355, test loss = 12258.881632\n",
            "Epoch 3043: train loss = 4.098345, test loss = 12258.863213\n",
            "Epoch 3044: train loss = 4.098323, test loss = 12258.838216\n",
            "Epoch 3045: train loss = 4.098335, test loss = 12258.801387\n",
            "Epoch 3046: train loss = 4.098319, test loss = 12258.784567\n",
            "Epoch 3047: train loss = 4.098299, test loss = 12258.766977\n",
            "Epoch 3048: train loss = 4.098293, test loss = 12258.744142\n",
            "Epoch 3049: train loss = 4.098297, test loss = 12258.709509\n",
            "Epoch 3050: train loss = 4.098289, test loss = 12258.691294\n",
            "Epoch 3051: train loss = 4.098266, test loss = 12258.666422\n",
            "Epoch 3052: train loss = 4.098277, test loss = 12258.629903\n",
            "Epoch 3053: train loss = 4.098262, test loss = 12258.612525\n",
            "Epoch 3054: train loss = 4.098240, test loss = 12258.596068\n",
            "Epoch 3055: train loss = 4.098237, test loss = 12258.572902\n",
            "Epoch 3056: train loss = 4.098239, test loss = 12258.538166\n",
            "Epoch 3057: train loss = 4.098232, test loss = 12258.519907\n",
            "Epoch 3058: train loss = 4.098209, test loss = 12258.494983\n",
            "Epoch 3059: train loss = 4.098218, test loss = 12258.458432\n",
            "Epoch 3060: train loss = 4.098206, test loss = 12258.441147\n",
            "Epoch 3061: train loss = 4.098183, test loss = 12258.417004\n",
            "Epoch 3062: train loss = 4.098198, test loss = 12258.379169\n",
            "Epoch 3063: train loss = 4.098179, test loss = 12258.362698\n",
            "Epoch 3064: train loss = 4.098159, test loss = 12258.335856\n",
            "Epoch 3065: train loss = 4.098174, test loss = 12258.314976\n",
            "Epoch 3066: train loss = 4.098152, test loss = 12258.288605\n",
            "Epoch 3067: train loss = 4.098140, test loss = 12258.256817\n",
            "Epoch 3068: train loss = 4.098148, test loss = 12258.235566\n",
            "Epoch 3069: train loss = 4.098125, test loss = 12258.209164\n",
            "Epoch 3070: train loss = 4.098121, test loss = 12258.175496\n",
            "Epoch 3071: train loss = 4.098121, test loss = 12258.155674\n",
            "Epoch 3072: train loss = 4.098099, test loss = 12258.130014\n",
            "Epoch 3073: train loss = 4.098101, test loss = 12258.095213\n",
            "Epoch 3074: train loss = 4.098095, test loss = 12258.076946\n",
            "Epoch 3075: train loss = 4.098072, test loss = 12258.051535\n",
            "Epoch 3076: train loss = 4.098081, test loss = 12258.015543\n",
            "Epoch 3077: train loss = 4.098068, test loss = 12257.997903\n",
            "Epoch 3078: train loss = 4.098047, test loss = 12257.980635\n",
            "Epoch 3079: train loss = 4.098043, test loss = 12257.957769\n",
            "Epoch 3080: train loss = 4.098043, test loss = 12257.923920\n",
            "Epoch 3081: train loss = 4.098038, test loss = 12257.905307\n",
            "Epoch 3082: train loss = 4.098016, test loss = 12257.880691\n",
            "Epoch 3083: train loss = 4.098023, test loss = 12257.844667\n",
            "Epoch 3084: train loss = 4.098012, test loss = 12257.826734\n",
            "Epoch 3085: train loss = 4.097989, test loss = 12257.802104\n",
            "Epoch 3086: train loss = 4.098003, test loss = 12257.764940\n",
            "Epoch 3087: train loss = 4.097985, test loss = 12257.748288\n",
            "Epoch 3088: train loss = 4.097965, test loss = 12257.731807\n",
            "Epoch 3089: train loss = 4.097960, test loss = 12257.708931\n",
            "Epoch 3090: train loss = 4.097965, test loss = 12257.673775\n",
            "Epoch 3091: train loss = 4.097955, test loss = 12257.656019\n",
            "Epoch 3092: train loss = 4.097932, test loss = 12257.631241\n",
            "Epoch 3093: train loss = 4.097944, test loss = 12257.594339\n",
            "Epoch 3094: train loss = 4.097929, test loss = 12257.577882\n",
            "Epoch 3095: train loss = 4.097906, test loss = 12257.560877\n",
            "Epoch 3096: train loss = 4.097903, test loss = 12257.537950\n",
            "Epoch 3097: train loss = 4.097906, test loss = 12257.502852\n",
            "Epoch 3098: train loss = 4.097899, test loss = 12257.484834\n",
            "Epoch 3099: train loss = 4.097876, test loss = 12257.460152\n",
            "Epoch 3100: train loss = 4.097886, test loss = 12257.423186\n",
            "Epoch 3101: train loss = 4.097872, test loss = 12257.406629\n",
            "Epoch 3102: train loss = 4.097850, test loss = 12257.382106\n",
            "Epoch 3103: train loss = 4.097866, test loss = 12257.343805\n",
            "Epoch 3104: train loss = 4.097846, test loss = 12257.327746\n",
            "Epoch 3105: train loss = 4.097827, test loss = 12257.300736\n",
            "Epoch 3106: train loss = 4.097841, test loss = 12257.280099\n",
            "Epoch 3107: train loss = 4.097818, test loss = 12257.253882\n",
            "Epoch 3108: train loss = 4.097808, test loss = 12257.221422\n",
            "Epoch 3109: train loss = 4.097815, test loss = 12257.200973\n",
            "Epoch 3110: train loss = 4.097792, test loss = 12257.174602\n",
            "Epoch 3111: train loss = 4.097789, test loss = 12257.140611\n",
            "Epoch 3112: train loss = 4.097788, test loss = 12257.120876\n",
            "Epoch 3113: train loss = 4.097765, test loss = 12257.095362\n",
            "Epoch 3114: train loss = 4.097769, test loss = 12257.060215\n",
            "Epoch 3115: train loss = 4.097762, test loss = 12257.042210\n",
            "Epoch 3116: train loss = 4.097739, test loss = 12257.016997\n",
            "Epoch 3117: train loss = 4.097749, test loss = 12256.980527\n",
            "Epoch 3118: train loss = 4.097735, test loss = 12256.963123\n",
            "Epoch 3119: train loss = 4.097713, test loss = 12256.946175\n",
            "Epoch 3120: train loss = 4.097709, test loss = 12256.923225\n",
            "Epoch 3121: train loss = 4.097711, test loss = 12256.889381\n",
            "Epoch 3122: train loss = 4.097705, test loss = 12256.870788\n",
            "Epoch 3123: train loss = 4.097682, test loss = 12256.845666\n",
            "Epoch 3124: train loss = 4.097691, test loss = 12256.809436\n",
            "Epoch 3125: train loss = 4.097679, test loss = 12256.791871\n",
            "Epoch 3126: train loss = 4.097656, test loss = 12256.767446\n",
            "Epoch 3127: train loss = 4.097671, test loss = 12256.730036\n",
            "Epoch 3128: train loss = 4.097652, test loss = 12256.713482\n",
            "Epoch 3129: train loss = 4.097631, test loss = 12256.697290\n",
            "Epoch 3130: train loss = 4.097627, test loss = 12256.674447\n",
            "Epoch 3131: train loss = 4.097632, test loss = 12256.638755\n",
            "Epoch 3132: train loss = 4.097622, test loss = 12256.621276\n",
            "Epoch 3133: train loss = 4.097599, test loss = 12256.596703\n",
            "Epoch 3134: train loss = 4.097612, test loss = 12256.559285\n",
            "Epoch 3135: train loss = 4.097596, test loss = 12256.542715\n",
            "Epoch 3136: train loss = 4.097573, test loss = 12256.509026\n",
            "Epoch 3137: train loss = 4.097571, test loss = 12256.484046\n",
            "Epoch 3138: train loss = 4.097572, test loss = 12256.449971\n",
            "Epoch 3139: train loss = 4.097568, test loss = 12256.430485\n",
            "Epoch 3140: train loss = 4.097545, test loss = 12256.404907\n",
            "Epoch 3141: train loss = 4.097552, test loss = 12256.369189\n",
            "Epoch 3142: train loss = 4.097542, test loss = 12256.351228\n",
            "Epoch 3143: train loss = 4.097520, test loss = 12256.333536\n",
            "Epoch 3144: train loss = 4.097516, test loss = 12256.310251\n",
            "Epoch 3145: train loss = 4.097515, test loss = 12256.276509\n",
            "Epoch 3146: train loss = 4.097512, test loss = 12256.257504\n",
            "Epoch 3147: train loss = 4.097489, test loss = 12256.232256\n",
            "Epoch 3148: train loss = 4.097495, test loss = 12256.197061\n",
            "Epoch 3149: train loss = 4.097485, test loss = 12256.178712\n",
            "Epoch 3150: train loss = 4.097462, test loss = 12256.153821\n",
            "Epoch 3151: train loss = 4.097475, test loss = 12256.116929\n",
            "Epoch 3152: train loss = 4.097459, test loss = 12256.099883\n",
            "Epoch 3153: train loss = 4.097438, test loss = 12256.082843\n",
            "Epoch 3154: train loss = 4.097433, test loss = 12256.060168\n",
            "Epoch 3155: train loss = 4.097436, test loss = 12256.025483\n",
            "Epoch 3156: train loss = 4.097429, test loss = 12256.007810\n",
            "Epoch 3157: train loss = 4.097406, test loss = 12255.982802\n",
            "Epoch 3158: train loss = 4.097417, test loss = 12255.946068\n",
            "Epoch 3159: train loss = 4.097402, test loss = 12255.928812\n",
            "Epoch 3160: train loss = 4.097380, test loss = 12255.912073\n",
            "Epoch 3161: train loss = 4.097377, test loss = 12255.889153\n",
            "Epoch 3162: train loss = 4.097378, test loss = 12255.854351\n",
            "Epoch 3163: train loss = 4.097372, test loss = 12255.836285\n",
            "Epoch 3164: train loss = 4.097350, test loss = 12255.811745\n",
            "Epoch 3165: train loss = 4.097358, test loss = 12255.775018\n",
            "Epoch 3166: train loss = 4.097346, test loss = 12255.757651\n",
            "Epoch 3167: train loss = 4.097323, test loss = 12255.733101\n",
            "Epoch 3168: train loss = 4.097338, test loss = 12255.695355\n",
            "Epoch 3169: train loss = 4.097320, test loss = 12255.679132\n",
            "Epoch 3170: train loss = 4.097299, test loss = 12255.652667\n",
            "Epoch 3171: train loss = 4.097315, test loss = 12255.631691\n",
            "Epoch 3172: train loss = 4.097292, test loss = 12255.605216\n",
            "Epoch 3173: train loss = 4.097280, test loss = 12255.572855\n",
            "Epoch 3174: train loss = 4.097288, test loss = 12255.551893\n",
            "Epoch 3175: train loss = 4.097266, test loss = 12255.525702\n",
            "Epoch 3176: train loss = 4.097261, test loss = 12255.492414\n",
            "Epoch 3177: train loss = 4.097262, test loss = 12255.472423\n",
            "Epoch 3178: train loss = 4.097239, test loss = 12255.446595\n",
            "Epoch 3179: train loss = 4.097241, test loss = 12255.411770\n",
            "Epoch 3180: train loss = 4.097235, test loss = 12255.393117\n",
            "Epoch 3181: train loss = 4.097213, test loss = 12255.368014\n",
            "Epoch 3182: train loss = 4.097221, test loss = 12255.332047\n",
            "Epoch 3183: train loss = 4.097209, test loss = 12255.314497\n",
            "Epoch 3184: train loss = 4.097187, test loss = 12255.297900\n",
            "Epoch 3185: train loss = 4.097183, test loss = 12255.274707\n",
            "Epoch 3186: train loss = 4.097183, test loss = 12255.240598\n",
            "Epoch 3187: train loss = 4.097179, test loss = 12255.221978\n",
            "Epoch 3188: train loss = 4.097156, test loss = 12255.196978\n",
            "Epoch 3189: train loss = 4.097163, test loss = 12255.160971\n",
            "Epoch 3190: train loss = 4.097153, test loss = 12255.143405\n",
            "Epoch 3191: train loss = 4.097130, test loss = 12255.119251\n",
            "Epoch 3192: train loss = 4.097143, test loss = 12255.081747\n",
            "Epoch 3193: train loss = 4.097126, test loss = 12255.065051\n",
            "Epoch 3194: train loss = 4.097105, test loss = 12255.048287\n",
            "Epoch 3195: train loss = 4.097100, test loss = 12255.025551\n",
            "Epoch 3196: train loss = 4.097105, test loss = 12254.990430\n",
            "Epoch 3197: train loss = 4.097096, test loss = 12254.973183\n",
            "Epoch 3198: train loss = 4.097073, test loss = 12254.948192\n",
            "Epoch 3199: train loss = 4.097085, test loss = 12254.911085\n",
            "Epoch 3200: train loss = 4.097070, test loss = 12254.894225\n",
            "Epoch 3201: train loss = 4.097047, test loss = 12254.869910\n",
            "Epoch 3202: train loss = 4.097065, test loss = 12254.831723\n",
            "Epoch 3203: train loss = 4.097043, test loss = 12254.816211\n",
            "Epoch 3204: train loss = 4.097026, test loss = 12254.788794\n",
            "Epoch 3205: train loss = 4.097038, test loss = 12254.768387\n",
            "Epoch 3206: train loss = 4.097016, test loss = 12254.742083\n",
            "Epoch 3207: train loss = 4.097007, test loss = 12254.709405\n",
            "Epoch 3208: train loss = 4.097012, test loss = 12254.688879\n",
            "Epoch 3209: train loss = 4.096989, test loss = 12254.662722\n",
            "Epoch 3210: train loss = 4.096987, test loss = 12254.628665\n",
            "Epoch 3211: train loss = 4.096986, test loss = 12254.609734\n",
            "Epoch 3212: train loss = 4.096963, test loss = 12254.583910\n",
            "Epoch 3213: train loss = 4.096968, test loss = 12254.548542\n",
            "Epoch 3214: train loss = 4.096959, test loss = 12254.530263\n",
            "Epoch 3215: train loss = 4.096936, test loss = 12254.505256\n",
            "Epoch 3216: train loss = 4.096948, test loss = 12254.468825\n",
            "Epoch 3217: train loss = 4.096933, test loss = 12254.451567\n",
            "Epoch 3218: train loss = 4.096912, test loss = 12254.434978\n",
            "Epoch 3219: train loss = 4.096907, test loss = 12254.411985\n",
            "Epoch 3220: train loss = 4.096910, test loss = 12254.377386\n",
            "Epoch 3221: train loss = 4.096903, test loss = 12254.359196\n",
            "Epoch 3222: train loss = 4.096880, test loss = 12254.334331\n",
            "Epoch 3223: train loss = 4.096890, test loss = 12254.297914\n",
            "Epoch 3224: train loss = 4.096877, test loss = 12254.281035\n",
            "Epoch 3225: train loss = 4.096854, test loss = 12254.256353\n",
            "Epoch 3226: train loss = 4.096870, test loss = 12254.218592\n",
            "Epoch 3227: train loss = 4.096850, test loss = 12254.202237\n",
            "Epoch 3228: train loss = 4.096830, test loss = 12254.175604\n",
            "Epoch 3229: train loss = 4.096845, test loss = 12254.154691\n",
            "Epoch 3230: train loss = 4.096822, test loss = 12254.128335\n",
            "Epoch 3231: train loss = 4.096812, test loss = 12254.096633\n",
            "Epoch 3232: train loss = 4.096819, test loss = 12254.075404\n",
            "Epoch 3233: train loss = 4.096796, test loss = 12254.049028\n",
            "Epoch 3234: train loss = 4.096792, test loss = 12254.015423\n",
            "Epoch 3235: train loss = 4.096792, test loss = 12253.995625\n",
            "Epoch 3236: train loss = 4.096770, test loss = 12253.969991\n",
            "Epoch 3237: train loss = 4.096773, test loss = 12253.935251\n",
            "Epoch 3238: train loss = 4.096766, test loss = 12253.916588\n",
            "Epoch 3239: train loss = 4.096743, test loss = 12253.892003\n",
            "Epoch 3240: train loss = 4.096753, test loss = 12253.855782\n",
            "Epoch 3241: train loss = 4.096740, test loss = 12253.838110\n",
            "Epoch 3242: train loss = 4.096719, test loss = 12253.820717\n",
            "Epoch 3243: train loss = 4.096714, test loss = 12253.797952\n",
            "Epoch 3244: train loss = 4.096715, test loss = 12253.764200\n",
            "Epoch 3245: train loss = 4.096710, test loss = 12253.745619\n",
            "Epoch 3246: train loss = 4.096687, test loss = 12253.721033\n",
            "Epoch 3247: train loss = 4.096695, test loss = 12253.685061\n",
            "Epoch 3248: train loss = 4.096683, test loss = 12253.667145\n",
            "Epoch 3249: train loss = 4.096661, test loss = 12253.650119\n",
            "Epoch 3250: train loss = 4.096657, test loss = 12253.627118\n",
            "Epoch 3251: train loss = 4.096657, test loss = 12253.593259\n",
            "Epoch 3252: train loss = 4.096653, test loss = 12253.575055\n",
            "Epoch 3253: train loss = 4.096630, test loss = 12253.549780\n",
            "Epoch 3254: train loss = 4.096637, test loss = 12253.513821\n",
            "Epoch 3255: train loss = 4.096627, test loss = 12253.496021\n",
            "Epoch 3256: train loss = 4.096604, test loss = 12253.471288\n",
            "Epoch 3257: train loss = 4.096617, test loss = 12253.434391\n",
            "Epoch 3258: train loss = 4.096600, test loss = 12253.418048\n",
            "Epoch 3259: train loss = 4.096579, test loss = 12253.400974\n",
            "Epoch 3260: train loss = 4.096575, test loss = 12253.378213\n",
            "Epoch 3261: train loss = 4.096579, test loss = 12253.343174\n",
            "Epoch 3262: train loss = 4.096570, test loss = 12253.325266\n",
            "Epoch 3263: train loss = 4.096548, test loss = 12253.300650\n",
            "Epoch 3264: train loss = 4.096559, test loss = 12253.263792\n",
            "Epoch 3265: train loss = 4.096544, test loss = 12253.246767\n",
            "Epoch 3266: train loss = 4.096521, test loss = 12253.223022\n",
            "Epoch 3267: train loss = 4.096539, test loss = 12253.184582\n",
            "Epoch 3268: train loss = 4.096518, test loss = 12253.168525\n",
            "Epoch 3269: train loss = 4.096500, test loss = 12253.141499\n",
            "Epoch 3270: train loss = 4.096513, test loss = 12253.120921\n",
            "Epoch 3271: train loss = 4.096490, test loss = 12253.094740\n",
            "Epoch 3272: train loss = 4.096481, test loss = 12253.062278\n",
            "Epoch 3273: train loss = 4.096487, test loss = 12253.041897\n",
            "Epoch 3274: train loss = 4.096464, test loss = 12253.015559\n",
            "Epoch 3275: train loss = 4.096461, test loss = 12252.981563\n",
            "Epoch 3276: train loss = 4.096460, test loss = 12252.961887\n",
            "Epoch 3277: train loss = 4.096437, test loss = 12252.936408\n",
            "Epoch 3278: train loss = 4.096442, test loss = 12252.901353\n",
            "Epoch 3279: train loss = 4.096434, test loss = 12252.883279\n",
            "Epoch 3280: train loss = 4.096411, test loss = 12252.858115\n",
            "Epoch 3281: train loss = 4.096422, test loss = 12252.821650\n",
            "Epoch 3282: train loss = 4.096408, test loss = 12252.804301\n",
            "Epoch 3283: train loss = 4.096386, test loss = 12252.787249\n",
            "Epoch 3284: train loss = 4.096382, test loss = 12252.764428\n",
            "Epoch 3285: train loss = 4.096384, test loss = 12252.730205\n",
            "Epoch 3286: train loss = 4.096377, test loss = 12252.712379\n",
            "Epoch 3287: train loss = 4.096355, test loss = 12252.687153\n",
            "Epoch 3288: train loss = 4.096364, test loss = 12252.650854\n",
            "Epoch 3289: train loss = 4.096351, test loss = 12252.633399\n",
            "Epoch 3290: train loss = 4.096328, test loss = 12252.608858\n",
            "Epoch 3291: train loss = 4.096344, test loss = 12252.571458\n",
            "Epoch 3292: train loss = 4.096325, test loss = 12252.555050\n",
            "Epoch 3293: train loss = 4.096305, test loss = 12252.538626\n",
            "Epoch 3294: train loss = 4.096299, test loss = 12252.515920\n",
            "Epoch 3295: train loss = 4.096306, test loss = 12252.480285\n",
            "Epoch 3296: train loss = 4.096295, test loss = 12252.462867\n",
            "Epoch 3297: train loss = 4.096272, test loss = 12252.438331\n",
            "Epoch 3298: train loss = 4.096286, test loss = 12252.400922\n",
            "Epoch 3299: train loss = 4.096269, test loss = 12252.384391\n",
            "Epoch 3300: train loss = 4.096247, test loss = 12252.358370\n",
            "Epoch 3301: train loss = 4.096264, test loss = 12252.336863\n",
            "Epoch 3302: train loss = 4.096241, test loss = 12252.310288\n",
            "Epoch 3303: train loss = 4.096228, test loss = 12252.278446\n",
            "Epoch 3304: train loss = 4.096237, test loss = 12252.257049\n",
            "Epoch 3305: train loss = 4.096215, test loss = 12252.230744\n",
            "Epoch 3306: train loss = 4.096209, test loss = 12252.197878\n",
            "Epoch 3307: train loss = 4.096211, test loss = 12252.177548\n",
            "Epoch 3308: train loss = 4.096188, test loss = 12252.151735\n",
            "Epoch 3309: train loss = 4.096189, test loss = 12252.117193\n",
            "Epoch 3310: train loss = 4.096185, test loss = 12252.098279\n",
            "Epoch 3311: train loss = 4.096162, test loss = 12252.073167\n",
            "Epoch 3312: train loss = 4.096169, test loss = 12252.037476\n",
            "Epoch 3313: train loss = 4.096158, test loss = 12252.020088\n",
            "Epoch 3314: train loss = 4.096136, test loss = 12252.002830\n",
            "Epoch 3315: train loss = 4.096133, test loss = 12251.979588\n",
            "Epoch 3316: train loss = 4.096131, test loss = 12251.945986\n",
            "Epoch 3317: train loss = 4.096128, test loss = 12251.927257\n",
            "Epoch 3318: train loss = 4.096106, test loss = 12251.902036\n",
            "Epoch 3319: train loss = 4.096111, test loss = 12251.866540\n",
            "Epoch 3320: train loss = 4.096102, test loss = 12251.848565\n",
            "Epoch 3321: train loss = 4.096079, test loss = 12251.824397\n",
            "Epoch 3322: train loss = 4.096091, test loss = 12251.787366\n",
            "Epoch 3323: train loss = 4.096076, test loss = 12251.770307\n",
            "Epoch 3324: train loss = 4.096054, test loss = 12251.753501\n",
            "Epoch 3325: train loss = 4.096050, test loss = 12251.730812\n",
            "Epoch 3326: train loss = 4.096053, test loss = 12251.695916\n",
            "Epoch 3327: train loss = 4.096046, test loss = 12251.678092\n",
            "Epoch 3328: train loss = 4.096023, test loss = 12251.653788\n",
            "Epoch 3329: train loss = 4.096033, test loss = 12251.616791\n",
            "Epoch 3330: train loss = 4.096019, test loss = 12251.599651\n",
            "Epoch 3331: train loss = 4.095997, test loss = 12251.575321\n",
            "Epoch 3332: train loss = 4.096013, test loss = 12251.537303\n",
            "Epoch 3333: train loss = 4.095993, test loss = 12251.521292\n",
            "Epoch 3334: train loss = 4.095974, test loss = 12251.494747\n",
            "Epoch 3335: train loss = 4.095988, test loss = 12251.473973\n",
            "Epoch 3336: train loss = 4.095965, test loss = 12251.447605\n",
            "Epoch 3337: train loss = 4.095955, test loss = 12251.415109\n",
            "Epoch 3338: train loss = 4.095962, test loss = 12251.394320\n",
            "Epoch 3339: train loss = 4.095939, test loss = 12251.368219\n",
            "Epoch 3340: train loss = 4.095936, test loss = 12251.334369\n",
            "Epoch 3341: train loss = 4.095936, test loss = 12251.315198\n",
            "Epoch 3342: train loss = 4.095913, test loss = 12251.289447\n",
            "Epoch 3343: train loss = 4.095916, test loss = 12251.254285\n",
            "Epoch 3344: train loss = 4.095909, test loss = 12251.235781\n",
            "Epoch 3345: train loss = 4.095886, test loss = 12251.210851\n",
            "Epoch 3346: train loss = 4.095897, test loss = 12251.174613\n",
            "Epoch 3347: train loss = 4.095883, test loss = 12251.157230\n",
            "Epoch 3348: train loss = 4.095862, test loss = 12251.140550\n",
            "Epoch 3349: train loss = 4.095857, test loss = 12251.117524\n",
            "Epoch 3350: train loss = 4.095859, test loss = 12251.083326\n",
            "Epoch 3351: train loss = 4.095853, test loss = 12251.064869\n",
            "Epoch 3352: train loss = 4.095830, test loss = 12251.039945\n",
            "Epoch 3353: train loss = 4.095839, test loss = 12251.003908\n",
            "Epoch 3354: train loss = 4.095827, test loss = 12250.986353\n",
            "Epoch 3355: train loss = 4.095804, test loss = 12250.962287\n",
            "Epoch 3356: train loss = 4.095819, test loss = 12250.924761\n",
            "Epoch 3357: train loss = 4.095800, test loss = 12250.908070\n",
            "Epoch 3358: train loss = 4.095781, test loss = 12250.891222\n",
            "Epoch 3359: train loss = 4.095775, test loss = 12250.868654\n",
            "Epoch 3360: train loss = 4.095781, test loss = 12250.833460\n",
            "Epoch 3361: train loss = 4.095770, test loss = 12250.816361\n",
            "Epoch 3362: train loss = 4.095748, test loss = 12250.791442\n",
            "Epoch 3363: train loss = 4.095761, test loss = 12250.754219\n",
            "Epoch 3364: train loss = 4.095744, test loss = 12250.737481\n",
            "Epoch 3365: train loss = 4.095722, test loss = 12250.720751\n",
            "Epoch 3366: train loss = 4.095718, test loss = 12250.698080\n",
            "Epoch 3367: train loss = 4.095723, test loss = 12250.662846\n",
            "Epoch 3368: train loss = 4.095714, test loss = 12250.645458\n",
            "Epoch 3369: train loss = 4.095692, test loss = 12250.620601\n",
            "Epoch 3370: train loss = 4.095703, test loss = 12250.583415\n",
            "Epoch 3371: train loss = 4.095688, test loss = 12250.566422\n",
            "Epoch 3372: train loss = 4.095665, test loss = 12250.532409\n",
            "Epoch 3373: train loss = 4.095664, test loss = 12250.507599\n",
            "Epoch 3374: train loss = 4.095662, test loss = 12250.473847\n",
            "Epoch 3375: train loss = 4.095660, test loss = 12250.454387\n",
            "Epoch 3376: train loss = 4.095638, test loss = 12250.429026\n",
            "Epoch 3377: train loss = 4.095643, test loss = 12250.393270\n",
            "Epoch 3378: train loss = 4.095634, test loss = 12250.374769\n",
            "Epoch 3379: train loss = 4.095611, test loss = 12250.349587\n",
            "Epoch 3380: train loss = 4.095624, test loss = 12250.312965\n",
            "Epoch 3381: train loss = 4.095608, test loss = 12250.295730\n",
            "Epoch 3382: train loss = 4.095588, test loss = 12250.278797\n",
            "Epoch 3383: train loss = 4.095582, test loss = 12250.255854\n",
            "Epoch 3384: train loss = 4.095586, test loss = 12250.221202\n",
            "Epoch 3385: train loss = 4.095578, test loss = 12250.203025\n",
            "Epoch 3386: train loss = 4.095555, test loss = 12250.178145\n",
            "Epoch 3387: train loss = 4.095566, test loss = 12250.141651\n",
            "Epoch 3388: train loss = 4.095552, test loss = 12250.124795\n",
            "Epoch 3389: train loss = 4.095530, test loss = 12250.107616\n",
            "Epoch 3390: train loss = 4.095526, test loss = 12250.084562\n",
            "Epoch 3391: train loss = 4.095528, test loss = 12250.050080\n",
            "Epoch 3392: train loss = 4.095522, test loss = 12250.031828\n",
            "Epoch 3393: train loss = 4.095499, test loss = 12250.006870\n",
            "Epoch 3394: train loss = 4.095508, test loss = 12249.970549\n",
            "Epoch 3395: train loss = 4.095496, test loss = 12249.953620\n",
            "Epoch 3396: train loss = 4.095473, test loss = 12249.928839\n",
            "Epoch 3397: train loss = 4.095488, test loss = 12249.891178\n",
            "Epoch 3398: train loss = 4.095469, test loss = 12249.874674\n",
            "Epoch 3399: train loss = 4.095449, test loss = 12249.848118\n",
            "Epoch 3400: train loss = 4.095464, test loss = 12249.827232\n",
            "Epoch 3401: train loss = 4.095442, test loss = 12249.800743\n",
            "Epoch 3402: train loss = 4.095430, test loss = 12249.768751\n",
            "Epoch 3403: train loss = 4.095438, test loss = 12249.748179\n",
            "Epoch 3404: train loss = 4.095416, test loss = 12249.721541\n",
            "Epoch 3405: train loss = 4.095411, test loss = 12249.688062\n",
            "Epoch 3406: train loss = 4.095412, test loss = 12249.668144\n",
            "Epoch 3407: train loss = 4.095389, test loss = 12249.642386\n",
            "Epoch 3408: train loss = 4.095392, test loss = 12249.607787\n",
            "Epoch 3409: train loss = 4.095386, test loss = 12249.589124\n",
            "Epoch 3410: train loss = 4.095363, test loss = 12249.564364\n",
            "Epoch 3411: train loss = 4.095372, test loss = 12249.528357\n",
            "Epoch 3412: train loss = 4.095359, test loss = 12249.510506\n",
            "Epoch 3413: train loss = 4.095338, test loss = 12249.493374\n",
            "Epoch 3414: train loss = 4.095334, test loss = 12249.470509\n",
            "Epoch 3415: train loss = 4.095334, test loss = 12249.436681\n",
            "Epoch 3416: train loss = 4.095330, test loss = 12249.418562\n",
            "Epoch 3417: train loss = 4.095307, test loss = 12249.393331\n",
            "Epoch 3418: train loss = 4.095314, test loss = 12249.357360\n",
            "Epoch 3419: train loss = 4.095303, test loss = 12249.339622\n",
            "Epoch 3420: train loss = 4.095280, test loss = 12249.315022\n",
            "Epoch 3421: train loss = 4.095294, test loss = 12249.277975\n",
            "Epoch 3422: train loss = 4.095277, test loss = 12249.261716\n",
            "Epoch 3423: train loss = 4.095257, test loss = 12249.244545\n",
            "Epoch 3424: train loss = 4.095251, test loss = 12249.221917\n",
            "Epoch 3425: train loss = 4.095256, test loss = 12249.186906\n",
            "Epoch 3426: train loss = 4.095247, test loss = 12249.169077\n",
            "Epoch 3427: train loss = 4.095224, test loss = 12249.144503\n",
            "Epoch 3428: train loss = 4.095236, test loss = 12249.107629\n",
            "Epoch 3429: train loss = 4.095221, test loss = 12249.090666\n",
            "Epoch 3430: train loss = 4.095198, test loss = 12249.074099\n",
            "Epoch 3431: train loss = 4.095195, test loss = 12249.051714\n",
            "Epoch 3432: train loss = 4.095198, test loss = 12249.016395\n",
            "Epoch 3433: train loss = 4.095191, test loss = 12248.998460\n",
            "Epoch 3434: train loss = 4.095168, test loss = 12248.973696\n",
            "Epoch 3435: train loss = 4.095178, test loss = 12248.936776\n",
            "Epoch 3436: train loss = 4.095165, test loss = 12248.919830\n",
            "Epoch 3437: train loss = 4.095142, test loss = 12248.895869\n",
            "Epoch 3438: train loss = 4.095159, test loss = 12248.857630\n",
            "Epoch 3439: train loss = 4.095139, test loss = 12248.841528\n",
            "Epoch 3440: train loss = 4.095119, test loss = 12248.814420\n",
            "Epoch 3441: train loss = 4.095134, test loss = 12248.793897\n",
            "Epoch 3442: train loss = 4.095111, test loss = 12248.767714\n",
            "Epoch 3443: train loss = 4.095101, test loss = 12248.735592\n",
            "Epoch 3444: train loss = 4.095107, test loss = 12248.714602\n",
            "Epoch 3445: train loss = 4.095085, test loss = 12248.688402\n",
            "Epoch 3446: train loss = 4.095081, test loss = 12248.654396\n",
            "Epoch 3447: train loss = 4.095081, test loss = 12248.634829\n",
            "Epoch 3448: train loss = 4.095058, test loss = 12248.609066\n",
            "Epoch 3449: train loss = 4.095062, test loss = 12248.574241\n",
            "Epoch 3450: train loss = 4.095055, test loss = 12248.556269\n",
            "Epoch 3451: train loss = 4.095032, test loss = 12248.530045\n",
            "Epoch 3452: train loss = 4.095042, test loss = 12248.494692\n",
            "Epoch 3453: train loss = 4.095029, test loss = 12248.477202\n",
            "Epoch 3454: train loss = 4.095007, test loss = 12248.460309\n",
            "Epoch 3455: train loss = 4.095003, test loss = 12248.436195\n",
            "Epoch 3456: train loss = 4.095004, test loss = 12248.403276\n",
            "Epoch 3457: train loss = 4.094999, test loss = 12248.384511\n",
            "Epoch 3458: train loss = 4.094976, test loss = 12248.358484\n",
            "Epoch 3459: train loss = 4.094984, test loss = 12248.324046\n",
            "Epoch 3460: train loss = 4.094973, test loss = 12248.305361\n",
            "Epoch 3461: train loss = 4.094950, test loss = 12248.279327\n",
            "Epoch 3462: train loss = 4.094964, test loss = 12248.244309\n",
            "Epoch 3463: train loss = 4.094946, test loss = 12248.226372\n",
            "Epoch 3464: train loss = 4.094926, test loss = 12248.210479\n",
            "Epoch 3465: train loss = 4.094921, test loss = 12248.186040\n",
            "Epoch 3466: train loss = 4.094926, test loss = 12248.153028\n",
            "Epoch 3467: train loss = 4.094917, test loss = 12248.133946\n",
            "Epoch 3468: train loss = 4.094894, test loss = 12248.107755\n",
            "Epoch 3469: train loss = 4.094907, test loss = 12248.073014\n",
            "Epoch 3470: train loss = 4.094890, test loss = 12248.055249\n",
            "Epoch 3471: train loss = 4.094868, test loss = 12248.021355\n",
            "Epoch 3472: train loss = 4.094866, test loss = 12247.995135\n",
            "Epoch 3473: train loss = 4.094866, test loss = 12247.963541\n",
            "Epoch 3474: train loss = 4.094863, test loss = 12247.942534\n",
            "Epoch 3475: train loss = 4.094840, test loss = 12247.915493\n",
            "Epoch 3476: train loss = 4.094847, test loss = 12247.882128\n",
            "Epoch 3477: train loss = 4.094837, test loss = 12247.862783\n",
            "Epoch 3478: train loss = 4.094815, test loss = 12247.845491\n",
            "Epoch 3479: train loss = 4.094811, test loss = 12247.820549\n",
            "Epoch 3480: train loss = 4.094810, test loss = 12247.789433\n",
            "Epoch 3481: train loss = 4.094807, test loss = 12247.768918\n",
            "Epoch 3482: train loss = 4.094784, test loss = 12247.741997\n",
            "Epoch 3483: train loss = 4.094790, test loss = 12247.709003\n",
            "Epoch 3484: train loss = 4.094781, test loss = 12247.689385\n",
            "Epoch 3485: train loss = 4.094758, test loss = 12247.663431\n",
            "Epoch 3486: train loss = 4.094770, test loss = 12247.628948\n",
            "Epoch 3487: train loss = 4.094754, test loss = 12247.610296\n",
            "Epoch 3488: train loss = 4.094734, test loss = 12247.593529\n",
            "Epoch 3489: train loss = 4.094729, test loss = 12247.569332\n",
            "Epoch 3490: train loss = 4.094732, test loss = 12247.537038\n",
            "Epoch 3491: train loss = 4.094725, test loss = 12247.517571\n",
            "Epoch 3492: train loss = 4.094702, test loss = 12247.491678\n",
            "Epoch 3493: train loss = 4.094712, test loss = 12247.457244\n",
            "Epoch 3494: train loss = 4.094698, test loss = 12247.438457\n",
            "Epoch 3495: train loss = 4.094676, test loss = 12247.422055\n",
            "Epoch 3496: train loss = 4.094673, test loss = 12247.397501\n",
            "Epoch 3497: train loss = 4.094675, test loss = 12247.365369\n",
            "Epoch 3498: train loss = 4.094669, test loss = 12247.346112\n",
            "Epoch 3499: train loss = 4.094646, test loss = 12247.319416\n",
            "Epoch 3500: train loss = 4.094655, test loss = 12247.285273\n",
            "Epoch 3501: train loss = 4.094642, test loss = 12247.266338\n",
            "Epoch 3502: train loss = 4.094620, test loss = 12247.240422\n",
            "Epoch 3503: train loss = 4.094635, test loss = 12247.205218\n",
            "Epoch 3504: train loss = 4.094616, test loss = 12247.187746\n",
            "Epoch 3505: train loss = 4.094596, test loss = 12247.163235\n",
            "Epoch 3506: train loss = 4.094611, test loss = 12247.140793\n",
            "Epoch 3507: train loss = 4.094589, test loss = 12247.112763\n",
            "Epoch 3508: train loss = 4.094577, test loss = 12247.083041\n",
            "Epoch 3509: train loss = 4.094585, test loss = 12247.060580\n",
            "Epoch 3510: train loss = 4.094563, test loss = 12247.032729\n",
            "Epoch 3511: train loss = 4.094558, test loss = 12247.001640\n",
            "Epoch 3512: train loss = 4.094559, test loss = 12246.980378\n",
            "Epoch 3513: train loss = 4.094536, test loss = 12246.953548\n",
            "Epoch 3514: train loss = 4.094538, test loss = 12246.921011\n",
            "Epoch 3515: train loss = 4.094533, test loss = 12246.900679\n",
            "Epoch 3516: train loss = 4.094510, test loss = 12246.874103\n",
            "Epoch 3517: train loss = 4.094519, test loss = 12246.840595\n",
            "Epoch 3518: train loss = 4.094506, test loss = 12246.821436\n",
            "Epoch 3519: train loss = 4.094484, test loss = 12246.805278\n",
            "Epoch 3520: train loss = 4.094481, test loss = 12246.780575\n",
            "Epoch 3521: train loss = 4.094481, test loss = 12246.748896\n",
            "Epoch 3522: train loss = 4.094477, test loss = 12246.728828\n",
            "Epoch 3523: train loss = 4.094454, test loss = 12246.702298\n",
            "Epoch 3524: train loss = 4.094461, test loss = 12246.668810\n",
            "Epoch 3525: train loss = 4.094451, test loss = 12246.650076\n",
            "Epoch 3526: train loss = 4.094428, test loss = 12246.623737\n",
            "Epoch 3527: train loss = 4.094441, test loss = 12246.588897\n",
            "Epoch 3528: train loss = 4.094424, test loss = 12246.570695\n",
            "Epoch 3529: train loss = 4.094403, test loss = 12246.554255\n",
            "Epoch 3530: train loss = 4.094399, test loss = 12246.530198\n",
            "Epoch 3531: train loss = 4.094403, test loss = 12246.497525\n",
            "Epoch 3532: train loss = 4.094395, test loss = 12246.478662\n",
            "Epoch 3533: train loss = 4.094372, test loss = 12246.452315\n",
            "Epoch 3534: train loss = 4.094384, test loss = 12246.417642\n",
            "Epoch 3535: train loss = 4.094368, test loss = 12246.399144\n",
            "Epoch 3536: train loss = 4.094345, test loss = 12246.373483\n",
            "Epoch 3537: train loss = 4.094364, test loss = 12246.337730\n",
            "Epoch 3538: train loss = 4.094342, test loss = 12246.320258\n",
            "Epoch 3539: train loss = 4.094324, test loss = 12246.295631\n",
            "Epoch 3540: train loss = 4.094337, test loss = 12246.274078\n",
            "Epoch 3541: train loss = 4.094315, test loss = 12246.246186\n",
            "Epoch 3542: train loss = 4.094306, test loss = 12246.215905\n",
            "Epoch 3543: train loss = 4.094311, test loss = 12246.193655\n",
            "Epoch 3544: train loss = 4.094288, test loss = 12246.166091\n",
            "Epoch 3545: train loss = 4.094287, test loss = 12246.134524\n",
            "Epoch 3546: train loss = 4.094285, test loss = 12246.113887\n",
            "Epoch 3547: train loss = 4.094262, test loss = 12246.086691\n",
            "Epoch 3548: train loss = 4.094267, test loss = 12246.053827\n",
            "Epoch 3549: train loss = 4.094259, test loss = 12246.033869\n",
            "Epoch 3550: train loss = 4.094236, test loss = 12246.007486\n",
            "Epoch 3551: train loss = 4.094247, test loss = 12245.973465\n",
            "Epoch 3552: train loss = 4.094233, test loss = 12245.955166\n",
            "Epoch 3553: train loss = 4.094212, test loss = 12245.938271\n",
            "Epoch 3554: train loss = 4.094207, test loss = 12245.913850\n",
            "Epoch 3555: train loss = 4.094209, test loss = 12245.881885\n",
            "Epoch 3556: train loss = 4.094203, test loss = 12245.862188\n",
            "Epoch 3557: train loss = 4.094180, test loss = 12245.835762\n",
            "Epoch 3558: train loss = 4.094190, test loss = 12245.801914\n",
            "Epoch 3559: train loss = 4.094177, test loss = 12245.783514\n",
            "Epoch 3560: train loss = 4.094154, test loss = 12245.757248\n",
            "Epoch 3561: train loss = 4.094170, test loss = 12245.722053\n",
            "Epoch 3562: train loss = 4.094150, test loss = 12245.704160\n",
            "Epoch 3563: train loss = 4.094131, test loss = 12245.679912\n",
            "Epoch 3564: train loss = 4.094146, test loss = 12245.657557\n",
            "Epoch 3565: train loss = 4.094123, test loss = 12245.629581\n",
            "Epoch 3566: train loss = 4.094112, test loss = 12245.600034\n",
            "Epoch 3567: train loss = 4.094119, test loss = 12245.577972\n",
            "Epoch 3568: train loss = 4.094097, test loss = 12245.549832\n",
            "Epoch 3569: train loss = 4.094093, test loss = 12245.518794\n",
            "Epoch 3570: train loss = 4.094093, test loss = 12245.497378\n",
            "Epoch 3571: train loss = 4.094070, test loss = 12245.470116\n",
            "Epoch 3572: train loss = 4.094073, test loss = 12245.437962\n",
            "Epoch 3573: train loss = 4.094067, test loss = 12245.417798\n",
            "Epoch 3574: train loss = 4.094044, test loss = 12245.391535\n",
            "Epoch 3575: train loss = 4.094054, test loss = 12245.357973\n",
            "Epoch 3576: train loss = 4.094041, test loss = 12245.338716\n",
            "Epoch 3577: train loss = 4.094020, test loss = 12245.321696\n",
            "Epoch 3578: train loss = 4.094015, test loss = 12245.297430\n",
            "Epoch 3579: train loss = 4.094016, test loss = 12245.266101\n",
            "Epoch 3580: train loss = 4.094011, test loss = 12245.246499\n",
            "Epoch 3581: train loss = 4.093988, test loss = 12245.219764\n",
            "Epoch 3582: train loss = 4.093996, test loss = 12245.186247\n",
            "Epoch 3583: train loss = 4.093985, test loss = 12245.167002\n",
            "Epoch 3584: train loss = 4.093962, test loss = 12245.150370\n",
            "Epoch 3585: train loss = 4.093959, test loss = 12245.125820\n",
            "Epoch 3586: train loss = 4.093959, test loss = 12245.094536\n",
            "Epoch 3587: train loss = 4.093955, test loss = 12245.074814\n",
            "Epoch 3588: train loss = 4.093932, test loss = 12245.047905\n",
            "Epoch 3589: train loss = 4.093939, test loss = 12245.014553\n",
            "Epoch 3590: train loss = 4.093929, test loss = 12244.995216\n",
            "Epoch 3591: train loss = 4.093906, test loss = 12244.969004\n",
            "Epoch 3592: train loss = 4.093919, test loss = 12244.934545\n",
            "Epoch 3593: train loss = 4.093903, test loss = 12244.916172\n",
            "Epoch 3594: train loss = 4.093881, test loss = 12244.899887\n",
            "Epoch 3595: train loss = 4.093877, test loss = 12244.876140\n",
            "Epoch 3596: train loss = 4.093881, test loss = 12244.843274\n",
            "Epoch 3597: train loss = 4.093873, test loss = 12244.823921\n",
            "Epoch 3598: train loss = 4.093850, test loss = 12244.797695\n",
            "Epoch 3599: train loss = 4.093861, test loss = 12244.763187\n",
            "Epoch 3600: train loss = 4.093847, test loss = 12244.744797\n",
            "Epoch 3601: train loss = 4.093824, test loss = 12244.719456\n",
            "Epoch 3602: train loss = 4.093842, test loss = 12244.683491\n",
            "Epoch 3603: train loss = 4.093821, test loss = 12244.665955\n",
            "Epoch 3604: train loss = 4.093802, test loss = 12244.641243\n",
            "Epoch 3605: train loss = 4.093816, test loss = 12244.619268\n",
            "Epoch 3606: train loss = 4.093793, test loss = 12244.591602\n",
            "Epoch 3607: train loss = 4.093784, test loss = 12244.561871\n",
            "Epoch 3608: train loss = 4.093790, test loss = 12244.539413\n",
            "Epoch 3609: train loss = 4.093767, test loss = 12244.511719\n",
            "Epoch 3610: train loss = 4.093765, test loss = 12244.480099\n",
            "Epoch 3611: train loss = 4.093763, test loss = 12244.459061\n",
            "Epoch 3612: train loss = 4.093741, test loss = 12244.432110\n",
            "Epoch 3613: train loss = 4.093745, test loss = 12244.399368\n",
            "Epoch 3614: train loss = 4.093737, test loss = 12244.379930\n",
            "Epoch 3615: train loss = 4.093715, test loss = 12244.353274\n",
            "Epoch 3616: train loss = 4.093725, test loss = 12244.319213\n",
            "Epoch 3617: train loss = 4.093711, test loss = 12244.300348\n",
            "Epoch 3618: train loss = 4.093690, test loss = 12244.283628\n",
            "Epoch 3619: train loss = 4.093686, test loss = 12244.259387\n",
            "Epoch 3620: train loss = 4.093688, test loss = 12244.227621\n",
            "Epoch 3621: train loss = 4.093681, test loss = 12244.207805\n",
            "Epoch 3622: train loss = 4.093659, test loss = 12244.181830\n",
            "Epoch 3623: train loss = 4.093668, test loss = 12244.147847\n",
            "Epoch 3624: train loss = 4.093655, test loss = 12244.128746\n",
            "Epoch 3625: train loss = 4.093632, test loss = 12244.102746\n",
            "Epoch 3626: train loss = 4.093648, test loss = 12244.067786\n",
            "Epoch 3627: train loss = 4.093629, test loss = 12244.049791\n",
            "Epoch 3628: train loss = 4.093610, test loss = 12244.033814\n",
            "Epoch 3629: train loss = 4.093603, test loss = 12244.009604\n",
            "Epoch 3630: train loss = 4.093610, test loss = 12243.976478\n",
            "Epoch 3631: train loss = 4.093599, test loss = 12243.957494\n",
            "Epoch 3632: train loss = 4.093577, test loss = 12243.931356\n",
            "Epoch 3633: train loss = 4.093590, test loss = 12243.896594\n",
            "Epoch 3634: train loss = 4.093573, test loss = 12243.878899\n",
            "Epoch 3635: train loss = 4.093551, test loss = 12243.862324\n",
            "Epoch 3636: train loss = 4.093548, test loss = 12243.838045\n",
            "Epoch 3637: train loss = 4.093552, test loss = 12243.805078\n",
            "Epoch 3638: train loss = 4.093544, test loss = 12243.785802\n",
            "Epoch 3639: train loss = 4.093521, test loss = 12243.759741\n",
            "Epoch 3640: train loss = 4.093533, test loss = 12243.725016\n",
            "Epoch 3641: train loss = 4.093518, test loss = 12243.707071\n",
            "Epoch 3642: train loss = 4.093495, test loss = 12243.673247\n",
            "Epoch 3643: train loss = 4.093493, test loss = 12243.646875\n",
            "Epoch 3644: train loss = 4.093493, test loss = 12243.615408\n",
            "Epoch 3645: train loss = 4.093490, test loss = 12243.594492\n",
            "Epoch 3646: train loss = 4.093467, test loss = 12243.567251\n",
            "Epoch 3647: train loss = 4.093474, test loss = 12243.534087\n",
            "Epoch 3648: train loss = 4.093464, test loss = 12243.514226\n",
            "Epoch 3649: train loss = 4.093441, test loss = 12243.487672\n",
            "Epoch 3650: train loss = 4.093454, test loss = 12243.453809\n",
            "Epoch 3651: train loss = 4.093438, test loss = 12243.434892\n",
            "Epoch 3652: train loss = 4.093418, test loss = 12243.417846\n",
            "Epoch 3653: train loss = 4.093412, test loss = 12243.393626\n",
            "Epoch 3654: train loss = 4.093416, test loss = 12243.361460\n",
            "Epoch 3655: train loss = 4.093408, test loss = 12243.341803\n",
            "Epoch 3656: train loss = 4.093386, test loss = 12243.315889\n",
            "Epoch 3657: train loss = 4.093397, test loss = 12243.281491\n",
            "Epoch 3658: train loss = 4.093382, test loss = 12243.262657\n",
            "Epoch 3659: train loss = 4.093360, test loss = 12243.246106\n",
            "Epoch 3660: train loss = 4.093357, test loss = 12243.221619\n",
            "Epoch 3661: train loss = 4.093359, test loss = 12243.189572\n",
            "Epoch 3662: train loss = 4.093353, test loss = 12243.170310\n",
            "Epoch 3663: train loss = 4.093330, test loss = 12243.143608\n",
            "Epoch 3664: train loss = 4.093339, test loss = 12243.109508\n",
            "Epoch 3665: train loss = 4.093326, test loss = 12243.090645\n",
            "Epoch 3666: train loss = 4.093304, test loss = 12243.064587\n",
            "Epoch 3667: train loss = 4.093319, test loss = 12243.029450\n",
            "Epoch 3668: train loss = 4.093300, test loss = 12243.011549\n",
            "Epoch 3669: train loss = 4.093280, test loss = 12242.987756\n",
            "Epoch 3670: train loss = 4.093296, test loss = 12242.965202\n",
            "Epoch 3671: train loss = 4.093273, test loss = 12242.937100\n",
            "Epoch 3672: train loss = 4.093262, test loss = 12242.907391\n",
            "Epoch 3673: train loss = 4.093269, test loss = 12242.884918\n",
            "Epoch 3674: train loss = 4.093247, test loss = 12242.857060\n",
            "Epoch 3675: train loss = 4.093243, test loss = 12242.826006\n",
            "Epoch 3676: train loss = 4.093243, test loss = 12242.804744\n",
            "Epoch 3677: train loss = 4.093221, test loss = 12242.777924\n",
            "Epoch 3678: train loss = 4.093223, test loss = 12242.745421\n",
            "Epoch 3679: train loss = 4.093217, test loss = 12242.725188\n",
            "Epoch 3680: train loss = 4.093194, test loss = 12242.698482\n",
            "Epoch 3681: train loss = 4.093204, test loss = 12242.665027\n",
            "Epoch 3682: train loss = 4.093191, test loss = 12242.645887\n",
            "Epoch 3683: train loss = 4.093170, test loss = 12242.629625\n",
            "Epoch 3684: train loss = 4.093165, test loss = 12242.605017\n",
            "Epoch 3685: train loss = 4.093166, test loss = 12242.573425\n",
            "Epoch 3686: train loss = 4.093161, test loss = 12242.553376\n",
            "Epoch 3687: train loss = 4.093139, test loss = 12242.526858\n",
            "Epoch 3688: train loss = 4.093146, test loss = 12242.493416\n",
            "Epoch 3689: train loss = 4.093135, test loss = 12242.474696\n",
            "Epoch 3690: train loss = 4.093112, test loss = 12242.448358\n",
            "Epoch 3691: train loss = 4.093127, test loss = 12242.413559\n",
            "Epoch 3692: train loss = 4.093109, test loss = 12242.395359\n",
            "Epoch 3693: train loss = 4.093089, test loss = 12242.378900\n",
            "Epoch 3694: train loss = 4.093083, test loss = 12242.354813\n",
            "Epoch 3695: train loss = 4.093089, test loss = 12242.322237\n",
            "Epoch 3696: train loss = 4.093079, test loss = 12242.303415\n",
            "Epoch 3697: train loss = 4.093057, test loss = 12242.277087\n",
            "Epoch 3698: train loss = 4.093069, test loss = 12242.242452\n",
            "Epoch 3699: train loss = 4.093053, test loss = 12242.223961\n",
            "Epoch 3700: train loss = 4.093031, test loss = 12242.207774\n",
            "Epoch 3701: train loss = 4.093028, test loss = 12242.183482\n",
            "Epoch 3702: train loss = 4.093031, test loss = 12242.150789\n",
            "Epoch 3703: train loss = 4.093024, test loss = 12242.131514\n",
            "Epoch 3704: train loss = 4.093001, test loss = 12242.105711\n",
            "Epoch 3705: train loss = 4.093012, test loss = 12242.070919\n",
            "Epoch 3706: train loss = 4.092998, test loss = 12242.052395\n",
            "Epoch 3707: train loss = 4.092975, test loss = 12242.026485\n",
            "Epoch 3708: train loss = 4.092992, test loss = 12241.990873\n",
            "Epoch 3709: train loss = 4.092972, test loss = 12241.973429\n",
            "Epoch 3710: train loss = 4.092953, test loss = 12241.949150\n",
            "Epoch 3711: train loss = 4.092967, test loss = 12241.926915\n",
            "Epoch 3712: train loss = 4.092944, test loss = 12241.899125\n",
            "Epoch 3713: train loss = 4.092934, test loss = 12241.868888\n",
            "Epoch 3714: train loss = 4.092941, test loss = 12241.846683\n",
            "Epoch 3715: train loss = 4.092918, test loss = 12241.819119\n",
            "Epoch 3716: train loss = 4.092915, test loss = 12241.787965\n",
            "Epoch 3717: train loss = 4.092915, test loss = 12241.766668\n",
            "Epoch 3718: train loss = 4.092892, test loss = 12241.739598\n",
            "Epoch 3719: train loss = 4.092896, test loss = 12241.706776\n",
            "Epoch 3720: train loss = 4.092889, test loss = 12241.686885\n",
            "Epoch 3721: train loss = 4.092866, test loss = 12241.660417\n",
            "Epoch 3722: train loss = 4.092876, test loss = 12241.626596\n",
            "Epoch 3723: train loss = 4.092862, test loss = 12241.607781\n",
            "Epoch 3724: train loss = 4.092840, test loss = 12241.591626\n",
            "Epoch 3725: train loss = 4.092837, test loss = 12241.567063\n",
            "Epoch 3726: train loss = 4.092838, test loss = 12241.535105\n",
            "Epoch 3727: train loss = 4.092833, test loss = 12241.515221\n",
            "Epoch 3728: train loss = 4.092810, test loss = 12241.488822\n",
            "Epoch 3729: train loss = 4.092819, test loss = 12241.455074\n",
            "Epoch 3730: train loss = 4.092807, test loss = 12241.436052\n",
            "Epoch 3731: train loss = 4.092784, test loss = 12241.410172\n",
            "Epoch 3732: train loss = 4.092799, test loss = 12241.375621\n",
            "Epoch 3733: train loss = 4.092781, test loss = 12241.357387\n",
            "Epoch 3734: train loss = 4.092760, test loss = 12241.333225\n",
            "Epoch 3735: train loss = 4.092776, test loss = 12241.310629\n",
            "Epoch 3736: train loss = 4.092753, test loss = 12241.282713\n",
            "Epoch 3737: train loss = 4.092742, test loss = 12241.253297\n",
            "Epoch 3738: train loss = 4.092750, test loss = 12241.230995\n",
            "Epoch 3739: train loss = 4.092727, test loss = 12241.203015\n",
            "Epoch 3740: train loss = 4.092723, test loss = 12241.172024\n",
            "Epoch 3741: train loss = 4.092724, test loss = 12241.150432\n",
            "Epoch 3742: train loss = 4.092701, test loss = 12241.123270\n",
            "Epoch 3743: train loss = 4.092703, test loss = 12241.091254\n",
            "Epoch 3744: train loss = 4.092698, test loss = 12241.071299\n",
            "Epoch 3745: train loss = 4.092675, test loss = 12241.044515\n",
            "Epoch 3746: train loss = 4.092684, test loss = 12241.011033\n",
            "Epoch 3747: train loss = 4.092671, test loss = 12240.991798\n",
            "Epoch 3748: train loss = 4.092650, test loss = 12240.975062\n",
            "Epoch 3749: train loss = 4.092646, test loss = 12240.950636\n",
            "Epoch 3750: train loss = 4.092646, test loss = 12240.919457\n",
            "Epoch 3751: train loss = 4.092642, test loss = 12240.899352\n",
            "Epoch 3752: train loss = 4.092619, test loss = 12240.873193\n",
            "Epoch 3753: train loss = 4.092626, test loss = 12240.839748\n",
            "Epoch 3754: train loss = 4.092616, test loss = 12240.820358\n",
            "Epoch 3755: train loss = 4.092593, test loss = 12240.794138\n",
            "Epoch 3756: train loss = 4.092607, test loss = 12240.759717\n",
            "Epoch 3757: train loss = 4.092590, test loss = 12240.741447\n",
            "Epoch 3758: train loss = 4.092569, test loss = 12240.724926\n",
            "Epoch 3759: train loss = 4.092564, test loss = 12240.701318\n",
            "Epoch 3760: train loss = 4.092569, test loss = 12240.668557\n",
            "Epoch 3761: train loss = 4.092560, test loss = 12240.649241\n",
            "Epoch 3762: train loss = 4.092537, test loss = 12240.623037\n",
            "Epoch 3763: train loss = 4.092549, test loss = 12240.588587\n",
            "Epoch 3764: train loss = 4.092534, test loss = 12240.570214\n",
            "Epoch 3765: train loss = 4.092512, test loss = 12240.554378\n",
            "Epoch 3766: train loss = 4.092508, test loss = 12240.529701\n",
            "Epoch 3767: train loss = 4.092511, test loss = 12240.497238\n",
            "Epoch 3768: train loss = 4.092504, test loss = 12240.477734\n",
            "Epoch 3769: train loss = 4.092482, test loss = 12240.451361\n",
            "Epoch 3770: train loss = 4.092492, test loss = 12240.417178\n",
            "Epoch 3771: train loss = 4.092478, test loss = 12240.399031\n",
            "Epoch 3772: train loss = 4.092455, test loss = 12240.372847\n",
            "Epoch 3773: train loss = 4.092472, test loss = 12240.337338\n",
            "Epoch 3774: train loss = 4.092452, test loss = 12240.319598\n",
            "Epoch 3775: train loss = 4.092433, test loss = 12240.295153\n",
            "Epoch 3776: train loss = 4.092447, test loss = 12240.273108\n",
            "Epoch 3777: train loss = 4.092425, test loss = 12240.245247\n",
            "Epoch 3778: train loss = 4.092414, test loss = 12240.215362\n",
            "Epoch 3779: train loss = 4.092421, test loss = 12240.193552\n",
            "Epoch 3780: train loss = 4.092399, test loss = 12240.165519\n",
            "Epoch 3781: train loss = 4.092395, test loss = 12240.134095\n",
            "Epoch 3782: train loss = 4.092395, test loss = 12240.112960\n",
            "Epoch 3783: train loss = 4.092373, test loss = 12240.085803\n",
            "Epoch 3784: train loss = 4.092376, test loss = 12240.053324\n",
            "Epoch 3785: train loss = 4.092369, test loss = 12240.033304\n",
            "Epoch 3786: train loss = 4.092347, test loss = 12240.007280\n",
            "Epoch 3787: train loss = 4.092356, test loss = 12239.973331\n",
            "Epoch 3788: train loss = 4.092343, test loss = 12239.954241\n",
            "Epoch 3789: train loss = 4.092321, test loss = 12239.937694\n",
            "Epoch 3790: train loss = 4.092318, test loss = 12239.913319\n",
            "Epoch 3791: train loss = 4.092319, test loss = 12239.881584\n",
            "Epoch 3792: train loss = 4.092314, test loss = 12239.862154\n",
            "Epoch 3793: train loss = 4.092291, test loss = 12239.835458\n",
            "Epoch 3794: train loss = 4.092299, test loss = 12239.801675\n",
            "Epoch 3795: train loss = 4.092288, test loss = 12239.782636\n",
            "Epoch 3796: train loss = 4.092265, test loss = 12239.756634\n",
            "Epoch 3797: train loss = 4.092279, test loss = 12239.721753\n",
            "Epoch 3798: train loss = 4.092262, test loss = 12239.704195\n",
            "Epoch 3799: train loss = 4.092241, test loss = 12239.687567\n",
            "Epoch 3800: train loss = 4.092236, test loss = 12239.663467\n",
            "Epoch 3801: train loss = 4.092242, test loss = 12239.630567\n",
            "Epoch 3802: train loss = 4.092232, test loss = 12239.611409\n",
            "Epoch 3803: train loss = 4.092209, test loss = 12239.585422\n",
            "Epoch 3804: train loss = 4.092222, test loss = 12239.550714\n",
            "Epoch 3805: train loss = 4.092206, test loss = 12239.532428\n",
            "Epoch 3806: train loss = 4.092183, test loss = 12239.499440\n",
            "Epoch 3807: train loss = 4.092182, test loss = 12239.473037\n",
            "Epoch 3808: train loss = 4.092182, test loss = 12239.441334\n",
            "Epoch 3809: train loss = 4.092179, test loss = 12239.420475\n",
            "Epoch 3810: train loss = 4.092156, test loss = 12239.393277\n",
            "Epoch 3811: train loss = 4.092163, test loss = 12239.360102\n",
            "Epoch 3812: train loss = 4.092153, test loss = 12239.340312\n",
            "Epoch 3813: train loss = 4.092131, test loss = 12239.323239\n",
            "Epoch 3814: train loss = 4.092127, test loss = 12239.298991\n",
            "Epoch 3815: train loss = 4.092126, test loss = 12239.267795\n",
            "Epoch 3816: train loss = 4.092123, test loss = 12239.247034\n",
            "Epoch 3817: train loss = 4.092100, test loss = 12239.220215\n",
            "Epoch 3818: train loss = 4.092106, test loss = 12239.187257\n",
            "Epoch 3819: train loss = 4.092097, test loss = 12239.167566\n",
            "Epoch 3820: train loss = 4.092074, test loss = 12239.141702\n",
            "Epoch 3821: train loss = 4.092087, test loss = 12239.107338\n",
            "Epoch 3822: train loss = 4.092071, test loss = 12239.088525\n",
            "Epoch 3823: train loss = 4.092051, test loss = 12239.071930\n",
            "Epoch 3824: train loss = 4.092045, test loss = 12239.047645\n",
            "Epoch 3825: train loss = 4.092049, test loss = 12239.015604\n",
            "Epoch 3826: train loss = 4.092041, test loss = 12238.996505\n",
            "Epoch 3827: train loss = 4.092019, test loss = 12238.969894\n",
            "Epoch 3828: train loss = 4.092029, test loss = 12238.935747\n",
            "Epoch 3829: train loss = 4.092015, test loss = 12238.917010\n",
            "Epoch 3830: train loss = 4.091993, test loss = 12238.900564\n",
            "Epoch 3831: train loss = 4.091990, test loss = 12238.876231\n",
            "Epoch 3832: train loss = 4.091992, test loss = 12238.844135\n",
            "Epoch 3833: train loss = 4.091986, test loss = 12238.824368\n",
            "Epoch 3834: train loss = 4.091963, test loss = 12238.798529\n",
            "Epoch 3835: train loss = 4.091972, test loss = 12238.764197\n",
            "Epoch 3836: train loss = 4.091960, test loss = 12238.745310\n",
            "Epoch 3837: train loss = 4.091937, test loss = 12238.719411\n",
            "Epoch 3838: train loss = 4.091952, test loss = 12238.684121\n",
            "Epoch 3839: train loss = 4.091934, test loss = 12238.666345\n",
            "Epoch 3840: train loss = 4.091913, test loss = 12238.642178\n",
            "Epoch 3841: train loss = 4.091929, test loss = 12238.620172\n",
            "Epoch 3842: train loss = 4.091906, test loss = 12238.592080\n",
            "Epoch 3843: train loss = 4.091895, test loss = 12238.562361\n",
            "Epoch 3844: train loss = 4.091903, test loss = 12238.539712\n",
            "Epoch 3845: train loss = 4.091880, test loss = 12238.511987\n",
            "Epoch 3846: train loss = 4.091876, test loss = 12238.480983\n",
            "Epoch 3847: train loss = 4.091877, test loss = 12238.459981\n",
            "Epoch 3848: train loss = 4.091854, test loss = 12238.432633\n",
            "Epoch 3849: train loss = 4.091857, test loss = 12238.400222\n",
            "Epoch 3850: train loss = 4.091851, test loss = 12238.380034\n",
            "Epoch 3851: train loss = 4.091828, test loss = 12238.353492\n",
            "Epoch 3852: train loss = 4.091837, test loss = 12238.319999\n",
            "Epoch 3853: train loss = 4.091825, test loss = 12238.301364\n",
            "Epoch 3854: train loss = 4.091803, test loss = 12238.284548\n",
            "Epoch 3855: train loss = 4.091800, test loss = 12238.259955\n",
            "Epoch 3856: train loss = 4.091800, test loss = 12238.228503\n",
            "Epoch 3857: train loss = 4.091795, test loss = 12238.208463\n",
            "Epoch 3858: train loss = 4.091773, test loss = 12238.181907\n",
            "Epoch 3859: train loss = 4.091780, test loss = 12238.148572\n",
            "Epoch 3860: train loss = 4.091769, test loss = 12238.129425\n",
            "Epoch 3861: train loss = 4.091747, test loss = 12238.103758\n",
            "Epoch 3862: train loss = 4.091760, test loss = 12238.068912\n",
            "Epoch 3863: train loss = 4.091743, test loss = 12238.050538\n",
            "Epoch 3864: train loss = 4.091722, test loss = 12238.034265\n",
            "Epoch 3865: train loss = 4.091718, test loss = 12238.010163\n",
            "Epoch 3866: train loss = 4.091723, test loss = 12237.977450\n",
            "Epoch 3867: train loss = 4.091714, test loss = 12237.958346\n",
            "Epoch 3868: train loss = 4.091691, test loss = 12237.932649\n",
            "Epoch 3869: train loss = 4.091703, test loss = 12237.897792\n",
            "Epoch 3870: train loss = 4.091688, test loss = 12237.879410\n",
            "Epoch 3871: train loss = 4.091665, test loss = 12237.853678\n",
            "Epoch 3872: train loss = 4.091683, test loss = 12237.817864\n",
            "Epoch 3873: train loss = 4.091662, test loss = 12237.800572\n",
            "Epoch 3874: train loss = 4.091644, test loss = 12237.776363\n",
            "Epoch 3875: train loss = 4.091657, test loss = 12237.754139\n",
            "Epoch 3876: train loss = 4.091635, test loss = 12237.726445\n",
            "Epoch 3877: train loss = 4.091626, test loss = 12237.696149\n",
            "Epoch 3878: train loss = 4.091631, test loss = 12237.674071\n",
            "Epoch 3879: train loss = 4.091608, test loss = 12237.646576\n",
            "Epoch 3880: train loss = 4.091607, test loss = 12237.614918\n",
            "Epoch 3881: train loss = 4.091605, test loss = 12237.594451\n",
            "Epoch 3882: train loss = 4.091582, test loss = 12237.567300\n",
            "Epoch 3883: train loss = 4.091587, test loss = 12237.534332\n",
            "Epoch 3884: train loss = 4.091579, test loss = 12237.514521\n",
            "Epoch 3885: train loss = 4.091556, test loss = 12237.488194\n",
            "Epoch 3886: train loss = 4.091568, test loss = 12237.454159\n",
            "Epoch 3887: train loss = 4.091553, test loss = 12237.435467\n",
            "Epoch 3888: train loss = 4.091532, test loss = 12237.418889\n",
            "Epoch 3889: train loss = 4.091528, test loss = 12237.395067\n",
            "Epoch 3890: train loss = 4.091530, test loss = 12237.362950\n",
            "Epoch 3891: train loss = 4.091524, test loss = 12237.343129\n",
            "Epoch 3892: train loss = 4.091501, test loss = 12237.316762\n",
            "Epoch 3893: train loss = 4.091511, test loss = 12237.282935\n",
            "Epoch 3894: train loss = 4.091498, test loss = 12237.264009\n",
            "Epoch 3895: train loss = 4.091475, test loss = 12237.238177\n",
            "Epoch 3896: train loss = 4.091491, test loss = 12237.203560\n",
            "Epoch 3897: train loss = 4.091472, test loss = 12237.185422\n",
            "Epoch 3898: train loss = 4.091452, test loss = 12237.168978\n",
            "Epoch 3899: train loss = 4.091446, test loss = 12237.145040\n",
            "Epoch 3900: train loss = 4.091453, test loss = 12237.111885\n",
            "Epoch 3901: train loss = 4.091442, test loss = 12237.093102\n",
            "Epoch 3902: train loss = 4.091419, test loss = 12237.067465\n",
            "Epoch 3903: train loss = 4.091434, test loss = 12237.032358\n",
            "Epoch 3904: train loss = 4.091416, test loss = 12237.014220\n",
            "Epoch 3905: train loss = 4.091395, test loss = 12236.990034\n",
            "Epoch 3906: train loss = 4.091411, test loss = 12236.967482\n",
            "Epoch 3907: train loss = 4.091389, test loss = 12236.939557\n",
            "Epoch 3908: train loss = 4.091376, test loss = 12236.910046\n",
            "Epoch 3909: train loss = 4.091385, test loss = 12236.887809\n",
            "Epoch 3910: train loss = 4.091363, test loss = 12236.859761\n",
            "Epoch 3911: train loss = 4.091357, test loss = 12236.828719\n",
            "Epoch 3912: train loss = 4.091359, test loss = 12236.807191\n",
            "Epoch 3913: train loss = 4.091337, test loss = 12236.780035\n",
            "Epoch 3914: train loss = 4.091338, test loss = 12236.747925\n",
            "Epoch 3915: train loss = 4.091333, test loss = 12236.727621\n",
            "Epoch 3916: train loss = 4.091311, test loss = 12236.701412\n",
            "Epoch 3917: train loss = 4.091319, test loss = 12236.667955\n",
            "Epoch 3918: train loss = 4.091307, test loss = 12236.648582\n",
            "Epoch 3919: train loss = 4.091285, test loss = 12236.631891\n",
            "Epoch 3920: train loss = 4.091282, test loss = 12236.607432\n",
            "Epoch 3921: train loss = 4.091281, test loss = 12236.576262\n",
            "Epoch 3922: train loss = 4.091278, test loss = 12236.556029\n",
            "Epoch 3923: train loss = 4.091255, test loss = 12236.529901\n",
            "Epoch 3924: train loss = 4.091262, test loss = 12236.496514\n",
            "Epoch 3925: train loss = 4.091252, test loss = 12236.477018\n",
            "Epoch 3926: train loss = 4.091229, test loss = 12236.450869\n",
            "Epoch 3927: train loss = 4.091242, test loss = 12236.416497\n",
            "Epoch 3928: train loss = 4.091226, test loss = 12236.398124\n",
            "Epoch 3929: train loss = 4.091205, test loss = 12236.382245\n",
            "Epoch 3930: train loss = 4.091200, test loss = 12236.357756\n",
            "Epoch 3931: train loss = 4.091204, test loss = 12236.325326\n",
            "Epoch 3932: train loss = 4.091196, test loss = 12236.305954\n",
            "Epoch 3933: train loss = 4.091174, test loss = 12236.279663\n",
            "Epoch 3934: train loss = 4.091185, test loss = 12236.245460\n",
            "Epoch 3935: train loss = 4.091170, test loss = 12236.226990\n",
            "Epoch 3936: train loss = 4.091148, test loss = 12236.201582\n",
            "Epoch 3937: train loss = 4.091165, test loss = 12236.165894\n",
            "Epoch 3938: train loss = 4.091145, test loss = 12236.148273\n",
            "Epoch 3939: train loss = 4.091126, test loss = 12236.123656\n",
            "Epoch 3940: train loss = 4.091140, test loss = 12236.101710\n",
            "Epoch 3941: train loss = 4.091117, test loss = 12236.073908\n",
            "Epoch 3942: train loss = 4.091108, test loss = 12236.043994\n",
            "Epoch 3943: train loss = 4.091114, test loss = 12236.021840\n",
            "Epoch 3944: train loss = 4.091091, test loss = 12235.994540\n",
            "Epoch 3945: train loss = 4.091089, test loss = 12235.962950\n",
            "Epoch 3946: train loss = 4.091088, test loss = 12235.941833\n",
            "Epoch 3947: train loss = 4.091065, test loss = 12235.914693\n",
            "Epoch 3948: train loss = 4.091069, test loss = 12235.882164\n",
            "Epoch 3949: train loss = 4.091062, test loss = 12235.862309\n",
            "Epoch 3950: train loss = 4.091039, test loss = 12235.836200\n",
            "Epoch 3951: train loss = 4.091050, test loss = 12235.802230\n",
            "Epoch 3952: train loss = 4.091036, test loss = 12235.783318\n",
            "Epoch 3953: train loss = 4.091015, test loss = 12235.766538\n",
            "Epoch 3954: train loss = 4.091010, test loss = 12235.742316\n",
            "Epoch 3955: train loss = 4.091012, test loss = 12235.710609\n",
            "Epoch 3956: train loss = 4.091006, test loss = 12235.691274\n",
            "Epoch 3957: train loss = 4.090984, test loss = 12235.664624\n",
            "Epoch 3958: train loss = 4.090993, test loss = 12235.630816\n",
            "Epoch 3959: train loss = 4.090980, test loss = 12235.611844\n",
            "Epoch 3960: train loss = 4.090958, test loss = 12235.585879\n",
            "Epoch 3961: train loss = 4.090973, test loss = 12235.550970\n",
            "Epoch 3962: train loss = 4.090954, test loss = 12235.533048\n",
            "Epoch 3963: train loss = 4.090935, test loss = 12235.517123\n",
            "Epoch 3964: train loss = 4.090929, test loss = 12235.492872\n",
            "Epoch 3965: train loss = 4.090935, test loss = 12235.459932\n",
            "Epoch 3966: train loss = 4.090925, test loss = 12235.440926\n",
            "Epoch 3967: train loss = 4.090902, test loss = 12235.414838\n",
            "Epoch 3968: train loss = 4.090916, test loss = 12235.380117\n",
            "Epoch 3969: train loss = 4.090899, test loss = 12235.361903\n",
            "Epoch 3970: train loss = 4.090877, test loss = 12235.345772\n",
            "Epoch 3971: train loss = 4.090874, test loss = 12235.322077\n",
            "Epoch 3972: train loss = 4.090878, test loss = 12235.288888\n",
            "Epoch 3973: train loss = 4.090870, test loss = 12235.269687\n",
            "Epoch 3974: train loss = 4.090847, test loss = 12235.243525\n",
            "Epoch 3975: train loss = 4.090859, test loss = 12235.208768\n",
            "Epoch 3976: train loss = 4.090844, test loss = 12235.190502\n",
            "Epoch 3977: train loss = 4.090821, test loss = 12235.157015\n",
            "Epoch 3978: train loss = 4.090820, test loss = 12235.131158\n",
            "Epoch 3979: train loss = 4.090819, test loss = 12235.099608\n",
            "Epoch 3980: train loss = 4.090817, test loss = 12235.078443\n",
            "Epoch 3981: train loss = 4.090794, test loss = 12235.051303\n",
            "Epoch 3982: train loss = 4.090800, test loss = 12235.018181\n",
            "Epoch 3983: train loss = 4.090791, test loss = 12234.998253\n",
            "Epoch 3984: train loss = 4.090768, test loss = 12234.972214\n",
            "Epoch 3985: train loss = 4.090781, test loss = 12234.937787\n",
            "Epoch 3986: train loss = 4.090765, test loss = 12234.918840\n",
            "Epoch 3987: train loss = 4.090745, test loss = 12234.902029\n",
            "Epoch 3988: train loss = 4.090739, test loss = 12234.877852\n",
            "Epoch 3989: train loss = 4.090743, test loss = 12234.845733\n",
            "Epoch 3990: train loss = 4.090735, test loss = 12234.826170\n",
            "Epoch 3991: train loss = 4.090713, test loss = 12234.800284\n",
            "Epoch 3992: train loss = 4.090724, test loss = 12234.765937\n",
            "Epoch 3993: train loss = 4.090709, test loss = 12234.747105\n",
            "Epoch 3994: train loss = 4.090688, test loss = 12234.730499\n",
            "Epoch 3995: train loss = 4.090684, test loss = 12234.706224\n",
            "Epoch 3996: train loss = 4.090686, test loss = 12234.674215\n",
            "Epoch 3997: train loss = 4.090680, test loss = 12234.654433\n",
            "Epoch 3998: train loss = 4.090657, test loss = 12234.628152\n",
            "Epoch 3999: train loss = 4.090667, test loss = 12234.594655\n",
            "Epoch 4000: train loss = 4.090654, test loss = 12234.575483\n",
            "Epoch 4001: train loss = 4.090631, test loss = 12234.549526\n",
            "Epoch 4002: train loss = 4.090647, test loss = 12234.514358\n",
            "Epoch 4003: train loss = 4.090628, test loss = 12234.496426\n",
            "Epoch 4004: train loss = 4.090608, test loss = 12234.472323\n",
            "Epoch 4005: train loss = 4.090624, test loss = 12234.450321\n",
            "Epoch 4006: train loss = 4.090601, test loss = 12234.422223\n",
            "Epoch 4007: train loss = 4.090590, test loss = 12234.392554\n",
            "Epoch 4008: train loss = 4.090598, test loss = 12234.369900\n",
            "Epoch 4009: train loss = 4.090575, test loss = 12234.342174\n",
            "Epoch 4010: train loss = 4.090571, test loss = 12234.311218\n",
            "Epoch 4011: train loss = 4.090572, test loss = 12234.290224\n",
            "Epoch 4012: train loss = 4.090549, test loss = 12234.262872\n",
            "Epoch 4013: train loss = 4.090552, test loss = 12234.230602\n",
            "Epoch 4014: train loss = 4.090546, test loss = 12234.210284\n",
            "Epoch 4015: train loss = 4.090523, test loss = 12234.183764\n",
            "Epoch 4016: train loss = 4.090532, test loss = 12234.150423\n",
            "Epoch 4017: train loss = 4.090520, test loss = 12234.131234\n",
            "Epoch 4018: train loss = 4.090498, test loss = 12234.115041\n",
            "Epoch 4019: train loss = 4.090494, test loss = 12234.090408\n",
            "Epoch 4020: train loss = 4.090495, test loss = 12234.058976\n",
            "Epoch 4021: train loss = 4.090490, test loss = 12234.038925\n",
            "Epoch 4022: train loss = 4.090468, test loss = 12234.012371\n",
            "Epoch 4023: train loss = 4.090475, test loss = 12233.979076\n",
            "Epoch 4024: train loss = 4.090464, test loss = 12233.959930\n",
            "Epoch 4025: train loss = 4.090441, test loss = 12233.933841\n",
            "Epoch 4026: train loss = 4.090456, test loss = 12233.899728\n",
            "Epoch 4027: train loss = 4.090438, test loss = 12233.881319\n",
            "Epoch 4028: train loss = 4.090418, test loss = 12233.864737\n",
            "Epoch 4029: train loss = 4.090413, test loss = 12233.840721\n",
            "Epoch 4030: train loss = 4.090418, test loss = 12233.808089\n",
            "Epoch 4031: train loss = 4.090409, test loss = 12233.789006\n",
            "Epoch 4032: train loss = 4.090386, test loss = 12233.763332\n",
            "Epoch 4033: train loss = 4.090399, test loss = 12233.728515\n",
            "Epoch 4034: train loss = 4.090383, test loss = 12233.710139\n",
            "Epoch 4035: train loss = 4.090361, test loss = 12233.693893\n",
            "Epoch 4036: train loss = 4.090358, test loss = 12233.669521\n",
            "Epoch 4037: train loss = 4.090361, test loss = 12233.637077\n",
            "Epoch 4038: train loss = 4.090354, test loss = 12233.618164\n",
            "Epoch 4039: train loss = 4.090331, test loss = 12233.591595\n",
            "Epoch 4040: train loss = 4.090342, test loss = 12233.557183\n",
            "Epoch 4041: train loss = 4.090328, test loss = 12233.538663\n",
            "Epoch 4042: train loss = 4.090305, test loss = 12233.512797\n",
            "Epoch 4043: train loss = 4.090322, test loss = 12233.477313\n",
            "Epoch 4044: train loss = 4.090302, test loss = 12233.459740\n",
            "Epoch 4045: train loss = 4.090283, test loss = 12233.435254\n",
            "Epoch 4046: train loss = 4.090297, test loss = 12233.413724\n",
            "Epoch 4047: train loss = 4.090275, test loss = 12233.385698\n",
            "Epoch 4048: train loss = 4.090265, test loss = 12233.355587\n",
            "Epoch 4049: train loss = 4.090271, test loss = 12233.333404\n",
            "Epoch 4050: train loss = 4.090249, test loss = 12233.305690\n",
            "Epoch 4051: train loss = 4.090246, test loss = 12233.274293\n",
            "Epoch 4052: train loss = 4.090245, test loss = 12233.253276\n",
            "Epoch 4053: train loss = 4.090223, test loss = 12233.226259\n",
            "Epoch 4054: train loss = 4.090227, test loss = 12233.194095\n",
            "Epoch 4055: train loss = 4.090220, test loss = 12233.174023\n",
            "Epoch 4056: train loss = 4.090197, test loss = 12233.147399\n",
            "Epoch 4057: train loss = 4.090207, test loss = 12233.113585\n",
            "Epoch 4058: train loss = 4.090194, test loss = 12233.094665\n",
            "Epoch 4059: train loss = 4.090172, test loss = 12233.078283\n",
            "Epoch 4060: train loss = 4.090168, test loss = 12233.054398\n",
            "Epoch 4061: train loss = 4.090170, test loss = 12233.022311\n",
            "Epoch 4062: train loss = 4.090164, test loss = 12233.002445\n",
            "Epoch 4063: train loss = 4.090142, test loss = 12232.976026\n",
            "Epoch 4064: train loss = 4.090150, test loss = 12232.942209\n",
            "Epoch 4065: train loss = 4.090138, test loss = 12232.923373\n",
            "Epoch 4066: train loss = 4.090116, test loss = 12232.897879\n",
            "Epoch 4067: train loss = 4.090131, test loss = 12232.862642\n",
            "Epoch 4068: train loss = 4.090113, test loss = 12232.844632\n",
            "Epoch 4069: train loss = 4.090092, test loss = 12232.820589\n",
            "Epoch 4070: train loss = 4.090108, test loss = 12232.798023\n",
            "Epoch 4071: train loss = 4.090085, test loss = 12232.770195\n",
            "Epoch 4072: train loss = 4.090074, test loss = 12232.740707\n",
            "Epoch 4073: train loss = 4.090082, test loss = 12232.718145\n",
            "Epoch 4074: train loss = 4.090059, test loss = 12232.690878\n",
            "Epoch 4075: train loss = 4.090055, test loss = 12232.659687\n",
            "Epoch 4076: train loss = 4.090056, test loss = 12232.638172\n",
            "Epoch 4077: train loss = 4.090033, test loss = 12232.611038\n",
            "Epoch 4078: train loss = 4.090036, test loss = 12232.578910\n",
            "Epoch 4079: train loss = 4.090030, test loss = 12232.558674\n",
            "Epoch 4080: train loss = 4.090007, test loss = 12232.532175\n",
            "Epoch 4081: train loss = 4.090016, test loss = 12232.499272\n",
            "Epoch 4082: train loss = 4.090004, test loss = 12232.479853\n",
            "Epoch 4083: train loss = 4.089983, test loss = 12232.463108\n",
            "Epoch 4084: train loss = 4.089979, test loss = 12232.438626\n",
            "Epoch 4085: train loss = 4.089979, test loss = 12232.407497\n",
            "Epoch 4086: train loss = 4.089975, test loss = 12232.387354\n",
            "Epoch 4087: train loss = 4.089952, test loss = 12232.361284\n",
            "Epoch 4088: train loss = 4.089959, test loss = 12232.327886\n",
            "Epoch 4089: train loss = 4.089949, test loss = 12232.308455\n",
            "Epoch 4090: train loss = 4.089926, test loss = 12232.282342\n",
            "Epoch 4091: train loss = 4.089940, test loss = 12232.247959\n",
            "Epoch 4092: train loss = 4.089923, test loss = 12232.229649\n",
            "Epoch 4093: train loss = 4.089903, test loss = 12232.213677\n",
            "Epoch 4094: train loss = 4.089897, test loss = 12232.189407\n",
            "Epoch 4095: train loss = 4.089902, test loss = 12232.156876\n",
            "Epoch 4096: train loss = 4.089893, test loss = 12232.137596\n",
            "Epoch 4097: train loss = 4.089871, test loss = 12232.111357\n",
            "Epoch 4098: train loss = 4.089883, test loss = 12232.077152\n",
            "Epoch 4099: train loss = 4.089868, test loss = 12232.058739\n",
            "Epoch 4100: train loss = 4.089845, test loss = 12232.042431\n",
            "Epoch 4101: train loss = 4.089842, test loss = 12232.018629\n",
            "Epoch 4102: train loss = 4.089845, test loss = 12231.986057\n",
            "Epoch 4103: train loss = 4.089838, test loss = 12231.966402\n",
            "Epoch 4104: train loss = 4.089815, test loss = 12231.940205\n",
            "Epoch 4105: train loss = 4.089826, test loss = 12231.905998\n",
            "Epoch 4106: train loss = 4.089812, test loss = 12231.887332\n",
            "Epoch 4107: train loss = 4.089790, test loss = 12231.861581\n",
            "Epoch 4108: train loss = 4.089806, test loss = 12231.826242\n",
            "Epoch 4109: train loss = 4.089787, test loss = 12231.808970\n",
            "Epoch 4110: train loss = 4.089767, test loss = 12231.784404\n",
            "Epoch 4111: train loss = 4.089782, test loss = 12231.762124\n",
            "Epoch 4112: train loss = 4.089759, test loss = 12231.734370\n",
            "Epoch 4113: train loss = 4.089749, test loss = 12231.704550\n",
            "Epoch 4114: train loss = 4.089756, test loss = 12231.682575\n",
            "Epoch 4115: train loss = 4.089733, test loss = 12231.654699\n",
            "Epoch 4116: train loss = 4.089730, test loss = 12231.623357\n",
            "Epoch 4117: train loss = 4.089730, test loss = 12231.602082\n",
            "Epoch 4118: train loss = 4.089707, test loss = 12231.575086\n",
            "Epoch 4119: train loss = 4.089711, test loss = 12231.542688\n",
            "Epoch 4120: train loss = 4.089704, test loss = 12231.523051\n",
            "Epoch 4121: train loss = 4.089682, test loss = 12231.496369\n",
            "Epoch 4122: train loss = 4.089692, test loss = 12231.462555\n",
            "Epoch 4123: train loss = 4.089678, test loss = 12231.443628\n",
            "Epoch 4124: train loss = 4.089657, test loss = 12231.427143\n",
            "Epoch 4125: train loss = 4.089653, test loss = 12231.402770\n",
            "Epoch 4126: train loss = 4.089654, test loss = 12231.371176\n",
            "Epoch 4127: train loss = 4.089649, test loss = 12231.351346\n",
            "Epoch 4128: train loss = 4.089626, test loss = 12231.324850\n",
            "Epoch 4129: train loss = 4.089635, test loss = 12231.291810\n",
            "Epoch 4130: train loss = 4.089623, test loss = 12231.272561\n",
            "Epoch 4131: train loss = 4.089600, test loss = 12231.246429\n",
            "Epoch 4132: train loss = 4.089615, test loss = 12231.211622\n",
            "Epoch 4133: train loss = 4.089597, test loss = 12231.193627\n",
            "Epoch 4134: train loss = 4.089577, test loss = 12231.177294\n",
            "Epoch 4135: train loss = 4.089572, test loss = 12231.153368\n",
            "Epoch 4136: train loss = 4.089578, test loss = 12231.120900\n",
            "Epoch 4137: train loss = 4.089568, test loss = 12231.101709\n",
            "Epoch 4138: train loss = 4.089545, test loss = 12231.075570\n",
            "Epoch 4139: train loss = 4.089558, test loss = 12231.040751\n",
            "Epoch 4140: train loss = 4.089542, test loss = 12231.022587\n",
            "Epoch 4141: train loss = 4.089519, test loss = 12230.989232\n",
            "Epoch 4142: train loss = 4.089518, test loss = 12230.963393\n",
            "Epoch 4143: train loss = 4.089518, test loss = 12230.931760\n",
            "Epoch 4144: train loss = 4.089515, test loss = 12230.910783\n",
            "Epoch 4145: train loss = 4.089492, test loss = 12230.883568\n",
            "Epoch 4146: train loss = 4.089500, test loss = 12230.850412\n",
            "Epoch 4147: train loss = 4.089489, test loss = 12230.830597\n",
            "Epoch 4148: train loss = 4.089467, test loss = 12230.814073\n",
            "Epoch 4149: train loss = 4.089464, test loss = 12230.789221\n",
            "Epoch 4150: train loss = 4.089462, test loss = 12230.758047\n",
            "Epoch 4151: train loss = 4.089460, test loss = 12230.737506\n",
            "Epoch 4152: train loss = 4.089437, test loss = 12230.710728\n",
            "Epoch 4153: train loss = 4.089443, test loss = 12230.677766\n",
            "Epoch 4154: train loss = 4.089434, test loss = 12230.658194\n",
            "Epoch 4155: train loss = 4.089411, test loss = 12230.631938\n",
            "Epoch 4156: train loss = 4.089424, test loss = 12230.598215\n",
            "Epoch 4157: train loss = 4.089408, test loss = 12230.579409\n",
            "Epoch 4158: train loss = 4.089388, test loss = 12230.562767\n",
            "Epoch 4159: train loss = 4.089383, test loss = 12230.538529\n",
            "Epoch 4160: train loss = 4.089386, test loss = 12230.506476\n",
            "Epoch 4161: train loss = 4.089379, test loss = 12230.486885\n",
            "Epoch 4162: train loss = 4.089356, test loss = 12230.460709\n",
            "Epoch 4163: train loss = 4.089367, test loss = 12230.427133\n",
            "Epoch 4164: train loss = 4.089353, test loss = 12230.408114\n",
            "Epoch 4165: train loss = 4.089331, test loss = 12230.391784\n",
            "Epoch 4166: train loss = 4.089328, test loss = 12230.367385\n",
            "Epoch 4167: train loss = 4.089329, test loss = 12230.335211\n",
            "Epoch 4168: train loss = 4.089324, test loss = 12230.315638\n",
            "Epoch 4169: train loss = 4.089301, test loss = 12230.289751\n",
            "Epoch 4170: train loss = 4.089310, test loss = 12230.255447\n",
            "Epoch 4171: train loss = 4.089298, test loss = 12230.236633\n",
            "Epoch 4172: train loss = 4.089275, test loss = 12230.210717\n",
            "Epoch 4173: train loss = 4.089291, test loss = 12230.175462\n",
            "Epoch 4174: train loss = 4.089272, test loss = 12230.157767\n",
            "Epoch 4175: train loss = 4.089252, test loss = 12230.133504\n",
            "Epoch 4176: train loss = 4.089267, test loss = 12230.111691\n",
            "Epoch 4177: train loss = 4.089245, test loss = 12230.083646\n",
            "Epoch 4178: train loss = 4.089234, test loss = 12230.053807\n",
            "Epoch 4179: train loss = 4.089242, test loss = 12230.031316\n",
            "Epoch 4180: train loss = 4.089219, test loss = 12230.003650\n",
            "Epoch 4181: train loss = 4.089215, test loss = 12229.972522\n",
            "Epoch 4182: train loss = 4.089216, test loss = 12229.951270\n",
            "Epoch 4183: train loss = 4.089193, test loss = 12229.924211\n",
            "Epoch 4184: train loss = 4.089196, test loss = 12229.892388\n",
            "Epoch 4185: train loss = 4.089190, test loss = 12229.872015\n",
            "Epoch 4186: train loss = 4.089167, test loss = 12229.845454\n",
            "Epoch 4187: train loss = 4.089176, test loss = 12229.811886\n",
            "Epoch 4188: train loss = 4.089164, test loss = 12229.792844\n",
            "Epoch 4189: train loss = 4.089142, test loss = 12229.776245\n",
            "Epoch 4190: train loss = 4.089139, test loss = 12229.751960\n",
            "Epoch 4191: train loss = 4.089139, test loss = 12229.721011\n",
            "Epoch 4192: train loss = 4.089135, test loss = 12229.700713\n",
            "Epoch 4193: train loss = 4.089112, test loss = 12229.674152\n",
            "Epoch 4194: train loss = 4.089120, test loss = 12229.640780\n",
            "Epoch 4195: train loss = 4.089109, test loss = 12229.621583\n",
            "Epoch 4196: train loss = 4.089086, test loss = 12229.596007\n",
            "Epoch 4197: train loss = 4.089100, test loss = 12229.561172\n",
            "Epoch 4198: train loss = 4.089083, test loss = 12229.542865\n",
            "Epoch 4199: train loss = 4.089062, test loss = 12229.526579\n",
            "Epoch 4200: train loss = 4.089058, test loss = 12229.502431\n",
            "Epoch 4201: train loss = 4.089063, test loss = 12229.469938\n",
            "Epoch 4202: train loss = 4.089054, test loss = 12229.450798\n",
            "Epoch 4203: train loss = 4.089031, test loss = 12229.424629\n",
            "Epoch 4204: train loss = 4.089043, test loss = 12229.390637\n",
            "Epoch 4205: train loss = 4.089028, test loss = 12229.372109\n",
            "Epoch 4206: train loss = 4.089005, test loss = 12229.346235\n",
            "Epoch 4207: train loss = 4.089024, test loss = 12229.310598\n",
            "Epoch 4208: train loss = 4.089002, test loss = 12229.293257\n",
            "Epoch 4209: train loss = 4.088985, test loss = 12229.268560\n",
            "Epoch 4210: train loss = 4.088998, test loss = 12229.246781\n",
            "Epoch 4211: train loss = 4.088975, test loss = 12229.219236\n",
            "Epoch 4212: train loss = 4.088967, test loss = 12229.189425\n",
            "Epoch 4213: train loss = 4.088972, test loss = 12229.167202\n",
            "Epoch 4214: train loss = 4.088949, test loss = 12229.139477\n",
            "Epoch 4215: train loss = 4.088948, test loss = 12229.107925\n",
            "Epoch 4216: train loss = 4.088946, test loss = 12229.087026\n",
            "Epoch 4217: train loss = 4.088923, test loss = 12229.060074\n",
            "Epoch 4218: train loss = 4.088929, test loss = 12229.027810\n",
            "Epoch 4219: train loss = 4.088920, test loss = 12229.007861\n",
            "Epoch 4220: train loss = 4.088897, test loss = 12228.981303\n",
            "Epoch 4221: train loss = 4.088909, test loss = 12228.947376\n",
            "Epoch 4222: train loss = 4.088894, test loss = 12228.928681\n",
            "Epoch 4223: train loss = 4.088874, test loss = 12228.912070\n",
            "Epoch 4224: train loss = 4.088869, test loss = 12228.888377\n",
            "Epoch 4225: train loss = 4.088872, test loss = 12228.856331\n",
            "Epoch 4226: train loss = 4.088865, test loss = 12228.836473\n",
            "Epoch 4227: train loss = 4.088842, test loss = 12228.810142\n",
            "Epoch 4228: train loss = 4.088852, test loss = 12228.776240\n",
            "Epoch 4229: train loss = 4.088839, test loss = 12228.757528\n",
            "Epoch 4230: train loss = 4.088816, test loss = 12228.741238\n",
            "Epoch 4231: train loss = 4.088814, test loss = 12228.716774\n",
            "Epoch 4232: train loss = 4.088815, test loss = 12228.685457\n",
            "Epoch 4233: train loss = 4.088810, test loss = 12228.665423\n",
            "Epoch 4234: train loss = 4.088787, test loss = 12228.638832\n",
            "Epoch 4235: train loss = 4.088796, test loss = 12228.605130\n",
            "Epoch 4236: train loss = 4.088784, test loss = 12228.586233\n",
            "Epoch 4237: train loss = 4.088761, test loss = 12228.560215\n",
            "Epoch 4238: train loss = 4.088776, test loss = 12228.525359\n",
            "Epoch 4239: train loss = 4.088758, test loss = 12228.507795\n",
            "Epoch 4240: train loss = 4.088737, test loss = 12228.483548\n",
            "Epoch 4241: train loss = 4.088754, test loss = 12228.461078\n",
            "Epoch 4242: train loss = 4.088731, test loss = 12228.433052\n",
            "Epoch 4243: train loss = 4.088719, test loss = 12228.403637\n",
            "Epoch 4244: train loss = 4.088728, test loss = 12228.381114\n",
            "Epoch 4245: train loss = 4.088705, test loss = 12228.353687\n",
            "Epoch 4246: train loss = 4.088700, test loss = 12228.322606\n",
            "Epoch 4247: train loss = 4.088702, test loss = 12228.301143\n",
            "Epoch 4248: train loss = 4.088680, test loss = 12228.273868\n",
            "Epoch 4249: train loss = 4.088681, test loss = 12228.241852\n",
            "Epoch 4250: train loss = 4.088676, test loss = 12228.221670\n",
            "Epoch 4251: train loss = 4.088654, test loss = 12228.195459\n",
            "Epoch 4252: train loss = 4.088662, test loss = 12228.161978\n",
            "Epoch 4253: train loss = 4.088650, test loss = 12228.142651\n",
            "Epoch 4254: train loss = 4.088628, test loss = 12228.126092\n",
            "Epoch 4255: train loss = 4.088625, test loss = 12228.101700\n",
            "Epoch 4256: train loss = 4.088625, test loss = 12228.070457\n",
            "Epoch 4257: train loss = 4.088621, test loss = 12228.050390\n",
            "Epoch 4258: train loss = 4.088598, test loss = 12228.023904\n",
            "Epoch 4259: train loss = 4.088605, test loss = 12227.991094\n",
            "Epoch 4260: train loss = 4.088595, test loss = 12227.971650\n",
            "Epoch 4261: train loss = 4.088573, test loss = 12227.945474\n",
            "Epoch 4262: train loss = 4.088586, test loss = 12227.910984\n",
            "Epoch 4263: train loss = 4.088570, test loss = 12227.892763\n",
            "Epoch 4264: train loss = 4.088549, test loss = 12227.876492\n",
            "Epoch 4265: train loss = 4.088544, test loss = 12227.852335\n",
            "Epoch 4266: train loss = 4.088549, test loss = 12227.820025\n",
            "Epoch 4267: train loss = 4.088540, test loss = 12227.801107\n",
            "Epoch 4268: train loss = 4.088518, test loss = 12227.774818\n",
            "Epoch 4269: train loss = 4.088529, test loss = 12227.740414\n",
            "Epoch 4270: train loss = 4.088515, test loss = 12227.721870\n",
            "Epoch 4271: train loss = 4.088492, test loss = 12227.696187\n",
            "Epoch 4272: train loss = 4.088510, test loss = 12227.660730\n",
            "Epoch 4273: train loss = 4.088489, test loss = 12227.643625\n",
            "Epoch 4274: train loss = 4.088471, test loss = 12227.618976\n",
            "Epoch 4275: train loss = 4.088484, test loss = 12227.596950\n",
            "Epoch 4276: train loss = 4.088462, test loss = 12227.569146\n",
            "Epoch 4277: train loss = 4.088452, test loss = 12227.539187\n",
            "Epoch 4278: train loss = 4.088458, test loss = 12227.516997\n",
            "Epoch 4279: train loss = 4.088436, test loss = 12227.489909\n",
            "Epoch 4280: train loss = 4.088434, test loss = 12227.458317\n",
            "Epoch 4281: train loss = 4.088433, test loss = 12227.437113\n",
            "Epoch 4282: train loss = 4.088410, test loss = 12227.410151\n",
            "Epoch 4283: train loss = 4.088415, test loss = 12227.377578\n",
            "Epoch 4284: train loss = 4.088407, test loss = 12227.357685\n",
            "Epoch 4285: train loss = 4.088384, test loss = 12227.331351\n",
            "Epoch 4286: train loss = 4.088395, test loss = 12227.297621\n",
            "Epoch 4287: train loss = 4.088381, test loss = 12227.279238\n",
            "Epoch 4288: train loss = 4.088360, test loss = 12227.262416\n",
            "Epoch 4289: train loss = 4.088356, test loss = 12227.238141\n",
            "Epoch 4290: train loss = 4.088358, test loss = 12227.206355\n",
            "Epoch 4291: train loss = 4.088352, test loss = 12227.186657\n",
            "Epoch 4292: train loss = 4.088329, test loss = 12227.160234\n",
            "Epoch 4293: train loss = 4.088339, test loss = 12227.126669\n",
            "Epoch 4294: train loss = 4.088326, test loss = 12227.108222\n",
            "Epoch 4295: train loss = 4.088303, test loss = 12227.091540\n",
            "Epoch 4296: train loss = 4.088301, test loss = 12227.067106\n",
            "Epoch 4297: train loss = 4.088301, test loss = 12227.035377\n",
            "Epoch 4298: train loss = 4.088297, test loss = 12227.015419\n",
            "Epoch 4299: train loss = 4.088274, test loss = 12226.989095\n",
            "Epoch 4300: train loss = 4.088282, test loss = 12226.955943\n",
            "Epoch 4301: train loss = 4.088271, test loss = 12226.936606\n",
            "Epoch 4302: train loss = 4.088248, test loss = 12226.910608\n",
            "Epoch 4303: train loss = 4.088263, test loss = 12226.875660\n",
            "Epoch 4304: train loss = 4.088245, test loss = 12226.857708\n",
            "Epoch 4305: train loss = 4.088224, test loss = 12226.833858\n",
            "Epoch 4306: train loss = 4.088241, test loss = 12226.811699\n",
            "Epoch 4307: train loss = 4.088218, test loss = 12226.783591\n",
            "Epoch 4308: train loss = 4.088206, test loss = 12226.754166\n",
            "Epoch 4309: train loss = 4.088215, test loss = 12226.731357\n",
            "Epoch 4310: train loss = 4.088192, test loss = 12226.703581\n",
            "Epoch 4311: train loss = 4.088187, test loss = 12226.672917\n",
            "Epoch 4312: train loss = 4.088189, test loss = 12226.651352\n",
            "Epoch 4313: train loss = 4.088166, test loss = 12226.624245\n",
            "Epoch 4314: train loss = 4.088168, test loss = 12226.592843\n",
            "Epoch 4315: train loss = 4.088163, test loss = 12226.572156\n",
            "Epoch 4316: train loss = 4.088141, test loss = 12226.545492\n",
            "Epoch 4317: train loss = 4.088149, test loss = 12226.512283\n",
            "Epoch 4318: train loss = 4.088137, test loss = 12226.493065\n",
            "Epoch 4319: train loss = 4.088115, test loss = 12226.476519\n",
            "Epoch 4320: train loss = 4.088112, test loss = 12226.452091\n",
            "Epoch 4321: train loss = 4.088111, test loss = 12226.421468\n",
            "Epoch 4322: train loss = 4.088108, test loss = 12226.401060\n",
            "Epoch 4323: train loss = 4.088086, test loss = 12226.374360\n",
            "Epoch 4324: train loss = 4.088092, test loss = 12226.341288\n",
            "Epoch 4325: train loss = 4.088082, test loss = 12226.321986\n",
            "Epoch 4326: train loss = 4.088060, test loss = 12226.295847\n",
            "Epoch 4327: train loss = 4.088073, test loss = 12226.262020\n",
            "Epoch 4328: train loss = 4.088057, test loss = 12226.243467\n",
            "Epoch 4329: train loss = 4.088036, test loss = 12226.226982\n",
            "Epoch 4330: train loss = 4.088031, test loss = 12226.202897\n",
            "Epoch 4331: train loss = 4.088035, test loss = 12226.170513\n",
            "Epoch 4332: train loss = 4.088027, test loss = 12226.151295\n",
            "Epoch 4333: train loss = 4.088005, test loss = 12226.125169\n",
            "Epoch 4334: train loss = 4.088016, test loss = 12226.091324\n",
            "Epoch 4335: train loss = 4.088002, test loss = 12226.072664\n",
            "Epoch 4336: train loss = 4.087979, test loss = 12226.046834\n",
            "Epoch 4337: train loss = 4.087997, test loss = 12226.011271\n",
            "Epoch 4338: train loss = 4.087976, test loss = 12225.993851\n",
            "Epoch 4339: train loss = 4.087958, test loss = 12225.969474\n",
            "Epoch 4340: train loss = 4.087971, test loss = 12225.947406\n",
            "Epoch 4341: train loss = 4.087949, test loss = 12225.919769\n",
            "Epoch 4342: train loss = 4.087939, test loss = 12225.890300\n",
            "Epoch 4343: train loss = 4.087946, test loss = 12225.867859\n",
            "Epoch 4344: train loss = 4.087923, test loss = 12225.840228\n",
            "Epoch 4345: train loss = 4.087921, test loss = 12225.808789\n",
            "Epoch 4346: train loss = 4.087920, test loss = 12225.787769\n",
            "Epoch 4347: train loss = 4.087897, test loss = 12225.760822\n",
            "Epoch 4348: train loss = 4.087902, test loss = 12225.728299\n",
            "Epoch 4349: train loss = 4.087894, test loss = 12225.708863\n",
            "Epoch 4350: train loss = 4.087871, test loss = 12225.682285\n",
            "Epoch 4351: train loss = 4.087883, test loss = 12225.648395\n",
            "Epoch 4352: train loss = 4.087868, test loss = 12225.629560\n",
            "Epoch 4353: train loss = 4.087848, test loss = 12225.612949\n",
            "Epoch 4354: train loss = 4.087843, test loss = 12225.588731\n",
            "Epoch 4355: train loss = 4.087845, test loss = 12225.557609\n",
            "Epoch 4356: train loss = 4.087839, test loss = 12225.537556\n",
            "Epoch 4357: train loss = 4.087816, test loss = 12225.511107\n",
            "Epoch 4358: train loss = 4.087826, test loss = 12225.477497\n",
            "Epoch 4359: train loss = 4.087813, test loss = 12225.458470\n",
            "Epoch 4360: train loss = 4.087791, test loss = 12225.442186\n",
            "Epoch 4361: train loss = 4.087788, test loss = 12225.417817\n",
            "Epoch 4362: train loss = 4.087789, test loss = 12225.386567\n",
            "Epoch 4363: train loss = 4.087784, test loss = 12225.366483\n",
            "Epoch 4364: train loss = 4.087761, test loss = 12225.339958\n",
            "Epoch 4365: train loss = 4.087769, test loss = 12225.306298\n",
            "Epoch 4366: train loss = 4.087758, test loss = 12225.287349\n",
            "Epoch 4367: train loss = 4.087736, test loss = 12225.261396\n",
            "Epoch 4368: train loss = 4.087750, test loss = 12225.226572\n",
            "Epoch 4369: train loss = 4.087733, test loss = 12225.208657\n",
            "Epoch 4370: train loss = 4.087711, test loss = 12225.192878\n",
            "Epoch 4371: train loss = 4.087707, test loss = 12225.168593\n",
            "Epoch 4372: train loss = 4.087713, test loss = 12225.135764\n",
            "Epoch 4373: train loss = 4.087704, test loss = 12225.116575\n",
            "Epoch 4374: train loss = 4.087681, test loss = 12225.090557\n",
            "Epoch 4375: train loss = 4.087693, test loss = 12225.055994\n",
            "Epoch 4376: train loss = 4.087678, test loss = 12225.038123\n",
            "Epoch 4377: train loss = 4.087655, test loss = 12225.004412\n",
            "Epoch 4378: train loss = 4.087654, test loss = 12224.978233\n",
            "Epoch 4379: train loss = 4.087654, test loss = 12224.946710\n",
            "Epoch 4380: train loss = 4.087651, test loss = 12224.925858\n",
            "Epoch 4381: train loss = 4.087628, test loss = 12224.898866\n",
            "Epoch 4382: train loss = 4.087635, test loss = 12224.866086\n",
            "Epoch 4383: train loss = 4.087625, test loss = 12224.846061\n",
            "Epoch 4384: train loss = 4.087603, test loss = 12224.829030\n",
            "Epoch 4385: train loss = 4.087600, test loss = 12224.804317\n",
            "Epoch 4386: train loss = 4.087598, test loss = 12224.773391\n",
            "Epoch 4387: train loss = 4.087596, test loss = 12224.752807\n",
            "Epoch 4388: train loss = 4.087574, test loss = 12224.726076\n",
            "Epoch 4389: train loss = 4.087579, test loss = 12224.693239\n",
            "Epoch 4390: train loss = 4.087570, test loss = 12224.674018\n",
            "Epoch 4391: train loss = 4.087548, test loss = 12224.647502\n",
            "Epoch 4392: train loss = 4.087560, test loss = 12224.613317\n",
            "Epoch 4393: train loss = 4.087545, test loss = 12224.594653\n",
            "Epoch 4394: train loss = 4.087524, test loss = 12224.578258\n",
            "Epoch 4395: train loss = 4.087519, test loss = 12224.553997\n",
            "Epoch 4396: train loss = 4.087522, test loss = 12224.522047\n",
            "Epoch 4397: train loss = 4.087516, test loss = 12224.502940\n",
            "Epoch 4398: train loss = 4.087493, test loss = 12224.476333\n",
            "Epoch 4399: train loss = 4.087503, test loss = 12224.442331\n",
            "Epoch 4400: train loss = 4.087490, test loss = 12224.423622\n",
            "Epoch 4401: train loss = 4.087467, test loss = 12224.397695\n",
            "Epoch 4402: train loss = 4.087484, test loss = 12224.362597\n",
            "Epoch 4403: train loss = 4.087464, test loss = 12224.345347\n",
            "Epoch 4404: train loss = 4.087445, test loss = 12224.320790\n",
            "Epoch 4405: train loss = 4.087460, test loss = 12224.298567\n",
            "Epoch 4406: train loss = 4.087437, test loss = 12224.270753\n",
            "Epoch 4407: train loss = 4.087427, test loss = 12224.240990\n",
            "Epoch 4408: train loss = 4.087434, test loss = 12224.218693\n",
            "Epoch 4409: train loss = 4.087411, test loss = 12224.191386\n",
            "Epoch 4410: train loss = 4.087408, test loss = 12224.160080\n",
            "Epoch 4411: train loss = 4.087408, test loss = 12224.138817\n",
            "Epoch 4412: train loss = 4.087386, test loss = 12224.111637\n",
            "Epoch 4413: train loss = 4.087389, test loss = 12224.079401\n",
            "Epoch 4414: train loss = 4.087382, test loss = 12224.059417\n",
            "Epoch 4415: train loss = 4.087360, test loss = 12224.032866\n",
            "Epoch 4416: train loss = 4.087370, test loss = 12223.999458\n",
            "Epoch 4417: train loss = 4.087357, test loss = 12223.980936\n",
            "Epoch 4418: train loss = 4.087336, test loss = 12223.963971\n",
            "Epoch 4419: train loss = 4.087331, test loss = 12223.939677\n",
            "Epoch 4420: train loss = 4.087333, test loss = 12223.908338\n",
            "Epoch 4421: train loss = 4.087328, test loss = 12223.888325\n",
            "Epoch 4422: train loss = 4.087305, test loss = 12223.861944\n",
            "Epoch 4423: train loss = 4.087313, test loss = 12223.828504\n",
            "Epoch 4424: train loss = 4.087302, test loss = 12223.809541\n",
            "Epoch 4425: train loss = 4.087279, test loss = 12223.793578\n",
            "Epoch 4426: train loss = 4.087276, test loss = 12223.768862\n",
            "Epoch 4427: train loss = 4.087276, test loss = 12223.737390\n",
            "Epoch 4428: train loss = 4.087273, test loss = 12223.717339\n",
            "Epoch 4429: train loss = 4.087250, test loss = 12223.690753\n",
            "Epoch 4430: train loss = 4.087257, test loss = 12223.657518\n",
            "Epoch 4431: train loss = 4.087247, test loss = 12223.638806\n",
            "Epoch 4432: train loss = 4.087224, test loss = 12223.612481\n",
            "Epoch 4433: train loss = 4.087238, test loss = 12223.577852\n",
            "Epoch 4434: train loss = 4.087221, test loss = 12223.559585\n",
            "Epoch 4435: train loss = 4.087200, test loss = 12223.543462\n",
            "Epoch 4436: train loss = 4.087196, test loss = 12223.519425\n",
            "Epoch 4437: train loss = 4.087200, test loss = 12223.487196\n",
            "Epoch 4438: train loss = 4.087192, test loss = 12223.467839\n",
            "Epoch 4439: train loss = 4.087170, test loss = 12223.441642\n",
            "Epoch 4440: train loss = 4.087181, test loss = 12223.407056\n",
            "Epoch 4441: train loss = 4.087167, test loss = 12223.388757\n",
            "Epoch 4442: train loss = 4.087144, test loss = 12223.363169\n",
            "Epoch 4443: train loss = 4.087162, test loss = 12223.327435\n",
            "Epoch 4444: train loss = 4.087141, test loss = 12223.310578\n",
            "Epoch 4445: train loss = 4.087123, test loss = 12223.285797\n",
            "Epoch 4446: train loss = 4.087136, test loss = 12223.263768\n",
            "Epoch 4447: train loss = 4.087114, test loss = 12223.236152\n",
            "Epoch 4448: train loss = 4.087105, test loss = 12223.206010\n",
            "Epoch 4449: train loss = 4.087111, test loss = 12223.183988\n",
            "Epoch 4450: train loss = 4.087088, test loss = 12223.156504\n",
            "Epoch 4451: train loss = 4.087086, test loss = 12223.124968\n",
            "Epoch 4452: train loss = 4.087085, test loss = 12223.104518\n",
            "Epoch 4453: train loss = 4.087062, test loss = 12223.077389\n",
            "Epoch 4454: train loss = 4.087067, test loss = 12223.044539\n",
            "Epoch 4455: train loss = 4.087059, test loss = 12223.024775\n",
            "Epoch 4456: train loss = 4.087037, test loss = 12222.998455\n",
            "Epoch 4457: train loss = 4.087048, test loss = 12222.964534\n",
            "Epoch 4458: train loss = 4.087034, test loss = 12222.946300\n",
            "Epoch 4459: train loss = 4.087012, test loss = 12222.929623\n",
            "Epoch 4460: train loss = 4.087008, test loss = 12222.905252\n",
            "Epoch 4461: train loss = 4.087011, test loss = 12222.873405\n",
            "Epoch 4462: train loss = 4.087004, test loss = 12222.853668\n",
            "Epoch 4463: train loss = 4.086982, test loss = 12222.827450\n",
            "Epoch 4464: train loss = 4.086991, test loss = 12222.794135\n",
            "Epoch 4465: train loss = 4.086979, test loss = 12222.774983\n",
            "Epoch 4466: train loss = 4.086956, test loss = 12222.749074\n",
            "Epoch 4467: train loss = 4.086972, test loss = 12222.714044\n",
            "Epoch 4468: train loss = 4.086953, test loss = 12222.696144\n",
            "Epoch 4469: train loss = 4.086933, test loss = 12222.672184\n",
            "Epoch 4470: train loss = 4.086949, test loss = 12222.649895\n",
            "Epoch 4471: train loss = 4.086926, test loss = 12222.621988\n",
            "Epoch 4472: train loss = 4.086915, test loss = 12222.593043\n",
            "Epoch 4473: train loss = 4.086923, test loss = 12222.570294\n",
            "Epoch 4474: train loss = 4.086900, test loss = 12222.542374\n",
            "Epoch 4475: train loss = 4.086897, test loss = 12222.511514\n",
            "Epoch 4476: train loss = 4.086897, test loss = 12222.490108\n",
            "Epoch 4477: train loss = 4.086875, test loss = 12222.463073\n",
            "Epoch 4478: train loss = 4.086878, test loss = 12222.431062\n",
            "Epoch 4479: train loss = 4.086872, test loss = 12222.411236\n",
            "Epoch 4480: train loss = 4.086849, test loss = 12222.384516\n",
            "Epoch 4481: train loss = 4.086859, test loss = 12222.351171\n",
            "Epoch 4482: train loss = 4.086846, test loss = 12222.331955\n",
            "Epoch 4483: train loss = 4.086825, test loss = 12222.315309\n",
            "Epoch 4484: train loss = 4.086820, test loss = 12222.291151\n",
            "Epoch 4485: train loss = 4.086821, test loss = 12222.260289\n",
            "Epoch 4486: train loss = 4.086817, test loss = 12222.240066\n",
            "Epoch 4487: train loss = 4.086794, test loss = 12222.213459\n",
            "Epoch 4488: train loss = 4.086802, test loss = 12222.180234\n",
            "Epoch 4489: train loss = 4.086791, test loss = 12222.161086\n",
            "Epoch 4490: train loss = 4.086768, test loss = 12222.135025\n",
            "Epoch 4491: train loss = 4.086783, test loss = 12222.100612\n",
            "Epoch 4492: train loss = 4.086765, test loss = 12222.082917\n",
            "Epoch 4493: train loss = 4.086746, test loss = 12222.066189\n",
            "Epoch 4494: train loss = 4.086740, test loss = 12222.042193\n",
            "Epoch 4495: train loss = 4.086745, test loss = 12222.009768\n",
            "Epoch 4496: train loss = 4.086736, test loss = 12221.990564\n",
            "Epoch 4497: train loss = 4.086713, test loss = 12221.964523\n",
            "Epoch 4498: train loss = 4.086726, test loss = 12221.930203\n",
            "Epoch 4499: train loss = 4.086710, test loss = 12221.912226\n",
            "Epoch 4500: train loss = 4.086689, test loss = 12221.895827\n",
            "Epoch 4501: train loss = 4.086685, test loss = 12221.871453\n",
            "Epoch 4502: train loss = 4.086689, test loss = 12221.839116\n",
            "Epoch 4503: train loss = 4.086682, test loss = 12221.819780\n",
            "Epoch 4504: train loss = 4.086659, test loss = 12221.793524\n",
            "Epoch 4505: train loss = 4.086670, test loss = 12221.759308\n",
            "Epoch 4506: train loss = 4.086656, test loss = 12221.740915\n",
            "Epoch 4507: train loss = 4.086633, test loss = 12221.715515\n",
            "Epoch 4508: train loss = 4.086650, test loss = 12221.679888\n",
            "Epoch 4509: train loss = 4.086630, test loss = 12221.662306\n",
            "Epoch 4510: train loss = 4.086612, test loss = 12221.637749\n",
            "Epoch 4511: train loss = 4.086626, test loss = 12221.615795\n",
            "Epoch 4512: train loss = 4.086603, test loss = 12221.588086\n",
            "Epoch 4513: train loss = 4.086594, test loss = 12221.558634\n",
            "Epoch 4514: train loss = 4.086600, test loss = 12221.536248\n",
            "Epoch 4515: train loss = 4.086578, test loss = 12221.508461\n",
            "Epoch 4516: train loss = 4.086575, test loss = 12221.477116\n",
            "Epoch 4517: train loss = 4.086574, test loss = 12221.456091\n",
            "Epoch 4518: train loss = 4.086552, test loss = 12221.429096\n",
            "Epoch 4519: train loss = 4.086556, test loss = 12221.397059\n",
            "Epoch 4520: train loss = 4.086549, test loss = 12221.376985\n",
            "Epoch 4521: train loss = 4.086526, test loss = 12221.350387\n",
            "Epoch 4522: train loss = 4.086537, test loss = 12221.316664\n",
            "Epoch 4523: train loss = 4.086523, test loss = 12221.297859\n",
            "Epoch 4524: train loss = 4.086502, test loss = 12221.281346\n",
            "Epoch 4525: train loss = 4.086498, test loss = 12221.257157\n",
            "Epoch 4526: train loss = 4.086500, test loss = 12221.225438\n",
            "Epoch 4527: train loss = 4.086494, test loss = 12221.206221\n",
            "Epoch 4528: train loss = 4.086471, test loss = 12221.179618\n",
            "Epoch 4529: train loss = 4.086480, test loss = 12221.145804\n",
            "Epoch 4530: train loss = 4.086468, test loss = 12221.126942\n",
            "Epoch 4531: train loss = 4.086446, test loss = 12221.101034\n",
            "Epoch 4532: train loss = 4.086461, test loss = 12221.066113\n",
            "Epoch 4533: train loss = 4.086443, test loss = 12221.048310\n",
            "Epoch 4534: train loss = 4.086423, test loss = 12221.032530\n",
            "Epoch 4535: train loss = 4.086417, test loss = 12221.008263\n",
            "Epoch 4536: train loss = 4.086424, test loss = 12220.975408\n",
            "Epoch 4537: train loss = 4.086414, test loss = 12220.956450\n",
            "Epoch 4538: train loss = 4.086391, test loss = 12220.930368\n",
            "Epoch 4539: train loss = 4.086404, test loss = 12220.895744\n",
            "Epoch 4540: train loss = 4.086388, test loss = 12220.878000\n",
            "Epoch 4541: train loss = 4.086366, test loss = 12220.853932\n",
            "Epoch 4542: train loss = 4.086384, test loss = 12220.831259\n",
            "Epoch 4543: train loss = 4.086361, test loss = 12220.803142\n",
            "Epoch 4544: train loss = 4.086348, test loss = 12220.773952\n",
            "Epoch 4545: train loss = 4.086358, test loss = 12220.751262\n",
            "Epoch 4546: train loss = 4.086335, test loss = 12220.723781\n",
            "Epoch 4547: train loss = 4.086329, test loss = 12220.692920\n",
            "Epoch 4548: train loss = 4.086332, test loss = 12220.671302\n",
            "Epoch 4549: train loss = 4.086310, test loss = 12220.643967\n",
            "Epoch 4550: train loss = 4.086310, test loss = 12220.612176\n",
            "Epoch 4551: train loss = 4.086307, test loss = 12220.591760\n",
            "Epoch 4552: train loss = 4.086284, test loss = 12220.565198\n",
            "Epoch 4553: train loss = 4.086291, test loss = 12220.532210\n",
            "Epoch 4554: train loss = 4.086281, test loss = 12220.513263\n",
            "Epoch 4555: train loss = 4.086258, test loss = 12220.486985\n",
            "Epoch 4556: train loss = 4.086272, test loss = 12220.452652\n",
            "Epoch 4557: train loss = 4.086255, test loss = 12220.434285\n",
            "Epoch 4558: train loss = 4.086236, test loss = 12220.417860\n",
            "Epoch 4559: train loss = 4.086230, test loss = 12220.393946\n",
            "Epoch 4560: train loss = 4.086235, test loss = 12220.361691\n",
            "Epoch 4561: train loss = 4.086226, test loss = 12220.342516\n",
            "Epoch 4562: train loss = 4.086204, test loss = 12220.316831\n",
            "Epoch 4563: train loss = 4.086216, test loss = 12220.282399\n",
            "Epoch 4564: train loss = 4.086201, test loss = 12220.263872\n",
            "Epoch 4565: train loss = 4.086179, test loss = 12220.247518\n",
            "Epoch 4566: train loss = 4.086175, test loss = 12220.223337\n",
            "Epoch 4567: train loss = 4.086178, test loss = 12220.191236\n",
            "Epoch 4568: train loss = 4.086172, test loss = 12220.172113\n",
            "Epoch 4569: train loss = 4.086149, test loss = 12220.145726\n",
            "Epoch 4570: train loss = 4.086159, test loss = 12220.111566\n",
            "Epoch 4571: train loss = 4.086146, test loss = 12220.092837\n",
            "Epoch 4572: train loss = 4.086123, test loss = 12220.067084\n",
            "Epoch 4573: train loss = 4.086140, test loss = 12220.031879\n",
            "Epoch 4574: train loss = 4.086120, test loss = 12220.014619\n",
            "Epoch 4575: train loss = 4.086101, test loss = 12219.990179\n",
            "Epoch 4576: train loss = 4.086116, test loss = 12219.967973\n",
            "Epoch 4577: train loss = 4.086093, test loss = 12219.940100\n",
            "Epoch 4578: train loss = 4.086083, test loss = 12219.910387\n",
            "Epoch 4579: train loss = 4.086090, test loss = 12219.888045\n",
            "Epoch 4580: train loss = 4.086068, test loss = 12219.860473\n",
            "Epoch 4581: train loss = 4.086064, test loss = 12219.829362\n",
            "Epoch 4582: train loss = 4.086065, test loss = 12219.808633\n",
            "Epoch 4583: train loss = 4.086042, test loss = 12219.781406\n",
            "Epoch 4584: train loss = 4.086046, test loss = 12219.748970\n",
            "Epoch 4585: train loss = 4.086039, test loss = 12219.728899\n",
            "Epoch 4586: train loss = 4.086016, test loss = 12219.702500\n",
            "Epoch 4587: train loss = 4.086026, test loss = 12219.668990\n",
            "Epoch 4588: train loss = 4.086013, test loss = 12219.650048\n",
            "Epoch 4589: train loss = 4.085992, test loss = 12219.634010\n",
            "Epoch 4590: train loss = 4.085988, test loss = 12219.609426\n",
            "Epoch 4591: train loss = 4.085989, test loss = 12219.577921\n",
            "Epoch 4592: train loss = 4.085984, test loss = 12219.558043\n",
            "Epoch 4593: train loss = 4.085962, test loss = 12219.531554\n",
            "Epoch 4594: train loss = 4.085970, test loss = 12219.498201\n",
            "Epoch 4595: train loss = 4.085959, test loss = 12219.479644\n",
            "Epoch 4596: train loss = 4.085936, test loss = 12219.453342\n",
            "Epoch 4597: train loss = 4.085951, test loss = 12219.418634\n",
            "Epoch 4598: train loss = 4.085933, test loss = 12219.400606\n",
            "Epoch 4599: train loss = 4.085913, test loss = 12219.384263\n",
            "Epoch 4600: train loss = 4.085908, test loss = 12219.360414\n",
            "Epoch 4601: train loss = 4.085914, test loss = 12219.328222\n",
            "Epoch 4602: train loss = 4.085904, test loss = 12219.308836\n",
            "Epoch 4603: train loss = 4.085881, test loss = 12219.282784\n",
            "Epoch 4604: train loss = 4.085895, test loss = 12219.248094\n",
            "Epoch 4605: train loss = 4.085879, test loss = 12219.229939\n",
            "Epoch 4606: train loss = 4.085856, test loss = 12219.213978\n",
            "Epoch 4607: train loss = 4.085853, test loss = 12219.189688\n",
            "Epoch 4608: train loss = 4.085857, test loss = 12219.157107\n",
            "Epoch 4609: train loss = 4.085850, test loss = 12219.138404\n",
            "Epoch 4610: train loss = 4.085827, test loss = 12219.111929\n",
            "Epoch 4611: train loss = 4.085838, test loss = 12219.077387\n",
            "Epoch 4612: train loss = 4.085824, test loss = 12219.059072\n",
            "Epoch 4613: train loss = 4.085801, test loss = 12219.025467\n",
            "Epoch 4614: train loss = 4.085800, test loss = 12218.999333\n",
            "Epoch 4615: train loss = 4.085799, test loss = 12218.968106\n",
            "Epoch 4616: train loss = 4.085797, test loss = 12218.947569\n",
            "Epoch 4617: train loss = 4.085775, test loss = 12218.920231\n",
            "Epoch 4618: train loss = 4.085780, test loss = 12218.887121\n",
            "Epoch 4619: train loss = 4.085772, test loss = 12218.867208\n",
            "Epoch 4620: train loss = 4.085749, test loss = 12218.840746\n",
            "Epoch 4621: train loss = 4.085761, test loss = 12218.806640\n",
            "Epoch 4622: train loss = 4.085746, test loss = 12218.788358\n",
            "Epoch 4623: train loss = 4.085726, test loss = 12218.771464\n",
            "Epoch 4624: train loss = 4.085721, test loss = 12218.747138\n",
            "Epoch 4625: train loss = 4.085724, test loss = 12218.715216\n",
            "Epoch 4626: train loss = 4.085717, test loss = 12218.695599\n",
            "Epoch 4627: train loss = 4.085695, test loss = 12218.669241\n",
            "Epoch 4628: train loss = 4.085705, test loss = 12218.635418\n",
            "Epoch 4629: train loss = 4.085692, test loss = 12218.617021\n",
            "Epoch 4630: train loss = 4.085669, test loss = 12218.600507\n",
            "Epoch 4631: train loss = 4.085666, test loss = 12218.576070\n",
            "Epoch 4632: train loss = 4.085668, test loss = 12218.544063\n",
            "Epoch 4633: train loss = 4.085663, test loss = 12218.524416\n",
            "Epoch 4634: train loss = 4.085640, test loss = 12218.498084\n",
            "Epoch 4635: train loss = 4.085649, test loss = 12218.464234\n",
            "Epoch 4636: train loss = 4.085637, test loss = 12218.445878\n",
            "Epoch 4637: train loss = 4.085614, test loss = 12218.419780\n",
            "Epoch 4638: train loss = 4.085630, test loss = 12218.384586\n",
            "Epoch 4639: train loss = 4.085612, test loss = 12218.366804\n",
            "Epoch 4640: train loss = 4.085591, test loss = 12218.342777\n",
            "Epoch 4641: train loss = 4.085607, test loss = 12218.320344\n",
            "Epoch 4642: train loss = 4.085585, test loss = 12218.292549\n",
            "Epoch 4643: train loss = 4.085573, test loss = 12218.263069\n",
            "Epoch 4644: train loss = 4.085582, test loss = 12218.241012\n",
            "Epoch 4645: train loss = 4.085559, test loss = 12218.213124\n",
            "Epoch 4646: train loss = 4.085555, test loss = 12218.182042\n",
            "Epoch 4647: train loss = 4.085556, test loss = 12218.160706\n",
            "Epoch 4648: train loss = 4.085533, test loss = 12218.133630\n",
            "Epoch 4649: train loss = 4.085536, test loss = 12218.101516\n",
            "Epoch 4650: train loss = 4.085530, test loss = 12218.081812\n",
            "Epoch 4651: train loss = 4.085508, test loss = 12218.055125\n",
            "Epoch 4652: train loss = 4.085517, test loss = 12218.021636\n",
            "Epoch 4653: train loss = 4.085505, test loss = 12218.002541\n",
            "Epoch 4654: train loss = 4.085483, test loss = 12217.986017\n",
            "Epoch 4655: train loss = 4.085479, test loss = 12217.961666\n",
            "Epoch 4656: train loss = 4.085480, test loss = 12217.930937\n",
            "Epoch 4657: train loss = 4.085476, test loss = 12217.910625\n",
            "Epoch 4658: train loss = 4.085453, test loss = 12217.884080\n",
            "Epoch 4659: train loss = 4.085461, test loss = 12217.850856\n",
            "Epoch 4660: train loss = 4.085450, test loss = 12217.831589\n",
            "Epoch 4661: train loss = 4.085427, test loss = 12217.805654\n",
            "Epoch 4662: train loss = 4.085441, test loss = 12217.771249\n",
            "Epoch 4663: train loss = 4.085424, test loss = 12217.753022\n",
            "Epoch 4664: train loss = 4.085404, test loss = 12217.737286\n",
            "Epoch 4665: train loss = 4.085399, test loss = 12217.713055\n",
            "Epoch 4666: train loss = 4.085404, test loss = 12217.680434\n",
            "Epoch 4667: train loss = 4.085396, test loss = 12217.661307\n",
            "Epoch 4668: train loss = 4.085373, test loss = 12217.635240\n",
            "Epoch 4669: train loss = 4.085385, test loss = 12217.600820\n",
            "Epoch 4670: train loss = 4.085370, test loss = 12217.582593\n",
            "Epoch 4671: train loss = 4.085347, test loss = 12217.566870\n",
            "Epoch 4672: train loss = 4.085345, test loss = 12217.542411\n",
            "Epoch 4673: train loss = 4.085348, test loss = 12217.509964\n",
            "Epoch 4674: train loss = 4.085341, test loss = 12217.490474\n",
            "Epoch 4675: train loss = 4.085318, test loss = 12217.464334\n",
            "Epoch 4676: train loss = 4.085329, test loss = 12217.430164\n",
            "Epoch 4677: train loss = 4.085316, test loss = 12217.412025\n",
            "Epoch 4678: train loss = 4.085293, test loss = 12217.386086\n",
            "Epoch 4679: train loss = 4.085310, test loss = 12217.350589\n",
            "Epoch 4680: train loss = 4.085290, test loss = 12217.332966\n",
            "Epoch 4681: train loss = 4.085271, test loss = 12217.308593\n",
            "Epoch 4682: train loss = 4.085286, test loss = 12217.286598\n",
            "Epoch 4683: train loss = 4.085263, test loss = 12217.259412\n",
            "Epoch 4684: train loss = 4.085253, test loss = 12217.229259\n",
            "Epoch 4685: train loss = 4.085260, test loss = 12217.206906\n",
            "Epoch 4686: train loss = 4.085238, test loss = 12217.179328\n",
            "Epoch 4687: train loss = 4.085234, test loss = 12217.148023\n",
            "Epoch 4688: train loss = 4.085234, test loss = 12217.126964\n",
            "Epoch 4689: train loss = 4.085212, test loss = 12217.100068\n",
            "Epoch 4690: train loss = 4.085215, test loss = 12217.067606\n",
            "Epoch 4691: train loss = 4.085209, test loss = 12217.048092\n",
            "Epoch 4692: train loss = 4.085186, test loss = 12217.021537\n",
            "Epoch 4693: train loss = 4.085196, test loss = 12216.987750\n",
            "Epoch 4694: train loss = 4.085183, test loss = 12216.968868\n",
            "Epoch 4695: train loss = 4.085161, test loss = 12216.952576\n",
            "Epoch 4696: train loss = 4.085158, test loss = 12216.928205\n",
            "Epoch 4697: train loss = 4.085159, test loss = 12216.896581\n",
            "Epoch 4698: train loss = 4.085154, test loss = 12216.876899\n",
            "Epoch 4699: train loss = 4.085132, test loss = 12216.850885\n",
            "Epoch 4700: train loss = 4.085140, test loss = 12216.817129\n",
            "Epoch 4701: train loss = 4.085129, test loss = 12216.798144\n",
            "Epoch 4702: train loss = 4.085106, test loss = 12216.772113\n",
            "Epoch 4703: train loss = 4.085121, test loss = 12216.737319\n",
            "Epoch 4704: train loss = 4.085103, test loss = 12216.719494\n",
            "Epoch 4705: train loss = 4.085082, test loss = 12216.695936\n",
            "Epoch 4706: train loss = 4.085099, test loss = 12216.673349\n",
            "Epoch 4707: train loss = 4.085076, test loss = 12216.645291\n",
            "Epoch 4708: train loss = 4.085064, test loss = 12216.615977\n",
            "Epoch 4709: train loss = 4.085073, test loss = 12216.593398\n",
            "Epoch 4710: train loss = 4.085051, test loss = 12216.565626\n",
            "Epoch 4711: train loss = 4.085046, test loss = 12216.535378\n",
            "Epoch 4712: train loss = 4.085048, test loss = 12216.513783\n",
            "Epoch 4713: train loss = 4.085025, test loss = 12216.486469\n",
            "Epoch 4714: train loss = 4.085027, test loss = 12216.454531\n",
            "Epoch 4715: train loss = 4.085022, test loss = 12216.434299\n",
            "Epoch 4716: train loss = 4.084999, test loss = 12216.407733\n",
            "Epoch 4717: train loss = 4.085008, test loss = 12216.374646\n",
            "Epoch 4718: train loss = 4.084996, test loss = 12216.355963\n",
            "Epoch 4719: train loss = 4.084975, test loss = 12216.339100\n",
            "Epoch 4720: train loss = 4.084971, test loss = 12216.314716\n",
            "Epoch 4721: train loss = 4.084971, test loss = 12216.283533\n",
            "Epoch 4722: train loss = 4.084968, test loss = 12216.263526\n",
            "Epoch 4723: train loss = 4.084945, test loss = 12216.237070\n",
            "Epoch 4724: train loss = 4.084952, test loss = 12216.203937\n",
            "Epoch 4725: train loss = 4.084942, test loss = 12216.184809\n",
            "Epoch 4726: train loss = 4.084919, test loss = 12216.159207\n",
            "Epoch 4727: train loss = 4.084933, test loss = 12216.124560\n",
            "Epoch 4728: train loss = 4.084916, test loss = 12216.106310\n",
            "Epoch 4729: train loss = 4.084896, test loss = 12216.089992\n",
            "Epoch 4730: train loss = 4.084891, test loss = 12216.065910\n",
            "Epoch 4731: train loss = 4.084896, test loss = 12216.033734\n",
            "Epoch 4732: train loss = 4.084888, test loss = 12216.014946\n",
            "Epoch 4733: train loss = 4.084865, test loss = 12215.988498\n",
            "Epoch 4734: train loss = 4.084877, test loss = 12215.954262\n",
            "Epoch 4735: train loss = 4.084862, test loss = 12215.935741\n",
            "Epoch 4736: train loss = 4.084839, test loss = 12215.919687\n",
            "Epoch 4737: train loss = 4.084837, test loss = 12215.895511\n",
            "Epoch 4738: train loss = 4.084840, test loss = 12215.863604\n",
            "Epoch 4739: train loss = 4.084833, test loss = 12215.843950\n",
            "Epoch 4740: train loss = 4.084810, test loss = 12215.817703\n",
            "Epoch 4741: train loss = 4.084821, test loss = 12215.783442\n",
            "Epoch 4742: train loss = 4.084808, test loss = 12215.764930\n",
            "Epoch 4743: train loss = 4.084785, test loss = 12215.739263\n",
            "Epoch 4744: train loss = 4.084801, test loss = 12215.703852\n",
            "Epoch 4745: train loss = 4.084782, test loss = 12215.686361\n",
            "Epoch 4746: train loss = 4.084763, test loss = 12215.662579\n",
            "Epoch 4747: train loss = 4.084778, test loss = 12215.640172\n",
            "Epoch 4748: train loss = 4.084755, test loss = 12215.612399\n",
            "Epoch 4749: train loss = 4.084745, test loss = 12215.582534\n",
            "Epoch 4750: train loss = 4.084752, test loss = 12215.560305\n",
            "Epoch 4751: train loss = 4.084730, test loss = 12215.532746\n",
            "Epoch 4752: train loss = 4.084726, test loss = 12215.501516\n",
            "Epoch 4753: train loss = 4.084727, test loss = 12215.480892\n",
            "Epoch 4754: train loss = 4.084704, test loss = 12215.453697\n",
            "Epoch 4755: train loss = 4.084707, test loss = 12215.421149\n",
            "Epoch 4756: train loss = 4.084701, test loss = 12215.401214\n",
            "Epoch 4757: train loss = 4.084678, test loss = 12215.374838\n",
            "Epoch 4758: train loss = 4.084688, test loss = 12215.341213\n",
            "Epoch 4759: train loss = 4.084676, test loss = 12215.322824\n",
            "Epoch 4760: train loss = 4.084653, test loss = 12215.306242\n",
            "Epoch 4761: train loss = 4.084650, test loss = 12215.281783\n",
            "Epoch 4762: train loss = 4.084651, test loss = 12215.250216\n",
            "Epoch 4763: train loss = 4.084647, test loss = 12215.230312\n",
            "Epoch 4764: train loss = 4.084624, test loss = 12215.204044\n",
            "Epoch 4765: train loss = 4.084632, test loss = 12215.170580\n",
            "Epoch 4766: train loss = 4.084621, test loss = 12215.151988\n",
            "Epoch 4767: train loss = 4.084598, test loss = 12215.125891\n",
            "Epoch 4768: train loss = 4.084613, test loss = 12215.091068\n",
            "Epoch 4769: train loss = 4.084596, test loss = 12215.072988\n",
            "Epoch 4770: train loss = 4.084575, test loss = 12215.056975\n",
            "Epoch 4771: train loss = 4.084570, test loss = 12215.033015\n",
            "Epoch 4772: train loss = 4.084576, test loss = 12215.000201\n",
            "Epoch 4773: train loss = 4.084567, test loss = 12214.981702\n",
            "Epoch 4774: train loss = 4.084544, test loss = 12214.955414\n",
            "Epoch 4775: train loss = 4.084557, test loss = 12214.920732\n",
            "Epoch 4776: train loss = 4.084541, test loss = 12214.902632\n",
            "Epoch 4777: train loss = 4.084519, test loss = 12214.869119\n",
            "Epoch 4778: train loss = 4.084517, test loss = 12214.843060\n",
            "Epoch 4779: train loss = 4.084518, test loss = 12214.811708\n",
            "Epoch 4780: train loss = 4.084514, test loss = 12214.790874\n",
            "Epoch 4781: train loss = 4.084492, test loss = 12214.764324\n",
            "Epoch 4782: train loss = 4.084499, test loss = 12214.731032\n",
            "Epoch 4783: train loss = 4.084489, test loss = 12214.711109\n",
            "Epoch 4784: train loss = 4.084467, test loss = 12214.694251\n",
            "Epoch 4785: train loss = 4.084464, test loss = 12214.669648\n",
            "Epoch 4786: train loss = 4.084462, test loss = 12214.638708\n",
            "Epoch 4787: train loss = 4.084460, test loss = 12214.618703\n",
            "Epoch 4788: train loss = 4.084438, test loss = 12214.591703\n",
            "Epoch 4789: train loss = 4.084444, test loss = 12214.558771\n",
            "Epoch 4790: train loss = 4.084435, test loss = 12214.539191\n",
            "Epoch 4791: train loss = 4.084412, test loss = 12214.512859\n",
            "Epoch 4792: train loss = 4.084425, test loss = 12214.478873\n",
            "Epoch 4793: train loss = 4.084409, test loss = 12214.460827\n",
            "Epoch 4794: train loss = 4.084389, test loss = 12214.444131\n",
            "Epoch 4795: train loss = 4.084384, test loss = 12214.419948\n",
            "Epoch 4796: train loss = 4.084388, test loss = 12214.387912\n",
            "Epoch 4797: train loss = 4.084380, test loss = 12214.368336\n",
            "Epoch 4798: train loss = 4.084358, test loss = 12214.342209\n",
            "Epoch 4799: train loss = 4.084369, test loss = 12214.308190\n",
            "Epoch 4800: train loss = 4.084355, test loss = 12214.289634\n",
            "Epoch 4801: train loss = 4.084332, test loss = 12214.264380\n",
            "Epoch 4802: train loss = 4.084349, test loss = 12214.228849\n",
            "Epoch 4803: train loss = 4.084329, test loss = 12214.211150\n",
            "Epoch 4804: train loss = 4.084311, test loss = 12214.187006\n",
            "Epoch 4805: train loss = 4.084325, test loss = 12214.164782\n",
            "Epoch 4806: train loss = 4.084302, test loss = 12214.137094\n",
            "Epoch 4807: train loss = 4.084293, test loss = 12214.107535\n",
            "Epoch 4808: train loss = 4.084300, test loss = 12214.085542\n",
            "Epoch 4809: train loss = 4.084277, test loss = 12214.057710\n",
            "Epoch 4810: train loss = 4.084274, test loss = 12214.026604\n",
            "Epoch 4811: train loss = 4.084274, test loss = 12214.005323\n",
            "Epoch 4812: train loss = 4.084251, test loss = 12213.978363\n",
            "Epoch 4813: train loss = 4.084256, test loss = 12213.946089\n",
            "Epoch 4814: train loss = 4.084248, test loss = 12213.926570\n",
            "Epoch 4815: train loss = 4.084226, test loss = 12213.899917\n",
            "Epoch 4816: train loss = 4.084237, test loss = 12213.866305\n",
            "Epoch 4817: train loss = 4.084223, test loss = 12213.847383\n",
            "Epoch 4818: train loss = 4.084203, test loss = 12213.830765\n",
            "Epoch 4819: train loss = 4.084198, test loss = 12213.806601\n",
            "Epoch 4820: train loss = 4.084200, test loss = 12213.775748\n",
            "Epoch 4821: train loss = 4.084194, test loss = 12213.755662\n",
            "Epoch 4822: train loss = 4.084171, test loss = 12213.729124\n",
            "Epoch 4823: train loss = 4.084181, test loss = 12213.695755\n",
            "Epoch 4824: train loss = 4.084168, test loss = 12213.676766\n",
            "Epoch 4825: train loss = 4.084146, test loss = 12213.660349\n",
            "Epoch 4826: train loss = 4.084143, test loss = 12213.636048\n",
            "Epoch 4827: train loss = 4.084144, test loss = 12213.604629\n",
            "Epoch 4828: train loss = 4.084140, test loss = 12213.585161\n",
            "Epoch 4829: train loss = 4.084117, test loss = 12213.558526\n",
            "Epoch 4830: train loss = 4.084125, test loss = 12213.525019\n",
            "Epoch 4831: train loss = 4.084114, test loss = 12213.505979\n",
            "Epoch 4832: train loss = 4.084091, test loss = 12213.480006\n",
            "Epoch 4833: train loss = 4.084106, test loss = 12213.445385\n",
            "Epoch 4834: train loss = 4.084089, test loss = 12213.427352\n",
            "Epoch 4835: train loss = 4.084068, test loss = 12213.411309\n",
            "Epoch 4836: train loss = 4.084063, test loss = 12213.387619\n",
            "Epoch 4837: train loss = 4.084068, test loss = 12213.354917\n",
            "Epoch 4838: train loss = 4.084060, test loss = 12213.335715\n",
            "Epoch 4839: train loss = 4.084037, test loss = 12213.309539\n",
            "Epoch 4840: train loss = 4.084049, test loss = 12213.275138\n",
            "Epoch 4841: train loss = 4.084034, test loss = 12213.256852\n",
            "Epoch 4842: train loss = 4.084012, test loss = 12213.231714\n",
            "Epoch 4843: train loss = 4.084030, test loss = 12213.195891\n",
            "Epoch 4844: train loss = 4.084009, test loss = 12213.178406\n",
            "Epoch 4845: train loss = 4.083991, test loss = 12213.153863\n",
            "Epoch 4846: train loss = 4.084005, test loss = 12213.132111\n",
            "Epoch 4847: train loss = 4.083982, test loss = 12213.104506\n",
            "Epoch 4848: train loss = 4.083974, test loss = 12213.074911\n",
            "Epoch 4849: train loss = 4.083979, test loss = 12213.052710\n",
            "Epoch 4850: train loss = 4.083957, test loss = 12213.025023\n",
            "Epoch 4851: train loss = 4.083955, test loss = 12212.993516\n",
            "Epoch 4852: train loss = 4.083954, test loss = 12212.972585\n",
            "Epoch 4853: train loss = 4.083931, test loss = 12212.945821\n",
            "Epoch 4854: train loss = 4.083936, test loss = 12212.913172\n",
            "Epoch 4855: train loss = 4.083928, test loss = 12212.893415\n",
            "Epoch 4856: train loss = 4.083905, test loss = 12212.867671\n",
            "Epoch 4857: train loss = 4.083917, test loss = 12212.833547\n",
            "Epoch 4858: train loss = 4.083903, test loss = 12212.814719\n",
            "Epoch 4859: train loss = 4.083882, test loss = 12212.798340\n",
            "Epoch 4860: train loss = 4.083877, test loss = 12212.774223\n",
            "Epoch 4861: train loss = 4.083880, test loss = 12212.742338\n",
            "Epoch 4862: train loss = 4.083874, test loss = 12212.722856\n",
            "Epoch 4863: train loss = 4.083851, test loss = 12212.697038\n",
            "Epoch 4864: train loss = 4.083861, test loss = 12212.662931\n",
            "Epoch 4865: train loss = 4.083848, test loss = 12212.644174\n",
            "Epoch 4866: train loss = 4.083826, test loss = 12212.618233\n",
            "Epoch 4867: train loss = 4.083842, test loss = 12212.583282\n",
            "Epoch 4868: train loss = 4.083823, test loss = 12212.565620\n",
            "Epoch 4869: train loss = 4.083804, test loss = 12212.541950\n",
            "Epoch 4870: train loss = 4.083819, test loss = 12212.519478\n",
            "Epoch 4871: train loss = 4.083796, test loss = 12212.491644\n",
            "Epoch 4872: train loss = 4.083786, test loss = 12212.462044\n",
            "Epoch 4873: train loss = 4.083793, test loss = 12212.439639\n",
            "Epoch 4874: train loss = 4.083771, test loss = 12212.412050\n",
            "Epoch 4875: train loss = 4.083767, test loss = 12212.381521\n",
            "Epoch 4876: train loss = 4.083768, test loss = 12212.360037\n",
            "Epoch 4877: train loss = 4.083745, test loss = 12212.332950\n",
            "Epoch 4878: train loss = 4.083749, test loss = 12212.300726\n",
            "Epoch 4879: train loss = 4.083742, test loss = 12212.280666\n",
            "Epoch 4880: train loss = 4.083719, test loss = 12212.254187\n",
            "Epoch 4881: train loss = 4.083730, test loss = 12212.220950\n",
            "Epoch 4882: train loss = 4.083717, test loss = 12212.201977\n",
            "Epoch 4883: train loss = 4.083696, test loss = 12212.185741\n",
            "Epoch 4884: train loss = 4.083691, test loss = 12212.161356\n",
            "Epoch 4885: train loss = 4.083693, test loss = 12212.130094\n",
            "Epoch 4886: train loss = 4.083688, test loss = 12212.110079\n",
            "Epoch 4887: train loss = 4.083665, test loss = 12212.083693\n",
            "Epoch 4888: train loss = 4.083674, test loss = 12212.050521\n",
            "Epoch 4889: train loss = 4.083662, test loss = 12212.031399\n",
            "Epoch 4890: train loss = 4.083640, test loss = 12212.015886\n",
            "Epoch 4891: train loss = 4.083637, test loss = 12211.990923\n",
            "Epoch 4892: train loss = 4.083637, test loss = 12211.959576\n",
            "Epoch 4893: train loss = 4.083634, test loss = 12211.939438\n",
            "Epoch 4894: train loss = 4.083611, test loss = 12211.912845\n",
            "Epoch 4895: train loss = 4.083618, test loss = 12211.879772\n",
            "Epoch 4896: train loss = 4.083608, test loss = 12211.860608\n",
            "Epoch 4897: train loss = 4.083585, test loss = 12211.834514\n",
            "Epoch 4898: train loss = 4.083599, test loss = 12211.800179\n",
            "Epoch 4899: train loss = 4.083583, test loss = 12211.782091\n",
            "Epoch 4900: train loss = 4.083562, test loss = 12211.765872\n",
            "Epoch 4901: train loss = 4.083557, test loss = 12211.742327\n",
            "Epoch 4902: train loss = 4.083562, test loss = 12211.709768\n",
            "Epoch 4903: train loss = 4.083554, test loss = 12211.690373\n",
            "Epoch 4904: train loss = 4.083531, test loss = 12211.664300\n",
            "Epoch 4905: train loss = 4.083543, test loss = 12211.629984\n",
            "Epoch 4906: train loss = 4.083528, test loss = 12211.612111\n",
            "Epoch 4907: train loss = 4.083506, test loss = 12211.586239\n",
            "Epoch 4908: train loss = 4.083524, test loss = 12211.550544\n",
            "Epoch 4909: train loss = 4.083503, test loss = 12211.533219\n",
            "Epoch 4910: train loss = 4.083485, test loss = 12211.508810\n",
            "Epoch 4911: train loss = 4.083499, test loss = 12211.486883\n",
            "Epoch 4912: train loss = 4.083476, test loss = 12211.459820\n",
            "Epoch 4913: train loss = 4.083467, test loss = 12211.429641\n",
            "Epoch 4914: train loss = 4.083473, test loss = 12211.407361\n",
            "Epoch 4915: train loss = 4.083451, test loss = 12211.379853\n",
            "Epoch 4916: train loss = 4.083449, test loss = 12211.348548\n",
            "Epoch 4917: train loss = 4.083448, test loss = 12211.327547\n",
            "Epoch 4918: train loss = 4.083425, test loss = 12211.301154\n",
            "Epoch 4919: train loss = 4.083430, test loss = 12211.268329\n",
            "Epoch 4920: train loss = 4.083422, test loss = 12211.248496\n",
            "Epoch 4921: train loss = 4.083400, test loss = 12211.222171\n",
            "Epoch 4922: train loss = 4.083411, test loss = 12211.188385\n",
            "Epoch 4923: train loss = 4.083397, test loss = 12211.169725\n",
            "Epoch 4924: train loss = 4.083376, test loss = 12211.153751\n",
            "Epoch 4925: train loss = 4.083372, test loss = 12211.129280\n",
            "Epoch 4926: train loss = 4.083374, test loss = 12211.097595\n",
            "Epoch 4927: train loss = 4.083368, test loss = 12211.077923\n",
            "Epoch 4928: train loss = 4.083345, test loss = 12211.051544\n",
            "Epoch 4929: train loss = 4.083355, test loss = 12211.018009\n",
            "Epoch 4930: train loss = 4.083343, test loss = 12211.000091\n",
            "Epoch 4931: train loss = 4.083320, test loss = 12210.973627\n",
            "Epoch 4932: train loss = 4.083336, test loss = 12210.938610\n",
            "Epoch 4933: train loss = 4.083317, test loss = 12210.920622\n",
            "Epoch 4934: train loss = 4.083298, test loss = 12210.904438\n",
            "Epoch 4935: train loss = 4.083292, test loss = 12210.880675\n",
            "Epoch 4936: train loss = 4.083299, test loss = 12210.847770\n",
            "Epoch 4937: train loss = 4.083289, test loss = 12210.828988\n",
            "Epoch 4938: train loss = 4.083266, test loss = 12210.803163\n",
            "Epoch 4939: train loss = 4.083280, test loss = 12210.768355\n",
            "Epoch 4940: train loss = 4.083263, test loss = 12210.750843\n",
            "Epoch 4941: train loss = 4.083241, test loss = 12210.726782\n",
            "Epoch 4942: train loss = 4.083259, test loss = 12210.704105\n",
            "Epoch 4943: train loss = 4.083236, test loss = 12210.676187\n",
            "Epoch 4944: train loss = 4.083224, test loss = 12210.646880\n",
            "Epoch 4945: train loss = 4.083233, test loss = 12210.624306\n",
            "Epoch 4946: train loss = 4.083211, test loss = 12210.596997\n",
            "Epoch 4947: train loss = 4.083205, test loss = 12210.566023\n",
            "Epoch 4948: train loss = 4.083208, test loss = 12210.544533\n",
            "Epoch 4949: train loss = 4.083185, test loss = 12210.517376\n",
            "Epoch 4950: train loss = 4.083187, test loss = 12210.485444\n",
            "Epoch 4951: train loss = 4.083183, test loss = 12210.465184\n",
            "Epoch 4952: train loss = 4.083160, test loss = 12210.439148\n",
            "Epoch 4953: train loss = 4.083168, test loss = 12210.405766\n",
            "Epoch 4954: train loss = 4.083157, test loss = 12210.386488\n",
            "Epoch 4955: train loss = 4.083135, test loss = 12210.370094\n",
            "Epoch 4956: train loss = 4.083132, test loss = 12210.345608\n",
            "Epoch 4957: train loss = 4.083131, test loss = 12210.315101\n",
            "Epoch 4958: train loss = 4.083128, test loss = 12210.294620\n",
            "Epoch 4959: train loss = 4.083106, test loss = 12210.268095\n",
            "Epoch 4960: train loss = 4.083112, test loss = 12210.235111\n",
            "Epoch 4961: train loss = 4.083103, test loss = 12210.215739\n",
            "Epoch 4962: train loss = 4.083080, test loss = 12210.189781\n",
            "Epoch 4963: train loss = 4.083093, test loss = 12210.156040\n",
            "Epoch 4964: train loss = 4.083077, test loss = 12210.137437\n",
            "Epoch 4965: train loss = 4.083056, test loss = 12210.121253\n",
            "Epoch 4966: train loss = 4.083052, test loss = 12210.097180\n",
            "Epoch 4967: train loss = 4.083056, test loss = 12210.064882\n",
            "Epoch 4968: train loss = 4.083049, test loss = 12210.045641\n",
            "Epoch 4969: train loss = 4.083026, test loss = 12210.020047\n",
            "Epoch 4970: train loss = 4.083037, test loss = 12209.985593\n",
            "Epoch 4971: train loss = 4.083023, test loss = 12209.967096\n",
            "Epoch 4972: train loss = 4.083001, test loss = 12209.941359\n",
            "Epoch 4973: train loss = 4.083018, test loss = 12209.906061\n",
            "Epoch 4974: train loss = 4.082998, test loss = 12209.889070\n",
            "Epoch 4975: train loss = 4.082979, test loss = 12209.864496\n",
            "Epoch 4976: train loss = 4.082994, test loss = 12209.842475\n",
            "Epoch 4977: train loss = 4.082971, test loss = 12209.814820\n",
            "Epoch 4978: train loss = 4.082962, test loss = 12209.784929\n",
            "Epoch 4979: train loss = 4.082968, test loss = 12209.762851\n",
            "Epoch 4980: train loss = 4.082946, test loss = 12209.735782\n",
            "Epoch 4981: train loss = 4.082943, test loss = 12209.704234\n",
            "Epoch 4982: train loss = 4.082943, test loss = 12209.683219\n",
            "Epoch 4983: train loss = 4.082920, test loss = 12209.656285\n",
            "Epoch 4984: train loss = 4.082925, test loss = 12209.623788\n",
            "Epoch 4985: train loss = 4.082917, test loss = 12209.603986\n",
            "Epoch 4986: train loss = 4.082895, test loss = 12209.578063\n",
            "Epoch 4987: train loss = 4.082906, test loss = 12209.544260\n",
            "Epoch 4988: train loss = 4.082892, test loss = 12209.525401\n",
            "Epoch 4989: train loss = 4.082871, test loss = 12209.508870\n",
            "Epoch 4990: train loss = 4.082867, test loss = 12209.484758\n",
            "Epoch 4991: train loss = 4.082869, test loss = 12209.453281\n",
            "Epoch 4992: train loss = 4.082863, test loss = 12209.433962\n",
            "Epoch 4993: train loss = 4.082841, test loss = 12209.407439\n",
            "Epoch 4994: train loss = 4.082850, test loss = 12209.373861\n",
            "Epoch 4995: train loss = 4.082838, test loss = 12209.354850\n",
            "Epoch 4996: train loss = 4.082815, test loss = 12209.329053\n",
            "Epoch 4997: train loss = 4.082831, test loss = 12209.294694\n",
            "Epoch 4998: train loss = 4.082812, test loss = 12209.276606\n",
            "Epoch 4999: train loss = 4.082793, test loss = 12209.260362\n",
            "Epoch 5000: train loss = 4.082787, test loss = 12209.236404\n",
            "Epoch 5001: train loss = 4.082794, test loss = 12209.203754\n",
            "Epoch 5002: train loss = 4.082784, test loss = 12209.184931\n",
            "Epoch 5003: train loss = 4.082761, test loss = 12209.159346\n",
            "Epoch 5004: train loss = 4.082775, test loss = 12209.124532\n",
            "Epoch 5005: train loss = 4.082758, test loss = 12209.106373\n",
            "Epoch 5006: train loss = 4.082737, test loss = 12209.090291\n",
            "Epoch 5007: train loss = 4.082733, test loss = 12209.066214\n",
            "Epoch 5008: train loss = 4.082738, test loss = 12209.033598\n",
            "Epoch 5009: train loss = 4.082730, test loss = 12209.014894\n",
            "Epoch 5010: train loss = 4.082707, test loss = 12208.988642\n",
            "Epoch 5011: train loss = 4.082719, test loss = 12208.953968\n",
            "Epoch 5012: train loss = 4.082704, test loss = 12208.935737\n",
            "Epoch 5013: train loss = 4.082682, test loss = 12208.902335\n",
            "Epoch 5014: train loss = 4.082681, test loss = 12208.876143\n",
            "Epoch 5015: train loss = 4.082680, test loss = 12208.845380\n",
            "Epoch 5016: train loss = 4.082678, test loss = 12208.824321\n",
            "Epoch 5017: train loss = 4.082655, test loss = 12208.797091\n",
            "Epoch 5018: train loss = 4.082662, test loss = 12208.764096\n",
            "Epoch 5019: train loss = 4.082653, test loss = 12208.744368\n",
            "Epoch 5020: train loss = 4.082630, test loss = 12208.718313\n",
            "Epoch 5021: train loss = 4.082643, test loss = 12208.683988\n",
            "Epoch 5022: train loss = 4.082627, test loss = 12208.665266\n",
            "Epoch 5023: train loss = 4.082608, test loss = 12208.648562\n",
            "Epoch 5024: train loss = 4.082602, test loss = 12208.624530\n",
            "Epoch 5025: train loss = 4.082606, test loss = 12208.592542\n",
            "Epoch 5026: train loss = 4.082599, test loss = 12208.573564\n",
            "Epoch 5027: train loss = 4.082576, test loss = 12208.547088\n",
            "Epoch 5028: train loss = 4.082587, test loss = 12208.512998\n",
            "Epoch 5029: train loss = 4.082573, test loss = 12208.494389\n",
            "Epoch 5030: train loss = 4.082552, test loss = 12208.478094\n",
            "Epoch 5031: train loss = 4.082548, test loss = 12208.453776\n",
            "Epoch 5032: train loss = 4.082550, test loss = 12208.422380\n",
            "Epoch 5033: train loss = 4.082545, test loss = 12208.402579\n",
            "Epoch 5034: train loss = 4.082522, test loss = 12208.376098\n",
            "Epoch 5035: train loss = 4.082532, test loss = 12208.342307\n",
            "Epoch 5036: train loss = 4.082519, test loss = 12208.323630\n",
            "Epoch 5037: train loss = 4.082496, test loss = 12208.298150\n",
            "Epoch 5038: train loss = 4.082513, test loss = 12208.262928\n",
            "Epoch 5039: train loss = 4.082494, test loss = 12208.245008\n",
            "Epoch 5040: train loss = 4.082474, test loss = 12208.221027\n",
            "Epoch 5041: train loss = 4.082490, test loss = 12208.198801\n",
            "Epoch 5042: train loss = 4.082467, test loss = 12208.170950\n",
            "Epoch 5043: train loss = 4.082456, test loss = 12208.142009\n",
            "Epoch 5044: train loss = 4.082464, test loss = 12208.119357\n",
            "Epoch 5045: train loss = 4.082442, test loss = 12208.091510\n",
            "Epoch 5046: train loss = 4.082438, test loss = 12208.060659\n",
            "Epoch 5047: train loss = 4.082439, test loss = 12208.039432\n",
            "Epoch 5048: train loss = 4.082416, test loss = 12208.012331\n",
            "Epoch 5049: train loss = 4.082419, test loss = 12207.980721\n",
            "Epoch 5050: train loss = 4.082413, test loss = 12207.960372\n",
            "Epoch 5051: train loss = 4.082391, test loss = 12207.933868\n",
            "Epoch 5052: train loss = 4.082401, test loss = 12207.900553\n",
            "Epoch 5053: train loss = 4.082388, test loss = 12207.881519\n",
            "Epoch 5054: train loss = 4.082367, test loss = 12207.865069\n",
            "Epoch 5055: train loss = 4.082363, test loss = 12207.841324\n",
            "Epoch 5056: train loss = 4.082364, test loss = 12207.809828\n",
            "Epoch 5057: train loss = 4.082359, test loss = 12207.789835\n",
            "Epoch 5058: train loss = 4.082337, test loss = 12207.763420\n",
            "Epoch 5059: train loss = 4.082345, test loss = 12207.730110\n",
            "Epoch 5060: train loss = 4.082334, test loss = 12207.711564\n",
            "Epoch 5061: train loss = 4.082311, test loss = 12207.685373\n",
            "Epoch 5062: train loss = 4.082326, test loss = 12207.650725\n",
            "Epoch 5063: train loss = 4.082309, test loss = 12207.632709\n",
            "Epoch 5064: train loss = 4.082289, test loss = 12207.616385\n",
            "Epoch 5065: train loss = 4.082283, test loss = 12207.592547\n",
            "Epoch 5066: train loss = 4.082289, test loss = 12207.560616\n",
            "Epoch 5067: train loss = 4.082280, test loss = 12207.541248\n",
            "Epoch 5068: train loss = 4.082257, test loss = 12207.515167\n",
            "Epoch 5069: train loss = 4.082270, test loss = 12207.480812\n",
            "Epoch 5070: train loss = 4.082255, test loss = 12207.462521\n",
            "Epoch 5071: train loss = 4.082232, test loss = 12207.446538\n",
            "Epoch 5072: train loss = 4.082229, test loss = 12207.422848\n",
            "Epoch 5073: train loss = 4.082233, test loss = 12207.390176\n",
            "Epoch 5074: train loss = 4.082226, test loss = 12207.370831\n",
            "Epoch 5075: train loss = 4.082203, test loss = 12207.344704\n",
            "Epoch 5076: train loss = 4.082214, test loss = 12207.310361\n",
            "Epoch 5077: train loss = 4.082201, test loss = 12207.292059\n",
            "Epoch 5078: train loss = 4.082178, test loss = 12207.266768\n",
            "Epoch 5079: train loss = 4.082195, test loss = 12207.231121\n",
            "Epoch 5080: train loss = 4.082175, test loss = 12207.213683\n",
            "Epoch 5081: train loss = 4.082157, test loss = 12207.189181\n",
            "Epoch 5082: train loss = 4.082171, test loss = 12207.167327\n",
            "Epoch 5083: train loss = 4.082149, test loss = 12207.140230\n",
            "Epoch 5084: train loss = 4.082139, test loss = 12207.109987\n",
            "Epoch 5085: train loss = 4.082146, test loss = 12207.087802\n",
            "Epoch 5086: train loss = 4.082123, test loss = 12207.060269\n",
            "Epoch 5087: train loss = 4.082121, test loss = 12207.028904\n",
            "Epoch 5088: train loss = 4.082120, test loss = 12207.008006\n",
            "Epoch 5089: train loss = 4.082098, test loss = 12206.981594\n",
            "Epoch 5090: train loss = 4.082102, test loss = 12206.948805\n",
            "Epoch 5091: train loss = 4.082095, test loss = 12206.928946\n",
            "Epoch 5092: train loss = 4.082072, test loss = 12206.902524\n",
            "Epoch 5093: train loss = 4.082083, test loss = 12206.868918\n",
            "Epoch 5094: train loss = 4.082070, test loss = 12206.850221\n",
            "Epoch 5095: train loss = 4.082048, test loss = 12206.834299\n",
            "Epoch 5096: train loss = 4.082045, test loss = 12206.809874\n",
            "Epoch 5097: train loss = 4.082046, test loss = 12206.778186\n",
            "Epoch 5098: train loss = 4.082041, test loss = 12206.758370\n",
            "Epoch 5099: train loss = 4.082018, test loss = 12206.732115\n",
            "Epoch 5100: train loss = 4.082027, test loss = 12206.698610\n",
            "Epoch 5101: train loss = 4.082016, test loss = 12206.680137\n",
            "Epoch 5102: train loss = 4.081993, test loss = 12206.654092\n",
            "Epoch 5103: train loss = 4.082009, test loss = 12206.619096\n",
            "Epoch 5104: train loss = 4.081990, test loss = 12206.601325\n",
            "Epoch 5105: train loss = 4.081970, test loss = 12206.577479\n",
            "Epoch 5106: train loss = 4.081986, test loss = 12206.555501\n",
            "Epoch 5107: train loss = 4.081964, test loss = 12206.527531\n",
            "Epoch 5108: train loss = 4.081952, test loss = 12206.498144\n",
            "Epoch 5109: train loss = 4.081961, test loss = 12206.475507\n",
            "Epoch 5110: train loss = 4.081938, test loss = 12206.447910\n",
            "Epoch 5111: train loss = 4.081934, test loss = 12206.417212\n",
            "Epoch 5112: train loss = 4.081935, test loss = 12206.396245\n",
            "Epoch 5113: train loss = 4.081913, test loss = 12206.368989\n",
            "Epoch 5114: train loss = 4.081915, test loss = 12206.337026\n",
            "Epoch 5115: train loss = 4.081910, test loss = 12206.316736\n",
            "Epoch 5116: train loss = 4.081887, test loss = 12206.290307\n",
            "Epoch 5117: train loss = 4.081897, test loss = 12206.257157\n",
            "Epoch 5118: train loss = 4.081885, test loss = 12206.238560\n",
            "Epoch 5119: train loss = 4.081863, test loss = 12206.221832\n",
            "Epoch 5120: train loss = 4.081859, test loss = 12206.197472\n",
            "Epoch 5121: train loss = 4.081860, test loss = 12206.166431\n",
            "Epoch 5122: train loss = 4.081856, test loss = 12206.146438\n",
            "Epoch 5123: train loss = 4.081833, test loss = 12206.120363\n",
            "Epoch 5124: train loss = 4.081841, test loss = 12206.087144\n",
            "Epoch 5125: train loss = 4.081831, test loss = 12206.067897\n",
            "Epoch 5126: train loss = 4.081808, test loss = 12206.041781\n",
            "Epoch 5127: train loss = 4.081822, test loss = 12206.007571\n",
            "Epoch 5128: train loss = 4.081805, test loss = 12205.989445\n",
            "Epoch 5129: train loss = 4.081785, test loss = 12205.973546\n",
            "Epoch 5130: train loss = 4.081780, test loss = 12205.949492\n",
            "Epoch 5131: train loss = 4.081785, test loss = 12205.917066\n",
            "Epoch 5132: train loss = 4.081777, test loss = 12205.897908\n",
            "Epoch 5133: train loss = 4.081754, test loss = 12205.871879\n",
            "Epoch 5134: train loss = 4.081766, test loss = 12205.837658\n",
            "Epoch 5135: train loss = 4.081751, test loss = 12205.819809\n",
            "Epoch 5136: train loss = 4.081729, test loss = 12205.803543\n",
            "Epoch 5137: train loss = 4.081726, test loss = 12205.779231\n",
            "Epoch 5138: train loss = 4.081729, test loss = 12205.747003\n",
            "Epoch 5139: train loss = 4.081723, test loss = 12205.727666\n",
            "Epoch 5140: train loss = 4.081700, test loss = 12205.701444\n",
            "Epoch 5141: train loss = 4.081711, test loss = 12205.667878\n",
            "Epoch 5142: train loss = 4.081697, test loss = 12205.649178\n",
            "Epoch 5143: train loss = 4.081675, test loss = 12205.623297\n",
            "Epoch 5144: train loss = 4.081692, test loss = 12205.588041\n",
            "Epoch 5145: train loss = 4.081672, test loss = 12205.570473\n",
            "Epoch 5146: train loss = 4.081653, test loss = 12205.546698\n",
            "Epoch 5147: train loss = 4.081668, test loss = 12205.524548\n",
            "Epoch 5148: train loss = 4.081645, test loss = 12205.496705\n",
            "Epoch 5149: train loss = 4.081635, test loss = 12205.466939\n",
            "Epoch 5150: train loss = 4.081643, test loss = 12205.444761\n",
            "Epoch 5151: train loss = 4.081620, test loss = 12205.417189\n",
            "Epoch 5152: train loss = 4.081617, test loss = 12205.386491\n",
            "Epoch 5153: train loss = 4.081617, test loss = 12205.365254\n",
            "Epoch 5154: train loss = 4.081595, test loss = 12205.338199\n",
            "Epoch 5155: train loss = 4.081599, test loss = 12205.305821\n",
            "Epoch 5156: train loss = 4.081592, test loss = 12205.285884\n",
            "Epoch 5157: train loss = 4.081569, test loss = 12205.259599\n",
            "Epoch 5158: train loss = 4.081580, test loss = 12205.226540\n",
            "Epoch 5159: train loss = 4.081567, test loss = 12205.207424\n",
            "Epoch 5160: train loss = 4.081545, test loss = 12205.191060\n",
            "Epoch 5161: train loss = 4.081541, test loss = 12205.166875\n",
            "Epoch 5162: train loss = 4.081543, test loss = 12205.135256\n",
            "Epoch 5163: train loss = 4.081538, test loss = 12205.115994\n",
            "Epoch 5164: train loss = 4.081515, test loss = 12205.089504\n",
            "Epoch 5165: train loss = 4.081524, test loss = 12205.055827\n",
            "Epoch 5166: train loss = 4.081513, test loss = 12205.036945\n",
            "Epoch 5167: train loss = 4.081490, test loss = 12205.011093\n",
            "Epoch 5168: train loss = 4.081505, test loss = 12204.976350\n",
            "Epoch 5169: train loss = 4.081487, test loss = 12204.958959\n",
            "Epoch 5170: train loss = 4.081467, test loss = 12204.942594\n",
            "Epoch 5171: train loss = 4.081462, test loss = 12204.918679\n",
            "Epoch 5172: train loss = 4.081468, test loss = 12204.885969\n",
            "Epoch 5173: train loss = 4.081459, test loss = 12204.866959\n",
            "Epoch 5174: train loss = 4.081436, test loss = 12204.841123\n",
            "Epoch 5175: train loss = 4.081449, test loss = 12204.807005\n",
            "Epoch 5176: train loss = 4.081434, test loss = 12204.788599\n",
            "Epoch 5177: train loss = 4.081411, test loss = 12204.755168\n",
            "Epoch 5178: train loss = 4.081410, test loss = 12204.729127\n",
            "Epoch 5179: train loss = 4.081411, test loss = 12204.697656\n",
            "Epoch 5180: train loss = 4.081407, test loss = 12204.676967\n",
            "Epoch 5181: train loss = 4.081384, test loss = 12204.650529\n",
            "Epoch 5182: train loss = 4.081392, test loss = 12204.617085\n",
            "Epoch 5183: train loss = 4.081382, test loss = 12204.597375\n",
            "Epoch 5184: train loss = 4.081360, test loss = 12204.580498\n",
            "Epoch 5185: train loss = 4.081357, test loss = 12204.555997\n",
            "Epoch 5186: train loss = 4.081356, test loss = 12204.525604\n",
            "Epoch 5187: train loss = 4.081353, test loss = 12204.504858\n",
            "Epoch 5188: train loss = 4.081331, test loss = 12204.478168\n",
            "Epoch 5189: train loss = 4.081337, test loss = 12204.445313\n",
            "Epoch 5190: train loss = 4.081328, test loss = 12204.425729\n",
            "Epoch 5191: train loss = 4.081305, test loss = 12204.399652\n",
            "Epoch 5192: train loss = 4.081318, test loss = 12204.366063\n",
            "Epoch 5193: train loss = 4.081303, test loss = 12204.347289\n",
            "Epoch 5194: train loss = 4.081283, test loss = 12204.330867\n",
            "Epoch 5195: train loss = 4.081278, test loss = 12204.306777\n",
            "Epoch 5196: train loss = 4.081282, test loss = 12204.274840\n",
            "Epoch 5197: train loss = 4.081274, test loss = 12204.255475\n",
            "Epoch 5198: train loss = 4.081252, test loss = 12204.229726\n",
            "Epoch 5199: train loss = 4.081263, test loss = 12204.195583\n",
            "Epoch 5200: train loss = 4.081249, test loss = 12204.176950\n",
            "Epoch 5201: train loss = 4.081226, test loss = 12204.160769\n",
            "Epoch 5202: train loss = 4.081224, test loss = 12204.136543\n",
            "Epoch 5203: train loss = 4.081226, test loss = 12204.104617\n",
            "Epoch 5204: train loss = 4.081220, test loss = 12204.085418\n",
            "Epoch 5205: train loss = 4.081198, test loss = 12204.059027\n",
            "Epoch 5206: train loss = 4.081207, test loss = 12204.025101\n",
            "Epoch 5207: train loss = 4.081195, test loss = 12204.006307\n",
            "Epoch 5208: train loss = 4.081172, test loss = 12203.980618\n",
            "Epoch 5209: train loss = 4.081188, test loss = 12203.945925\n",
            "Epoch 5210: train loss = 4.081170, test loss = 12203.928051\n",
            "Epoch 5211: train loss = 4.081150, test loss = 12203.903956\n",
            "Epoch 5212: train loss = 4.081166, test loss = 12203.881657\n",
            "Epoch 5213: train loss = 4.081143, test loss = 12203.853960\n",
            "Epoch 5214: train loss = 4.081132, test loss = 12203.824460\n",
            "Epoch 5215: train loss = 4.081140, test loss = 12203.802508\n",
            "Epoch 5216: train loss = 4.081118, test loss = 12203.774687\n",
            "Epoch 5217: train loss = 4.081114, test loss = 12203.743657\n",
            "Epoch 5218: train loss = 4.081115, test loss = 12203.722404\n",
            "Epoch 5219: train loss = 4.081093, test loss = 12203.695455\n",
            "Epoch 5220: train loss = 4.081095, test loss = 12203.663344\n",
            "Epoch 5221: train loss = 4.081090, test loss = 12203.643684\n",
            "Epoch 5222: train loss = 4.081067, test loss = 12203.617126\n",
            "Epoch 5223: train loss = 4.081077, test loss = 12203.583596\n",
            "Epoch 5224: train loss = 4.081064, test loss = 12203.564670\n",
            "Epoch 5225: train loss = 4.081043, test loss = 12203.548406\n",
            "Epoch 5226: train loss = 4.081039, test loss = 12203.524504\n",
            "Epoch 5227: train loss = 4.081040, test loss = 12203.493002\n",
            "Epoch 5228: train loss = 4.081036, test loss = 12203.473080\n",
            "Epoch 5229: train loss = 4.081013, test loss = 12203.446577\n",
            "Epoch 5230: train loss = 4.081021, test loss = 12203.413355\n",
            "Epoch 5231: train loss = 4.081011, test loss = 12203.394359\n",
            "Epoch 5232: train loss = 4.080988, test loss = 12203.368842\n",
            "Epoch 5233: train loss = 4.081003, test loss = 12203.334141\n",
            "Epoch 5234: train loss = 4.080985, test loss = 12203.316045\n",
            "Epoch 5235: train loss = 4.080965, test loss = 12203.299889\n",
            "Epoch 5236: train loss = 4.080960, test loss = 12203.275984\n",
            "Epoch 5237: train loss = 4.080966, test loss = 12203.243444\n",
            "Epoch 5238: train loss = 4.080957, test loss = 12203.224884\n",
            "Epoch 5239: train loss = 4.080934, test loss = 12203.198720\n",
            "Epoch 5240: train loss = 4.080947, test loss = 12203.164149\n",
            "Epoch 5241: train loss = 4.080932, test loss = 12203.145954\n",
            "Epoch 5242: train loss = 4.080909, test loss = 12203.120466\n",
            "Epoch 5243: train loss = 4.080928, test loss = 12203.084793\n",
            "Epoch 5244: train loss = 4.080906, test loss = 12203.068058\n",
            "Epoch 5245: train loss = 4.080889, test loss = 12203.043407\n",
            "Epoch 5246: train loss = 4.080902, test loss = 12203.021518\n",
            "Epoch 5247: train loss = 4.080880, test loss = 12202.994012\n",
            "Epoch 5248: train loss = 4.080871, test loss = 12202.963894\n",
            "Epoch 5249: train loss = 4.080877, test loss = 12202.942480\n",
            "Epoch 5250: train loss = 4.080854, test loss = 12202.914827\n",
            "Epoch 5251: train loss = 4.080853, test loss = 12202.883179\n",
            "Epoch 5252: train loss = 4.080852, test loss = 12202.862447\n",
            "Epoch 5253: train loss = 4.080829, test loss = 12202.835657\n",
            "Epoch 5254: train loss = 4.080835, test loss = 12202.802937\n",
            "Epoch 5255: train loss = 4.080826, test loss = 12202.783843\n",
            "Epoch 5256: train loss = 4.080804, test loss = 12202.757383\n",
            "Epoch 5257: train loss = 4.080816, test loss = 12202.723349\n",
            "Epoch 5258: train loss = 4.080801, test loss = 12202.704782\n",
            "Epoch 5259: train loss = 4.080781, test loss = 12202.688469\n",
            "Epoch 5260: train loss = 4.080776, test loss = 12202.664339\n",
            "Epoch 5261: train loss = 4.080779, test loss = 12202.633087\n",
            "Epoch 5262: train loss = 4.080773, test loss = 12202.613295\n",
            "Epoch 5263: train loss = 4.080750, test loss = 12202.587019\n",
            "Epoch 5264: train loss = 4.080760, test loss = 12202.553284\n",
            "Epoch 5265: train loss = 4.080747, test loss = 12202.534569\n",
            "Epoch 5266: train loss = 4.080725, test loss = 12202.518917\n",
            "Epoch 5267: train loss = 4.080722, test loss = 12202.494408\n",
            "Epoch 5268: train loss = 4.080724, test loss = 12202.462465\n",
            "Epoch 5269: train loss = 4.080719, test loss = 12202.442842\n",
            "Epoch 5270: train loss = 4.080696, test loss = 12202.416579\n",
            "Epoch 5271: train loss = 4.080705, test loss = 12202.382859\n",
            "Epoch 5272: train loss = 4.080694, test loss = 12202.364615\n",
            "Epoch 5273: train loss = 4.080671, test loss = 12202.338565\n",
            "Epoch 5274: train loss = 4.080686, test loss = 12202.303506\n",
            "Epoch 5275: train loss = 4.080668, test loss = 12202.285724\n",
            "Epoch 5276: train loss = 4.080648, test loss = 12202.261791\n",
            "Epoch 5277: train loss = 4.080664, test loss = 12202.239547\n",
            "Epoch 5278: train loss = 4.080642, test loss = 12202.212244\n",
            "Epoch 5279: train loss = 4.080630, test loss = 12202.182619\n",
            "Epoch 5280: train loss = 4.080639, test loss = 12202.160079\n",
            "Epoch 5281: train loss = 4.080616, test loss = 12202.132409\n",
            "Epoch 5282: train loss = 4.080612, test loss = 12202.101602\n",
            "Epoch 5283: train loss = 4.080614, test loss = 12202.080358\n",
            "Epoch 5284: train loss = 4.080591, test loss = 12202.053805\n",
            "Epoch 5285: train loss = 4.080593, test loss = 12202.021503\n",
            "Epoch 5286: train loss = 4.080588, test loss = 12202.001362\n",
            "Epoch 5287: train loss = 4.080566, test loss = 12201.974903\n",
            "Epoch 5288: train loss = 4.080575, test loss = 12201.941641\n",
            "Epoch 5289: train loss = 4.080563, test loss = 12201.923133\n",
            "Epoch 5290: train loss = 4.080541, test loss = 12201.906450\n",
            "Epoch 5291: train loss = 4.080538, test loss = 12201.882107\n",
            "Epoch 5292: train loss = 4.080538, test loss = 12201.851037\n",
            "Epoch 5293: train loss = 4.080535, test loss = 12201.830950\n",
            "Epoch 5294: train loss = 4.080512, test loss = 12201.804589\n",
            "Epoch 5295: train loss = 4.080519, test loss = 12201.771976\n",
            "Epoch 5296: train loss = 4.080509, test loss = 12201.752559\n",
            "Epoch 5297: train loss = 4.080487, test loss = 12201.726527\n",
            "Epoch 5298: train loss = 4.080501, test loss = 12201.692188\n",
            "Epoch 5299: train loss = 4.080484, test loss = 12201.674027\n",
            "Epoch 5300: train loss = 4.080463, test loss = 12201.657973\n",
            "Epoch 5301: train loss = 4.080459, test loss = 12201.634490\n",
            "Epoch 5302: train loss = 4.080464, test loss = 12201.601847\n",
            "Epoch 5303: train loss = 4.080456, test loss = 12201.582688\n",
            "Epoch 5304: train loss = 4.080433, test loss = 12201.556553\n",
            "Epoch 5305: train loss = 4.080445, test loss = 12201.522377\n",
            "Epoch 5306: train loss = 4.080430, test loss = 12201.504163\n",
            "Epoch 5307: train loss = 4.080408, test loss = 12201.478931\n",
            "Epoch 5308: train loss = 4.080426, test loss = 12201.443292\n",
            "Epoch 5309: train loss = 4.080405, test loss = 12201.425944\n",
            "Epoch 5310: train loss = 4.080387, test loss = 12201.401468\n",
            "Epoch 5311: train loss = 4.080401, test loss = 12201.379705\n",
            "Epoch 5312: train loss = 4.080378, test loss = 12201.352617\n",
            "Epoch 5313: train loss = 4.080370, test loss = 12201.322434\n",
            "Epoch 5314: train loss = 4.080376, test loss = 12201.300330\n",
            "Epoch 5315: train loss = 4.080353, test loss = 12201.272857\n",
            "Epoch 5316: train loss = 4.080351, test loss = 12201.241502\n",
            "Epoch 5317: train loss = 4.080350, test loss = 12201.220680\n",
            "Epoch 5318: train loss = 4.080328, test loss = 12201.194220\n",
            "Epoch 5319: train loss = 4.080333, test loss = 12201.161569\n",
            "Epoch 5320: train loss = 4.080325, test loss = 12201.141763\n",
            "Epoch 5321: train loss = 4.080302, test loss = 12201.115375\n",
            "Epoch 5322: train loss = 4.080314, test loss = 12201.081713\n",
            "Epoch 5323: train loss = 4.080300, test loss = 12201.063139\n",
            "Epoch 5324: train loss = 4.080280, test loss = 12201.047099\n",
            "Epoch 5325: train loss = 4.080275, test loss = 12201.022837\n",
            "Epoch 5326: train loss = 4.080278, test loss = 12200.991213\n",
            "Epoch 5327: train loss = 4.080271, test loss = 12200.971479\n",
            "Epoch 5328: train loss = 4.080249, test loss = 12200.945275\n",
            "Epoch 5329: train loss = 4.080259, test loss = 12200.911629\n",
            "Epoch 5330: train loss = 4.080246, test loss = 12200.893404\n",
            "Epoch 5331: train loss = 4.080224, test loss = 12200.877035\n",
            "Epoch 5332: train loss = 4.080221, test loss = 12200.852561\n",
            "Epoch 5333: train loss = 4.080222, test loss = 12200.821020\n",
            "Epoch 5334: train loss = 4.080218, test loss = 12200.801288\n",
            "Epoch 5335: train loss = 4.080195, test loss = 12200.775341\n",
            "Epoch 5336: train loss = 4.080204, test loss = 12200.741672\n",
            "Epoch 5337: train loss = 4.080193, test loss = 12200.722716\n",
            "Epoch 5338: train loss = 4.080170, test loss = 12200.696737\n",
            "Epoch 5339: train loss = 4.080185, test loss = 12200.662039\n",
            "Epoch 5340: train loss = 4.080167, test loss = 12200.644254\n",
            "Epoch 5341: train loss = 4.080146, test loss = 12200.620825\n",
            "Epoch 5342: train loss = 4.080163, test loss = 12200.598242\n",
            "Epoch 5343: train loss = 4.080141, test loss = 12200.570297\n",
            "Epoch 5344: train loss = 4.080129, test loss = 12200.541084\n",
            "Epoch 5345: train loss = 4.080138, test loss = 12200.518555\n",
            "Epoch 5346: train loss = 4.080115, test loss = 12200.490845\n",
            "Epoch 5347: train loss = 4.080111, test loss = 12200.460687\n",
            "Epoch 5348: train loss = 4.080113, test loss = 12200.439105\n",
            "Epoch 5349: train loss = 4.080090, test loss = 12200.411859\n",
            "Epoch 5350: train loss = 4.080092, test loss = 12200.380063\n",
            "Epoch 5351: train loss = 4.080087, test loss = 12200.359887\n",
            "Epoch 5352: train loss = 4.080065, test loss = 12200.333778\n",
            "Epoch 5353: train loss = 4.080074, test loss = 12200.300562\n",
            "Epoch 5354: train loss = 4.080062, test loss = 12200.281366\n",
            "Epoch 5355: train loss = 4.080040, test loss = 12200.264862\n",
            "Epoch 5356: train loss = 4.080037, test loss = 12200.240611\n",
            "Epoch 5357: train loss = 4.080037, test loss = 12200.209610\n",
            "Epoch 5358: train loss = 4.080034, test loss = 12200.190054\n",
            "Epoch 5359: train loss = 4.080011, test loss = 12200.163405\n",
            "Epoch 5360: train loss = 4.080018, test loss = 12200.130292\n",
            "Epoch 5361: train loss = 4.080008, test loss = 12200.111104\n",
            "Epoch 5362: train loss = 4.079986, test loss = 12200.085135\n",
            "Epoch 5363: train loss = 4.079999, test loss = 12200.050892\n",
            "Epoch 5364: train loss = 4.079983, test loss = 12200.033195\n",
            "Epoch 5365: train loss = 4.079963, test loss = 12200.016853\n",
            "Epoch 5366: train loss = 4.079958, test loss = 12199.992699\n",
            "Epoch 5367: train loss = 4.079963, test loss = 12199.960564\n",
            "Epoch 5368: train loss = 4.079955, test loss = 12199.941381\n",
            "Epoch 5369: train loss = 4.079932, test loss = 12199.915259\n",
            "Epoch 5370: train loss = 4.079944, test loss = 12199.881689\n",
            "Epoch 5371: train loss = 4.079930, test loss = 12199.863010\n",
            "Epoch 5372: train loss = 4.079907, test loss = 12199.837338\n",
            "Epoch 5373: train loss = 4.079925, test loss = 12199.802040\n",
            "Epoch 5374: train loss = 4.079904, test loss = 12199.784569\n",
            "Epoch 5375: train loss = 4.079886, test loss = 12199.760791\n",
            "Epoch 5376: train loss = 4.079900, test loss = 12199.738701\n",
            "Epoch 5377: train loss = 4.079878, test loss = 12199.710974\n",
            "Epoch 5378: train loss = 4.079869, test loss = 12199.681185\n",
            "Epoch 5379: train loss = 4.079875, test loss = 12199.659114\n",
            "Epoch 5380: train loss = 4.079852, test loss = 12199.631606\n",
            "Epoch 5381: train loss = 4.079851, test loss = 12199.600880\n",
            "Epoch 5382: train loss = 4.079850, test loss = 12199.579641\n",
            "Epoch 5383: train loss = 4.079827, test loss = 12199.552775\n",
            "Epoch 5384: train loss = 4.079832, test loss = 12199.520345\n",
            "Epoch 5385: train loss = 4.079825, test loss = 12199.500488\n",
            "Epoch 5386: train loss = 4.079802, test loss = 12199.474254\n",
            "Epoch 5387: train loss = 4.079814, test loss = 12199.441163\n",
            "Epoch 5388: train loss = 4.079799, test loss = 12199.422132\n",
            "Epoch 5389: train loss = 4.079779, test loss = 12199.405652\n",
            "Epoch 5390: train loss = 4.079774, test loss = 12199.381631\n",
            "Epoch 5391: train loss = 4.079777, test loss = 12199.350033\n",
            "Epoch 5392: train loss = 4.079771, test loss = 12199.330444\n",
            "Epoch 5393: train loss = 4.079748, test loss = 12199.304659\n",
            "Epoch 5394: train loss = 4.079758, test loss = 12199.270869\n",
            "Epoch 5395: train loss = 4.079746, test loss = 12199.252009\n",
            "Epoch 5396: train loss = 4.079723, test loss = 12199.235731\n",
            "Epoch 5397: train loss = 4.079721, test loss = 12199.211534\n",
            "Epoch 5398: train loss = 4.079722, test loss = 12199.180501\n",
            "Epoch 5399: train loss = 4.079717, test loss = 12199.160381\n",
            "Epoch 5400: train loss = 4.079695, test loss = 12199.134044\n",
            "Epoch 5401: train loss = 4.079703, test loss = 12199.100595\n",
            "Epoch 5402: train loss = 4.079692, test loss = 12199.081594\n",
            "Epoch 5403: train loss = 4.079669, test loss = 12199.055775\n",
            "Epoch 5404: train loss = 4.079684, test loss = 12199.021641\n",
            "Epoch 5405: train loss = 4.079667, test loss = 12199.003403\n",
            "Epoch 5406: train loss = 4.079646, test loss = 12198.987423\n",
            "Epoch 5407: train loss = 4.079642, test loss = 12198.963494\n",
            "Epoch 5408: train loss = 4.079647, test loss = 12198.930724\n",
            "Epoch 5409: train loss = 4.079639, test loss = 12198.911826\n",
            "Epoch 5410: train loss = 4.079616, test loss = 12198.886314\n",
            "Epoch 5411: train loss = 4.079629, test loss = 12198.851571\n",
            "Epoch 5412: train loss = 4.079613, test loss = 12198.833401\n",
            "Epoch 5413: train loss = 4.079591, test loss = 12198.799840\n",
            "Epoch 5414: train loss = 4.079590, test loss = 12198.773902\n",
            "Epoch 5415: train loss = 4.079590, test loss = 12198.742637\n",
            "Epoch 5416: train loss = 4.079587, test loss = 12198.722253\n",
            "Epoch 5417: train loss = 4.079565, test loss = 12198.695155\n",
            "Epoch 5418: train loss = 4.079572, test loss = 12198.662020\n",
            "Epoch 5419: train loss = 4.079562, test loss = 12198.642234\n",
            "Epoch 5420: train loss = 4.079540, test loss = 12198.625587\n",
            "Epoch 5421: train loss = 4.079537, test loss = 12198.601417\n",
            "Epoch 5422: train loss = 4.079536, test loss = 12198.570372\n",
            "Epoch 5423: train loss = 4.079534, test loss = 12198.549866\n",
            "Epoch 5424: train loss = 4.079511, test loss = 12198.523128\n",
            "Epoch 5425: train loss = 4.079517, test loss = 12198.490375\n",
            "Epoch 5426: train loss = 4.079509, test loss = 12198.470907\n",
            "Epoch 5427: train loss = 4.079486, test loss = 12198.445152\n",
            "Epoch 5428: train loss = 4.079499, test loss = 12198.410934\n",
            "Epoch 5429: train loss = 4.079483, test loss = 12198.392406\n",
            "Epoch 5430: train loss = 4.079462, test loss = 12198.376058\n",
            "Epoch 5431: train loss = 4.079458, test loss = 12198.352064\n",
            "Epoch 5432: train loss = 4.079462, test loss = 12198.320152\n",
            "Epoch 5433: train loss = 4.079455, test loss = 12198.301088\n",
            "Epoch 5434: train loss = 4.079432, test loss = 12198.274777\n",
            "Epoch 5435: train loss = 4.079443, test loss = 12198.240714\n",
            "Epoch 5436: train loss = 4.079430, test loss = 12198.222159\n",
            "Epoch 5437: train loss = 4.079407, test loss = 12198.196514\n",
            "Epoch 5438: train loss = 4.079424, test loss = 12198.161767\n",
            "Epoch 5439: train loss = 4.079405, test loss = 12198.143989\n",
            "Epoch 5440: train loss = 4.079386, test loss = 12198.119823\n",
            "Epoch 5441: train loss = 4.079401, test loss = 12198.097684\n",
            "Epoch 5442: train loss = 4.079378, test loss = 12198.070047\n",
            "Epoch 5443: train loss = 4.079368, test loss = 12198.040516\n",
            "Epoch 5444: train loss = 4.079375, test loss = 12198.018667\n",
            "Epoch 5445: train loss = 4.079353, test loss = 12197.990901\n",
            "Epoch 5446: train loss = 4.079350, test loss = 12197.959827\n",
            "Epoch 5447: train loss = 4.079350, test loss = 12197.938615\n",
            "Epoch 5448: train loss = 4.079328, test loss = 12197.911770\n",
            "Epoch 5449: train loss = 4.079332, test loss = 12197.879517\n",
            "Epoch 5450: train loss = 4.079325, test loss = 12197.860093\n",
            "Epoch 5451: train loss = 4.079302, test loss = 12197.833575\n",
            "Epoch 5452: train loss = 4.079313, test loss = 12197.799989\n",
            "Epoch 5453: train loss = 4.079300, test loss = 12197.781150\n",
            "Epoch 5454: train loss = 4.079279, test loss = 12197.764768\n",
            "Epoch 5455: train loss = 4.079275, test loss = 12197.740587\n",
            "Epoch 5456: train loss = 4.079277, test loss = 12197.709799\n",
            "Epoch 5457: train loss = 4.079271, test loss = 12197.689794\n",
            "Epoch 5458: train loss = 4.079249, test loss = 12197.663334\n",
            "Epoch 5459: train loss = 4.079258, test loss = 12197.630044\n",
            "Epoch 5460: train loss = 4.079246, test loss = 12197.611129\n",
            "Epoch 5461: train loss = 4.079224, test loss = 12197.595334\n",
            "Epoch 5462: train loss = 4.079221, test loss = 12197.570801\n",
            "Epoch 5463: train loss = 4.079221, test loss = 12197.539325\n",
            "Epoch 5464: train loss = 4.079218, test loss = 12197.519471\n",
            "Epoch 5465: train loss = 4.079195, test loss = 12197.493111\n",
            "Epoch 5466: train loss = 4.079203, test loss = 12197.459801\n",
            "Epoch 5467: train loss = 4.079193, test loss = 12197.441256\n",
            "Epoch 5468: train loss = 4.079170, test loss = 12197.415161\n",
            "Epoch 5469: train loss = 4.079184, test loss = 12197.380499\n",
            "Epoch 5470: train loss = 4.079168, test loss = 12197.362484\n",
            "Epoch 5471: train loss = 4.079146, test loss = 12197.346607\n",
            "Epoch 5472: train loss = 4.079143, test loss = 12197.322531\n",
            "Epoch 5473: train loss = 4.079147, test loss = 12197.290550\n",
            "Epoch 5474: train loss = 4.079139, test loss = 12197.271260\n",
            "Epoch 5475: train loss = 4.079117, test loss = 12197.245125\n",
            "Epoch 5476: train loss = 4.079129, test loss = 12197.210776\n",
            "Epoch 5477: train loss = 4.079114, test loss = 12197.192497\n",
            "Epoch 5478: train loss = 4.079091, test loss = 12197.167059\n",
            "Epoch 5479: train loss = 4.079110, test loss = 12197.131966\n",
            "Epoch 5480: train loss = 4.079089, test loss = 12197.114416\n",
            "Epoch 5481: train loss = 4.079071, test loss = 12197.089956\n",
            "Epoch 5482: train loss = 4.079085, test loss = 12197.068248\n",
            "Epoch 5483: train loss = 4.079062, test loss = 12197.040656\n",
            "Epoch 5484: train loss = 4.079054, test loss = 12197.011135\n",
            "Epoch 5485: train loss = 4.079060, test loss = 12196.989011\n",
            "Epoch 5486: train loss = 4.079037, test loss = 12196.961402\n",
            "Epoch 5487: train loss = 4.079036, test loss = 12196.929977\n",
            "Epoch 5488: train loss = 4.079035, test loss = 12196.909173\n",
            "Epoch 5489: train loss = 4.079012, test loss = 12196.882437\n",
            "Epoch 5490: train loss = 4.079017, test loss = 12196.850297\n",
            "Epoch 5491: train loss = 4.079010, test loss = 12196.830392\n",
            "Epoch 5492: train loss = 4.078987, test loss = 12196.804108\n",
            "Epoch 5493: train loss = 4.078999, test loss = 12196.770277\n",
            "Epoch 5494: train loss = 4.078984, test loss = 12196.751625\n",
            "Epoch 5495: train loss = 4.078963, test loss = 12196.735484\n",
            "Epoch 5496: train loss = 4.078959, test loss = 12196.711861\n",
            "Epoch 5497: train loss = 4.078962, test loss = 12196.679782\n",
            "Epoch 5498: train loss = 4.078956, test loss = 12196.660246\n",
            "Epoch 5499: train loss = 4.078933, test loss = 12196.634031\n",
            "Epoch 5500: train loss = 4.078944, test loss = 12196.600240\n",
            "Epoch 5501: train loss = 4.078931, test loss = 12196.582059\n",
            "Epoch 5502: train loss = 4.078908, test loss = 12196.556025\n",
            "Epoch 5503: train loss = 4.078925, test loss = 12196.521039\n",
            "Epoch 5504: train loss = 4.078906, test loss = 12196.503359\n",
            "Epoch 5505: train loss = 4.078886, test loss = 12196.479391\n",
            "Epoch 5506: train loss = 4.078902, test loss = 12196.457266\n",
            "Epoch 5507: train loss = 4.078879, test loss = 12196.430031\n",
            "Epoch 5508: train loss = 4.078869, test loss = 12196.400348\n",
            "Epoch 5509: train loss = 4.078877, test loss = 12196.377915\n",
            "Epoch 5510: train loss = 4.078854, test loss = 12196.350304\n",
            "Epoch 5511: train loss = 4.078851, test loss = 12196.319384\n",
            "Epoch 5512: train loss = 4.078851, test loss = 12196.298301\n",
            "Epoch 5513: train loss = 4.078829, test loss = 12196.271808\n",
            "Epoch 5514: train loss = 4.078832, test loss = 12196.239452\n",
            "Epoch 5515: train loss = 4.078826, test loss = 12196.219423\n",
            "Epoch 5516: train loss = 4.078804, test loss = 12196.192923\n",
            "Epoch 5517: train loss = 4.078814, test loss = 12196.159734\n",
            "Epoch 5518: train loss = 4.078801, test loss = 12196.140826\n",
            "Epoch 5519: train loss = 4.078780, test loss = 12196.124764\n",
            "Epoch 5520: train loss = 4.078776, test loss = 12196.100445\n",
            "Epoch 5521: train loss = 4.078777, test loss = 12196.069260\n",
            "Epoch 5522: train loss = 4.078773, test loss = 12196.049315\n",
            "Epoch 5523: train loss = 4.078750, test loss = 12196.023003\n",
            "Epoch 5524: train loss = 4.078759, test loss = 12195.990343\n",
            "Epoch 5525: train loss = 4.078747, test loss = 12195.971021\n",
            "Epoch 5526: train loss = 4.078725, test loss = 12195.945038\n",
            "Epoch 5527: train loss = 4.078740, test loss = 12195.910542\n",
            "Epoch 5528: train loss = 4.078722, test loss = 12195.892554\n",
            "Epoch 5529: train loss = 4.078703, test loss = 12195.876413\n",
            "Epoch 5530: train loss = 4.078697, test loss = 12195.852983\n",
            "Epoch 5531: train loss = 4.078703, test loss = 12195.820479\n",
            "Epoch 5532: train loss = 4.078694, test loss = 12195.801415\n",
            "Epoch 5533: train loss = 4.078671, test loss = 12195.775322\n",
            "Epoch 5534: train loss = 4.078685, test loss = 12195.741095\n",
            "Epoch 5535: train loss = 4.078669, test loss = 12195.722970\n",
            "Epoch 5536: train loss = 4.078647, test loss = 12195.707314\n",
            "Epoch 5537: train loss = 4.078644, test loss = 12195.683038\n",
            "Epoch 5538: train loss = 4.078648, test loss = 12195.650675\n",
            "Epoch 5539: train loss = 4.078641, test loss = 12195.631359\n",
            "Epoch 5540: train loss = 4.078618, test loss = 12195.605326\n",
            "Epoch 5541: train loss = 4.078629, test loss = 12195.571101\n",
            "Epoch 5542: train loss = 4.078616, test loss = 12195.553281\n",
            "Epoch 5543: train loss = 4.078593, test loss = 12195.527439\n",
            "Epoch 5544: train loss = 4.078611, test loss = 12195.491876\n",
            "Epoch 5545: train loss = 4.078590, test loss = 12195.474506\n",
            "Epoch 5546: train loss = 4.078572, test loss = 12195.450279\n",
            "Epoch 5547: train loss = 4.078586, test loss = 12195.428790\n",
            "Epoch 5548: train loss = 4.078564, test loss = 12195.401012\n",
            "Epoch 5549: train loss = 4.078555, test loss = 12195.371158\n",
            "Epoch 5550: train loss = 4.078561, test loss = 12195.348949\n",
            "Epoch 5551: train loss = 4.078539, test loss = 12195.321515\n",
            "Epoch 5552: train loss = 4.078537, test loss = 12195.290355\n",
            "Epoch 5553: train loss = 4.078536, test loss = 12195.269804\n",
            "Epoch 5554: train loss = 4.078514, test loss = 12195.242757\n",
            "Epoch 5555: train loss = 4.078518, test loss = 12195.210139\n",
            "Epoch 5556: train loss = 4.078511, test loss = 12195.190440\n",
            "Epoch 5557: train loss = 4.078488, test loss = 12195.164192\n",
            "Epoch 5558: train loss = 4.078500, test loss = 12195.130488\n",
            "Epoch 5559: train loss = 4.078486, test loss = 12195.112350\n",
            "Epoch 5560: train loss = 4.078465, test loss = 12195.095860\n",
            "Epoch 5561: train loss = 4.078461, test loss = 12195.071546\n",
            "Epoch 5562: train loss = 4.078463, test loss = 12195.040043\n",
            "Epoch 5563: train loss = 4.078458, test loss = 12195.020414\n",
            "Epoch 5564: train loss = 4.078435, test loss = 12194.994090\n",
            "Epoch 5565: train loss = 4.078445, test loss = 12194.961058\n",
            "Epoch 5566: train loss = 4.078433, test loss = 12194.942100\n",
            "Epoch 5567: train loss = 4.078410, test loss = 12194.916103\n",
            "Epoch 5568: train loss = 4.078426, test loss = 12194.881358\n",
            "Epoch 5569: train loss = 4.078407, test loss = 12194.863551\n",
            "Epoch 5570: train loss = 4.078388, test loss = 12194.848022\n",
            "Epoch 5571: train loss = 4.078382, test loss = 12194.823985\n",
            "Epoch 5572: train loss = 4.078389, test loss = 12194.791069\n",
            "Epoch 5573: train loss = 4.078379, test loss = 12194.772296\n",
            "Epoch 5574: train loss = 4.078357, test loss = 12194.746443\n",
            "Epoch 5575: train loss = 4.078370, test loss = 12194.711746\n",
            "Epoch 5576: train loss = 4.078354, test loss = 12194.694311\n",
            "Epoch 5577: train loss = 4.078332, test loss = 12194.670377\n",
            "Epoch 5578: train loss = 4.078350, test loss = 12194.647687\n",
            "Epoch 5579: train loss = 4.078328, test loss = 12194.619871\n",
            "Epoch 5580: train loss = 4.078315, test loss = 12194.590673\n",
            "Epoch 5581: train loss = 4.078325, test loss = 12194.568082\n",
            "Epoch 5582: train loss = 4.078303, test loss = 12194.540827\n",
            "Epoch 5583: train loss = 4.078297, test loss = 12194.510005\n",
            "Epoch 5584: train loss = 4.078300, test loss = 12194.488499\n",
            "Epoch 5585: train loss = 4.078277, test loss = 12194.461406\n",
            "Epoch 5586: train loss = 4.078278, test loss = 12194.429630\n",
            "Epoch 5587: train loss = 4.078275, test loss = 12194.409846\n",
            "Epoch 5588: train loss = 4.078252, test loss = 12194.383125\n",
            "Epoch 5589: train loss = 4.078260, test loss = 12194.350033\n",
            "Epoch 5590: train loss = 4.078250, test loss = 12194.330853\n",
            "Epoch 5591: train loss = 4.078227, test loss = 12194.304901\n",
            "Epoch 5592: train loss = 4.078241, test loss = 12194.270654\n",
            "Epoch 5593: train loss = 4.078224, test loss = 12194.253039\n",
            "Epoch 5594: train loss = 4.078205, test loss = 12194.236572\n",
            "Epoch 5595: train loss = 4.078199, test loss = 12194.212556\n",
            "Epoch 5596: train loss = 4.078205, test loss = 12194.180537\n",
            "Epoch 5597: train loss = 4.078196, test loss = 12194.161299\n",
            "Epoch 5598: train loss = 4.078174, test loss = 12194.135342\n",
            "Epoch 5599: train loss = 4.078186, test loss = 12194.101762\n",
            "Epoch 5600: train loss = 4.078171, test loss = 12194.083145\n",
            "Epoch 5601: train loss = 4.078149, test loss = 12194.067048\n",
            "Epoch 5602: train loss = 4.078146, test loss = 12194.042940\n",
            "Epoch 5603: train loss = 4.078149, test loss = 12194.010830\n",
            "Epoch 5604: train loss = 4.078143, test loss = 12193.991532\n",
            "Epoch 5605: train loss = 4.078120, test loss = 12193.965896\n",
            "Epoch 5606: train loss = 4.078131, test loss = 12193.931644\n",
            "Epoch 5607: train loss = 4.078118, test loss = 12193.913099\n",
            "Epoch 5608: train loss = 4.078095, test loss = 12193.887326\n",
            "Epoch 5609: train loss = 4.078112, test loss = 12193.852179\n",
            "Epoch 5610: train loss = 4.078093, test loss = 12193.835208\n",
            "Epoch 5611: train loss = 4.078074, test loss = 12193.810740\n",
            "Epoch 5612: train loss = 4.078089, test loss = 12193.788702\n",
            "Epoch 5613: train loss = 4.078066, test loss = 12193.761116\n",
            "Epoch 5614: train loss = 4.078056, test loss = 12193.731384\n",
            "Epoch 5615: train loss = 4.078064, test loss = 12193.709245\n",
            "Epoch 5616: train loss = 4.078041, test loss = 12193.682257\n",
            "Epoch 5617: train loss = 4.078038, test loss = 12193.650849\n",
            "Epoch 5618: train loss = 4.078039, test loss = 12193.629773\n",
            "Epoch 5619: train loss = 4.078016, test loss = 12193.602870\n",
            "Epoch 5620: train loss = 4.078020, test loss = 12193.570562\n",
            "Epoch 5621: train loss = 4.078013, test loss = 12193.550758\n",
            "Epoch 5622: train loss = 4.077991, test loss = 12193.524830\n",
            "Epoch 5623: train loss = 4.078002, test loss = 12193.491217\n",
            "Epoch 5624: train loss = 4.077988, test loss = 12193.472355\n",
            "Epoch 5625: train loss = 4.077967, test loss = 12193.455947\n",
            "Epoch 5626: train loss = 4.077963, test loss = 12193.431836\n",
            "Epoch 5627: train loss = 4.077965, test loss = 12193.400537\n",
            "Epoch 5628: train loss = 4.077960, test loss = 12193.381162\n",
            "Epoch 5629: train loss = 4.077937, test loss = 12193.354681\n",
            "Epoch 5630: train loss = 4.077946, test loss = 12193.321296\n",
            "Epoch 5631: train loss = 4.077935, test loss = 12193.302289\n",
            "Epoch 5632: train loss = 4.077912, test loss = 12193.276489\n",
            "Epoch 5633: train loss = 4.077928, test loss = 12193.242421\n",
            "Epoch 5634: train loss = 4.077910, test loss = 12193.224198\n",
            "Epoch 5635: train loss = 4.077890, test loss = 12193.208097\n",
            "Epoch 5636: train loss = 4.077885, test loss = 12193.184151\n",
            "Epoch 5637: train loss = 4.077891, test loss = 12193.151682\n",
            "Epoch 5638: train loss = 4.077882, test loss = 12193.132806\n",
            "Epoch 5639: train loss = 4.077859, test loss = 12193.107271\n",
            "Epoch 5640: train loss = 4.077873, test loss = 12193.072646\n",
            "Epoch 5641: train loss = 4.077857, test loss = 12193.054495\n",
            "Epoch 5642: train loss = 4.077834, test loss = 12193.038543\n",
            "Epoch 5643: train loss = 4.077832, test loss = 12193.014523\n",
            "Epoch 5644: train loss = 4.077836, test loss = 12192.982035\n",
            "Epoch 5645: train loss = 4.077829, test loss = 12192.963275\n",
            "Epoch 5646: train loss = 4.077806, test loss = 12192.937060\n",
            "Epoch 5647: train loss = 4.077817, test loss = 12192.902571\n",
            "Epoch 5648: train loss = 4.077804, test loss = 12192.884345\n",
            "Epoch 5649: train loss = 4.077781, test loss = 12192.850920\n",
            "Epoch 5650: train loss = 4.077780, test loss = 12192.824832\n",
            "Epoch 5651: train loss = 4.077779, test loss = 12192.794204\n",
            "Epoch 5652: train loss = 4.077777, test loss = 12192.773120\n",
            "Epoch 5653: train loss = 4.077755, test loss = 12192.745990\n",
            "Epoch 5654: train loss = 4.077761, test loss = 12192.713113\n",
            "Epoch 5655: train loss = 4.077752, test loss = 12192.693357\n",
            "Epoch 5656: train loss = 4.077730, test loss = 12192.667357\n",
            "Epoch 5657: train loss = 4.077743, test loss = 12192.633195\n",
            "Epoch 5658: train loss = 4.077727, test loss = 12192.614500\n",
            "Epoch 5659: train loss = 4.077708, test loss = 12192.597930\n",
            "Epoch 5660: train loss = 4.077702, test loss = 12192.573964\n",
            "Epoch 5661: train loss = 4.077706, test loss = 12192.542083\n",
            "Epoch 5662: train loss = 4.077699, test loss = 12192.523073\n",
            "Epoch 5663: train loss = 4.077677, test loss = 12192.496641\n",
            "Epoch 5664: train loss = 4.077688, test loss = 12192.462714\n",
            "Epoch 5665: train loss = 4.077674, test loss = 12192.444078\n",
            "Epoch 5666: train loss = 4.077652, test loss = 12192.427969\n",
            "Epoch 5667: train loss = 4.077649, test loss = 12192.403715\n",
            "Epoch 5668: train loss = 4.077651, test loss = 12192.372440\n",
            "Epoch 5669: train loss = 4.077646, test loss = 12192.352607\n",
            "Epoch 5670: train loss = 4.077623, test loss = 12192.326222\n",
            "Epoch 5671: train loss = 4.077633, test loss = 12192.292545\n",
            "Epoch 5672: train loss = 4.077621, test loss = 12192.273839\n",
            "Epoch 5673: train loss = 4.077598, test loss = 12192.248413\n",
            "Epoch 5674: train loss = 4.077614, test loss = 12192.213351\n",
            "Epoch 5675: train loss = 4.077596, test loss = 12192.195457\n",
            "Epoch 5676: train loss = 4.077576, test loss = 12192.171567\n",
            "Epoch 5677: train loss = 4.077592, test loss = 12192.149420\n",
            "Epoch 5678: train loss = 4.077570, test loss = 12192.121611\n",
            "Epoch 5679: train loss = 4.077558, test loss = 12192.092746\n",
            "Epoch 5680: train loss = 4.077567, test loss = 12192.070174\n",
            "Epoch 5681: train loss = 4.077544, test loss = 12192.042368\n",
            "Epoch 5682: train loss = 4.077540, test loss = 12192.011580\n",
            "Epoch 5683: train loss = 4.077542, test loss = 12191.990387\n",
            "Epoch 5684: train loss = 4.077519, test loss = 12191.963384\n",
            "Epoch 5685: train loss = 4.077522, test loss = 12191.931886\n",
            "Epoch 5686: train loss = 4.077517, test loss = 12191.911627\n",
            "Epoch 5687: train loss = 4.077494, test loss = 12191.885097\n",
            "Epoch 5688: train loss = 4.077504, test loss = 12191.851896\n",
            "Epoch 5689: train loss = 4.077492, test loss = 12191.832863\n",
            "Epoch 5690: train loss = 4.077470, test loss = 12191.816593\n",
            "Epoch 5691: train loss = 4.077467, test loss = 12191.792919\n",
            "Epoch 5692: train loss = 4.077467, test loss = 12191.761471\n",
            "Epoch 5693: train loss = 4.077463, test loss = 12191.741515\n",
            "Epoch 5694: train loss = 4.077441, test loss = 12191.715202\n",
            "Epoch 5695: train loss = 4.077449, test loss = 12191.681998\n",
            "Epoch 5696: train loss = 4.077438, test loss = 12191.663447\n",
            "Epoch 5697: train loss = 4.077416, test loss = 12191.637365\n",
            "Epoch 5698: train loss = 4.077430, test loss = 12191.602808\n",
            "Epoch 5699: train loss = 4.077413, test loss = 12191.584783\n",
            "Epoch 5700: train loss = 4.077393, test loss = 12191.568732\n",
            "Epoch 5701: train loss = 4.077388, test loss = 12191.544826\n",
            "Epoch 5702: train loss = 4.077394, test loss = 12191.513014\n",
            "Epoch 5703: train loss = 4.077385, test loss = 12191.493641\n",
            "Epoch 5704: train loss = 4.077363, test loss = 12191.467665\n",
            "Epoch 5705: train loss = 4.077375, test loss = 12191.433407\n",
            "Epoch 5706: train loss = 4.077360, test loss = 12191.415107\n",
            "Epoch 5707: train loss = 4.077337, test loss = 12191.399300\n",
            "Epoch 5708: train loss = 4.077335, test loss = 12191.375677\n",
            "Epoch 5709: train loss = 4.077339, test loss = 12191.343052\n",
            "Epoch 5710: train loss = 4.077332, test loss = 12191.323744\n",
            "Epoch 5711: train loss = 4.077309, test loss = 12191.297716\n",
            "Epoch 5712: train loss = 4.077320, test loss = 12191.263479\n",
            "Epoch 5713: train loss = 4.077307, test loss = 12191.245606\n",
            "Epoch 5714: train loss = 4.077284, test loss = 12191.219725\n",
            "Epoch 5715: train loss = 4.077302, test loss = 12191.184306\n",
            "Epoch 5716: train loss = 4.077282, test loss = 12191.166922\n",
            "Epoch 5717: train loss = 4.077263, test loss = 12191.142565\n",
            "Epoch 5718: train loss = 4.077278, test loss = 12191.120815\n",
            "Epoch 5719: train loss = 4.077256, test loss = 12191.093734\n",
            "Epoch 5720: train loss = 4.077246, test loss = 12191.063606\n",
            "Epoch 5721: train loss = 4.077253, test loss = 12191.041517\n",
            "Epoch 5722: train loss = 4.077231, test loss = 12191.014042\n",
            "Epoch 5723: train loss = 4.077228, test loss = 12190.982730\n",
            "Epoch 5724: train loss = 4.077228, test loss = 12190.961931\n",
            "Epoch 5725: train loss = 4.077205, test loss = 12190.935571\n",
            "Epoch 5726: train loss = 4.077209, test loss = 12190.902821\n",
            "Epoch 5727: train loss = 4.077203, test loss = 12190.883012\n",
            "Epoch 5728: train loss = 4.077180, test loss = 12190.856694\n",
            "Epoch 5729: train loss = 4.077191, test loss = 12190.823122\n",
            "Epoch 5730: train loss = 4.077178, test loss = 12190.804488\n",
            "Epoch 5731: train loss = 4.077156, test loss = 12190.788796\n",
            "Epoch 5732: train loss = 4.077153, test loss = 12190.764397\n",
            "Epoch 5733: train loss = 4.077155, test loss = 12190.732745\n",
            "Epoch 5734: train loss = 4.077150, test loss = 12190.712969\n",
            "Epoch 5735: train loss = 4.077127, test loss = 12190.686813\n",
            "Epoch 5736: train loss = 4.077136, test loss = 12190.653784\n",
            "Epoch 5737: train loss = 4.077125, test loss = 12190.634671\n",
            "Epoch 5738: train loss = 4.077102, test loss = 12190.608869\n",
            "Epoch 5739: train loss = 4.077118, test loss = 12190.574119\n",
            "Epoch 5740: train loss = 4.077100, test loss = 12190.556256\n",
            "Epoch 5741: train loss = 4.077079, test loss = 12190.532594\n",
            "Epoch 5742: train loss = 4.077096, test loss = 12190.510685\n",
            "Epoch 5743: train loss = 4.077073, test loss = 12190.482735\n",
            "Epoch 5744: train loss = 4.077062, test loss = 12190.453436\n",
            "Epoch 5745: train loss = 4.077071, test loss = 12190.430900\n",
            "Epoch 5746: train loss = 4.077048, test loss = 12190.403313\n",
            "Epoch 5747: train loss = 4.077044, test loss = 12190.372704\n",
            "Epoch 5748: train loss = 4.077046, test loss = 12190.351850\n",
            "Epoch 5749: train loss = 4.077023, test loss = 12190.324655\n",
            "Epoch 5750: train loss = 4.077026, test loss = 12190.292725\n",
            "Epoch 5751: train loss = 4.077021, test loss = 12190.272547\n",
            "Epoch 5752: train loss = 4.076998, test loss = 12190.246173\n",
            "Epoch 5753: train loss = 4.077007, test loss = 12190.213045\n",
            "Epoch 5754: train loss = 4.076995, test loss = 12190.194515\n",
            "Epoch 5755: train loss = 4.076974, test loss = 12190.178004\n",
            "Epoch 5756: train loss = 4.076971, test loss = 12190.153621\n",
            "Epoch 5757: train loss = 4.076971, test loss = 12190.122658\n",
            "Epoch 5758: train loss = 4.076967, test loss = 12190.102767\n",
            "Epoch 5759: train loss = 4.076945, test loss = 12190.076754\n",
            "Epoch 5760: train loss = 4.076952, test loss = 12190.043566\n",
            "Epoch 5761: train loss = 4.076942, test loss = 12190.024376\n",
            "Epoch 5762: train loss = 4.076920, test loss = 12189.998367\n",
            "Epoch 5763: train loss = 4.076934, test loss = 12189.964179\n",
            "Epoch 5764: train loss = 4.076917, test loss = 12189.946122\n",
            "Epoch 5765: train loss = 4.076897, test loss = 12189.930452\n",
            "Epoch 5766: train loss = 4.076892, test loss = 12189.906375\n",
            "Epoch 5767: train loss = 4.076897, test loss = 12189.874026\n",
            "Epoch 5768: train loss = 4.076889, test loss = 12189.854967\n",
            "Epoch 5769: train loss = 4.076866, test loss = 12189.828997\n",
            "Epoch 5770: train loss = 4.076879, test loss = 12189.794806\n",
            "Epoch 5771: train loss = 4.076864, test loss = 12189.777017\n",
            "Epoch 5772: train loss = 4.076842, test loss = 12189.760965\n",
            "Epoch 5773: train loss = 4.076839, test loss = 12189.736631\n",
            "Epoch 5774: train loss = 4.076842, test loss = 12189.704482\n",
            "Epoch 5775: train loss = 4.076836, test loss = 12189.685239\n",
            "Epoch 5776: train loss = 4.076813, test loss = 12189.659074\n",
            "Epoch 5777: train loss = 4.076824, test loss = 12189.625547\n",
            "Epoch 5778: train loss = 4.076811, test loss = 12189.606951\n",
            "Epoch 5779: train loss = 4.076788, test loss = 12189.581122\n",
            "Epoch 5780: train loss = 4.076805, test loss = 12189.545892\n",
            "Epoch 5781: train loss = 4.076786, test loss = 12189.528379\n",
            "Epoch 5782: train loss = 4.076767, test loss = 12189.504750\n",
            "Epoch 5783: train loss = 4.076782, test loss = 12189.482607\n",
            "Epoch 5784: train loss = 4.076760, test loss = 12189.454836\n",
            "Epoch 5785: train loss = 4.076749, test loss = 12189.425203\n",
            "Epoch 5786: train loss = 4.076757, test loss = 12189.403082\n",
            "Epoch 5787: train loss = 4.076735, test loss = 12189.375528\n",
            "Epoch 5788: train loss = 4.076731, test loss = 12189.344908\n",
            "Epoch 5789: train loss = 4.076732, test loss = 12189.323772\n",
            "Epoch 5790: train loss = 4.076710, test loss = 12189.296729\n",
            "Epoch 5791: train loss = 4.076713, test loss = 12189.264430\n",
            "Epoch 5792: train loss = 4.076707, test loss = 12189.244701\n",
            "Epoch 5793: train loss = 4.076684, test loss = 12189.218349\n",
            "Epoch 5794: train loss = 4.076695, test loss = 12189.185338\n",
            "Epoch 5795: train loss = 4.076682, test loss = 12189.166346\n",
            "Epoch 5796: train loss = 4.076660, test loss = 12189.150150\n",
            "Epoch 5797: train loss = 4.076657, test loss = 12189.125951\n",
            "Epoch 5798: train loss = 4.076658, test loss = 12189.094394\n",
            "Epoch 5799: train loss = 4.076654, test loss = 12189.074796\n",
            "Epoch 5800: train loss = 4.076631, test loss = 12189.049016\n",
            "Epoch 5801: train loss = 4.076640, test loss = 12189.015280\n",
            "Epoch 5802: train loss = 4.076629, test loss = 12188.996445\n",
            "Epoch 5803: train loss = 4.076606, test loss = 12188.970628\n",
            "Epoch 5804: train loss = 4.076622, test loss = 12188.935898\n",
            "Epoch 5805: train loss = 4.076604, test loss = 12188.918565\n",
            "Epoch 5806: train loss = 4.076583, test loss = 12188.902507\n",
            "Epoch 5807: train loss = 4.076579, test loss = 12188.878439\n",
            "Epoch 5808: train loss = 4.076585, test loss = 12188.845820\n",
            "Epoch 5809: train loss = 4.076576, test loss = 12188.826917\n",
            "Epoch 5810: train loss = 4.076553, test loss = 12188.801094\n",
            "Epoch 5811: train loss = 4.076566, test loss = 12188.767063\n",
            "Epoch 5812: train loss = 4.076551, test loss = 12188.748765\n",
            "Epoch 5813: train loss = 4.076529, test loss = 12188.715321\n",
            "Epoch 5814: train loss = 4.076527, test loss = 12188.689328\n",
            "Epoch 5815: train loss = 4.076528, test loss = 12188.657938\n",
            "Epoch 5816: train loss = 4.076525, test loss = 12188.637368\n",
            "Epoch 5817: train loss = 4.076502, test loss = 12188.610955\n",
            "Epoch 5818: train loss = 4.076510, test loss = 12188.577579\n",
            "Epoch 5819: train loss = 4.076500, test loss = 12188.557988\n",
            "Epoch 5820: train loss = 4.076478, test loss = 12188.541232\n",
            "Epoch 5821: train loss = 4.076475, test loss = 12188.516774\n",
            "Epoch 5822: train loss = 4.076474, test loss = 12188.486056\n",
            "Epoch 5823: train loss = 4.076472, test loss = 12188.466065\n",
            "Epoch 5824: train loss = 4.076450, test loss = 12188.439256\n",
            "Epoch 5825: train loss = 4.076456, test loss = 12188.406398\n",
            "Epoch 5826: train loss = 4.076447, test loss = 12188.386892\n",
            "Epoch 5827: train loss = 4.076424, test loss = 12188.360814\n",
            "Epoch 5828: train loss = 4.076437, test loss = 12188.327293\n",
            "Epoch 5829: train loss = 4.076422, test loss = 12188.308631\n",
            "Epoch 5830: train loss = 4.076402, test loss = 12188.292378\n",
            "Epoch 5831: train loss = 4.076397, test loss = 12188.268374\n",
            "Epoch 5832: train loss = 4.076401, test loss = 12188.236361\n",
            "Epoch 5833: train loss = 4.076394, test loss = 12188.217111\n",
            "Epoch 5834: train loss = 4.076371, test loss = 12188.191387\n",
            "Epoch 5835: train loss = 4.076383, test loss = 12188.157321\n",
            "Epoch 5836: train loss = 4.076369, test loss = 12188.138799\n",
            "Epoch 5837: train loss = 4.076346, test loss = 12188.113015\n",
            "Epoch 5838: train loss = 4.076364, test loss = 12188.077963\n",
            "Epoch 5839: train loss = 4.076344, test loss = 12188.060552\n",
            "Epoch 5840: train loss = 4.076326, test loss = 12188.036868\n",
            "Epoch 5841: train loss = 4.076340, test loss = 12188.014682\n",
            "Epoch 5842: train loss = 4.076318, test loss = 12187.986984\n",
            "Epoch 5843: train loss = 4.076308, test loss = 12187.957351\n",
            "Epoch 5844: train loss = 4.076315, test loss = 12187.935194\n",
            "Epoch 5845: train loss = 4.076293, test loss = 12187.908165\n",
            "Epoch 5846: train loss = 4.076290, test loss = 12187.876888\n",
            "Epoch 5847: train loss = 4.076290, test loss = 12187.855810\n",
            "Epoch 5848: train loss = 4.076268, test loss = 12187.828825\n",
            "Epoch 5849: train loss = 4.076272, test loss = 12187.796736\n",
            "Epoch 5850: train loss = 4.076265, test loss = 12187.776914\n",
            "Epoch 5851: train loss = 4.076243, test loss = 12187.750989\n",
            "Epoch 5852: train loss = 4.076254, test loss = 12187.717392\n",
            "Epoch 5853: train loss = 4.076240, test loss = 12187.698584\n",
            "Epoch 5854: train loss = 4.076220, test loss = 12187.682042\n",
            "Epoch 5855: train loss = 4.076215, test loss = 12187.658064\n",
            "Epoch 5856: train loss = 4.076217, test loss = 12187.626904\n",
            "Epoch 5857: train loss = 4.076212, test loss = 12187.607553\n",
            "Epoch 5858: train loss = 4.076189, test loss = 12187.581094\n",
            "Epoch 5859: train loss = 4.076199, test loss = 12187.547734\n",
            "Epoch 5860: train loss = 4.076187, test loss = 12187.528781\n",
            "Epoch 5861: train loss = 4.076165, test loss = 12187.512654\n",
            "Epoch 5862: train loss = 4.076162, test loss = 12187.488352\n",
            "Epoch 5863: train loss = 4.076163, test loss = 12187.457643\n",
            "Epoch 5864: train loss = 4.076159, test loss = 12187.437576\n",
            "Epoch 5865: train loss = 4.076136, test loss = 12187.411067\n",
            "Epoch 5866: train loss = 4.076144, test loss = 12187.377908\n",
            "Epoch 5867: train loss = 4.076134, test loss = 12187.358951\n",
            "Epoch 5868: train loss = 4.076111, test loss = 12187.333443\n",
            "Epoch 5869: train loss = 4.076126, test loss = 12187.298778\n",
            "Epoch 5870: train loss = 4.076109, test loss = 12187.280782\n",
            "Epoch 5871: train loss = 4.076088, test loss = 12187.264742\n",
            "Epoch 5872: train loss = 4.076084, test loss = 12187.240866\n",
            "Epoch 5873: train loss = 4.076089, test loss = 12187.208419\n",
            "Epoch 5874: train loss = 4.076081, test loss = 12187.189908\n",
            "Epoch 5875: train loss = 4.076058, test loss = 12187.163755\n",
            "Epoch 5876: train loss = 4.076071, test loss = 12187.129286\n",
            "Epoch 5877: train loss = 4.076056, test loss = 12187.111137\n",
            "Epoch 5878: train loss = 4.076033, test loss = 12187.085661\n",
            "Epoch 5879: train loss = 4.076052, test loss = 12187.050038\n",
            "Epoch 5880: train loss = 4.076031, test loss = 12187.033412\n",
            "Epoch 5881: train loss = 4.076014, test loss = 12187.008785\n",
            "Epoch 5882: train loss = 4.076027, test loss = 12186.986972\n",
            "Epoch 5883: train loss = 4.076005, test loss = 12186.959579\n",
            "Epoch 5884: train loss = 4.075997, test loss = 12186.929618\n",
            "Epoch 5885: train loss = 4.076002, test loss = 12186.908095\n",
            "Epoch 5886: train loss = 4.075980, test loss = 12186.880519\n",
            "Epoch 5887: train loss = 4.075979, test loss = 12186.848973\n",
            "Epoch 5888: train loss = 4.075977, test loss = 12186.828263\n",
            "Epoch 5889: train loss = 4.075955, test loss = 12186.801547\n",
            "Epoch 5890: train loss = 4.075961, test loss = 12186.768926\n",
            "Epoch 5891: train loss = 4.075952, test loss = 12186.749854\n",
            "Epoch 5892: train loss = 4.075930, test loss = 12186.723469\n",
            "Epoch 5893: train loss = 4.075942, test loss = 12186.689532\n",
            "Epoch 5894: train loss = 4.075928, test loss = 12186.671037\n",
            "Epoch 5895: train loss = 4.075907, test loss = 12186.654852\n",
            "Epoch 5896: train loss = 4.075903, test loss = 12186.630755\n",
            "Epoch 5897: train loss = 4.075906, test loss = 12186.599594\n",
            "Epoch 5898: train loss = 4.075900, test loss = 12186.579904\n",
            "Epoch 5899: train loss = 4.075877, test loss = 12186.553565\n",
            "Epoch 5900: train loss = 4.075887, test loss = 12186.519948\n",
            "Epoch 5901: train loss = 4.075875, test loss = 12186.501257\n",
            "Epoch 5902: train loss = 4.075852, test loss = 12186.475692\n",
            "Epoch 5903: train loss = 4.075869, test loss = 12186.441181\n",
            "Epoch 5904: train loss = 4.075850, test loss = 12186.423357\n",
            "Epoch 5905: train loss = 4.075830, test loss = 12186.399284\n",
            "Epoch 5906: train loss = 4.075846, test loss = 12186.377181\n",
            "Epoch 5907: train loss = 4.075823, test loss = 12186.349583\n",
            "Epoch 5908: train loss = 4.075813, test loss = 12186.320570\n",
            "Epoch 5909: train loss = 4.075821, test loss = 12186.298060\n",
            "Epoch 5910: train loss = 4.075798, test loss = 12186.270380\n",
            "Epoch 5911: train loss = 4.075795, test loss = 12186.239661\n",
            "Epoch 5912: train loss = 4.075796, test loss = 12186.218426\n",
            "Epoch 5913: train loss = 4.075773, test loss = 12186.191555\n",
            "Epoch 5914: train loss = 4.075777, test loss = 12186.159968\n",
            "Epoch 5915: train loss = 4.075771, test loss = 12186.139812\n",
            "Epoch 5916: train loss = 4.075748, test loss = 12186.113402\n",
            "Epoch 5917: train loss = 4.075759, test loss = 12186.080104\n",
            "Epoch 5918: train loss = 4.075746, test loss = 12186.061270\n",
            "Epoch 5919: train loss = 4.075726, test loss = 12186.044773\n",
            "Epoch 5920: train loss = 4.075721, test loss = 12186.021368\n",
            "Epoch 5921: train loss = 4.075723, test loss = 12185.989929\n",
            "Epoch 5922: train loss = 4.075718, test loss = 12185.970062\n",
            "Epoch 5923: train loss = 4.075695, test loss = 12185.943645\n",
            "Epoch 5924: train loss = 4.075704, test loss = 12185.910615\n",
            "Epoch 5925: train loss = 4.075693, test loss = 12185.891685\n",
            "Epoch 5926: train loss = 4.075670, test loss = 12185.875863\n",
            "Epoch 5927: train loss = 4.075668, test loss = 12185.851452\n",
            "Epoch 5928: train loss = 4.075668, test loss = 12185.820180\n",
            "Epoch 5929: train loss = 4.075665, test loss = 12185.800337\n",
            "Epoch 5930: train loss = 4.075642, test loss = 12185.773916\n",
            "Epoch 5931: train loss = 4.075650, test loss = 12185.741338\n",
            "Epoch 5932: train loss = 4.075640, test loss = 12185.721942\n",
            "Epoch 5933: train loss = 4.075617, test loss = 12185.695972\n",
            "Epoch 5934: train loss = 4.075631, test loss = 12185.661702\n",
            "Epoch 5935: train loss = 4.075615, test loss = 12185.643558\n",
            "Epoch 5936: train loss = 4.075594, test loss = 12185.627684\n",
            "Epoch 5937: train loss = 4.075590, test loss = 12185.604185\n",
            "Epoch 5938: train loss = 4.075595, test loss = 12185.571779\n",
            "Epoch 5939: train loss = 4.075587, test loss = 12185.552480\n",
            "Epoch 5940: train loss = 4.075564, test loss = 12185.526513\n",
            "Epoch 5941: train loss = 4.075576, test loss = 12185.492282\n",
            "Epoch 5942: train loss = 4.075562, test loss = 12185.474111\n",
            "Epoch 5943: train loss = 4.075539, test loss = 12185.448970\n",
            "Epoch 5944: train loss = 4.075558, test loss = 12185.413496\n",
            "Epoch 5945: train loss = 4.075537, test loss = 12185.396036\n",
            "Epoch 5946: train loss = 4.075519, test loss = 12185.371752\n",
            "Epoch 5947: train loss = 4.075533, test loss = 12185.350001\n",
            "Epoch 5948: train loss = 4.075511, test loss = 12185.322567\n",
            "Epoch 5949: train loss = 4.075502, test loss = 12185.293200\n",
            "Epoch 5950: train loss = 4.075508, test loss = 12185.270901\n",
            "Epoch 5951: train loss = 4.075486, test loss = 12185.243490\n",
            "Epoch 5952: train loss = 4.075484, test loss = 12185.212101\n",
            "Epoch 5953: train loss = 4.075483, test loss = 12185.191434\n",
            "Epoch 5954: train loss = 4.075461, test loss = 12185.165054\n",
            "Epoch 5955: train loss = 4.075466, test loss = 12185.132366\n",
            "Epoch 5956: train loss = 4.075459, test loss = 12185.112542\n",
            "Epoch 5957: train loss = 4.075436, test loss = 12185.086408\n",
            "Epoch 5958: train loss = 4.075448, test loss = 12185.052753\n",
            "Epoch 5959: train loss = 4.075434, test loss = 12185.034108\n",
            "Epoch 5960: train loss = 4.075413, test loss = 12185.018380\n",
            "Epoch 5961: train loss = 4.075409, test loss = 12184.994079\n",
            "Epoch 5962: train loss = 4.075412, test loss = 12184.962527\n",
            "Epoch 5963: train loss = 4.075406, test loss = 12184.942850\n",
            "Epoch 5964: train loss = 4.075383, test loss = 12184.916762\n",
            "Epoch 5965: train loss = 4.075393, test loss = 12184.883136\n",
            "Epoch 5966: train loss = 4.075381, test loss = 12184.864957\n",
            "Epoch 5967: train loss = 4.075358, test loss = 12184.839006\n",
            "Epoch 5968: train loss = 4.075375, test loss = 12184.804071\n",
            "Epoch 5969: train loss = 4.075356, test loss = 12184.786403\n",
            "Epoch 5970: train loss = 4.075336, test loss = 12184.770357\n",
            "Epoch 5971: train loss = 4.075331, test loss = 12184.746828\n",
            "Epoch 5972: train loss = 4.075338, test loss = 12184.714438\n",
            "Epoch 5973: train loss = 4.075328, test loss = 12184.695515\n",
            "Epoch 5974: train loss = 4.075305, test loss = 12184.669577\n",
            "Epoch 5975: train loss = 4.075320, test loss = 12184.634933\n",
            "Epoch 5976: train loss = 4.075303, test loss = 12184.617074\n",
            "Epoch 5977: train loss = 4.075281, test loss = 12184.593724\n",
            "Epoch 5978: train loss = 4.075299, test loss = 12184.571251\n",
            "Epoch 5979: train loss = 4.075277, test loss = 12184.543219\n",
            "Epoch 5980: train loss = 4.075264, test loss = 12184.513987\n",
            "Epoch 5981: train loss = 4.075274, test loss = 12184.491538\n",
            "Epoch 5982: train loss = 4.075252, test loss = 12184.463913\n",
            "Epoch 5983: train loss = 4.075247, test loss = 12184.433723\n",
            "Epoch 5984: train loss = 4.075249, test loss = 12184.412309\n",
            "Epoch 5985: train loss = 4.075227, test loss = 12184.385061\n",
            "Epoch 5986: train loss = 4.075229, test loss = 12184.353198\n",
            "Epoch 5987: train loss = 4.075224, test loss = 12184.333075\n",
            "Epoch 5988: train loss = 4.075202, test loss = 12184.306734\n",
            "Epoch 5989: train loss = 4.075210, test loss = 12184.274124\n",
            "Epoch 5990: train loss = 4.075199, test loss = 12184.254930\n",
            "Epoch 5991: train loss = 4.075177, test loss = 12184.238547\n",
            "Epoch 5992: train loss = 4.075175, test loss = 12184.214171\n",
            "Epoch 5993: train loss = 4.075174, test loss = 12184.183312\n",
            "Epoch 5994: train loss = 4.075171, test loss = 12184.163325\n",
            "Epoch 5995: train loss = 4.075149, test loss = 12184.137351\n",
            "Epoch 5996: train loss = 4.075156, test loss = 12184.104340\n",
            "Epoch 5997: train loss = 4.075146, test loss = 12184.084972\n",
            "Epoch 5998: train loss = 4.075124, test loss = 12184.058989\n",
            "Epoch 5999: train loss = 4.075137, test loss = 12184.024897\n",
            "Epoch 6000: train loss = 4.075122, test loss = 12184.007237\n",
            "Epoch 6001: train loss = 4.075100, test loss = 12183.991004\n",
            "Epoch 6002: train loss = 4.075097, test loss = 12183.966992\n",
            "Epoch 6003: train loss = 4.075101, test loss = 12183.934868\n",
            "Epoch 6004: train loss = 4.075094, test loss = 12183.915604\n",
            "Epoch 6005: train loss = 4.075071, test loss = 12183.889790\n",
            "Epoch 6006: train loss = 4.075083, test loss = 12183.856094\n",
            "Epoch 6007: train loss = 4.075069, test loss = 12183.837477\n",
            "Epoch 6008: train loss = 4.075046, test loss = 12183.811916\n",
            "Epoch 6009: train loss = 4.075064, test loss = 12183.776648\n",
            "Epoch 6010: train loss = 4.075044, test loss = 12183.759234\n",
            "Epoch 6011: train loss = 4.075026, test loss = 12183.735204\n",
            "Epoch 6012: train loss = 4.075040, test loss = 12183.713781\n",
            "Epoch 6013: train loss = 4.075018, test loss = 12183.686056\n",
            "Epoch 6014: train loss = 4.075008, test loss = 12183.656164\n",
            "Epoch 6015: train loss = 4.075015, test loss = 12183.634184\n",
            "Epoch 6016: train loss = 4.074993, test loss = 12183.606682\n",
            "Epoch 6017: train loss = 4.074991, test loss = 12183.575685\n",
            "Epoch 6018: train loss = 4.074990, test loss = 12183.555207\n",
            "Epoch 6019: train loss = 4.074968, test loss = 12183.528199\n",
            "Epoch 6020: train loss = 4.074973, test loss = 12183.495676\n",
            "Epoch 6021: train loss = 4.074965, test loss = 12183.475971\n",
            "Epoch 6022: train loss = 4.074943, test loss = 12183.449819\n",
            "Epoch 6023: train loss = 4.074954, test loss = 12183.416639\n",
            "Epoch 6024: train loss = 4.074940, test loss = 12183.397796\n",
            "Epoch 6025: train loss = 4.074920, test loss = 12183.381421\n",
            "Epoch 6026: train loss = 4.074916, test loss = 12183.357478\n",
            "Epoch 6027: train loss = 4.074918, test loss = 12183.325926\n",
            "Epoch 6028: train loss = 4.074912, test loss = 12183.306430\n",
            "Epoch 6029: train loss = 4.074890, test loss = 12183.280598\n",
            "Epoch 6030: train loss = 4.074900, test loss = 12183.246970\n",
            "Epoch 6031: train loss = 4.074888, test loss = 12183.228143\n",
            "Epoch 6032: train loss = 4.074865, test loss = 12183.202305\n",
            "Epoch 6033: train loss = 4.074881, test loss = 12183.167681\n",
            "Epoch 6034: train loss = 4.074863, test loss = 12183.149877\n",
            "Epoch 6035: train loss = 4.074843, test loss = 12183.134516\n",
            "Epoch 6036: train loss = 4.074838, test loss = 12183.110433\n",
            "Epoch 6037: train loss = 4.074845, test loss = 12183.077768\n",
            "Epoch 6038: train loss = 4.074835, test loss = 12183.058866\n",
            "Epoch 6039: train loss = 4.074812, test loss = 12183.033127\n",
            "Epoch 6040: train loss = 4.074826, test loss = 12182.998976\n",
            "Epoch 6041: train loss = 4.074810, test loss = 12182.980909\n",
            "Epoch 6042: train loss = 4.074788, test loss = 12182.964954\n",
            "Epoch 6043: train loss = 4.074785, test loss = 12182.940947\n",
            "Epoch 6044: train loss = 4.074790, test loss = 12182.908302\n",
            "Epoch 6045: train loss = 4.074782, test loss = 12182.889413\n",
            "Epoch 6046: train loss = 4.074760, test loss = 12182.863955\n",
            "Epoch 6047: train loss = 4.074772, test loss = 12182.829206\n",
            "Epoch 6048: train loss = 4.074757, test loss = 12182.811029\n",
            "Epoch 6049: train loss = 4.074735, test loss = 12182.777627\n",
            "Epoch 6050: train loss = 4.074734, test loss = 12182.751543\n",
            "Epoch 6051: train loss = 4.074734, test loss = 12182.720432\n",
            "Epoch 6052: train loss = 4.074731, test loss = 12182.700120\n",
            "Epoch 6053: train loss = 4.074709, test loss = 12182.673083\n",
            "Epoch 6054: train loss = 4.074716, test loss = 12182.639934\n",
            "Epoch 6055: train loss = 4.074707, test loss = 12182.620333\n",
            "Epoch 6056: train loss = 4.074684, test loss = 12182.593959\n",
            "Epoch 6057: train loss = 4.074698, test loss = 12182.559962\n",
            "Epoch 6058: train loss = 4.074682, test loss = 12182.541846\n",
            "Epoch 6059: train loss = 4.074663, test loss = 12182.525370\n",
            "Epoch 6060: train loss = 4.074657, test loss = 12182.501200\n",
            "Epoch 6061: train loss = 4.074661, test loss = 12182.469353\n",
            "Epoch 6062: train loss = 4.074654, test loss = 12182.449931\n",
            "Epoch 6063: train loss = 4.074631, test loss = 12182.424287\n",
            "Epoch 6064: train loss = 4.074643, test loss = 12182.390227\n",
            "Epoch 6065: train loss = 4.074629, test loss = 12182.371503\n",
            "Epoch 6066: train loss = 4.074608, test loss = 12182.355463\n",
            "Epoch 6067: train loss = 4.074604, test loss = 12182.331250\n",
            "Epoch 6068: train loss = 4.074607, test loss = 12182.299600\n",
            "Epoch 6069: train loss = 4.074601, test loss = 12182.280490\n",
            "Epoch 6070: train loss = 4.074579, test loss = 12182.254106\n",
            "Epoch 6071: train loss = 4.074589, test loss = 12182.220203\n",
            "Epoch 6072: train loss = 4.074576, test loss = 12182.201643\n",
            "Epoch 6073: train loss = 4.074554, test loss = 12182.175946\n",
            "Epoch 6074: train loss = 4.074570, test loss = 12182.140929\n",
            "Epoch 6075: train loss = 4.074552, test loss = 12182.123813\n",
            "Epoch 6076: train loss = 4.074532, test loss = 12182.099629\n",
            "Epoch 6077: train loss = 4.074548, test loss = 12182.077550\n",
            "Epoch 6078: train loss = 4.074525, test loss = 12182.049744\n",
            "Epoch 6079: train loss = 4.074515, test loss = 12182.020434\n",
            "Epoch 6080: train loss = 4.074523, test loss = 12181.998064\n",
            "Epoch 6081: train loss = 4.074500, test loss = 12181.971022\n",
            "Epoch 6082: train loss = 4.074497, test loss = 12181.940025\n",
            "Epoch 6083: train loss = 4.074498, test loss = 12181.918719\n",
            "Epoch 6084: train loss = 4.074476, test loss = 12181.891821\n",
            "Epoch 6085: train loss = 4.074479, test loss = 12181.859709\n",
            "Epoch 6086: train loss = 4.074473, test loss = 12181.840393\n",
            "Epoch 6087: train loss = 4.074451, test loss = 12181.813706\n",
            "Epoch 6088: train loss = 4.074461, test loss = 12181.780401\n",
            "Epoch 6089: train loss = 4.074448, test loss = 12181.761478\n",
            "Epoch 6090: train loss = 4.074427, test loss = 12181.745232\n",
            "Epoch 6091: train loss = 4.074423, test loss = 12181.721165\n",
            "Epoch 6092: train loss = 4.074425, test loss = 12181.690399\n",
            "Epoch 6093: train loss = 4.074420, test loss = 12181.670526\n",
            "Epoch 6094: train loss = 4.074398, test loss = 12181.644015\n",
            "Epoch 6095: train loss = 4.074406, test loss = 12181.610781\n",
            "Epoch 6096: train loss = 4.074395, test loss = 12181.591937\n",
            "Epoch 6097: train loss = 4.074373, test loss = 12181.566134\n",
            "Epoch 6098: train loss = 4.074388, test loss = 12181.532120\n",
            "Epoch 6099: train loss = 4.074371, test loss = 12181.514119\n",
            "Epoch 6100: train loss = 4.074351, test loss = 12181.497865\n",
            "Epoch 6101: train loss = 4.074346, test loss = 12181.473985\n",
            "Epoch 6102: train loss = 4.074352, test loss = 12181.441712\n",
            "Epoch 6103: train loss = 4.074343, test loss = 12181.422840\n",
            "Epoch 6104: train loss = 4.074320, test loss = 12181.397303\n",
            "Epoch 6105: train loss = 4.074333, test loss = 12181.362839\n",
            "Epoch 6106: train loss = 4.074318, test loss = 12181.344691\n",
            "Epoch 6107: train loss = 4.074296, test loss = 12181.328746\n",
            "Epoch 6108: train loss = 4.074293, test loss = 12181.304811\n",
            "Epoch 6109: train loss = 4.074297, test loss = 12181.272850\n",
            "Epoch 6110: train loss = 4.074290, test loss = 12181.253418\n",
            "Epoch 6111: train loss = 4.074268, test loss = 12181.227360\n",
            "Epoch 6112: train loss = 4.074279, test loss = 12181.193198\n",
            "Epoch 6113: train loss = 4.074265, test loss = 12181.174878\n",
            "Epoch 6114: train loss = 4.074243, test loss = 12181.149467\n",
            "Epoch 6115: train loss = 4.074260, test loss = 12181.114439\n",
            "Epoch 6116: train loss = 4.074241, test loss = 12181.096899\n",
            "Epoch 6117: train loss = 4.074222, test loss = 12181.072587\n",
            "Epoch 6118: train loss = 4.074237, test loss = 12181.050825\n",
            "Epoch 6119: train loss = 4.074214, test loss = 12181.023237\n",
            "Epoch 6120: train loss = 4.074205, test loss = 12180.993613\n",
            "Epoch 6121: train loss = 4.074212, test loss = 12180.971957\n",
            "Epoch 6122: train loss = 4.074189, test loss = 12180.944256\n",
            "Epoch 6123: train loss = 4.074187, test loss = 12180.913014\n",
            "Epoch 6124: train loss = 4.074187, test loss = 12180.892187\n",
            "Epoch 6125: train loss = 4.074165, test loss = 12180.865331\n",
            "Epoch 6126: train loss = 4.074169, test loss = 12180.833035\n",
            "Epoch 6127: train loss = 4.074162, test loss = 12180.813759\n",
            "Epoch 6128: train loss = 4.074140, test loss = 12180.787362\n",
            "Epoch 6129: train loss = 4.074151, test loss = 12180.753545\n",
            "Epoch 6130: train loss = 4.074137, test loss = 12180.735023\n",
            "Epoch 6131: train loss = 4.074116, test loss = 12180.718877\n",
            "Epoch 6132: train loss = 4.074113, test loss = 12180.695268\n",
            "Epoch 6133: train loss = 4.074115, test loss = 12180.663521\n",
            "Epoch 6134: train loss = 4.074110, test loss = 12180.643763\n",
            "Epoch 6135: train loss = 4.074087, test loss = 12180.617673\n",
            "Epoch 6136: train loss = 4.074096, test loss = 12180.584032\n",
            "Epoch 6137: train loss = 4.074085, test loss = 12180.565434\n",
            "Epoch 6138: train loss = 4.074062, test loss = 12180.540078\n",
            "Epoch 6139: train loss = 4.074078, test loss = 12180.505134\n",
            "Epoch 6140: train loss = 4.074060, test loss = 12180.487322\n",
            "Epoch 6141: train loss = 4.074040, test loss = 12180.463662\n",
            "Epoch 6142: train loss = 4.074056, test loss = 12180.441352\n",
            "Epoch 6143: train loss = 4.074034, test loss = 12180.413765\n",
            "Epoch 6144: train loss = 4.074023, test loss = 12180.384910\n",
            "Epoch 6145: train loss = 4.074031, test loss = 12180.362332\n",
            "Epoch 6146: train loss = 4.074009, test loss = 12180.334586\n",
            "Epoch 6147: train loss = 4.074005, test loss = 12180.304065\n",
            "Epoch 6148: train loss = 4.074006, test loss = 12180.282759\n",
            "Epoch 6149: train loss = 4.073984, test loss = 12180.256320\n",
            "Epoch 6150: train loss = 4.073987, test loss = 12180.224170\n",
            "Epoch 6151: train loss = 4.073982, test loss = 12180.204087\n",
            "Epoch 6152: train loss = 4.073959, test loss = 12180.177729\n",
            "Epoch 6153: train loss = 4.073969, test loss = 12180.144555\n",
            "Epoch 6154: train loss = 4.073957, test loss = 12180.125719\n",
            "Epoch 6155: train loss = 4.073936, test loss = 12180.109805\n",
            "Epoch 6156: train loss = 4.073932, test loss = 12180.085577\n",
            "Epoch 6157: train loss = 4.073933, test loss = 12180.054449\n",
            "Epoch 6158: train loss = 4.073929, test loss = 12180.034570\n",
            "Epoch 6159: train loss = 4.073906, test loss = 12180.008174\n",
            "Epoch 6160: train loss = 4.073914, test loss = 12179.975300\n",
            "Epoch 6161: train loss = 4.073904, test loss = 12179.956746\n",
            "Epoch 6162: train loss = 4.073881, test loss = 12179.930542\n",
            "Epoch 6163: train loss = 4.073896, test loss = 12179.896244\n",
            "Epoch 6164: train loss = 4.073879, test loss = 12179.878164\n",
            "Epoch 6165: train loss = 4.073859, test loss = 12179.862243\n",
            "Epoch 6166: train loss = 4.073854, test loss = 12179.838355\n",
            "Epoch 6167: train loss = 4.073860, test loss = 12179.806739\n",
            "Epoch 6168: train loss = 4.073851, test loss = 12179.787372\n",
            "Epoch 6169: train loss = 4.073829, test loss = 12179.761387\n",
            "Epoch 6170: train loss = 4.073841, test loss = 12179.727307\n",
            "Epoch 6171: train loss = 4.073826, test loss = 12179.709006\n",
            "Epoch 6172: train loss = 4.073804, test loss = 12179.693664\n",
            "Epoch 6173: train loss = 4.073802, test loss = 12179.669269\n",
            "Epoch 6174: train loss = 4.073805, test loss = 12179.637196\n",
            "Epoch 6175: train loss = 4.073799, test loss = 12179.617806\n",
            "Epoch 6176: train loss = 4.073776, test loss = 12179.591811\n",
            "Epoch 6177: train loss = 4.073787, test loss = 12179.557773\n",
            "Epoch 6178: train loss = 4.073774, test loss = 12179.539914\n",
            "Epoch 6179: train loss = 4.073751, test loss = 12179.514121\n",
            "Epoch 6180: train loss = 4.073769, test loss = 12179.478691\n",
            "Epoch 6181: train loss = 4.073749, test loss = 12179.461384\n",
            "Epoch 6182: train loss = 4.073730, test loss = 12179.437167\n",
            "Epoch 6183: train loss = 4.073745, test loss = 12179.415475\n",
            "Epoch 6184: train loss = 4.073723, test loss = 12179.388342\n",
            "Epoch 6185: train loss = 4.073713, test loss = 12179.358454\n",
            "Epoch 6186: train loss = 4.073721, test loss = 12179.336206\n",
            "Epoch 6187: train loss = 4.073698, test loss = 12179.308839\n",
            "Epoch 6188: train loss = 4.073695, test loss = 12179.277747\n",
            "Epoch 6189: train loss = 4.073696, test loss = 12179.256781\n",
            "Epoch 6190: train loss = 4.073673, test loss = 12179.230479\n",
            "Epoch 6191: train loss = 4.073678, test loss = 12179.197897\n",
            "Epoch 6192: train loss = 4.073671, test loss = 12179.178194\n",
            "Epoch 6193: train loss = 4.073648, test loss = 12179.151832\n",
            "Epoch 6194: train loss = 4.073659, test loss = 12179.118410\n",
            "Epoch 6195: train loss = 4.073646, test loss = 12179.100122\n",
            "Epoch 6196: train loss = 4.073624, test loss = 12179.083831\n",
            "Epoch 6197: train loss = 4.073621, test loss = 12179.059594\n",
            "Epoch 6198: train loss = 4.073623, test loss = 12179.028239\n",
            "Epoch 6199: train loss = 4.073618, test loss = 12179.008497\n",
            "Epoch 6200: train loss = 4.073596, test loss = 12178.982343\n",
            "Epoch 6201: train loss = 4.073605, test loss = 12178.949368\n",
            "Epoch 6202: train loss = 4.073594, test loss = 12178.930406\n",
            "Epoch 6203: train loss = 4.073571, test loss = 12178.904581\n",
            "Epoch 6204: train loss = 4.073587, test loss = 12178.869872\n",
            "Epoch 6205: train loss = 4.073569, test loss = 12178.852158\n",
            "Epoch 6206: train loss = 4.073548, test loss = 12178.836263\n",
            "Epoch 6207: train loss = 4.073544, test loss = 12178.813046\n",
            "Epoch 6208: train loss = 4.073550, test loss = 12178.780128\n",
            "Epoch 6209: train loss = 4.073541, test loss = 12178.761259\n",
            "Epoch 6210: train loss = 4.073518, test loss = 12178.735322\n",
            "Epoch 6211: train loss = 4.073532, test loss = 12178.700915\n",
            "Epoch 6212: train loss = 4.073516, test loss = 12178.683436\n",
            "Epoch 6213: train loss = 4.073494, test loss = 12178.649766\n",
            "Epoch 6214: train loss = 4.073493, test loss = 12178.623814\n",
            "Epoch 6215: train loss = 4.073494, test loss = 12178.592407\n",
            "Epoch 6216: train loss = 4.073491, test loss = 12178.571928\n",
            "Epoch 6217: train loss = 4.073468, test loss = 12178.544989\n",
            "Epoch 6218: train loss = 4.073476, test loss = 12178.512495\n",
            "Epoch 6219: train loss = 4.073466, test loss = 12178.492652\n",
            "Epoch 6220: train loss = 4.073444, test loss = 12178.475993\n",
            "Epoch 6221: train loss = 4.073441, test loss = 12178.451608\n",
            "Epoch 6222: train loss = 4.073440, test loss = 12178.420729\n",
            "Epoch 6223: train loss = 4.073438, test loss = 12178.400593\n",
            "Epoch 6224: train loss = 4.073416, test loss = 12178.374429\n",
            "Epoch 6225: train loss = 4.073422, test loss = 12178.341349\n",
            "Epoch 6226: train loss = 4.073413, test loss = 12178.321939\n",
            "Epoch 6227: train loss = 4.073391, test loss = 12178.295869\n",
            "Epoch 6228: train loss = 4.073404, test loss = 12178.261833\n",
            "Epoch 6229: train loss = 4.073388, test loss = 12178.243667\n",
            "Epoch 6230: train loss = 4.073368, test loss = 12178.227867\n",
            "Epoch 6231: train loss = 4.073364, test loss = 12178.203698\n",
            "Epoch 6232: train loss = 4.073368, test loss = 12178.171756\n",
            "Epoch 6233: train loss = 4.073361, test loss = 12178.152469\n",
            "Epoch 6234: train loss = 4.073338, test loss = 12178.126327\n",
            "Epoch 6235: train loss = 4.073350, test loss = 12178.092657\n",
            "Epoch 6236: train loss = 4.073336, test loss = 12178.074563\n",
            "Epoch 6237: train loss = 4.073313, test loss = 12178.058371\n",
            "Epoch 6238: train loss = 4.073311, test loss = 12178.034221\n",
            "Epoch 6239: train loss = 4.073314, test loss = 12178.002349\n",
            "Epoch 6240: train loss = 4.073308, test loss = 12177.982824\n",
            "Epoch 6241: train loss = 4.073286, test loss = 12177.957244\n",
            "Epoch 6242: train loss = 4.073296, test loss = 12177.923253\n",
            "Epoch 6243: train loss = 4.073284, test loss = 12177.904510\n",
            "Epoch 6244: train loss = 4.073261, test loss = 12177.878932\n",
            "Epoch 6245: train loss = 4.073277, test loss = 12177.843877\n",
            "Epoch 6246: train loss = 4.073259, test loss = 12177.826284\n",
            "Epoch 6247: train loss = 4.073239, test loss = 12177.802862\n",
            "Epoch 6248: train loss = 4.073255, test loss = 12177.780661\n",
            "Epoch 6249: train loss = 4.073233, test loss = 12177.752855\n",
            "Epoch 6250: train loss = 4.073222, test loss = 12177.723511\n",
            "Epoch 6251: train loss = 4.073230, test loss = 12177.701206\n",
            "Epoch 6252: train loss = 4.073208, test loss = 12177.673649\n",
            "Epoch 6253: train loss = 4.073204, test loss = 12177.643286\n",
            "Epoch 6254: train loss = 4.073205, test loss = 12177.622016\n",
            "Epoch 6255: train loss = 4.073183, test loss = 12177.595009\n",
            "Epoch 6256: train loss = 4.073186, test loss = 12177.563024\n",
            "Epoch 6257: train loss = 4.073181, test loss = 12177.543026\n",
            "Epoch 6258: train loss = 4.073158, test loss = 12177.517285\n",
            "Epoch 6259: train loss = 4.073168, test loss = 12177.483661\n",
            "Epoch 6260: train loss = 4.073156, test loss = 12177.464804\n",
            "Epoch 6261: train loss = 4.073134, test loss = 12177.448574\n",
            "Epoch 6262: train loss = 4.073131, test loss = 12177.424593\n",
            "Epoch 6263: train loss = 4.073132, test loss = 12177.393286\n",
            "Epoch 6264: train loss = 4.073128, test loss = 12177.374020\n",
            "Epoch 6265: train loss = 4.073106, test loss = 12177.347485\n",
            "Epoch 6266: train loss = 4.073114, test loss = 12177.314245\n",
            "Epoch 6267: train loss = 4.073103, test loss = 12177.295340\n",
            "Epoch 6268: train loss = 4.073081, test loss = 12177.269492\n",
            "Epoch 6269: train loss = 4.073096, test loss = 12177.235120\n",
            "Epoch 6270: train loss = 4.073078, test loss = 12177.217617\n",
            "Epoch 6271: train loss = 4.073058, test loss = 12177.201636\n",
            "Epoch 6272: train loss = 4.073054, test loss = 12177.177636\n",
            "Epoch 6273: train loss = 4.073059, test loss = 12177.145246\n",
            "Epoch 6274: train loss = 4.073051, test loss = 12177.126235\n",
            "Epoch 6275: train loss = 4.073028, test loss = 12177.100470\n",
            "Epoch 6276: train loss = 4.073041, test loss = 12177.066645\n",
            "Epoch 6277: train loss = 4.073026, test loss = 12177.048237\n",
            "Epoch 6278: train loss = 4.073003, test loss = 12177.022739\n",
            "Epoch 6279: train loss = 4.073023, test loss = 12176.987150\n",
            "Epoch 6280: train loss = 4.073001, test loss = 12176.970183\n",
            "Epoch 6281: train loss = 4.072984, test loss = 12176.946165\n",
            "Epoch 6282: train loss = 4.072998, test loss = 12176.924455\n",
            "Epoch 6283: train loss = 4.072975, test loss = 12176.896874\n",
            "Epoch 6284: train loss = 4.072967, test loss = 12176.866929\n",
            "Epoch 6285: train loss = 4.072973, test loss = 12176.845190\n",
            "Epoch 6286: train loss = 4.072950, test loss = 12176.817798\n",
            "Epoch 6287: train loss = 4.072950, test loss = 12176.786910\n",
            "Epoch 6288: train loss = 4.072948, test loss = 12176.765941\n",
            "Epoch 6289: train loss = 4.072926, test loss = 12176.739325\n",
            "Epoch 6290: train loss = 4.072932, test loss = 12176.706589\n",
            "Epoch 6291: train loss = 4.072923, test loss = 12176.687136\n",
            "Epoch 6292: train loss = 4.072901, test loss = 12176.661009\n",
            "Epoch 6293: train loss = 4.072914, test loss = 12176.627726\n",
            "Epoch 6294: train loss = 4.072898, test loss = 12176.609088\n",
            "Epoch 6295: train loss = 4.072878, test loss = 12176.592785\n",
            "Epoch 6296: train loss = 4.072874, test loss = 12176.568851\n",
            "Epoch 6297: train loss = 4.072877, test loss = 12176.537095\n",
            "Epoch 6298: train loss = 4.072871, test loss = 12176.517843\n",
            "Epoch 6299: train loss = 4.072848, test loss = 12176.492140\n",
            "Epoch 6300: train loss = 4.072859, test loss = 12176.458272\n",
            "Epoch 6301: train loss = 4.072846, test loss = 12176.439552\n",
            "Epoch 6302: train loss = 4.072823, test loss = 12176.423700\n",
            "Epoch 6303: train loss = 4.072821, test loss = 12176.399449\n",
            "Epoch 6304: train loss = 4.072823, test loss = 12176.368372\n",
            "Epoch 6305: train loss = 4.072818, test loss = 12176.348459\n",
            "Epoch 6306: train loss = 4.072796, test loss = 12176.322271\n",
            "Epoch 6307: train loss = 4.072805, test loss = 12176.288581\n",
            "Epoch 6308: train loss = 4.072794, test loss = 12176.269967\n",
            "Epoch 6309: train loss = 4.072771, test loss = 12176.244353\n",
            "Epoch 6310: train loss = 4.072787, test loss = 12176.209924\n",
            "Epoch 6311: train loss = 4.072769, test loss = 12176.192074\n",
            "Epoch 6312: train loss = 4.072748, test loss = 12176.168161\n",
            "Epoch 6313: train loss = 4.072765, test loss = 12176.146097\n",
            "Epoch 6314: train loss = 4.072743, test loss = 12176.118321\n",
            "Epoch 6315: train loss = 4.072731, test loss = 12176.089103\n",
            "Epoch 6316: train loss = 4.072740, test loss = 12176.067186\n",
            "Epoch 6317: train loss = 4.072718, test loss = 12176.039443\n",
            "Epoch 6318: train loss = 4.072714, test loss = 12176.008667\n",
            "Epoch 6319: train loss = 4.072716, test loss = 12175.987445\n",
            "Epoch 6320: train loss = 4.072693, test loss = 12175.960577\n",
            "Epoch 6321: train loss = 4.072696, test loss = 12175.928611\n",
            "Epoch 6322: train loss = 4.072691, test loss = 12175.909210\n",
            "Epoch 6323: train loss = 4.072668, test loss = 12175.882581\n",
            "Epoch 6324: train loss = 4.072678, test loss = 12175.849397\n",
            "Epoch 6325: train loss = 4.072666, test loss = 12175.830390\n",
            "Epoch 6326: train loss = 4.072644, test loss = 12175.814343\n",
            "Epoch 6327: train loss = 4.072641, test loss = 12175.790652\n",
            "Epoch 6328: train loss = 4.072642, test loss = 12175.759273\n",
            "Epoch 6329: train loss = 4.072638, test loss = 12175.739410\n",
            "Epoch 6330: train loss = 4.072616, test loss = 12175.713002\n",
            "Epoch 6331: train loss = 4.072624, test loss = 12175.680102\n",
            "Epoch 6332: train loss = 4.072614, test loss = 12175.661012\n",
            "Epoch 6333: train loss = 4.072591, test loss = 12175.635712\n",
            "Epoch 6334: train loss = 4.072606, test loss = 12175.601110\n",
            "Epoch 6335: train loss = 4.072589, test loss = 12175.583083\n",
            "Epoch 6336: train loss = 4.072568, test loss = 12175.567239\n",
            "Epoch 6337: train loss = 4.072564, test loss = 12175.543299\n",
            "Epoch 6338: train loss = 4.072569, test loss = 12175.511129\n",
            "Epoch 6339: train loss = 4.072561, test loss = 12175.492548\n",
            "Epoch 6340: train loss = 4.072539, test loss = 12175.466516\n",
            "Epoch 6341: train loss = 4.072551, test loss = 12175.432145\n",
            "Epoch 6342: train loss = 4.072536, test loss = 12175.413982\n",
            "Epoch 6343: train loss = 4.072514, test loss = 12175.388472\n",
            "Epoch 6344: train loss = 4.072533, test loss = 12175.353597\n",
            "Epoch 6345: train loss = 4.072512, test loss = 12175.336193\n",
            "Epoch 6346: train loss = 4.072494, test loss = 12175.311806\n",
            "Epoch 6347: train loss = 4.072508, test loss = 12175.290250\n",
            "Epoch 6348: train loss = 4.072486, test loss = 12175.262698\n",
            "Epoch 6349: train loss = 4.072477, test loss = 12175.232830\n",
            "Epoch 6350: train loss = 4.072483, test loss = 12175.211496\n",
            "Epoch 6351: train loss = 4.072461, test loss = 12175.183937\n",
            "Epoch 6352: train loss = 4.072460, test loss = 12175.152497\n",
            "Epoch 6353: train loss = 4.072459, test loss = 12175.131914\n",
            "Epoch 6354: train loss = 4.072436, test loss = 12175.105075\n",
            "Epoch 6355: train loss = 4.072442, test loss = 12175.072581\n",
            "Epoch 6356: train loss = 4.072434, test loss = 12175.053573\n",
            "Epoch 6357: train loss = 4.072411, test loss = 12175.027214\n",
            "Epoch 6358: train loss = 4.072424, test loss = 12174.993373\n",
            "Epoch 6359: train loss = 4.072409, test loss = 12174.974964\n",
            "Epoch 6360: train loss = 4.072389, test loss = 12174.958708\n",
            "Epoch 6361: train loss = 4.072384, test loss = 12174.934715\n",
            "Epoch 6362: train loss = 4.072387, test loss = 12174.903696\n",
            "Epoch 6363: train loss = 4.072381, test loss = 12174.884068\n",
            "Epoch 6364: train loss = 4.072359, test loss = 12174.857758\n",
            "Epoch 6365: train loss = 4.072369, test loss = 12174.824322\n",
            "Epoch 6366: train loss = 4.072357, test loss = 12174.805587\n",
            "Epoch 6367: train loss = 4.072334, test loss = 12174.789649\n",
            "Epoch 6368: train loss = 4.072332, test loss = 12174.765976\n",
            "Epoch 6369: train loss = 4.072333, test loss = 12174.734240\n",
            "Epoch 6370: train loss = 4.072329, test loss = 12174.714492\n",
            "Epoch 6371: train loss = 4.072306, test loss = 12174.688307\n",
            "Epoch 6372: train loss = 4.072315, test loss = 12174.654887\n",
            "Epoch 6373: train loss = 4.072304, test loss = 12174.636572\n",
            "Epoch 6374: train loss = 4.072282, test loss = 12174.610711\n",
            "Epoch 6375: train loss = 4.072297, test loss = 12174.575812\n",
            "Epoch 6376: train loss = 4.072280, test loss = 12174.557993\n",
            "Epoch 6377: train loss = 4.072259, test loss = 12174.534405\n",
            "Epoch 6378: train loss = 4.072276, test loss = 12174.512217\n",
            "Epoch 6379: train loss = 4.072253, test loss = 12174.484903\n",
            "Epoch 6380: train loss = 4.072242, test loss = 12174.455686\n",
            "Epoch 6381: train loss = 4.072251, test loss = 12174.433057\n",
            "Epoch 6382: train loss = 4.072229, test loss = 12174.405493\n",
            "Epoch 6383: train loss = 4.072224, test loss = 12174.374874\n",
            "Epoch 6384: train loss = 4.072226, test loss = 12174.353711\n",
            "Epoch 6385: train loss = 4.072204, test loss = 12174.327165\n",
            "Epoch 6386: train loss = 4.072206, test loss = 12174.295256\n",
            "Epoch 6387: train loss = 4.072202, test loss = 12174.275042\n",
            "Epoch 6388: train loss = 4.072179, test loss = 12174.248698\n",
            "Epoch 6389: train loss = 4.072188, test loss = 12174.215610\n",
            "Epoch 6390: train loss = 4.072177, test loss = 12174.197201\n",
            "Epoch 6391: train loss = 4.072155, test loss = 12174.180811\n",
            "Epoch 6392: train loss = 4.072152, test loss = 12174.156446\n",
            "Epoch 6393: train loss = 4.072152, test loss = 12174.125537\n",
            "Epoch 6394: train loss = 4.072149, test loss = 12174.105591\n",
            "Epoch 6395: train loss = 4.072127, test loss = 12174.079419\n",
            "Epoch 6396: train loss = 4.072134, test loss = 12174.046857\n",
            "Epoch 6397: train loss = 4.072125, test loss = 12174.027650\n",
            "Epoch 6398: train loss = 4.072102, test loss = 12174.001596\n",
            "Epoch 6399: train loss = 4.072116, test loss = 12173.967445\n",
            "Epoch 6400: train loss = 4.072100, test loss = 12173.949486\n",
            "Epoch 6401: train loss = 4.072079, test loss = 12173.933497\n",
            "Epoch 6402: train loss = 4.072075, test loss = 12173.910153\n",
            "Epoch 6403: train loss = 4.072080, test loss = 12173.877714\n",
            "Epoch 6404: train loss = 4.072072, test loss = 12173.858719\n",
            "Epoch 6405: train loss = 4.072050, test loss = 12173.832642\n",
            "Epoch 6406: train loss = 4.072062, test loss = 12173.798632\n",
            "Epoch 6407: train loss = 4.072047, test loss = 12173.780394\n",
            "Epoch 6408: train loss = 4.072025, test loss = 12173.755400\n",
            "Epoch 6409: train loss = 4.072044, test loss = 12173.719809\n",
            "Epoch 6410: train loss = 4.072023, test loss = 12173.702653\n",
            "Epoch 6411: train loss = 4.072005, test loss = 12173.678348\n",
            "Epoch 6412: train loss = 4.072019, test loss = 12173.656677\n",
            "Epoch 6413: train loss = 4.071997, test loss = 12173.629592\n",
            "Epoch 6414: train loss = 4.071988, test loss = 12173.599713\n",
            "Epoch 6415: train loss = 4.071994, test loss = 12173.577680\n",
            "Epoch 6416: train loss = 4.071972, test loss = 12173.550194\n",
            "Epoch 6417: train loss = 4.071970, test loss = 12173.519133\n",
            "Epoch 6418: train loss = 4.071970, test loss = 12173.498287\n",
            "Epoch 6419: train loss = 4.071947, test loss = 12173.472140\n",
            "Epoch 6420: train loss = 4.071953, test loss = 12173.439426\n",
            "Epoch 6421: train loss = 4.071945, test loss = 12173.419784\n",
            "Epoch 6422: train loss = 4.071922, test loss = 12173.393509\n",
            "Epoch 6423: train loss = 4.071935, test loss = 12173.360003\n",
            "Epoch 6424: train loss = 4.071920, test loss = 12173.341541\n",
            "Epoch 6425: train loss = 4.071900, test loss = 12173.325704\n",
            "Epoch 6426: train loss = 4.071896, test loss = 12173.301561\n",
            "Epoch 6427: train loss = 4.071898, test loss = 12173.270008\n",
            "Epoch 6428: train loss = 4.071893, test loss = 12173.250583\n",
            "Epoch 6429: train loss = 4.071870, test loss = 12173.224331\n",
            "Epoch 6430: train loss = 4.071880, test loss = 12173.190947\n",
            "Epoch 6431: train loss = 4.071868, test loss = 12173.172701\n",
            "Epoch 6432: train loss = 4.071845, test loss = 12173.156545\n",
            "Epoch 6433: train loss = 4.071843, test loss = 12173.132295\n",
            "Epoch 6434: train loss = 4.071844, test loss = 12173.100800\n",
            "Epoch 6435: train loss = 4.071840, test loss = 12173.081176\n",
            "Epoch 6436: train loss = 4.071818, test loss = 12173.055350\n",
            "Epoch 6437: train loss = 4.071826, test loss = 12173.021925\n",
            "Epoch 6438: train loss = 4.071816, test loss = 12173.002922\n",
            "Epoch 6439: train loss = 4.071793, test loss = 12172.977173\n",
            "Epoch 6440: train loss = 4.071808, test loss = 12172.942500\n",
            "Epoch 6441: train loss = 4.071791, test loss = 12172.924836\n",
            "Epoch 6442: train loss = 4.071770, test loss = 12172.901713\n",
            "Epoch 6443: train loss = 4.071787, test loss = 12172.879100\n",
            "Epoch 6444: train loss = 4.071765, test loss = 12172.851380\n",
            "Epoch 6445: train loss = 4.071753, test loss = 12172.822204\n",
            "Epoch 6446: train loss = 4.071763, test loss = 12172.799876\n",
            "Epoch 6447: train loss = 4.071740, test loss = 12172.772190\n",
            "Epoch 6448: train loss = 4.071735, test loss = 12172.742233\n",
            "Epoch 6449: train loss = 4.071738, test loss = 12172.720646\n",
            "Epoch 6450: train loss = 4.071715, test loss = 12172.693648\n",
            "Epoch 6451: train loss = 4.071718, test loss = 12172.661978\n",
            "Epoch 6452: train loss = 4.071713, test loss = 12172.641798\n",
            "Epoch 6453: train loss = 4.071691, test loss = 12172.615499\n",
            "Epoch 6454: train loss = 4.071700, test loss = 12172.583004\n",
            "Epoch 6455: train loss = 4.071689, test loss = 12172.563882\n",
            "Epoch 6456: train loss = 4.071667, test loss = 12172.547487\n",
            "Epoch 6457: train loss = 4.071664, test loss = 12172.523322\n",
            "Epoch 6458: train loss = 4.071664, test loss = 12172.492454\n",
            "Epoch 6459: train loss = 4.071661, test loss = 12172.473003\n",
            "Epoch 6460: train loss = 4.071638, test loss = 12172.446458\n",
            "Epoch 6461: train loss = 4.071646, test loss = 12172.413473\n",
            "Epoch 6462: train loss = 4.071636, test loss = 12172.394476\n",
            "Epoch 6463: train loss = 4.071614, test loss = 12172.368477\n",
            "Epoch 6464: train loss = 4.071628, test loss = 12172.334335\n",
            "Epoch 6465: train loss = 4.071611, test loss = 12172.316824\n",
            "Epoch 6466: train loss = 4.071591, test loss = 12172.300685\n",
            "Epoch 6467: train loss = 4.071587, test loss = 12172.276661\n",
            "Epoch 6468: train loss = 4.071591, test loss = 12172.244774\n",
            "Epoch 6469: train loss = 4.071584, test loss = 12172.225550\n",
            "Epoch 6470: train loss = 4.071561, test loss = 12172.199567\n",
            "Epoch 6471: train loss = 4.071573, test loss = 12172.166152\n",
            "Epoch 6472: train loss = 4.071559, test loss = 12172.147676\n",
            "Epoch 6473: train loss = 4.071537, test loss = 12172.121985\n",
            "Epoch 6474: train loss = 4.071555, test loss = 12172.086867\n",
            "Epoch 6475: train loss = 4.071535, test loss = 12172.069525\n",
            "Epoch 6476: train loss = 4.071517, test loss = 12172.045821\n",
            "Epoch 6477: train loss = 4.071531, test loss = 12172.023885\n",
            "Epoch 6478: train loss = 4.071508, test loss = 12171.996394\n",
            "Epoch 6479: train loss = 4.071500, test loss = 12171.966613\n",
            "Epoch 6480: train loss = 4.071506, test loss = 12171.944673\n",
            "Epoch 6481: train loss = 4.071484, test loss = 12171.917391\n",
            "Epoch 6482: train loss = 4.071482, test loss = 12171.886662\n",
            "Epoch 6483: train loss = 4.071482, test loss = 12171.865735\n",
            "Epoch 6484: train loss = 4.071459, test loss = 12171.838765\n",
            "Epoch 6485: train loss = 4.071464, test loss = 12171.806417\n",
            "Epoch 6486: train loss = 4.071457, test loss = 12171.786902\n",
            "Epoch 6487: train loss = 4.071434, test loss = 12171.760643\n",
            "Epoch 6488: train loss = 4.071446, test loss = 12171.727695\n",
            "Epoch 6489: train loss = 4.071432, test loss = 12171.708790\n",
            "Epoch 6490: train loss = 4.071412, test loss = 12171.692513\n",
            "Epoch 6491: train loss = 4.071407, test loss = 12171.668471\n",
            "Epoch 6492: train loss = 4.071410, test loss = 12171.637195\n",
            "Epoch 6493: train loss = 4.071405, test loss = 12171.617705\n",
            "Epoch 6494: train loss = 4.071382, test loss = 12171.591941\n",
            "Epoch 6495: train loss = 4.071392, test loss = 12171.558491\n",
            "Epoch 6496: train loss = 4.071380, test loss = 12171.539585\n",
            "Epoch 6497: train loss = 4.071357, test loss = 12171.523615\n",
            "Epoch 6498: train loss = 4.071355, test loss = 12171.499414\n",
            "Epoch 6499: train loss = 4.071356, test loss = 12171.468553\n",
            "Epoch 6500: train loss = 4.071352, test loss = 12171.448547\n",
            "Epoch 6501: train loss = 4.071330, test loss = 12171.422356\n",
            "Epoch 6502: train loss = 4.071338, test loss = 12171.388947\n",
            "Epoch 6503: train loss = 4.071328, test loss = 12171.370181\n",
            "Epoch 6504: train loss = 4.071305, test loss = 12171.344360\n",
            "Epoch 6505: train loss = 4.071320, test loss = 12171.310385\n",
            "Epoch 6506: train loss = 4.071303, test loss = 12171.292372\n",
            "Epoch 6507: train loss = 4.071282, test loss = 12171.276457\n",
            "Epoch 6508: train loss = 4.071278, test loss = 12171.252673\n",
            "Epoch 6509: train loss = 4.071284, test loss = 12171.220065\n",
            "Epoch 6510: train loss = 4.071276, test loss = 12171.201356\n",
            "Epoch 6511: train loss = 4.071253, test loss = 12171.175869\n",
            "Epoch 6512: train loss = 4.071266, test loss = 12171.141299\n",
            "Epoch 6513: train loss = 4.071251, test loss = 12171.123127\n",
            "Epoch 6514: train loss = 4.071229, test loss = 12171.089788\n",
            "Epoch 6515: train loss = 4.071227, test loss = 12171.063846\n",
            "Epoch 6516: train loss = 4.071228, test loss = 12171.032798\n",
            "Epoch 6517: train loss = 4.071225, test loss = 12171.012523\n",
            "Epoch 6518: train loss = 4.071203, test loss = 12170.985486\n",
            "Epoch 6519: train loss = 4.071211, test loss = 12170.952397\n",
            "Epoch 6520: train loss = 4.071201, test loss = 12170.932875\n",
            "Epoch 6521: train loss = 4.071179, test loss = 12170.916418\n",
            "Epoch 6522: train loss = 4.071176, test loss = 12170.891932\n",
            "Epoch 6523: train loss = 4.071175, test loss = 12170.861723\n",
            "Epoch 6524: train loss = 4.071173, test loss = 12170.841098\n",
            "Epoch 6525: train loss = 4.071151, test loss = 12170.814624\n",
            "Epoch 6526: train loss = 4.071157, test loss = 12170.781793\n",
            "Epoch 6527: train loss = 4.071149, test loss = 12170.762446\n",
            "Epoch 6528: train loss = 4.071126, test loss = 12170.736762\n",
            "Epoch 6529: train loss = 4.071139, test loss = 12170.702697\n",
            "Epoch 6530: train loss = 4.071124, test loss = 12170.684295\n",
            "Epoch 6531: train loss = 4.071103, test loss = 12170.668152\n",
            "Epoch 6532: train loss = 4.071099, test loss = 12170.644294\n",
            "Epoch 6533: train loss = 4.071103, test loss = 12170.612415\n",
            "Epoch 6534: train loss = 4.071097, test loss = 12170.593692\n",
            "Epoch 6535: train loss = 4.071074, test loss = 12170.567340\n",
            "Epoch 6536: train loss = 4.071085, test loss = 12170.533500\n",
            "Epoch 6537: train loss = 4.071072, test loss = 12170.514936\n",
            "Epoch 6538: train loss = 4.071049, test loss = 12170.489377\n",
            "Epoch 6539: train loss = 4.071067, test loss = 12170.454465\n",
            "Epoch 6540: train loss = 4.071047, test loss = 12170.437385\n",
            "Epoch 6541: train loss = 4.071029, test loss = 12170.413261\n",
            "Epoch 6542: train loss = 4.071044, test loss = 12170.391212\n",
            "Epoch 6543: train loss = 4.071021, test loss = 12170.363749\n",
            "Epoch 6544: train loss = 4.071012, test loss = 12170.334185\n",
            "Epoch 6545: train loss = 4.071019, test loss = 12170.312535\n",
            "Epoch 6546: train loss = 4.070997, test loss = 12170.284801\n",
            "Epoch 6547: train loss = 4.070994, test loss = 12170.253854\n",
            "Epoch 6548: train loss = 4.070994, test loss = 12170.232889\n",
            "Epoch 6549: train loss = 4.070972, test loss = 12170.206036\n",
            "Epoch 6550: train loss = 4.070976, test loss = 12170.173999\n",
            "Epoch 6551: train loss = 4.070970, test loss = 12170.154596\n",
            "Epoch 6552: train loss = 4.070947, test loss = 12170.128302\n",
            "Epoch 6553: train loss = 4.070959, test loss = 12170.094774\n",
            "Epoch 6554: train loss = 4.070945, test loss = 12170.076070\n",
            "Epoch 6555: train loss = 4.070925, test loss = 12170.059728\n",
            "Epoch 6556: train loss = 4.070920, test loss = 12170.035866\n",
            "Epoch 6557: train loss = 4.070923, test loss = 12170.005090\n",
            "Epoch 6558: train loss = 4.070918, test loss = 12169.985321\n",
            "Epoch 6559: train loss = 4.070895, test loss = 12169.958964\n",
            "Epoch 6560: train loss = 4.070905, test loss = 12169.925769\n",
            "Epoch 6561: train loss = 4.070893, test loss = 12169.906877\n",
            "Epoch 6562: train loss = 4.070870, test loss = 12169.890930\n",
            "Epoch 6563: train loss = 4.070868, test loss = 12169.867263\n",
            "Epoch 6564: train loss = 4.070869, test loss = 12169.835760\n",
            "Epoch 6565: train loss = 4.070865, test loss = 12169.815913\n",
            "Epoch 6566: train loss = 4.070843, test loss = 12169.789596\n",
            "Epoch 6567: train loss = 4.070851, test loss = 12169.756596\n",
            "Epoch 6568: train loss = 4.070841, test loss = 12169.738026\n",
            "Epoch 6569: train loss = 4.070818, test loss = 12169.712062\n",
            "Epoch 6570: train loss = 4.070833, test loss = 12169.677503\n",
            "Epoch 6571: train loss = 4.070816, test loss = 12169.659615\n",
            "Epoch 6572: train loss = 4.070795, test loss = 12169.643887\n",
            "Epoch 6573: train loss = 4.070791, test loss = 12169.619988\n",
            "Epoch 6574: train loss = 4.070797, test loss = 12169.588146\n",
            "Epoch 6575: train loss = 4.070789, test loss = 12169.568876\n",
            "Epoch 6576: train loss = 4.070766, test loss = 12169.543079\n",
            "Epoch 6577: train loss = 4.070779, test loss = 12169.508684\n",
            "Epoch 6578: train loss = 4.070764, test loss = 12169.490633\n",
            "Epoch 6579: train loss = 4.070741, test loss = 12169.465137\n",
            "Epoch 6580: train loss = 4.070760, test loss = 12169.430230\n",
            "Epoch 6581: train loss = 4.070739, test loss = 12169.412908\n",
            "Epoch 6582: train loss = 4.070722, test loss = 12169.388422\n",
            "Epoch 6583: train loss = 4.070736, test loss = 12169.366925\n",
            "Epoch 6584: train loss = 4.070713, test loss = 12169.339466\n",
            "Epoch 6585: train loss = 4.070705, test loss = 12169.309719\n",
            "Epoch 6586: train loss = 4.070711, test loss = 12169.288297\n",
            "Epoch 6587: train loss = 4.070689, test loss = 12169.260789\n",
            "Epoch 6588: train loss = 4.070688, test loss = 12169.229275\n",
            "Epoch 6589: train loss = 4.070687, test loss = 12169.208634\n",
            "Epoch 6590: train loss = 4.070664, test loss = 12169.182033\n",
            "Epoch 6591: train loss = 4.070670, test loss = 12169.149876\n",
            "Epoch 6592: train loss = 4.070662, test loss = 12169.130261\n",
            "Epoch 6593: train loss = 4.070639, test loss = 12169.103993\n",
            "Epoch 6594: train loss = 4.070652, test loss = 12169.070166\n",
            "Epoch 6595: train loss = 4.070637, test loss = 12169.051799\n",
            "Epoch 6596: train loss = 4.070616, test loss = 12169.035854\n",
            "Epoch 6597: train loss = 4.070613, test loss = 12169.012258\n",
            "Epoch 6598: train loss = 4.070616, test loss = 12168.980509\n",
            "Epoch 6599: train loss = 4.070610, test loss = 12168.960884\n",
            "Epoch 6600: train loss = 4.070587, test loss = 12168.934753\n",
            "Epoch 6601: train loss = 4.070598, test loss = 12168.901207\n",
            "Epoch 6602: train loss = 4.070585, test loss = 12168.882710\n",
            "Epoch 6603: train loss = 4.070563, test loss = 12168.857503\n",
            "Epoch 6604: train loss = 4.070580, test loss = 12168.822551\n",
            "Epoch 6605: train loss = 4.070561, test loss = 12168.804795\n",
            "Epoch 6606: train loss = 4.070541, test loss = 12168.780909\n",
            "Epoch 6607: train loss = 4.070557, test loss = 12168.758975\n",
            "Epoch 6608: train loss = 4.070535, test loss = 12168.731425\n",
            "Epoch 6609: train loss = 4.070525, test loss = 12168.702510\n",
            "Epoch 6610: train loss = 4.070532, test loss = 12168.680128\n",
            "Epoch 6611: train loss = 4.070510, test loss = 12168.652568\n",
            "Epoch 6612: train loss = 4.070507, test loss = 12168.621711\n",
            "Epoch 6613: train loss = 4.070508, test loss = 12168.600843\n",
            "Epoch 6614: train loss = 4.070485, test loss = 12168.574328\n",
            "Epoch 6615: train loss = 4.070489, test loss = 12168.542074\n",
            "Epoch 6616: train loss = 4.070483, test loss = 12168.522142\n",
            "Epoch 6617: train loss = 4.070461, test loss = 12168.495920\n",
            "Epoch 6618: train loss = 4.070472, test loss = 12168.462676\n",
            "Epoch 6619: train loss = 4.070458, test loss = 12168.444025\n",
            "Epoch 6620: train loss = 4.070438, test loss = 12168.428148\n",
            "Epoch 6621: train loss = 4.070434, test loss = 12168.403857\n",
            "Epoch 6622: train loss = 4.070436, test loss = 12168.372801\n",
            "Epoch 6623: train loss = 4.070431, test loss = 12168.353058\n",
            "Epoch 6624: train loss = 4.070408, test loss = 12168.326792\n",
            "Epoch 6625: train loss = 4.070418, test loss = 12168.293884\n",
            "Epoch 6626: train loss = 4.070406, test loss = 12168.275338\n",
            "Epoch 6627: train loss = 4.070384, test loss = 12168.259158\n",
            "Epoch 6628: train loss = 4.070382, test loss = 12168.234762\n",
            "Epoch 6629: train loss = 4.070382, test loss = 12168.203759\n",
            "Epoch 6630: train loss = 4.070379, test loss = 12168.183864\n",
            "Epoch 6631: train loss = 4.070356, test loss = 12168.158155\n",
            "Epoch 6632: train loss = 4.070364, test loss = 12168.124801\n",
            "Epoch 6633: train loss = 4.070354, test loss = 12168.105739\n",
            "Epoch 6634: train loss = 4.070332, test loss = 12168.079833\n",
            "Epoch 6635: train loss = 4.070346, test loss = 12168.045647\n",
            "Epoch 6636: train loss = 4.070330, test loss = 12168.027713\n",
            "Epoch 6637: train loss = 4.070308, test loss = 12168.012368\n",
            "Epoch 6638: train loss = 4.070305, test loss = 12167.988283\n",
            "Epoch 6639: train loss = 4.070310, test loss = 12167.955901\n",
            "Epoch 6640: train loss = 4.070302, test loss = 12167.937022\n",
            "Epoch 6641: train loss = 4.070280, test loss = 12167.911000\n",
            "Epoch 6642: train loss = 4.070292, test loss = 12167.876940\n",
            "Epoch 6643: train loss = 4.070278, test loss = 12167.859151\n",
            "Epoch 6644: train loss = 4.070255, test loss = 12167.833543\n",
            "Epoch 6645: train loss = 4.070274, test loss = 12167.798131\n",
            "Epoch 6646: train loss = 4.070253, test loss = 12167.780834\n",
            "Epoch 6647: train loss = 4.070235, test loss = 12167.756738\n",
            "Epoch 6648: train loss = 4.070250, test loss = 12167.735035\n",
            "Epoch 6649: train loss = 4.070227, test loss = 12167.708213\n",
            "Epoch 6650: train loss = 4.070218, test loss = 12167.678081\n",
            "Epoch 6651: train loss = 4.070225, test loss = 12167.656175\n",
            "Epoch 6652: train loss = 4.070203, test loss = 12167.628733\n",
            "Epoch 6653: train loss = 4.070201, test loss = 12167.597576\n",
            "Epoch 6654: train loss = 4.070200, test loss = 12167.576849\n",
            "Epoch 6655: train loss = 4.070178, test loss = 12167.550736\n",
            "Epoch 6656: train loss = 4.070183, test loss = 12167.517978\n",
            "Epoch 6657: train loss = 4.070176, test loss = 12167.498405\n",
            "Epoch 6658: train loss = 4.070153, test loss = 12167.472165\n",
            "Epoch 6659: train loss = 4.070165, test loss = 12167.438604\n",
            "Epoch 6660: train loss = 4.070151, test loss = 12167.420591\n",
            "Epoch 6661: train loss = 4.070130, test loss = 12167.404239\n",
            "Epoch 6662: train loss = 4.070127, test loss = 12167.380206\n",
            "Epoch 6663: train loss = 4.070129, test loss = 12167.348596\n",
            "Epoch 6664: train loss = 4.070124, test loss = 12167.329308\n",
            "Epoch 6665: train loss = 4.070101, test loss = 12167.303102\n",
            "Epoch 6666: train loss = 4.070111, test loss = 12167.270123\n",
            "Epoch 6667: train loss = 4.070099, test loss = 12167.251186\n",
            "Epoch 6668: train loss = 4.070077, test loss = 12167.225516\n",
            "Epoch 6669: train loss = 4.070093, test loss = 12167.190788\n",
            "Epoch 6670: train loss = 4.070075, test loss = 12167.173100\n",
            "Epoch 6671: train loss = 4.070055, test loss = 12167.149513\n",
            "Epoch 6672: train loss = 4.070071, test loss = 12167.127797\n",
            "Epoch 6673: train loss = 4.070049, test loss = 12167.100065\n",
            "Epoch 6674: train loss = 4.070038, test loss = 12167.070712\n",
            "Epoch 6675: train loss = 4.070046, test loss = 12167.048419\n",
            "Epoch 6676: train loss = 4.070024, test loss = 12167.020833\n",
            "Epoch 6677: train loss = 4.070021, test loss = 12166.990260\n",
            "Epoch 6678: train loss = 4.070022, test loss = 12166.969687\n",
            "Epoch 6679: train loss = 4.069999, test loss = 12166.942487\n",
            "Epoch 6680: train loss = 4.070003, test loss = 12166.910593\n",
            "Epoch 6681: train loss = 4.069997, test loss = 12166.890603\n",
            "Epoch 6682: train loss = 4.069975, test loss = 12166.864446\n",
            "Epoch 6683: train loss = 4.069985, test loss = 12166.831733\n",
            "Epoch 6684: train loss = 4.069973, test loss = 12166.812725\n",
            "Epoch 6685: train loss = 4.069952, test loss = 12166.796238\n",
            "Epoch 6686: train loss = 4.069948, test loss = 12166.772266\n",
            "Epoch 6687: train loss = 4.069949, test loss = 12166.741386\n",
            "Epoch 6688: train loss = 4.069945, test loss = 12166.721573\n",
            "Epoch 6689: train loss = 4.069923, test loss = 12166.695833\n",
            "Epoch 6690: train loss = 4.069932, test loss = 12166.662560\n",
            "Epoch 6691: train loss = 4.069921, test loss = 12166.643695\n",
            "Epoch 6692: train loss = 4.069898, test loss = 12166.627500\n",
            "Epoch 6693: train loss = 4.069896, test loss = 12166.603330\n",
            "Epoch 6694: train loss = 4.069896, test loss = 12166.572346\n",
            "Epoch 6695: train loss = 4.069893, test loss = 12166.552978\n",
            "Epoch 6696: train loss = 4.069871, test loss = 12166.526454\n",
            "Epoch 6697: train loss = 4.069878, test loss = 12166.493372\n",
            "Epoch 6698: train loss = 4.069869, test loss = 12166.474390\n",
            "Epoch 6699: train loss = 4.069846, test loss = 12166.448461\n",
            "Epoch 6700: train loss = 4.069860, test loss = 12166.414909\n",
            "Epoch 6701: train loss = 4.069844, test loss = 12166.396572\n",
            "Epoch 6702: train loss = 4.069823, test loss = 12166.380710\n",
            "Epoch 6703: train loss = 4.069819, test loss = 12166.356713\n",
            "Epoch 6704: train loss = 4.069824, test loss = 12166.324648\n",
            "Epoch 6705: train loss = 4.069817, test loss = 12166.305566\n",
            "Epoch 6706: train loss = 4.069794, test loss = 12166.280239\n",
            "Epoch 6707: train loss = 4.069806, test loss = 12166.245859\n",
            "Epoch 6708: train loss = 4.069792, test loss = 12166.227637\n",
            "Epoch 6709: train loss = 4.069770, test loss = 12166.202046\n",
            "Epoch 6710: train loss = 4.069788, test loss = 12166.166846\n",
            "Epoch 6711: train loss = 4.069767, test loss = 12166.149662\n",
            "Epoch 6712: train loss = 4.069749, test loss = 12166.125963\n",
            "Epoch 6713: train loss = 4.069764, test loss = 12166.104073\n",
            "Epoch 6714: train loss = 4.069742, test loss = 12166.076469\n",
            "Epoch 6715: train loss = 4.069733, test loss = 12166.046926\n",
            "Epoch 6716: train loss = 4.069739, test loss = 12166.024875\n",
            "Epoch 6717: train loss = 4.069717, test loss = 12165.997590\n",
            "Epoch 6718: train loss = 4.069715, test loss = 12165.966893\n",
            "Epoch 6719: train loss = 4.069715, test loss = 12165.945928\n",
            "Epoch 6720: train loss = 4.069692, test loss = 12165.919140\n",
            "Epoch 6721: train loss = 4.069698, test loss = 12165.886686\n",
            "Epoch 6722: train loss = 4.069690, test loss = 12165.867257\n",
            "Epoch 6723: train loss = 4.069668, test loss = 12165.841460\n",
            "Epoch 6724: train loss = 4.069680, test loss = 12165.807618\n",
            "Epoch 6725: train loss = 4.069666, test loss = 12165.789094\n",
            "Epoch 6726: train loss = 4.069645, test loss = 12165.773007\n",
            "Epoch 6727: train loss = 4.069641, test loss = 12165.748956\n",
            "Epoch 6728: train loss = 4.069644, test loss = 12165.717680\n",
            "Epoch 6729: train loss = 4.069638, test loss = 12165.698570\n",
            "Epoch 6730: train loss = 4.069616, test loss = 12165.672148\n",
            "Epoch 6731: train loss = 4.069626, test loss = 12165.638696\n",
            "Epoch 6732: train loss = 4.069614, test loss = 12165.620098\n",
            "Epoch 6733: train loss = 4.069591, test loss = 12165.594339\n",
            "Epoch 6734: train loss = 4.069608, test loss = 12165.559838\n",
            "Epoch 6735: train loss = 4.069589, test loss = 12165.542594\n",
            "Epoch 6736: train loss = 4.069570, test loss = 12165.526457\n",
            "Epoch 6737: train loss = 4.069565, test loss = 12165.502752\n",
            "Epoch 6738: train loss = 4.069572, test loss = 12165.470167\n",
            "Epoch 6739: train loss = 4.069562, test loss = 12165.451439\n",
            "Epoch 6740: train loss = 4.069539, test loss = 12165.425750\n",
            "Epoch 6741: train loss = 4.069554, test loss = 12165.391734\n",
            "Epoch 6742: train loss = 4.069537, test loss = 12165.373606\n",
            "Epoch 6743: train loss = 4.069516, test loss = 12165.350081\n",
            "Epoch 6744: train loss = 4.069534, test loss = 12165.327572\n",
            "Epoch 6745: train loss = 4.069511, test loss = 12165.299813\n",
            "Epoch 6746: train loss = 4.069499, test loss = 12165.271327\n",
            "Epoch 6747: train loss = 4.069509, test loss = 12165.248593\n",
            "Epoch 6748: train loss = 4.069487, test loss = 12165.220792\n",
            "Epoch 6749: train loss = 4.069482, test loss = 12165.190505\n",
            "Epoch 6750: train loss = 4.069485, test loss = 12165.169077\n",
            "Epoch 6751: train loss = 4.069462, test loss = 12165.142076\n",
            "Epoch 6752: train loss = 4.069464, test loss = 12165.111011\n",
            "Epoch 6753: train loss = 4.069460, test loss = 12165.090666\n",
            "Epoch 6754: train loss = 4.069438, test loss = 12165.064115\n",
            "Epoch 6755: train loss = 4.069446, test loss = 12165.031353\n",
            "Epoch 6756: train loss = 4.069436, test loss = 12165.012252\n",
            "Epoch 6757: train loss = 4.069413, test loss = 12164.996237\n",
            "Epoch 6758: train loss = 4.069411, test loss = 12164.972406\n",
            "Epoch 6759: train loss = 4.069410, test loss = 12164.941490\n",
            "Epoch 6760: train loss = 4.069408, test loss = 12164.921331\n",
            "Epoch 6761: train loss = 4.069386, test loss = 12164.895017\n",
            "Epoch 6762: train loss = 4.069393, test loss = 12164.862333\n",
            "Epoch 6763: train loss = 4.069384, test loss = 12164.843589\n",
            "Epoch 6764: train loss = 4.069361, test loss = 12164.817592\n",
            "Epoch 6765: train loss = 4.069375, test loss = 12164.783351\n",
            "Epoch 6766: train loss = 4.069359, test loss = 12164.765212\n",
            "Epoch 6767: train loss = 4.069338, test loss = 12164.749454\n",
            "Epoch 6768: train loss = 4.069334, test loss = 12164.725622\n",
            "Epoch 6769: train loss = 4.069339, test loss = 12164.694086\n",
            "Epoch 6770: train loss = 4.069332, test loss = 12164.674832\n",
            "Epoch 6771: train loss = 4.069309, test loss = 12164.648679\n",
            "Epoch 6772: train loss = 4.069321, test loss = 12164.614831\n",
            "Epoch 6773: train loss = 4.069307, test loss = 12164.596467\n",
            "Epoch 6774: train loss = 4.069285, test loss = 12164.571035\n",
            "Epoch 6775: train loss = 4.069303, test loss = 12164.536291\n",
            "Epoch 6776: train loss = 4.069283, test loss = 12164.518940\n",
            "Epoch 6777: train loss = 4.069264, test loss = 12164.494702\n",
            "Epoch 6778: train loss = 4.069279, test loss = 12164.472954\n",
            "Epoch 6779: train loss = 4.069257, test loss = 12164.445467\n",
            "Epoch 6780: train loss = 4.069248, test loss = 12164.415946\n",
            "Epoch 6781: train loss = 4.069255, test loss = 12164.394441\n",
            "Epoch 6782: train loss = 4.069232, test loss = 12164.366745\n",
            "Epoch 6783: train loss = 4.069230, test loss = 12164.335712\n",
            "Epoch 6784: train loss = 4.069230, test loss = 12164.314788\n",
            "Epoch 6785: train loss = 4.069208, test loss = 12164.288189\n",
            "Epoch 6786: train loss = 4.069213, test loss = 12164.255918\n",
            "Epoch 6787: train loss = 4.069206, test loss = 12164.236757\n",
            "Epoch 6788: train loss = 4.069183, test loss = 12164.210285\n",
            "Epoch 6789: train loss = 4.069195, test loss = 12164.176850\n",
            "Epoch 6790: train loss = 4.069181, test loss = 12164.158259\n",
            "Epoch 6791: train loss = 4.069160, test loss = 12164.142070\n",
            "Epoch 6792: train loss = 4.069156, test loss = 12164.118606\n",
            "Epoch 6793: train loss = 4.069159, test loss = 12164.087016\n",
            "Epoch 6794: train loss = 4.069154, test loss = 12164.067493\n",
            "Epoch 6795: train loss = 4.069131, test loss = 12164.041217\n",
            "Epoch 6796: train loss = 4.069141, test loss = 12164.007995\n",
            "Epoch 6797: train loss = 4.069129, test loss = 12163.989230\n",
            "Epoch 6798: train loss = 4.069107, test loss = 12163.964052\n",
            "Epoch 6799: train loss = 4.069123, test loss = 12163.929330\n",
            "Epoch 6800: train loss = 4.069105, test loss = 12163.911446\n",
            "Epoch 6801: train loss = 4.069085, test loss = 12163.895609\n",
            "Epoch 6802: train loss = 4.069080, test loss = 12163.871875\n",
            "Epoch 6803: train loss = 4.069087, test loss = 12163.839593\n",
            "Epoch 6804: train loss = 4.069077, test loss = 12163.821203\n",
            "Epoch 6805: train loss = 4.069055, test loss = 12163.795241\n",
            "Epoch 6806: train loss = 4.069069, test loss = 12163.760694\n",
            "Epoch 6807: train loss = 4.069053, test loss = 12163.742808\n",
            "Epoch 6808: train loss = 4.069031, test loss = 12163.727094\n",
            "Epoch 6809: train loss = 4.069028, test loss = 12163.703297\n",
            "Epoch 6810: train loss = 4.069033, test loss = 12163.671264\n",
            "Epoch 6811: train loss = 4.069026, test loss = 12163.652104\n",
            "Epoch 6812: train loss = 4.069003, test loss = 12163.626053\n",
            "Epoch 6813: train loss = 4.069015, test loss = 12163.591828\n",
            "Epoch 6814: train loss = 4.069001, test loss = 12163.573782\n",
            "Epoch 6815: train loss = 4.068979, test loss = 12163.540778\n",
            "Epoch 6816: train loss = 4.068978, test loss = 12163.514691\n",
            "Epoch 6817: train loss = 4.068978, test loss = 12163.483443\n",
            "Epoch 6818: train loss = 4.068976, test loss = 12163.462853\n",
            "Epoch 6819: train loss = 4.068953, test loss = 12163.435891\n",
            "Epoch 6820: train loss = 4.068960, test loss = 12163.403160\n",
            "Epoch 6821: train loss = 4.068951, test loss = 12163.383948\n",
            "Epoch 6822: train loss = 4.068929, test loss = 12163.357545\n",
            "Epoch 6823: train loss = 4.068943, test loss = 12163.323562\n",
            "Epoch 6824: train loss = 4.068927, test loss = 12163.305011\n",
            "Epoch 6825: train loss = 4.068908, test loss = 12163.288796\n",
            "Epoch 6826: train loss = 4.068902, test loss = 12163.264853\n",
            "Epoch 6827: train loss = 4.068907, test loss = 12163.233752\n",
            "Epoch 6828: train loss = 4.068900, test loss = 12163.214067\n",
            "Epoch 6829: train loss = 4.068877, test loss = 12163.187941\n",
            "Epoch 6830: train loss = 4.068889, test loss = 12163.154142\n",
            "Epoch 6831: train loss = 4.068875, test loss = 12163.135721\n",
            "Epoch 6832: train loss = 4.068853, test loss = 12163.119818\n",
            "Epoch 6833: train loss = 4.068851, test loss = 12163.096176\n",
            "Epoch 6834: train loss = 4.068853, test loss = 12163.064293\n",
            "Epoch 6835: train loss = 4.068848, test loss = 12163.044671\n",
            "Epoch 6836: train loss = 4.068825, test loss = 12163.018657\n",
            "Epoch 6837: train loss = 4.068836, test loss = 12162.984977\n",
            "Epoch 6838: train loss = 4.068823, test loss = 12162.966907\n",
            "Epoch 6839: train loss = 4.068801, test loss = 12162.940937\n",
            "Epoch 6840: train loss = 4.068818, test loss = 12162.906094\n",
            "Epoch 6841: train loss = 4.068799, test loss = 12162.888535\n",
            "Epoch 6842: train loss = 4.068779, test loss = 12162.864661\n",
            "Epoch 6843: train loss = 4.068795, test loss = 12162.842738\n",
            "Epoch 6844: train loss = 4.068773, test loss = 12162.815529\n",
            "Epoch 6845: train loss = 4.068763, test loss = 12162.786120\n",
            "Epoch 6846: train loss = 4.068771, test loss = 12162.763672\n",
            "Epoch 6847: train loss = 4.068749, test loss = 12162.736249\n",
            "Epoch 6848: train loss = 4.068745, test loss = 12162.705432\n",
            "Epoch 6849: train loss = 4.068746, test loss = 12162.684457\n",
            "Epoch 6850: train loss = 4.068724, test loss = 12162.658065\n",
            "Epoch 6851: train loss = 4.068728, test loss = 12162.626006\n",
            "Epoch 6852: train loss = 4.068722, test loss = 12162.605929\n",
            "Epoch 6853: train loss = 4.068699, test loss = 12162.579684\n",
            "Epoch 6854: train loss = 4.068710, test loss = 12162.546495\n",
            "Epoch 6855: train loss = 4.068697, test loss = 12162.528217\n",
            "Epoch 6856: train loss = 4.068676, test loss = 12162.511861\n",
            "Epoch 6857: train loss = 4.068673, test loss = 12162.487687\n",
            "Epoch 6858: train loss = 4.068674, test loss = 12162.456668\n",
            "Epoch 6859: train loss = 4.068670, test loss = 12162.436861\n",
            "Epoch 6860: train loss = 4.068648, test loss = 12162.410840\n",
            "Epoch 6861: train loss = 4.068656, test loss = 12162.378142\n",
            "Epoch 6862: train loss = 4.068646, test loss = 12162.359057\n",
            "Epoch 6863: train loss = 4.068623, test loss = 12162.333102\n",
            "Epoch 6864: train loss = 4.068639, test loss = 12162.298861\n",
            "Epoch 6865: train loss = 4.068621, test loss = 12162.281023\n",
            "Epoch 6866: train loss = 4.068601, test loss = 12162.265072\n",
            "Epoch 6867: train loss = 4.068596, test loss = 12162.242006\n",
            "Epoch 6868: train loss = 4.068603, test loss = 12162.209422\n",
            "Epoch 6869: train loss = 4.068594, test loss = 12162.190365\n",
            "Epoch 6870: train loss = 4.068571, test loss = 12162.164554\n",
            "Epoch 6871: train loss = 4.068585, test loss = 12162.130460\n",
            "Epoch 6872: train loss = 4.068569, test loss = 12162.112333\n",
            "Epoch 6873: train loss = 4.068547, test loss = 12162.097256\n",
            "Epoch 6874: train loss = 4.068545, test loss = 12162.072956\n",
            "Epoch 6875: train loss = 4.068549, test loss = 12162.040611\n",
            "Epoch 6876: train loss = 4.068542, test loss = 12162.021528\n",
            "Epoch 6877: train loss = 4.068520, test loss = 12161.995673\n",
            "Epoch 6878: train loss = 4.068531, test loss = 12161.961984\n",
            "Epoch 6879: train loss = 4.068518, test loss = 12161.943642\n",
            "Epoch 6880: train loss = 4.068495, test loss = 12161.917941\n",
            "Epoch 6881: train loss = 4.068513, test loss = 12161.882615\n",
            "Epoch 6882: train loss = 4.068493, test loss = 12161.865445\n",
            "Epoch 6883: train loss = 4.068475, test loss = 12161.841359\n",
            "Epoch 6884: train loss = 4.068490, test loss = 12161.820113\n",
            "Epoch 6885: train loss = 4.068467, test loss = 12161.792567\n",
            "Epoch 6886: train loss = 4.068458, test loss = 12161.762642\n",
            "Epoch 6887: train loss = 4.068465, test loss = 12161.740775\n",
            "Epoch 6888: train loss = 4.068443, test loss = 12161.713353\n",
            "Epoch 6889: train loss = 4.068441, test loss = 12161.682269\n",
            "Epoch 6890: train loss = 4.068441, test loss = 12161.661908\n",
            "Epoch 6891: train loss = 4.068418, test loss = 12161.635058\n",
            "Epoch 6892: train loss = 4.068423, test loss = 12161.602635\n",
            "Epoch 6893: train loss = 4.068416, test loss = 12161.582936\n",
            "Epoch 6894: train loss = 4.068394, test loss = 12161.556998\n",
            "Epoch 6895: train loss = 4.068405, test loss = 12161.523339\n",
            "Epoch 6896: train loss = 4.068392, test loss = 12161.505335\n",
            "Epoch 6897: train loss = 4.068370, test loss = 12161.489084\n",
            "Epoch 6898: train loss = 4.068367, test loss = 12161.465048\n",
            "Epoch 6899: train loss = 4.068370, test loss = 12161.433465\n",
            "Epoch 6900: train loss = 4.068365, test loss = 12161.414107\n",
            "Epoch 6901: train loss = 4.068342, test loss = 12161.387957\n",
            "Epoch 6902: train loss = 4.068352, test loss = 12161.355024\n",
            "Epoch 6903: train loss = 4.068340, test loss = 12161.336082\n",
            "Epoch 6904: train loss = 4.068318, test loss = 12161.310431\n",
            "Epoch 6905: train loss = 4.068334, test loss = 12161.275748\n",
            "Epoch 6906: train loss = 4.068316, test loss = 12161.258050\n",
            "Epoch 6907: train loss = 4.068296, test loss = 12161.234902\n",
            "Epoch 6908: train loss = 4.068312, test loss = 12161.212518\n",
            "Epoch 6909: train loss = 4.068290, test loss = 12161.184933\n",
            "Epoch 6910: train loss = 4.068279, test loss = 12161.155648\n",
            "Epoch 6911: train loss = 4.068288, test loss = 12161.133441\n",
            "Epoch 6912: train loss = 4.068265, test loss = 12161.105878\n",
            "Epoch 6913: train loss = 4.068262, test loss = 12161.075808\n",
            "Epoch 6914: train loss = 4.068263, test loss = 12161.054384\n",
            "Epoch 6915: train loss = 4.068241, test loss = 12161.027605\n",
            "Epoch 6916: train loss = 4.068244, test loss = 12160.995663\n",
            "Epoch 6917: train loss = 4.068239, test loss = 12160.975772\n",
            "Epoch 6918: train loss = 4.068216, test loss = 12160.949491\n",
            "Epoch 6919: train loss = 4.068226, test loss = 12160.916984\n",
            "Epoch 6920: train loss = 4.068214, test loss = 12160.897924\n",
            "Epoch 6921: train loss = 4.068193, test loss = 12160.881632\n",
            "Epoch 6922: train loss = 4.068190, test loss = 12160.857608\n",
            "Epoch 6923: train loss = 4.068191, test loss = 12160.826647\n",
            "Epoch 6924: train loss = 4.068187, test loss = 12160.807438\n",
            "Epoch 6925: train loss = 4.068165, test loss = 12160.780888\n",
            "Epoch 6926: train loss = 4.068173, test loss = 12160.747904\n",
            "Epoch 6927: train loss = 4.068163, test loss = 12160.728851\n",
            "Epoch 6928: train loss = 4.068140, test loss = 12160.703158\n",
            "Epoch 6929: train loss = 4.068155, test loss = 12160.669025\n",
            "Epoch 6930: train loss = 4.068138, test loss = 12160.651476\n",
            "Epoch 6931: train loss = 4.068118, test loss = 12160.635431\n",
            "Epoch 6932: train loss = 4.068114, test loss = 12160.611539\n",
            "Epoch 6933: train loss = 4.068119, test loss = 12160.579552\n",
            "Epoch 6934: train loss = 4.068111, test loss = 12160.560481\n",
            "Epoch 6935: train loss = 4.068088, test loss = 12160.534732\n",
            "Epoch 6936: train loss = 4.068101, test loss = 12160.501059\n",
            "Epoch 6937: train loss = 4.068086, test loss = 12160.482748\n",
            "Epoch 6938: train loss = 4.068064, test loss = 12160.467035\n",
            "Epoch 6939: train loss = 4.068062, test loss = 12160.442919\n",
            "Epoch 6940: train loss = 4.068066, test loss = 12160.410909\n",
            "Epoch 6941: train loss = 4.068059, test loss = 12160.391687\n",
            "Epoch 6942: train loss = 4.068037, test loss = 12160.366371\n",
            "Epoch 6943: train loss = 4.068048, test loss = 12160.332067\n",
            "Epoch 6944: train loss = 4.068035, test loss = 12160.313734\n",
            "Epoch 6945: train loss = 4.068012, test loss = 12160.288175\n",
            "Epoch 6946: train loss = 4.068030, test loss = 12160.253057\n",
            "Epoch 6947: train loss = 4.068010, test loss = 12160.236265\n",
            "Epoch 6948: train loss = 4.067991, test loss = 12160.211936\n",
            "Epoch 6949: train loss = 4.068007, test loss = 12160.190127\n",
            "Epoch 6950: train loss = 4.067985, test loss = 12160.162569\n",
            "Epoch 6951: train loss = 4.067975, test loss = 12160.133096\n",
            "Epoch 6952: train loss = 4.067982, test loss = 12160.111063\n",
            "Epoch 6953: train loss = 4.067960, test loss = 12160.084213\n",
            "Epoch 6954: train loss = 4.067958, test loss = 12160.052847\n",
            "Epoch 6955: train loss = 4.067958, test loss = 12160.032042\n",
            "Epoch 6956: train loss = 4.067936, test loss = 12160.005214\n",
            "Epoch 6957: train loss = 4.067940, test loss = 12159.973106\n",
            "Epoch 6958: train loss = 4.067934, test loss = 12159.953368\n",
            "Epoch 6959: train loss = 4.067911, test loss = 12159.927782\n",
            "Epoch 6960: train loss = 4.067922, test loss = 12159.894006\n",
            "Epoch 6961: train loss = 4.067909, test loss = 12159.875397\n",
            "Epoch 6962: train loss = 4.067887, test loss = 12159.859499\n",
            "Epoch 6963: train loss = 4.067885, test loss = 12159.835378\n",
            "Epoch 6964: train loss = 4.067887, test loss = 12159.804080\n",
            "Epoch 6965: train loss = 4.067882, test loss = 12159.784976\n",
            "Epoch 6966: train loss = 4.067859, test loss = 12159.758734\n",
            "Epoch 6967: train loss = 4.067869, test loss = 12159.725191\n",
            "Epoch 6968: train loss = 4.067857, test loss = 12159.706521\n",
            "Epoch 6969: train loss = 4.067835, test loss = 12159.680817\n",
            "Epoch 6970: train loss = 4.067851, test loss = 12159.646756\n",
            "Epoch 6971: train loss = 4.067833, test loss = 12159.628871\n",
            "Epoch 6972: train loss = 4.067813, test loss = 12159.605169\n",
            "Epoch 6973: train loss = 4.067830, test loss = 12159.583009\n",
            "Epoch 6974: train loss = 4.067807, test loss = 12159.555303\n",
            "Epoch 6975: train loss = 4.067796, test loss = 12159.526404\n",
            "Epoch 6976: train loss = 4.067805, test loss = 12159.504454\n",
            "Epoch 6977: train loss = 4.067783, test loss = 12159.476737\n",
            "Epoch 6978: train loss = 4.067779, test loss = 12159.446070\n",
            "Epoch 6979: train loss = 4.067781, test loss = 12159.424978\n",
            "Epoch 6980: train loss = 4.067758, test loss = 12159.398132\n",
            "Epoch 6981: train loss = 4.067761, test loss = 12159.366359\n",
            "Epoch 6982: train loss = 4.067756, test loss = 12159.347021\n",
            "Epoch 6983: train loss = 4.067734, test loss = 12159.320369\n",
            "Epoch 6984: train loss = 4.067744, test loss = 12159.287283\n",
            "Epoch 6985: train loss = 4.067732, test loss = 12159.268409\n",
            "Epoch 6986: train loss = 4.067711, test loss = 12159.252314\n",
            "Epoch 6987: train loss = 4.067707, test loss = 12159.228215\n",
            "Epoch 6988: train loss = 4.067708, test loss = 12159.198030\n",
            "Epoch 6989: train loss = 4.067705, test loss = 12159.177881\n",
            "Epoch 6990: train loss = 4.067682, test loss = 12159.151468\n",
            "Epoch 6991: train loss = 4.067690, test loss = 12159.118665\n",
            "Epoch 6992: train loss = 4.067680, test loss = 12159.099706\n",
            "Epoch 6993: train loss = 4.067657, test loss = 12159.074321\n",
            "Epoch 6994: train loss = 4.067672, test loss = 12159.040031\n",
            "Epoch 6995: train loss = 4.067656, test loss = 12159.021986\n",
            "Epoch 6996: train loss = 4.067636, test loss = 12159.005996\n",
            "Epoch 6997: train loss = 4.067631, test loss = 12158.982416\n",
            "Epoch 6998: train loss = 4.067636, test loss = 12158.950330\n",
            "Epoch 6999: train loss = 4.067628, test loss = 12158.931789\n",
            "Epoch 7000: train loss = 4.067606, test loss = 12158.905729\n",
            "Epoch 7001: train loss = 4.067619, test loss = 12158.871695\n",
            "Epoch 7002: train loss = 4.067604, test loss = 12158.853412\n",
            "Epoch 7003: train loss = 4.067582, test loss = 12158.837876\n",
            "Epoch 7004: train loss = 4.067579, test loss = 12158.813788\n",
            "Epoch 7005: train loss = 4.067583, test loss = 12158.782237\n",
            "Epoch 7006: train loss = 4.067577, test loss = 12158.762894\n",
            "Epoch 7007: train loss = 4.067554, test loss = 12158.736851\n",
            "Epoch 7008: train loss = 4.067565, test loss = 12158.702875\n",
            "Epoch 7009: train loss = 4.067552, test loss = 12158.684734\n",
            "Epoch 7010: train loss = 4.067530, test loss = 12158.659116\n",
            "Epoch 7011: train loss = 4.067547, test loss = 12158.624437\n",
            "Epoch 7012: train loss = 4.067528, test loss = 12158.606923\n",
            "Epoch 7013: train loss = 4.067509, test loss = 12158.582928\n",
            "Epoch 7014: train loss = 4.067525, test loss = 12158.561018\n",
            "Epoch 7015: train loss = 4.067502, test loss = 12158.533684\n",
            "Epoch 7016: train loss = 4.067492, test loss = 12158.504558\n",
            "Epoch 7017: train loss = 4.067500, test loss = 12158.482320\n",
            "Epoch 7018: train loss = 4.067478, test loss = 12158.454768\n",
            "Epoch 7019: train loss = 4.067475, test loss = 12158.423814\n",
            "Epoch 7020: train loss = 4.067476, test loss = 12158.402947\n",
            "Epoch 7021: train loss = 4.067453, test loss = 12158.376362\n",
            "Epoch 7022: train loss = 4.067458, test loss = 12158.344553\n",
            "Epoch 7023: train loss = 4.067451, test loss = 12158.324722\n",
            "Epoch 7024: train loss = 4.067429, test loss = 12158.298389\n",
            "Epoch 7025: train loss = 4.067440, test loss = 12158.265028\n",
            "Epoch 7026: train loss = 4.067427, test loss = 12158.246513\n",
            "Epoch 7027: train loss = 4.067405, test loss = 12158.230470\n",
            "Epoch 7028: train loss = 4.067402, test loss = 12158.206959\n",
            "Epoch 7029: train loss = 4.067404, test loss = 12158.175354\n",
            "Epoch 7030: train loss = 4.067400, test loss = 12158.155858\n",
            "Epoch 7031: train loss = 4.067377, test loss = 12158.129580\n",
            "Epoch 7032: train loss = 4.067387, test loss = 12158.096364\n",
            "Epoch 7033: train loss = 4.067375, test loss = 12158.077644\n",
            "Epoch 7034: train loss = 4.067353, test loss = 12158.052469\n",
            "Epoch 7035: train loss = 4.067369, test loss = 12158.017753\n",
            "Epoch 7036: train loss = 4.067351, test loss = 12157.999868\n",
            "Epoch 7037: train loss = 4.067331, test loss = 12157.984219\n",
            "Epoch 7038: train loss = 4.067326, test loss = 12157.960437\n",
            "Epoch 7039: train loss = 4.067333, test loss = 12157.928586\n",
            "Epoch 7040: train loss = 4.067324, test loss = 12157.909519\n",
            "Epoch 7041: train loss = 4.067301, test loss = 12157.883696\n",
            "Epoch 7042: train loss = 4.067315, test loss = 12157.849215\n",
            "Epoch 7043: train loss = 4.067299, test loss = 12157.831411\n",
            "Epoch 7044: train loss = 4.067277, test loss = 12157.798219\n",
            "Epoch 7045: train loss = 4.067276, test loss = 12157.772694\n",
            "Epoch 7046: train loss = 4.067278, test loss = 12157.741308\n",
            "Epoch 7047: train loss = 4.067274, test loss = 12157.720642\n",
            "Epoch 7048: train loss = 4.067252, test loss = 12157.693975\n",
            "Epoch 7049: train loss = 4.067260, test loss = 12157.660939\n",
            "Epoch 7050: train loss = 4.067250, test loss = 12157.641605\n",
            "Epoch 7051: train loss = 4.067229, test loss = 12157.625505\n",
            "Epoch 7052: train loss = 4.067226, test loss = 12157.600982\n",
            "Epoch 7053: train loss = 4.067225, test loss = 12157.570164\n",
            "Epoch 7054: train loss = 4.067223, test loss = 12157.550094\n",
            "Epoch 7055: train loss = 4.067200, test loss = 12157.523503\n",
            "Epoch 7056: train loss = 4.067207, test loss = 12157.490919\n",
            "Epoch 7057: train loss = 4.067198, test loss = 12157.472053\n",
            "Epoch 7058: train loss = 4.067176, test loss = 12157.445870\n",
            "Epoch 7059: train loss = 4.067190, test loss = 12157.411920\n",
            "Epoch 7060: train loss = 4.067174, test loss = 12157.393615\n",
            "Epoch 7061: train loss = 4.067154, test loss = 12157.377640\n",
            "Epoch 7062: train loss = 4.067150, test loss = 12157.354204\n",
            "Epoch 7063: train loss = 4.067154, test loss = 12157.322331\n",
            "Epoch 7064: train loss = 4.067147, test loss = 12157.302944\n",
            "Epoch 7065: train loss = 4.067124, test loss = 12157.276968\n",
            "Epoch 7066: train loss = 4.067136, test loss = 12157.243155\n",
            "Epoch 7067: train loss = 4.067123, test loss = 12157.224902\n",
            "Epoch 7068: train loss = 4.067100, test loss = 12157.209622\n",
            "Epoch 7069: train loss = 4.067098, test loss = 12157.185230\n",
            "Epoch 7070: train loss = 4.067101, test loss = 12157.153507\n",
            "Epoch 7071: train loss = 4.067095, test loss = 12157.134010\n",
            "Epoch 7072: train loss = 4.067073, test loss = 12157.108085\n",
            "Epoch 7073: train loss = 4.067083, test loss = 12157.074353\n",
            "Epoch 7074: train loss = 4.067071, test loss = 12157.056408\n",
            "Epoch 7075: train loss = 4.067049, test loss = 12157.030490\n",
            "Epoch 7076: train loss = 4.067065, test loss = 12156.995583\n",
            "Epoch 7077: train loss = 4.067047, test loss = 12156.978146\n",
            "Epoch 7078: train loss = 4.067027, test loss = 12156.954264\n",
            "Epoch 7079: train loss = 4.067043, test loss = 12156.932359\n",
            "Epoch 7080: train loss = 4.067021, test loss = 12156.905202\n",
            "Epoch 7081: train loss = 4.067010, test loss = 12156.875824\n",
            "Epoch 7082: train loss = 4.067019, test loss = 12156.853438\n",
            "Epoch 7083: train loss = 4.066997, test loss = 12156.826017\n",
            "Epoch 7084: train loss = 4.066993, test loss = 12156.795234\n",
            "Epoch 7085: train loss = 4.066995, test loss = 12156.774752\n",
            "Epoch 7086: train loss = 4.066972, test loss = 12156.747640\n",
            "Epoch 7087: train loss = 4.066976, test loss = 12156.715758\n",
            "Epoch 7088: train loss = 4.066970, test loss = 12156.695793\n",
            "Epoch 7089: train loss = 4.066948, test loss = 12156.669625\n",
            "Epoch 7090: train loss = 4.066958, test loss = 12156.636380\n",
            "Epoch 7091: train loss = 4.066946, test loss = 12156.618211\n",
            "Epoch 7092: train loss = 4.066924, test loss = 12156.602002\n",
            "Epoch 7093: train loss = 4.066921, test loss = 12156.577760\n",
            "Epoch 7094: train loss = 4.066922, test loss = 12156.546749\n",
            "Epoch 7095: train loss = 4.066919, test loss = 12156.526975\n",
            "Epoch 7096: train loss = 4.066896, test loss = 12156.500939\n",
            "Epoch 7097: train loss = 4.066905, test loss = 12156.468223\n",
            "Epoch 7098: train loss = 4.066894, test loss = 12156.449235\n",
            "Epoch 7099: train loss = 4.066872, test loss = 12156.423323\n",
            "Epoch 7100: train loss = 4.066887, test loss = 12156.389025\n",
            "Epoch 7101: train loss = 4.066870, test loss = 12156.371290\n",
            "Epoch 7102: train loss = 4.066849, test loss = 12156.355925\n",
            "Epoch 7103: train loss = 4.066845, test loss = 12156.331987\n",
            "Epoch 7104: train loss = 4.066851, test loss = 12156.299602\n",
            "Epoch 7105: train loss = 4.066843, test loss = 12156.280826\n",
            "Epoch 7106: train loss = 4.066820, test loss = 12156.254915\n",
            "Epoch 7107: train loss = 4.066833, test loss = 12156.220780\n",
            "Epoch 7108: train loss = 4.066818, test loss = 12156.203199\n",
            "Epoch 7109: train loss = 4.066796, test loss = 12156.177639\n",
            "Epoch 7110: train loss = 4.066815, test loss = 12156.142156\n",
            "Epoch 7111: train loss = 4.066794, test loss = 12156.125061\n",
            "Epoch 7112: train loss = 4.066777, test loss = 12156.100964\n",
            "Epoch 7113: train loss = 4.066791, test loss = 12156.079387\n",
            "Epoch 7114: train loss = 4.066768, test loss = 12156.052475\n",
            "Epoch 7115: train loss = 4.066761, test loss = 12156.022491\n",
            "Epoch 7116: train loss = 4.066766, test loss = 12156.000679\n",
            "Epoch 7117: train loss = 4.066744, test loss = 12155.973329\n",
            "Epoch 7118: train loss = 4.066743, test loss = 12155.942228\n",
            "Epoch 7119: train loss = 4.066742, test loss = 12155.921550\n",
            "Epoch 7120: train loss = 4.066719, test loss = 12155.895347\n",
            "Epoch 7121: train loss = 4.066726, test loss = 12155.862727\n",
            "Epoch 7122: train loss = 4.066718, test loss = 12155.843237\n",
            "Epoch 7123: train loss = 4.066695, test loss = 12155.817091\n",
            "Epoch 7124: train loss = 4.066708, test loss = 12155.783448\n",
            "Epoch 7125: train loss = 4.066693, test loss = 12155.765637\n",
            "Epoch 7126: train loss = 4.066673, test loss = 12155.749265\n",
            "Epoch 7127: train loss = 4.066669, test loss = 12155.725455\n",
            "Epoch 7128: train loss = 4.066673, test loss = 12155.693803\n",
            "Epoch 7129: train loss = 4.066666, test loss = 12155.674419\n",
            "Epoch 7130: train loss = 4.066644, test loss = 12155.648477\n",
            "Epoch 7131: train loss = 4.066655, test loss = 12155.615480\n",
            "Epoch 7132: train loss = 4.066642, test loss = 12155.596672\n",
            "Epoch 7133: train loss = 4.066619, test loss = 12155.580912\n",
            "Epoch 7134: train loss = 4.066617, test loss = 12155.556679\n",
            "Epoch 7135: train loss = 4.066619, test loss = 12155.525134\n",
            "Epoch 7136: train loss = 4.066615, test loss = 12155.505722\n",
            "Epoch 7137: train loss = 4.066592, test loss = 12155.480131\n",
            "Epoch 7138: train loss = 4.066602, test loss = 12155.446396\n",
            "Epoch 7139: train loss = 4.066590, test loss = 12155.427828\n",
            "Epoch 7140: train loss = 4.066568, test loss = 12155.402052\n",
            "Epoch 7141: train loss = 4.066584, test loss = 12155.367304\n",
            "Epoch 7142: train loss = 4.066566, test loss = 12155.349838\n",
            "Epoch 7143: train loss = 4.066546, test loss = 12155.326683\n",
            "Epoch 7144: train loss = 4.066563, test loss = 12155.304287\n",
            "Epoch 7145: train loss = 4.066540, test loss = 12155.276779\n",
            "Epoch 7146: train loss = 4.066529, test loss = 12155.247479\n",
            "Epoch 7147: train loss = 4.066538, test loss = 12155.225252\n",
            "Epoch 7148: train loss = 4.066516, test loss = 12155.197768\n",
            "Epoch 7149: train loss = 4.066512, test loss = 12155.167679\n",
            "Epoch 7150: train loss = 4.066514, test loss = 12155.146290\n",
            "Epoch 7151: train loss = 4.066491, test loss = 12155.119489\n",
            "Epoch 7152: train loss = 4.066495, test loss = 12155.087581\n",
            "Epoch 7153: train loss = 4.066490, test loss = 12155.067718\n",
            "Epoch 7154: train loss = 4.066467, test loss = 12155.041860\n",
            "Epoch 7155: train loss = 4.066477, test loss = 12155.008682\n",
            "Epoch 7156: train loss = 4.066465, test loss = 12154.989791\n",
            "Epoch 7157: train loss = 4.066443, test loss = 12154.973658\n",
            "Epoch 7158: train loss = 4.066441, test loss = 12154.949685\n",
            "Epoch 7159: train loss = 4.066441, test loss = 12154.918704\n",
            "Epoch 7160: train loss = 4.066438, test loss = 12154.899521\n",
            "Epoch 7161: train loss = 4.066416, test loss = 12154.872948\n",
            "Epoch 7162: train loss = 4.066424, test loss = 12154.840009\n",
            "Epoch 7163: train loss = 4.066414, test loss = 12154.820981\n",
            "Epoch 7164: train loss = 4.066391, test loss = 12154.795270\n",
            "Epoch 7165: train loss = 4.066406, test loss = 12154.761190\n",
            "Epoch 7166: train loss = 4.066389, test loss = 12154.743664\n",
            "Epoch 7167: train loss = 4.066369, test loss = 12154.727715\n",
            "Epoch 7168: train loss = 4.066365, test loss = 12154.703793\n",
            "Epoch 7169: train loss = 4.066370, test loss = 12154.671828\n",
            "Epoch 7170: train loss = 4.066362, test loss = 12154.652777\n",
            "Epoch 7171: train loss = 4.066340, test loss = 12154.627453\n",
            "Epoch 7172: train loss = 4.066353, test loss = 12154.593116\n",
            "Epoch 7173: train loss = 4.066338, test loss = 12154.574971\n",
            "Epoch 7174: train loss = 4.066315, test loss = 12154.549477\n",
            "Epoch 7175: train loss = 4.066335, test loss = 12154.514382\n",
            "Epoch 7176: train loss = 4.066314, test loss = 12154.497178\n",
            "Epoch 7177: train loss = 4.066296, test loss = 12154.473571\n",
            "Epoch 7178: train loss = 4.066310, test loss = 12154.451682\n",
            "Epoch 7179: train loss = 4.066288, test loss = 12154.424326\n",
            "Epoch 7180: train loss = 4.066280, test loss = 12154.394605\n",
            "Epoch 7181: train loss = 4.066286, test loss = 12154.372702\n",
            "Epoch 7182: train loss = 4.066264, test loss = 12154.345552\n",
            "Epoch 7183: train loss = 4.066263, test loss = 12154.314781\n",
            "Epoch 7184: train loss = 4.066262, test loss = 12154.294025\n",
            "Epoch 7185: train loss = 4.066239, test loss = 12154.267175\n",
            "Epoch 7186: train loss = 4.066245, test loss = 12154.234865\n",
            "Epoch 7187: train loss = 4.066237, test loss = 12154.215300\n",
            "Epoch 7188: train loss = 4.066215, test loss = 12154.189315\n",
            "Epoch 7189: train loss = 4.066228, test loss = 12154.156290\n",
            "Epoch 7190: train loss = 4.066213, test loss = 12154.137549\n",
            "Epoch 7191: train loss = 4.066193, test loss = 12154.121443\n",
            "Epoch 7192: train loss = 4.066188, test loss = 12154.097545\n",
            "Epoch 7193: train loss = 4.066192, test loss = 12154.066244\n",
            "Epoch 7194: train loss = 4.066186, test loss = 12154.047214\n",
            "Epoch 7195: train loss = 4.066163, test loss = 12154.020965\n",
            "Epoch 7196: train loss = 4.066174, test loss = 12153.987382\n",
            "Epoch 7197: train loss = 4.066162, test loss = 12153.968866\n",
            "Epoch 7198: train loss = 4.066139, test loss = 12153.953090\n",
            "Epoch 7199: train loss = 4.066137, test loss = 12153.928988\n",
            "Epoch 7200: train loss = 4.066139, test loss = 12153.898088\n",
            "Epoch 7201: train loss = 4.066134, test loss = 12153.878234\n",
            "Epoch 7202: train loss = 4.066112, test loss = 12153.852204\n",
            "Epoch 7203: train loss = 4.066121, test loss = 12153.818699\n",
            "Epoch 7204: train loss = 4.066110, test loss = 12153.800089\n",
            "Epoch 7205: train loss = 4.066088, test loss = 12153.774371\n",
            "Epoch 7206: train loss = 4.066103, test loss = 12153.740347\n",
            "Epoch 7207: train loss = 4.066086, test loss = 12153.722392\n",
            "Epoch 7208: train loss = 4.066065, test loss = 12153.698860\n",
            "Epoch 7209: train loss = 4.066082, test loss = 12153.676632\n",
            "Epoch 7210: train loss = 4.066060, test loss = 12153.649058\n",
            "Epoch 7211: train loss = 4.066049, test loss = 12153.619941\n",
            "Epoch 7212: train loss = 4.066058, test loss = 12153.598129\n",
            "Epoch 7213: train loss = 4.066036, test loss = 12153.570472\n",
            "Epoch 7214: train loss = 4.066032, test loss = 12153.539782\n",
            "Epoch 7215: train loss = 4.066034, test loss = 12153.518673\n",
            "Epoch 7216: train loss = 4.066011, test loss = 12153.491805\n",
            "Epoch 7217: train loss = 4.066014, test loss = 12153.460682\n",
            "Epoch 7218: train loss = 4.066010, test loss = 12153.440371\n",
            "Epoch 7219: train loss = 4.065987, test loss = 12153.414100\n",
            "Epoch 7220: train loss = 4.065997, test loss = 12153.381040\n",
            "Epoch 7221: train loss = 4.065985, test loss = 12153.362228\n",
            "Epoch 7222: train loss = 4.065963, test loss = 12153.346236\n",
            "Epoch 7223: train loss = 4.065961, test loss = 12153.322596\n",
            "Epoch 7224: train loss = 4.065961, test loss = 12153.291573\n",
            "Epoch 7225: train loss = 4.065958, test loss = 12153.271584\n",
            "Epoch 7226: train loss = 4.065936, test loss = 12153.245504\n",
            "Epoch 7227: train loss = 4.065944, test loss = 12153.212553\n",
            "Epoch 7228: train loss = 4.065934, test loss = 12153.193655\n",
            "Epoch 7229: train loss = 4.065911, test loss = 12153.168260\n",
            "Epoch 7230: train loss = 4.065926, test loss = 12153.134017\n",
            "Epoch 7231: train loss = 4.065909, test loss = 12153.116007\n",
            "Epoch 7232: train loss = 4.065889, test loss = 12153.100115\n",
            "Epoch 7233: train loss = 4.065885, test loss = 12153.076470\n",
            "Epoch 7234: train loss = 4.065890, test loss = 12153.044395\n",
            "Epoch 7235: train loss = 4.065882, test loss = 12153.026011\n",
            "Epoch 7236: train loss = 4.065860, test loss = 12152.999867\n",
            "Epoch 7237: train loss = 4.065872, test loss = 12152.965831\n",
            "Epoch 7238: train loss = 4.065858, test loss = 12152.947587\n",
            "Epoch 7239: train loss = 4.065835, test loss = 12152.922227\n",
            "Epoch 7240: train loss = 4.065855, test loss = 12152.887116\n",
            "Epoch 7241: train loss = 4.065834, test loss = 12152.870345\n",
            "Epoch 7242: train loss = 4.065816, test loss = 12152.846192\n",
            "Epoch 7243: train loss = 4.065830, test loss = 12152.824422\n",
            "Epoch 7244: train loss = 4.065808, test loss = 12152.796961\n",
            "Epoch 7245: train loss = 4.065800, test loss = 12152.767385\n",
            "Epoch 7246: train loss = 4.065806, test loss = 12152.746017\n",
            "Epoch 7247: train loss = 4.065784, test loss = 12152.718449\n",
            "Epoch 7248: train loss = 4.065783, test loss = 12152.687309\n",
            "Epoch 7249: train loss = 4.065782, test loss = 12152.666525\n",
            "Epoch 7250: train loss = 4.065759, test loss = 12152.640056\n",
            "Epoch 7251: train loss = 4.065765, test loss = 12152.607672\n",
            "Epoch 7252: train loss = 4.065758, test loss = 12152.588658\n",
            "Epoch 7253: train loss = 4.065735, test loss = 12152.562319\n",
            "Epoch 7254: train loss = 4.065748, test loss = 12152.528764\n",
            "Epoch 7255: train loss = 4.065733, test loss = 12152.510315\n",
            "Epoch 7256: train loss = 4.065713, test loss = 12152.494152\n",
            "Epoch 7257: train loss = 4.065709, test loss = 12152.470509\n",
            "Epoch 7258: train loss = 4.065712, test loss = 12152.439509\n",
            "Epoch 7259: train loss = 4.065706, test loss = 12152.419800\n",
            "Epoch 7260: train loss = 4.065684, test loss = 12152.393759\n",
            "Epoch 7261: train loss = 4.065695, test loss = 12152.360388\n",
            "Epoch 7262: train loss = 4.065682, test loss = 12152.341741\n",
            "Epoch 7263: train loss = 4.065660, test loss = 12152.326558\n",
            "Epoch 7264: train loss = 4.065658, test loss = 12152.302110\n",
            "Epoch 7265: train loss = 4.065659, test loss = 12152.270612\n",
            "Epoch 7266: train loss = 4.065655, test loss = 12152.251063\n",
            "Epoch 7267: train loss = 4.065632, test loss = 12152.225020\n",
            "Epoch 7268: train loss = 4.065641, test loss = 12152.191668\n",
            "Epoch 7269: train loss = 4.065631, test loss = 12152.173583\n",
            "Epoch 7270: train loss = 4.065608, test loss = 12152.147614\n",
            "Epoch 7271: train loss = 4.065624, test loss = 12152.112929\n",
            "Epoch 7272: train loss = 4.065606, test loss = 12152.095283\n",
            "Epoch 7273: train loss = 4.065585, test loss = 12152.071806\n",
            "Epoch 7274: train loss = 4.065603, test loss = 12152.049615\n",
            "Epoch 7275: train loss = 4.065581, test loss = 12152.022588\n",
            "Epoch 7276: train loss = 4.065569, test loss = 12151.993242\n",
            "Epoch 7277: train loss = 4.065579, test loss = 12151.970880\n",
            "Epoch 7278: train loss = 4.065556, test loss = 12151.943263\n",
            "Epoch 7279: train loss = 4.065552, test loss = 12151.912881\n",
            "Epoch 7280: train loss = 4.065554, test loss = 12151.891719\n",
            "Epoch 7281: train loss = 4.065532, test loss = 12151.865452\n",
            "Epoch 7282: train loss = 4.065535, test loss = 12151.833445\n",
            "Epoch 7283: train loss = 4.065530, test loss = 12151.813401\n",
            "Epoch 7284: train loss = 4.065508, test loss = 12151.787066\n",
            "Epoch 7285: train loss = 4.065517, test loss = 12151.754243\n",
            "Epoch 7286: train loss = 4.065506, test loss = 12151.735842\n",
            "Epoch 7287: train loss = 4.065484, test loss = 12151.719505\n",
            "Epoch 7288: train loss = 4.065481, test loss = 12151.695387\n",
            "Epoch 7289: train loss = 4.065482, test loss = 12151.664535\n",
            "Epoch 7290: train loss = 4.065479, test loss = 12151.644817\n",
            "Epoch 7291: train loss = 4.065456, test loss = 12151.618531\n",
            "Epoch 7292: train loss = 4.065464, test loss = 12151.586269\n",
            "Epoch 7293: train loss = 4.065454, test loss = 12151.566959\n",
            "Epoch 7294: train loss = 4.065432, test loss = 12151.541169\n",
            "Epoch 7295: train loss = 4.065446, test loss = 12151.507130\n",
            "Epoch 7296: train loss = 4.065430, test loss = 12151.489078\n",
            "Epoch 7297: train loss = 4.065410, test loss = 12151.473399\n",
            "Epoch 7298: train loss = 4.065406, test loss = 12151.450051\n",
            "Epoch 7299: train loss = 4.065411, test loss = 12151.417992\n",
            "Epoch 7300: train loss = 4.065403, test loss = 12151.398774\n",
            "Epoch 7301: train loss = 4.065381, test loss = 12151.372979\n",
            "Epoch 7302: train loss = 4.065393, test loss = 12151.338985\n",
            "Epoch 7303: train loss = 4.065379, test loss = 12151.320896\n",
            "Epoch 7304: train loss = 4.065356, test loss = 12151.295928\n",
            "Epoch 7305: train loss = 4.065375, test loss = 12151.260669\n",
            "Epoch 7306: train loss = 4.065355, test loss = 12151.243292\n",
            "Epoch 7307: train loss = 4.065337, test loss = 12151.219303\n",
            "Epoch 7308: train loss = 4.065351, test loss = 12151.197635\n",
            "Epoch 7309: train loss = 4.065329, test loss = 12151.170770\n",
            "Epoch 7310: train loss = 4.065321, test loss = 12151.140971\n",
            "Epoch 7311: train loss = 4.065327, test loss = 12151.118947\n",
            "Epoch 7312: train loss = 4.065305, test loss = 12151.091670\n",
            "Epoch 7313: train loss = 4.065304, test loss = 12151.060571\n",
            "Epoch 7314: train loss = 4.065303, test loss = 12151.040062\n",
            "Epoch 7315: train loss = 4.065280, test loss = 12151.013755\n",
            "Epoch 7316: train loss = 4.065286, test loss = 12150.981318\n",
            "Epoch 7317: train loss = 4.065279, test loss = 12150.961587\n",
            "Epoch 7318: train loss = 4.065256, test loss = 12150.935573\n",
            "Epoch 7319: train loss = 4.065269, test loss = 12150.902160\n",
            "Epoch 7320: train loss = 4.065254, test loss = 12150.883622\n",
            "Epoch 7321: train loss = 4.065234, test loss = 12150.868095\n",
            "Epoch 7322: train loss = 4.065230, test loss = 12150.843949\n",
            "Epoch 7323: train loss = 4.065233, test loss = 12150.812702\n",
            "Epoch 7324: train loss = 4.065227, test loss = 12150.793125\n",
            "Epoch 7325: train loss = 4.065205, test loss = 12150.767157\n",
            "Epoch 7326: train loss = 4.065215, test loss = 12150.733779\n",
            "Epoch 7327: train loss = 4.065203, test loss = 12150.715706\n",
            "Epoch 7328: train loss = 4.065181, test loss = 12150.699600\n",
            "Epoch 7329: train loss = 4.065179, test loss = 12150.675569\n",
            "Epoch 7330: train loss = 4.065180, test loss = 12150.644159\n",
            "Epoch 7331: train loss = 4.065176, test loss = 12150.624663\n",
            "Epoch 7332: train loss = 4.065154, test loss = 12150.598911\n",
            "Epoch 7333: train loss = 4.065163, test loss = 12150.565482\n",
            "Epoch 7334: train loss = 4.065152, test loss = 12150.546695\n",
            "Epoch 7335: train loss = 4.065129, test loss = 12150.520950\n",
            "Epoch 7336: train loss = 4.065145, test loss = 12150.486531\n",
            "Epoch 7337: train loss = 4.065127, test loss = 12150.468783\n",
            "Epoch 7338: train loss = 4.065107, test loss = 12150.453843\n",
            "Epoch 7339: train loss = 4.065103, test loss = 12150.429740\n",
            "Epoch 7340: train loss = 4.065109, test loss = 12150.397253\n",
            "Epoch 7341: train loss = 4.065101, test loss = 12150.378374\n",
            "Epoch 7342: train loss = 4.065078, test loss = 12150.352722\n",
            "Epoch 7343: train loss = 4.065091, test loss = 12150.318441\n",
            "Epoch 7344: train loss = 4.065076, test loss = 12150.300922\n",
            "Epoch 7345: train loss = 4.065054, test loss = 12150.267486\n",
            "Epoch 7346: train loss = 4.065053, test loss = 12150.241466\n",
            "Epoch 7347: train loss = 4.065054, test loss = 12150.210445\n",
            "Epoch 7348: train loss = 4.065051, test loss = 12150.189865\n",
            "Epoch 7349: train loss = 4.065029, test loss = 12150.163177\n",
            "Epoch 7350: train loss = 4.065037, test loss = 12150.130674\n",
            "Epoch 7351: train loss = 4.065027, test loss = 12150.111047\n",
            "Epoch 7352: train loss = 4.065005, test loss = 12150.094567\n",
            "Epoch 7353: train loss = 4.065003, test loss = 12150.070308\n",
            "Epoch 7354: train loss = 4.065002, test loss = 12150.039578\n",
            "Epoch 7355: train loss = 4.065000, test loss = 12150.019918\n",
            "Epoch 7356: train loss = 4.064978, test loss = 12149.993121\n",
            "Epoch 7357: train loss = 4.064985, test loss = 12149.960459\n",
            "Epoch 7358: train loss = 4.064976, test loss = 12149.941219\n",
            "Epoch 7359: train loss = 4.064954, test loss = 12149.915160\n",
            "Epoch 7360: train loss = 4.064967, test loss = 12149.881382\n",
            "Epoch 7361: train loss = 4.064952, test loss = 12149.863551\n",
            "Epoch 7362: train loss = 4.064931, test loss = 12149.847595\n",
            "Epoch 7363: train loss = 4.064928, test loss = 12149.823535\n",
            "Epoch 7364: train loss = 4.064932, test loss = 12149.791818\n",
            "Epoch 7365: train loss = 4.064925, test loss = 12149.772576\n",
            "Epoch 7366: train loss = 4.064902, test loss = 12149.746676\n",
            "Epoch 7367: train loss = 4.064914, test loss = 12149.713476\n",
            "Epoch 7368: train loss = 4.064901, test loss = 12149.694789\n",
            "Epoch 7369: train loss = 4.064878, test loss = 12149.669270\n",
            "Epoch 7370: train loss = 4.064896, test loss = 12149.634231\n",
            "Epoch 7371: train loss = 4.064877, test loss = 12149.617020\n",
            "Epoch 7372: train loss = 4.064858, test loss = 12149.593152\n",
            "Epoch 7373: train loss = 4.064873, test loss = 12149.571835\n",
            "Epoch 7374: train loss = 4.064851, test loss = 12149.544052\n",
            "Epoch 7375: train loss = 4.064842, test loss = 12149.514675\n",
            "Epoch 7376: train loss = 4.064849, test loss = 12149.492624\n",
            "Epoch 7377: train loss = 4.064827, test loss = 12149.465176\n",
            "Epoch 7378: train loss = 4.064825, test loss = 12149.434857\n",
            "Epoch 7379: train loss = 4.064825, test loss = 12149.413725\n",
            "Epoch 7380: train loss = 4.064802, test loss = 12149.387027\n",
            "Epoch 7381: train loss = 4.064807, test loss = 12149.354848\n",
            "Epoch 7382: train loss = 4.064800, test loss = 12149.335256\n",
            "Epoch 7383: train loss = 4.064778, test loss = 12149.309052\n",
            "Epoch 7384: train loss = 4.064790, test loss = 12149.276322\n",
            "Epoch 7385: train loss = 4.064776, test loss = 12149.257503\n",
            "Epoch 7386: train loss = 4.064756, test loss = 12149.241238\n",
            "Epoch 7387: train loss = 4.064752, test loss = 12149.217475\n",
            "Epoch 7388: train loss = 4.064754, test loss = 12149.186276\n",
            "Epoch 7389: train loss = 4.064749, test loss = 12149.166733\n",
            "Epoch 7390: train loss = 4.064727, test loss = 12149.141150\n",
            "Epoch 7391: train loss = 4.064737, test loss = 12149.107810\n",
            "Epoch 7392: train loss = 4.064725, test loss = 12149.088969\n",
            "Epoch 7393: train loss = 4.064703, test loss = 12149.073192\n",
            "Epoch 7394: train loss = 4.064701, test loss = 12149.048980\n",
            "Epoch 7395: train loss = 4.064701, test loss = 12149.017853\n",
            "Epoch 7396: train loss = 4.064698, test loss = 12148.998721\n",
            "Epoch 7397: train loss = 4.064676, test loss = 12148.972335\n",
            "Epoch 7398: train loss = 4.064684, test loss = 12148.939100\n",
            "Epoch 7399: train loss = 4.064674, test loss = 12148.920431\n",
            "Epoch 7400: train loss = 4.064651, test loss = 12148.894597\n",
            "Epoch 7401: train loss = 4.064666, test loss = 12148.860705\n",
            "Epoch 7402: train loss = 4.064650, test loss = 12148.842706\n",
            "Epoch 7403: train loss = 4.064629, test loss = 12148.827066\n",
            "Epoch 7404: train loss = 4.064625, test loss = 12148.803182\n",
            "Epoch 7405: train loss = 4.064631, test loss = 12148.771061\n",
            "Epoch 7406: train loss = 4.064623, test loss = 12148.752152\n",
            "Epoch 7407: train loss = 4.064600, test loss = 12148.726772\n",
            "Epoch 7408: train loss = 4.064613, test loss = 12148.692415\n",
            "Epoch 7409: train loss = 4.064599, test loss = 12148.674400\n",
            "Epoch 7410: train loss = 4.064576, test loss = 12148.648940\n",
            "Epoch 7411: train loss = 4.064595, test loss = 12148.613597\n",
            "Epoch 7412: train loss = 4.064574, test loss = 12148.596629\n",
            "Epoch 7413: train loss = 4.064557, test loss = 12148.572865\n",
            "Epoch 7414: train loss = 4.064571, test loss = 12148.551294\n",
            "Epoch 7415: train loss = 4.064549, test loss = 12148.523787\n",
            "Epoch 7416: train loss = 4.064541, test loss = 12148.493935\n",
            "Epoch 7417: train loss = 4.064547, test loss = 12148.472262\n",
            "Epoch 7418: train loss = 4.064525, test loss = 12148.445099\n",
            "Epoch 7419: train loss = 4.064524, test loss = 12148.414222\n",
            "Epoch 7420: train loss = 4.064523, test loss = 12148.393601\n",
            "Epoch 7421: train loss = 4.064500, test loss = 12148.366802\n",
            "Epoch 7422: train loss = 4.064506, test loss = 12148.334356\n",
            "Epoch 7423: train loss = 4.064499, test loss = 12148.314932\n",
            "Epoch 7424: train loss = 4.064476, test loss = 12148.289439\n",
            "Epoch 7425: train loss = 4.064489, test loss = 12148.255454\n",
            "Epoch 7426: train loss = 4.064474, test loss = 12148.237219\n",
            "Epoch 7427: train loss = 4.064454, test loss = 12148.221164\n",
            "Epoch 7428: train loss = 4.064450, test loss = 12148.197345\n",
            "Epoch 7429: train loss = 4.064453, test loss = 12148.165733\n",
            "Epoch 7430: train loss = 4.064447, test loss = 12148.146990\n",
            "Epoch 7431: train loss = 4.064425, test loss = 12148.120780\n",
            "Epoch 7432: train loss = 4.064436, test loss = 12148.087066\n",
            "Epoch 7433: train loss = 4.064423, test loss = 12148.068685\n",
            "Epoch 7434: train loss = 4.064401, test loss = 12148.043066\n",
            "Epoch 7435: train loss = 4.064418, test loss = 12148.008452\n",
            "Epoch 7436: train loss = 4.064399, test loss = 12147.991365\n",
            "Epoch 7437: train loss = 4.064380, test loss = 12147.967519\n",
            "Epoch 7438: train loss = 4.064396, test loss = 12147.945417\n",
            "Epoch 7439: train loss = 4.064373, test loss = 12147.917936\n",
            "Epoch 7440: train loss = 4.064364, test loss = 12147.888797\n",
            "Epoch 7441: train loss = 4.064371, test loss = 12147.866590\n",
            "Epoch 7442: train loss = 4.064349, test loss = 12147.839710\n",
            "Epoch 7443: train loss = 4.064347, test loss = 12147.808774\n",
            "Epoch 7444: train loss = 4.064347, test loss = 12147.787859\n",
            "Epoch 7445: train loss = 4.064325, test loss = 12147.760958\n",
            "Epoch 7446: train loss = 4.064329, test loss = 12147.729117\n",
            "Epoch 7447: train loss = 4.064323, test loss = 12147.709770\n",
            "Epoch 7448: train loss = 4.064301, test loss = 12147.683399\n",
            "Epoch 7449: train loss = 4.064312, test loss = 12147.650127\n",
            "Epoch 7450: train loss = 4.064299, test loss = 12147.631590\n",
            "Epoch 7451: train loss = 4.064279, test loss = 12147.615338\n",
            "Epoch 7452: train loss = 4.064274, test loss = 12147.591520\n",
            "Epoch 7453: train loss = 4.064276, test loss = 12147.561036\n",
            "Epoch 7454: train loss = 4.064272, test loss = 12147.541199\n",
            "Epoch 7455: train loss = 4.064249, test loss = 12147.514989\n",
            "Epoch 7456: train loss = 4.064259, test loss = 12147.481878\n",
            "Epoch 7457: train loss = 4.064248, test loss = 12147.463180\n",
            "Epoch 7458: train loss = 4.064225, test loss = 12147.447331\n",
            "Epoch 7459: train loss = 4.064223, test loss = 12147.423604\n",
            "Epoch 7460: train loss = 4.064224, test loss = 12147.392529\n",
            "Epoch 7461: train loss = 4.064221, test loss = 12147.372574\n",
            "Epoch 7462: train loss = 4.064198, test loss = 12147.346471\n",
            "Epoch 7463: train loss = 4.064206, test loss = 12147.313444\n",
            "Epoch 7464: train loss = 4.064197, test loss = 12147.294649\n",
            "Epoch 7465: train loss = 4.064174, test loss = 12147.269286\n",
            "Epoch 7466: train loss = 4.064189, test loss = 12147.234934\n",
            "Epoch 7467: train loss = 4.064172, test loss = 12147.216937\n",
            "Epoch 7468: train loss = 4.064151, test loss = 12147.201401\n",
            "Epoch 7469: train loss = 4.064148, test loss = 12147.177515\n",
            "Epoch 7470: train loss = 4.064153, test loss = 12147.145961\n",
            "Epoch 7471: train loss = 4.064146, test loss = 12147.126687\n",
            "Epoch 7472: train loss = 4.064123, test loss = 12147.100817\n",
            "Epoch 7473: train loss = 4.064136, test loss = 12147.066772\n",
            "Epoch 7474: train loss = 4.064121, test loss = 12147.048657\n",
            "Epoch 7475: train loss = 4.064099, test loss = 12147.023349\n",
            "Epoch 7476: train loss = 4.064118, test loss = 12146.988488\n",
            "Epoch 7477: train loss = 4.064097, test loss = 12146.971343\n",
            "Epoch 7478: train loss = 4.064080, test loss = 12146.947043\n",
            "Epoch 7479: train loss = 4.064094, test loss = 12146.925517\n",
            "Epoch 7480: train loss = 4.064072, test loss = 12146.898109\n",
            "Epoch 7481: train loss = 4.064063, test loss = 12146.868532\n",
            "Epoch 7482: train loss = 4.064070, test loss = 12146.847231\n",
            "Epoch 7483: train loss = 4.064047, test loss = 12146.819663\n",
            "Epoch 7484: train loss = 4.064046, test loss = 12146.788523\n",
            "Epoch 7485: train loss = 4.064046, test loss = 12146.767794\n",
            "Epoch 7486: train loss = 4.064023, test loss = 12146.741319\n",
            "Epoch 7487: train loss = 4.064029, test loss = 12146.708935\n",
            "Epoch 7488: train loss = 4.064022, test loss = 12146.689974\n",
            "Epoch 7489: train loss = 4.063999, test loss = 12146.663626\n",
            "Epoch 7490: train loss = 4.064012, test loss = 12146.630023\n",
            "Epoch 7491: train loss = 4.063997, test loss = 12146.611684\n",
            "Epoch 7492: train loss = 4.063977, test loss = 12146.595671\n",
            "Epoch 7493: train loss = 4.063973, test loss = 12146.572318\n",
            "Epoch 7494: train loss = 4.063976, test loss = 12146.540625\n",
            "Epoch 7495: train loss = 4.063970, test loss = 12146.521285\n",
            "Epoch 7496: train loss = 4.063948, test loss = 12146.495126\n",
            "Epoch 7497: train loss = 4.063959, test loss = 12146.461807\n",
            "Epoch 7498: train loss = 4.063946, test loss = 12146.443227\n",
            "Epoch 7499: train loss = 4.063924, test loss = 12146.418176\n",
            "Epoch 7500: train loss = 4.063941, test loss = 12146.383199\n",
            "Epoch 7501: train loss = 4.063922, test loss = 12146.365776\n",
            "Epoch 7502: train loss = 4.063903, test loss = 12146.342040\n",
            "Epoch 7503: train loss = 4.063919, test loss = 12146.320093\n",
            "Epoch 7504: train loss = 4.063896, test loss = 12146.292553\n",
            "Epoch 7505: train loss = 4.063886, test loss = 12146.263951\n",
            "Epoch 7506: train loss = 4.063895, test loss = 12146.241544\n",
            "Epoch 7507: train loss = 4.063872, test loss = 12146.213937\n",
            "Epoch 7508: train loss = 4.063870, test loss = 12146.183515\n",
            "Epoch 7509: train loss = 4.063870, test loss = 12146.162397\n",
            "Epoch 7510: train loss = 4.063848, test loss = 12146.135581\n",
            "Epoch 7511: train loss = 4.063852, test loss = 12146.104376\n",
            "Epoch 7512: train loss = 4.063846, test loss = 12146.084336\n",
            "Epoch 7513: train loss = 4.063824, test loss = 12146.057965\n",
            "Epoch 7514: train loss = 4.063835, test loss = 12146.025112\n",
            "Epoch 7515: train loss = 4.063822, test loss = 12146.006253\n",
            "Epoch 7516: train loss = 4.063802, test loss = 12145.990498\n",
            "Epoch 7517: train loss = 4.063798, test loss = 12145.966426\n",
            "Epoch 7518: train loss = 4.063799, test loss = 12145.935578\n",
            "Epoch 7519: train loss = 4.063795, test loss = 12145.915781\n",
            "Epoch 7520: train loss = 4.063773, test loss = 12145.889678\n",
            "Epoch 7521: train loss = 4.063782, test loss = 12145.856881\n",
            "Epoch 7522: train loss = 4.063771, test loss = 12145.838417\n",
            "Epoch 7523: train loss = 4.063749, test loss = 12145.822397\n",
            "Epoch 7524: train loss = 4.063747, test loss = 12145.798072\n",
            "Epoch 7525: train loss = 4.063747, test loss = 12145.767196\n",
            "Epoch 7526: train loss = 4.063744, test loss = 12145.747431\n",
            "Epoch 7527: train loss = 4.063722, test loss = 12145.721265\n",
            "Epoch 7528: train loss = 4.063729, test loss = 12145.688876\n",
            "Epoch 7529: train loss = 4.063720, test loss = 12145.669816\n",
            "Epoch 7530: train loss = 4.063697, test loss = 12145.643839\n",
            "Epoch 7531: train loss = 4.063712, test loss = 12145.609720\n",
            "Epoch 7532: train loss = 4.063696, test loss = 12145.591848\n",
            "Epoch 7533: train loss = 4.063675, test loss = 12145.576246\n",
            "Epoch 7534: train loss = 4.063671, test loss = 12145.552851\n",
            "Epoch 7535: train loss = 4.063676, test loss = 12145.520765\n",
            "Epoch 7536: train loss = 4.063669, test loss = 12145.501575\n",
            "Epoch 7537: train loss = 4.063646, test loss = 12145.475660\n",
            "Epoch 7538: train loss = 4.063659, test loss = 12145.441816\n",
            "Epoch 7539: train loss = 4.063645, test loss = 12145.424187\n",
            "Epoch 7540: train loss = 4.063622, test loss = 12145.398476\n",
            "Epoch 7541: train loss = 4.063641, test loss = 12145.363375\n",
            "Epoch 7542: train loss = 4.063621, test loss = 12145.346096\n",
            "Epoch 7543: train loss = 4.063603, test loss = 12145.322122\n",
            "Epoch 7544: train loss = 4.063617, test loss = 12145.300471\n",
            "Epoch 7545: train loss = 4.063595, test loss = 12145.273696\n",
            "Epoch 7546: train loss = 4.063587, test loss = 12145.243764\n",
            "Epoch 7547: train loss = 4.063593, test loss = 12145.221878\n",
            "Epoch 7548: train loss = 4.063571, test loss = 12145.194672\n",
            "Epoch 7549: train loss = 4.063570, test loss = 12145.163526\n",
            "Epoch 7550: train loss = 4.063569, test loss = 12145.143012\n",
            "Epoch 7551: train loss = 4.063547, test loss = 12145.116739\n",
            "Epoch 7552: train loss = 4.063552, test loss = 12145.084317\n",
            "Epoch 7553: train loss = 4.063545, test loss = 12145.064636\n",
            "Epoch 7554: train loss = 4.063523, test loss = 12145.038618\n",
            "Epoch 7555: train loss = 4.063535, test loss = 12145.005125\n",
            "Epoch 7556: train loss = 4.063521, test loss = 12144.987299\n",
            "Epoch 7557: train loss = 4.063500, test loss = 12144.970999\n",
            "Epoch 7558: train loss = 4.063496, test loss = 12144.947129\n",
            "Epoch 7559: train loss = 4.063500, test loss = 12144.915673\n",
            "Epoch 7560: train loss = 4.063494, test loss = 12144.896322\n",
            "Epoch 7561: train loss = 4.063472, test loss = 12144.870338\n",
            "Epoch 7562: train loss = 4.063482, test loss = 12144.837427\n",
            "Epoch 7563: train loss = 4.063470, test loss = 12144.818682\n",
            "Epoch 7564: train loss = 4.063447, test loss = 12144.792931\n",
            "Epoch 7565: train loss = 4.063465, test loss = 12144.758496\n",
            "Epoch 7566: train loss = 4.063446, test loss = 12144.740848\n",
            "Epoch 7567: train loss = 4.063426, test loss = 12144.725217\n",
            "Epoch 7568: train loss = 4.063421, test loss = 12144.702051\n",
            "Epoch 7569: train loss = 4.063429, test loss = 12144.669407\n",
            "Epoch 7570: train loss = 4.063419, test loss = 12144.650745\n",
            "Epoch 7571: train loss = 4.063396, test loss = 12144.624972\n",
            "Epoch 7572: train loss = 4.063411, test loss = 12144.590637\n",
            "Epoch 7573: train loss = 4.063395, test loss = 12144.572828\n",
            "Epoch 7574: train loss = 4.063373, test loss = 12144.549988\n",
            "Epoch 7575: train loss = 4.063392, test loss = 12144.527431\n",
            "Epoch 7576: train loss = 4.063369, test loss = 12144.499707\n",
            "Epoch 7577: train loss = 4.063357, test loss = 12144.470680\n",
            "Epoch 7578: train loss = 4.063367, test loss = 12144.448312\n",
            "Epoch 7579: train loss = 4.063345, test loss = 12144.420782\n",
            "Epoch 7580: train loss = 4.063340, test loss = 12144.391026\n",
            "Epoch 7581: train loss = 4.063343, test loss = 12144.369468\n",
            "Epoch 7582: train loss = 4.063321, test loss = 12144.342589\n",
            "Epoch 7583: train loss = 4.063323, test loss = 12144.310902\n",
            "Epoch 7584: train loss = 4.063319, test loss = 12144.290932\n",
            "Epoch 7585: train loss = 4.063297, test loss = 12144.265149\n",
            "Epoch 7586: train loss = 4.063306, test loss = 12144.232060\n",
            "Epoch 7587: train loss = 4.063295, test loss = 12144.213083\n",
            "Epoch 7588: train loss = 4.063273, test loss = 12144.197051\n",
            "Epoch 7589: train loss = 4.063271, test loss = 12144.173126\n",
            "Epoch 7590: train loss = 4.063270, test loss = 12144.142347\n",
            "Epoch 7591: train loss = 4.063268, test loss = 12144.122973\n",
            "Epoch 7592: train loss = 4.063246, test loss = 12144.096459\n",
            "Epoch 7593: train loss = 4.063253, test loss = 12144.063709\n",
            "Epoch 7594: train loss = 4.063244, test loss = 12144.044695\n",
            "Epoch 7595: train loss = 4.063222, test loss = 12144.018821\n",
            "Epoch 7596: train loss = 4.063236, test loss = 12143.984980\n",
            "Epoch 7597: train loss = 4.063220, test loss = 12143.967386\n",
            "Epoch 7598: train loss = 4.063199, test loss = 12143.951611\n",
            "Epoch 7599: train loss = 4.063196, test loss = 12143.927676\n",
            "Epoch 7600: train loss = 4.063200, test loss = 12143.895797\n",
            "Epoch 7601: train loss = 4.063193, test loss = 12143.876687\n",
            "Epoch 7602: train loss = 4.063171, test loss = 12143.850959\n",
            "Epoch 7603: train loss = 4.063183, test loss = 12143.817615\n",
            "Epoch 7604: train loss = 4.063169, test loss = 12143.799108\n",
            "Epoch 7605: train loss = 4.063146, test loss = 12143.773648\n",
            "Epoch 7606: train loss = 4.063165, test loss = 12143.738520\n",
            "Epoch 7607: train loss = 4.063145, test loss = 12143.721470\n",
            "Epoch 7608: train loss = 4.063127, test loss = 12143.697905\n",
            "Epoch 7609: train loss = 4.063142, test loss = 12143.676104\n",
            "Epoch 7610: train loss = 4.063119, test loss = 12143.648552\n",
            "Epoch 7611: train loss = 4.063111, test loss = 12143.619062\n",
            "Epoch 7612: train loss = 4.063118, test loss = 12143.597198\n",
            "Epoch 7613: train loss = 4.063095, test loss = 12143.569899\n",
            "Epoch 7614: train loss = 4.063094, test loss = 12143.539459\n",
            "Epoch 7615: train loss = 4.063093, test loss = 12143.518432\n",
            "Epoch 7616: train loss = 4.063071, test loss = 12143.491873\n",
            "Epoch 7617: train loss = 4.063077, test loss = 12143.459559\n",
            "Epoch 7618: train loss = 4.063069, test loss = 12143.440056\n",
            "Epoch 7619: train loss = 4.063047, test loss = 12143.413988\n",
            "Epoch 7620: train loss = 4.063059, test loss = 12143.381122\n",
            "Epoch 7621: train loss = 4.063045, test loss = 12143.362341\n",
            "Epoch 7622: train loss = 4.063025, test loss = 12143.346408\n",
            "Epoch 7623: train loss = 4.063021, test loss = 12143.322457\n",
            "Epoch 7624: train loss = 4.063024, test loss = 12143.291261\n",
            "Epoch 7625: train loss = 4.063018, test loss = 12143.271761\n",
            "Epoch 7626: train loss = 4.062996, test loss = 12143.246290\n",
            "Epoch 7627: train loss = 4.063006, test loss = 12143.212817\n",
            "Epoch 7628: train loss = 4.062994, test loss = 12143.194045\n",
            "Epoch 7629: train loss = 4.062972, test loss = 12143.168465\n",
            "Epoch 7630: train loss = 4.062989, test loss = 12143.133937\n",
            "Epoch 7631: train loss = 4.062970, test loss = 12143.116953\n",
            "Epoch 7632: train loss = 4.062951, test loss = 12143.100891\n",
            "Epoch 7633: train loss = 4.062946, test loss = 12143.077333\n",
            "Epoch 7634: train loss = 4.062953, test loss = 12143.044819\n",
            "Epoch 7635: train loss = 4.062943, test loss = 12143.026240\n",
            "Epoch 7636: train loss = 4.062921, test loss = 12143.000669\n",
            "Epoch 7637: train loss = 4.062936, test loss = 12142.966692\n",
            "Epoch 7638: train loss = 4.062919, test loss = 12142.948788\n",
            "Epoch 7639: train loss = 4.062898, test loss = 12142.933062\n",
            "Epoch 7640: train loss = 4.062895, test loss = 12142.909179\n",
            "Epoch 7641: train loss = 4.062900, test loss = 12142.876890\n",
            "Epoch 7642: train loss = 4.062893, test loss = 12142.858086\n",
            "Epoch 7643: train loss = 4.062870, test loss = 12142.832739\n",
            "Epoch 7644: train loss = 4.062883, test loss = 12142.798402\n",
            "Epoch 7645: train loss = 4.062869, test loss = 12142.780216\n",
            "Epoch 7646: train loss = 4.062846, test loss = 12142.746803\n",
            "Epoch 7647: train loss = 4.062845, test loss = 12142.721059\n",
            "Epoch 7648: train loss = 4.062846, test loss = 12142.690101\n",
            "Epoch 7649: train loss = 4.062844, test loss = 12142.669918\n",
            "Epoch 7650: train loss = 4.062821, test loss = 12142.643024\n",
            "Epoch 7651: train loss = 4.062829, test loss = 12142.610168\n",
            "Epoch 7652: train loss = 4.062820, test loss = 12142.590575\n",
            "Epoch 7653: train loss = 4.062797, test loss = 12142.564649\n",
            "Epoch 7654: train loss = 4.062812, test loss = 12142.531074\n",
            "Epoch 7655: train loss = 4.062796, test loss = 12142.512457\n",
            "Epoch 7656: train loss = 4.062777, test loss = 12142.496286\n",
            "Epoch 7657: train loss = 4.062772, test loss = 12142.472558\n",
            "Epoch 7658: train loss = 4.062776, test loss = 12142.440800\n",
            "Epoch 7659: train loss = 4.062769, test loss = 12142.421735\n",
            "Epoch 7660: train loss = 4.062747, test loss = 12142.396169\n",
            "Epoch 7661: train loss = 4.062759, test loss = 12142.362180\n",
            "Epoch 7662: train loss = 4.062745, test loss = 12142.343783\n",
            "Epoch 7663: train loss = 4.062723, test loss = 12142.327973\n",
            "Epoch 7664: train loss = 4.062721, test loss = 12142.303979\n",
            "Epoch 7665: train loss = 4.062724, test loss = 12142.272526\n",
            "Epoch 7666: train loss = 4.062718, test loss = 12142.253537\n",
            "Epoch 7667: train loss = 4.062696, test loss = 12142.227270\n",
            "Epoch 7668: train loss = 4.062706, test loss = 12142.193671\n",
            "Epoch 7669: train loss = 4.062694, test loss = 12142.175214\n",
            "Epoch 7670: train loss = 4.062672, test loss = 12142.149636\n",
            "Epoch 7671: train loss = 4.062689, test loss = 12142.114996\n",
            "Epoch 7672: train loss = 4.062670, test loss = 12142.097907\n",
            "Epoch 7673: train loss = 4.062651, test loss = 12142.074009\n",
            "Epoch 7674: train loss = 4.062667, test loss = 12142.051959\n",
            "Epoch 7675: train loss = 4.062645, test loss = 12142.024481\n",
            "Epoch 7676: train loss = 4.062634, test loss = 12141.995186\n",
            "Epoch 7677: train loss = 4.062643, test loss = 12141.973628\n",
            "Epoch 7678: train loss = 4.062621, test loss = 12141.946020\n",
            "Epoch 7679: train loss = 4.062618, test loss = 12141.915155\n",
            "Epoch 7680: train loss = 4.062619, test loss = 12141.894375\n",
            "Epoch 7681: train loss = 4.062596, test loss = 12141.867511\n",
            "Epoch 7682: train loss = 4.062601, test loss = 12141.835679\n",
            "Epoch 7683: train loss = 4.062595, test loss = 12141.816309\n",
            "Epoch 7684: train loss = 4.062572, test loss = 12141.790012\n",
            "Epoch 7685: train loss = 4.062583, test loss = 12141.756726\n",
            "Epoch 7686: train loss = 4.062571, test loss = 12141.738170\n",
            "Epoch 7687: train loss = 4.062550, test loss = 12141.722114\n",
            "Epoch 7688: train loss = 4.062546, test loss = 12141.698246\n",
            "Epoch 7689: train loss = 4.062548, test loss = 12141.667674\n",
            "Epoch 7690: train loss = 4.062544, test loss = 12141.647856\n",
            "Epoch 7691: train loss = 4.062521, test loss = 12141.621711\n",
            "Epoch 7692: train loss = 4.062531, test loss = 12141.588593\n",
            "Epoch 7693: train loss = 4.062520, test loss = 12141.569882\n",
            "Epoch 7694: train loss = 4.062497, test loss = 12141.544207\n",
            "Epoch 7695: train loss = 4.062513, test loss = 12141.510555\n",
            "Epoch 7696: train loss = 4.062496, test loss = 12141.492456\n",
            "Epoch 7697: train loss = 4.062476, test loss = 12141.476709\n",
            "Epoch 7698: train loss = 4.062471, test loss = 12141.452988\n",
            "Epoch 7699: train loss = 4.062478, test loss = 12141.420892\n",
            "Epoch 7700: train loss = 4.062469, test loss = 12141.402493\n",
            "Epoch 7701: train loss = 4.062446, test loss = 12141.376688\n",
            "Epoch 7702: train loss = 4.062460, test loss = 12141.342352\n",
            "Epoch 7703: train loss = 4.062445, test loss = 12141.324415\n",
            "Epoch 7704: train loss = 4.062423, test loss = 12141.308857\n",
            "Epoch 7705: train loss = 4.062421, test loss = 12141.285036\n",
            "Epoch 7706: train loss = 4.062425, test loss = 12141.253431\n",
            "Epoch 7707: train loss = 4.062418, test loss = 12141.234092\n",
            "Epoch 7708: train loss = 4.062396, test loss = 12141.208240\n",
            "Epoch 7709: train loss = 4.062408, test loss = 12141.174135\n",
            "Epoch 7710: train loss = 4.062394, test loss = 12141.156157\n",
            "Epoch 7711: train loss = 4.062372, test loss = 12141.130733\n",
            "Epoch 7712: train loss = 4.062390, test loss = 12141.096023\n",
            "Epoch 7713: train loss = 4.062370, test loss = 12141.078588\n",
            "Epoch 7714: train loss = 4.062352, test loss = 12141.054546\n",
            "Epoch 7715: train loss = 4.062367, test loss = 12141.032973\n",
            "Epoch 7716: train loss = 4.062345, test loss = 12141.005556\n",
            "Epoch 7717: train loss = 4.062336, test loss = 12140.975974\n",
            "Epoch 7718: train loss = 4.062343, test loss = 12140.954600\n",
            "Epoch 7719: train loss = 4.062321, test loss = 12140.927248\n",
            "Epoch 7720: train loss = 4.062319, test loss = 12140.895945\n",
            "Epoch 7721: train loss = 4.062319, test loss = 12140.875370\n",
            "Epoch 7722: train loss = 4.062297, test loss = 12140.848681\n",
            "Epoch 7723: train loss = 4.062302, test loss = 12140.816903\n",
            "Epoch 7724: train loss = 4.062295, test loss = 12140.797207\n",
            "Epoch 7725: train loss = 4.062272, test loss = 12140.771041\n",
            "Epoch 7726: train loss = 4.062284, test loss = 12140.737548\n",
            "Epoch 7727: train loss = 4.062271, test loss = 12140.719091\n",
            "Epoch 7728: train loss = 4.062249, test loss = 12140.703510\n",
            "Epoch 7729: train loss = 4.062246, test loss = 12140.679944\n",
            "Epoch 7730: train loss = 4.062249, test loss = 12140.648335\n",
            "Epoch 7731: train loss = 4.062244, test loss = 12140.628822\n",
            "Epoch 7732: train loss = 4.062222, test loss = 12140.602823\n",
            "Epoch 7733: train loss = 4.062232, test loss = 12140.569377\n",
            "Epoch 7734: train loss = 4.062220, test loss = 12140.551013\n",
            "Epoch 7735: train loss = 4.062197, test loss = 12140.525865\n",
            "Epoch 7736: train loss = 4.062214, test loss = 12140.491041\n",
            "Epoch 7737: train loss = 4.062196, test loss = 12140.473367\n",
            "Epoch 7738: train loss = 4.062176, test loss = 12140.449884\n",
            "Epoch 7739: train loss = 4.062193, test loss = 12140.427922\n",
            "Epoch 7740: train loss = 4.062170, test loss = 12140.400338\n",
            "Epoch 7741: train loss = 4.062160, test loss = 12140.371777\n",
            "Epoch 7742: train loss = 4.062169, test loss = 12140.349319\n",
            "Epoch 7743: train loss = 4.062146, test loss = 12140.321950\n",
            "Epoch 7744: train loss = 4.062143, test loss = 12140.291280\n",
            "Epoch 7745: train loss = 4.062145, test loss = 12140.270380\n",
            "Epoch 7746: train loss = 4.062122, test loss = 12140.244002\n",
            "Epoch 7747: train loss = 4.062126, test loss = 12140.212056\n",
            "Epoch 7748: train loss = 4.062121, test loss = 12140.192216\n",
            "Epoch 7749: train loss = 4.062098, test loss = 12140.165918\n",
            "Epoch 7750: train loss = 4.062109, test loss = 12140.132998\n",
            "Epoch 7751: train loss = 4.062096, test loss = 12140.114210\n",
            "Epoch 7752: train loss = 4.062076, test loss = 12140.098849\n",
            "Epoch 7753: train loss = 4.062072, test loss = 12140.074567\n",
            "Epoch 7754: train loss = 4.062073, test loss = 12140.043696\n",
            "Epoch 7755: train loss = 4.062070, test loss = 12140.023950\n",
            "Epoch 7756: train loss = 4.062047, test loss = 12139.997856\n",
            "Epoch 7757: train loss = 4.062056, test loss = 12139.965044\n",
            "Epoch 7758: train loss = 4.062046, test loss = 12139.946591\n",
            "Epoch 7759: train loss = 4.062023, test loss = 12139.920746\n",
            "Epoch 7760: train loss = 4.062039, test loss = 12139.886451\n",
            "Epoch 7761: train loss = 4.062022, test loss = 12139.868742\n",
            "Epoch 7762: train loss = 4.062002, test loss = 12139.852928\n",
            "Epoch 7763: train loss = 4.061997, test loss = 12139.829382\n",
            "Epoch 7764: train loss = 4.062003, test loss = 12139.797765\n",
            "Epoch 7765: train loss = 4.061995, test loss = 12139.778772\n",
            "Epoch 7766: train loss = 4.061972, test loss = 12139.752938\n",
            "Epoch 7767: train loss = 4.061986, test loss = 12139.718825\n",
            "Epoch 7768: train loss = 4.061971, test loss = 12139.700944\n",
            "Epoch 7769: train loss = 4.061949, test loss = 12139.685788\n",
            "Epoch 7770: train loss = 4.061947, test loss = 12139.661589\n",
            "Epoch 7771: train loss = 4.061951, test loss = 12139.629575\n",
            "Epoch 7772: train loss = 4.061944, test loss = 12139.610561\n",
            "Epoch 7773: train loss = 4.061922, test loss = 12139.584606\n",
            "Epoch 7774: train loss = 4.061933, test loss = 12139.550884\n",
            "Epoch 7775: train loss = 4.061920, test loss = 12139.533054\n",
            "Epoch 7776: train loss = 4.061898, test loss = 12139.507391\n",
            "Epoch 7777: train loss = 4.061916, test loss = 12139.472248\n",
            "Epoch 7778: train loss = 4.061896, test loss = 12139.455077\n",
            "Epoch 7779: train loss = 4.061878, test loss = 12139.431105\n",
            "Epoch 7780: train loss = 4.061893, test loss = 12139.409534\n",
            "Epoch 7781: train loss = 4.061871, test loss = 12139.382679\n",
            "Epoch 7782: train loss = 4.061861, test loss = 12139.352868\n",
            "Epoch 7783: train loss = 4.061869, test loss = 12139.331016\n",
            "Epoch 7784: train loss = 4.061847, test loss = 12139.303603\n",
            "Epoch 7785: train loss = 4.061845, test loss = 12139.272563\n",
            "Epoch 7786: train loss = 4.061845, test loss = 12139.251987\n",
            "Epoch 7787: train loss = 4.061823, test loss = 12139.225859\n",
            "Epoch 7788: train loss = 4.061828, test loss = 12139.193350\n",
            "Epoch 7789: train loss = 4.061821, test loss = 12139.173905\n",
            "Epoch 7790: train loss = 4.061799, test loss = 12139.147712\n",
            "Epoch 7791: train loss = 4.061810, test loss = 12139.114262\n",
            "Epoch 7792: train loss = 4.061797, test loss = 12139.096332\n",
            "Epoch 7793: train loss = 4.061776, test loss = 12139.080361\n",
            "Epoch 7794: train loss = 4.061773, test loss = 12139.056251\n",
            "Epoch 7795: train loss = 4.061775, test loss = 12139.025069\n",
            "Epoch 7796: train loss = 4.061770, test loss = 12139.005566\n",
            "Epoch 7797: train loss = 4.061748, test loss = 12138.979493\n",
            "Epoch 7798: train loss = 4.061758, test loss = 12138.946756\n",
            "Epoch 7799: train loss = 4.061746, test loss = 12138.928025\n",
            "Epoch 7800: train loss = 4.061724, test loss = 12138.902261\n",
            "Epoch 7801: train loss = 4.061740, test loss = 12138.867847\n",
            "Epoch 7802: train loss = 4.061722, test loss = 12138.850177\n",
            "Epoch 7803: train loss = 4.061702, test loss = 12138.826816\n",
            "Epoch 7804: train loss = 4.061719, test loss = 12138.805153\n",
            "Epoch 7805: train loss = 4.061697, test loss = 12138.777428\n",
            "Epoch 7806: train loss = 4.061686, test loss = 12138.748329\n",
            "Epoch 7807: train loss = 4.061695, test loss = 12138.726189\n",
            "Epoch 7808: train loss = 4.061673, test loss = 12138.698661\n",
            "Epoch 7809: train loss = 4.061669, test loss = 12138.668340\n",
            "Epoch 7810: train loss = 4.061671, test loss = 12138.647674\n",
            "Epoch 7811: train loss = 4.061649, test loss = 12138.620705\n",
            "Epoch 7812: train loss = 4.061652, test loss = 12138.588878\n",
            "Epoch 7813: train loss = 4.061647, test loss = 12138.569161\n",
            "Epoch 7814: train loss = 4.061624, test loss = 12138.542863\n",
            "Epoch 7815: train loss = 4.061635, test loss = 12138.510497\n",
            "Epoch 7816: train loss = 4.061623, test loss = 12138.491443\n",
            "Epoch 7817: train loss = 4.061602, test loss = 12138.475353\n",
            "Epoch 7818: train loss = 4.061599, test loss = 12138.451430\n",
            "Epoch 7819: train loss = 4.061600, test loss = 12138.420625\n",
            "Epoch 7820: train loss = 4.061596, test loss = 12138.401010\n",
            "Epoch 7821: train loss = 4.061574, test loss = 12138.375255\n",
            "Epoch 7822: train loss = 4.061582, test loss = 12138.342376\n",
            "Epoch 7823: train loss = 4.061572, test loss = 12138.323340\n",
            "Epoch 7824: train loss = 4.061550, test loss = 12138.297637\n",
            "Epoch 7825: train loss = 4.061565, test loss = 12138.263525\n",
            "Epoch 7826: train loss = 4.061548, test loss = 12138.245787\n",
            "Epoch 7827: train loss = 4.061529, test loss = 12138.230505\n",
            "Epoch 7828: train loss = 4.061524, test loss = 12138.206573\n",
            "Epoch 7829: train loss = 4.061530, test loss = 12138.174606\n",
            "Epoch 7830: train loss = 4.061521, test loss = 12138.155658\n",
            "Epoch 7831: train loss = 4.061499, test loss = 12138.130019\n",
            "Epoch 7832: train loss = 4.061512, test loss = 12138.096023\n",
            "Epoch 7833: train loss = 4.061497, test loss = 12138.078528\n",
            "Epoch 7834: train loss = 4.061476, test loss = 12138.062634\n",
            "Epoch 7835: train loss = 4.061473, test loss = 12138.038704\n",
            "Epoch 7836: train loss = 4.061477, test loss = 12138.006822\n",
            "Epoch 7837: train loss = 4.061471, test loss = 12137.987677\n",
            "Epoch 7838: train loss = 4.061448, test loss = 12137.962310\n",
            "Epoch 7839: train loss = 4.061460, test loss = 12137.928198\n",
            "Epoch 7840: train loss = 4.061447, test loss = 12137.910058\n",
            "Epoch 7841: train loss = 4.061424, test loss = 12137.884491\n",
            "Epoch 7842: train loss = 4.061442, test loss = 12137.849520\n",
            "Epoch 7843: train loss = 4.061423, test loss = 12137.832291\n",
            "Epoch 7844: train loss = 4.061404, test loss = 12137.808936\n",
            "Epoch 7845: train loss = 4.061420, test loss = 12137.787038\n",
            "Epoch 7846: train loss = 4.061397, test loss = 12137.759473\n",
            "Epoch 7847: train loss = 4.061388, test loss = 12137.730084\n",
            "Epoch 7848: train loss = 4.061396, test loss = 12137.708091\n",
            "Epoch 7849: train loss = 4.061373, test loss = 12137.680969\n",
            "Epoch 7850: train loss = 4.061371, test loss = 12137.650479\n",
            "Epoch 7851: train loss = 4.061372, test loss = 12137.629537\n",
            "Epoch 7852: train loss = 4.061349, test loss = 12137.602716\n",
            "Epoch 7853: train loss = 4.061354, test loss = 12137.570622\n",
            "Epoch 7854: train loss = 4.061348, test loss = 12137.551034\n",
            "Epoch 7855: train loss = 4.061325, test loss = 12137.525132\n",
            "Epoch 7856: train loss = 4.061337, test loss = 12137.492172\n",
            "Epoch 7857: train loss = 4.061324, test loss = 12137.473540\n",
            "Epoch 7858: train loss = 4.061302, test loss = 12137.457538\n",
            "Epoch 7859: train loss = 4.061299, test loss = 12137.433642\n",
            "Epoch 7860: train loss = 4.061302, test loss = 12137.402518\n",
            "Epoch 7861: train loss = 4.061297, test loss = 12137.383421\n",
            "Epoch 7862: train loss = 4.061275, test loss = 12137.357180\n",
            "Epoch 7863: train loss = 4.061284, test loss = 12137.323801\n",
            "Epoch 7864: train loss = 4.061273, test loss = 12137.305347\n",
            "Epoch 7865: train loss = 4.061251, test loss = 12137.279651\n",
            "Epoch 7866: train loss = 4.061267, test loss = 12137.245267\n",
            "Epoch 7867: train loss = 4.061249, test loss = 12137.228126\n",
            "Epoch 7868: train loss = 4.061229, test loss = 12137.212362\n",
            "Epoch 7869: train loss = 4.061225, test loss = 12137.188690\n",
            "Epoch 7870: train loss = 4.061232, test loss = 12137.156197\n",
            "Epoch 7871: train loss = 4.061223, test loss = 12137.137640\n",
            "Epoch 7872: train loss = 4.061200, test loss = 12137.111922\n",
            "Epoch 7873: train loss = 4.061214, test loss = 12137.078232\n",
            "Epoch 7874: train loss = 4.061199, test loss = 12137.060128\n",
            "Epoch 7875: train loss = 4.061176, test loss = 12137.026885\n",
            "Epoch 7876: train loss = 4.061175, test loss = 12137.000965\n",
            "Epoch 7877: train loss = 4.061177, test loss = 12136.969940\n",
            "Epoch 7878: train loss = 4.061174, test loss = 12136.949561\n",
            "Epoch 7879: train loss = 4.061152, test loss = 12136.923278\n",
            "Epoch 7880: train loss = 4.061161, test loss = 12136.890197\n",
            "Epoch 7881: train loss = 4.061150, test loss = 12136.870750\n",
            "Epoch 7882: train loss = 4.061129, test loss = 12136.854515\n",
            "Epoch 7883: train loss = 4.061126, test loss = 12136.830187\n",
            "Epoch 7884: train loss = 4.061126, test loss = 12136.799724\n",
            "Epoch 7885: train loss = 4.061124, test loss = 12136.780004\n",
            "Epoch 7886: train loss = 4.061101, test loss = 12136.753429\n",
            "Epoch 7887: train loss = 4.061109, test loss = 12136.720665\n",
            "Epoch 7888: train loss = 4.061100, test loss = 12136.701627\n",
            "Epoch 7889: train loss = 4.061077, test loss = 12136.675630\n",
            "Epoch 7890: train loss = 4.061091, test loss = 12136.642314\n",
            "Epoch 7891: train loss = 4.061076, test loss = 12136.623913\n",
            "Epoch 7892: train loss = 4.061056, test loss = 12136.607986\n",
            "Epoch 7893: train loss = 4.061051, test loss = 12136.584269\n",
            "Epoch 7894: train loss = 4.061056, test loss = 12136.552554\n",
            "Epoch 7895: train loss = 4.061049, test loss = 12136.533503\n",
            "Epoch 7896: train loss = 4.061027, test loss = 12136.508017\n",
            "Epoch 7897: train loss = 4.061039, test loss = 12136.474223\n",
            "Epoch 7898: train loss = 4.061025, test loss = 12136.455801\n",
            "Epoch 7899: train loss = 4.061003, test loss = 12136.440185\n",
            "Epoch 7900: train loss = 4.061001, test loss = 12136.416151\n",
            "Epoch 7901: train loss = 4.061004, test loss = 12136.384631\n",
            "Epoch 7902: train loss = 4.060999, test loss = 12136.365841\n",
            "Epoch 7903: train loss = 4.060976, test loss = 12136.339548\n",
            "Epoch 7904: train loss = 4.060986, test loss = 12136.305928\n",
            "Epoch 7905: train loss = 4.060975, test loss = 12136.287478\n",
            "Epoch 7906: train loss = 4.060952, test loss = 12136.262113\n",
            "Epoch 7907: train loss = 4.060969, test loss = 12136.227678\n",
            "Epoch 7908: train loss = 4.060951, test loss = 12136.210140\n",
            "Epoch 7909: train loss = 4.060931, test loss = 12136.186263\n",
            "Epoch 7910: train loss = 4.060947, test loss = 12136.164428\n",
            "Epoch 7911: train loss = 4.060925, test loss = 12136.137059\n",
            "Epoch 7912: train loss = 4.060915, test loss = 12136.107742\n",
            "Epoch 7913: train loss = 4.060923, test loss = 12136.086280\n",
            "Epoch 7914: train loss = 4.060901, test loss = 12136.058570\n",
            "Epoch 7915: train loss = 4.060898, test loss = 12136.027759\n",
            "Epoch 7916: train loss = 4.060900, test loss = 12136.006908\n",
            "Epoch 7917: train loss = 4.060877, test loss = 12135.980246\n",
            "Epoch 7918: train loss = 4.060881, test loss = 12135.948323\n",
            "Epoch 7919: train loss = 4.060876, test loss = 12135.929222\n",
            "Epoch 7920: train loss = 4.060853, test loss = 12135.902754\n",
            "Epoch 7921: train loss = 4.060864, test loss = 12135.869519\n",
            "Epoch 7922: train loss = 4.060852, test loss = 12135.850927\n",
            "Epoch 7923: train loss = 4.060830, test loss = 12135.835116\n",
            "Epoch 7924: train loss = 4.060827, test loss = 12135.811096\n",
            "Epoch 7925: train loss = 4.060829, test loss = 12135.780744\n",
            "Epoch 7926: train loss = 4.060825, test loss = 12135.760793\n",
            "Epoch 7927: train loss = 4.060803, test loss = 12135.734547\n",
            "Epoch 7928: train loss = 4.060812, test loss = 12135.701613\n",
            "Epoch 7929: train loss = 4.060801, test loss = 12135.682923\n",
            "Epoch 7930: train loss = 4.060778, test loss = 12135.657674\n",
            "Epoch 7931: train loss = 4.060794, test loss = 12135.623288\n",
            "Epoch 7932: train loss = 4.060777, test loss = 12135.605416\n",
            "Epoch 7933: train loss = 4.060757, test loss = 12135.589736\n",
            "Epoch 7934: train loss = 4.060753, test loss = 12135.566165\n",
            "Epoch 7935: train loss = 4.060759, test loss = 12135.534085\n",
            "Epoch 7936: train loss = 4.060751, test loss = 12135.515712\n",
            "Epoch 7937: train loss = 4.060728, test loss = 12135.489808\n",
            "Epoch 7938: train loss = 4.060742, test loss = 12135.455660\n",
            "Epoch 7939: train loss = 4.060727, test loss = 12135.437630\n",
            "Epoch 7940: train loss = 4.060704, test loss = 12135.412496\n",
            "Epoch 7941: train loss = 4.060724, test loss = 12135.377038\n",
            "Epoch 7942: train loss = 4.060703, test loss = 12135.360580\n",
            "Epoch 7943: train loss = 4.060686, test loss = 12135.336262\n",
            "Epoch 7944: train loss = 4.060700, test loss = 12135.314839\n",
            "Epoch 7945: train loss = 4.060677, test loss = 12135.287558\n",
            "Epoch 7946: train loss = 4.060670, test loss = 12135.257918\n",
            "Epoch 7947: train loss = 4.060676, test loss = 12135.236185\n",
            "Epoch 7948: train loss = 4.060653, test loss = 12135.209551\n",
            "Epoch 7949: train loss = 4.060653, test loss = 12135.178042\n",
            "Epoch 7950: train loss = 4.060652, test loss = 12135.157529\n",
            "Epoch 7951: train loss = 4.060629, test loss = 12135.130916\n",
            "Epoch 7952: train loss = 4.060636, test loss = 12135.098678\n",
            "Epoch 7953: train loss = 4.060628, test loss = 12135.079725\n",
            "Epoch 7954: train loss = 4.060605, test loss = 12135.053587\n",
            "Epoch 7955: train loss = 4.060619, test loss = 12135.019816\n",
            "Epoch 7956: train loss = 4.060604, test loss = 12135.001601\n",
            "Epoch 7957: train loss = 4.060584, test loss = 12134.985645\n",
            "Epoch 7958: train loss = 4.060579, test loss = 12134.962061\n",
            "Epoch 7959: train loss = 4.060584, test loss = 12134.930993\n",
            "Epoch 7960: train loss = 4.060577, test loss = 12134.911575\n",
            "Epoch 7961: train loss = 4.060555, test loss = 12134.885475\n",
            "Epoch 7962: train loss = 4.060566, test loss = 12134.852051\n",
            "Epoch 7963: train loss = 4.060553, test loss = 12134.833717\n",
            "Epoch 7964: train loss = 4.060531, test loss = 12134.818008\n",
            "Epoch 7965: train loss = 4.060529, test loss = 12134.794549\n",
            "Epoch 7966: train loss = 4.060531, test loss = 12134.762826\n",
            "Epoch 7967: train loss = 4.060527, test loss = 12134.743481\n",
            "Epoch 7968: train loss = 4.060504, test loss = 12134.717342\n",
            "Epoch 7969: train loss = 4.060514, test loss = 12134.684048\n",
            "Epoch 7970: train loss = 4.060503, test loss = 12134.665491\n",
            "Epoch 7971: train loss = 4.060480, test loss = 12134.640476\n",
            "Epoch 7972: train loss = 4.060497, test loss = 12134.605687\n",
            "Epoch 7973: train loss = 4.060479, test loss = 12134.588018\n",
            "Epoch 7974: train loss = 4.060459, test loss = 12134.564487\n",
            "Epoch 7975: train loss = 4.060476, test loss = 12134.542450\n",
            "Epoch 7976: train loss = 4.060453, test loss = 12134.515156\n",
            "Epoch 7977: train loss = 4.060443, test loss = 12134.486434\n",
            "Epoch 7978: train loss = 4.060452, test loss = 12134.464071\n",
            "Epoch 7979: train loss = 4.060430, test loss = 12134.436562\n",
            "Epoch 7980: train loss = 4.060426, test loss = 12134.406045\n",
            "Epoch 7981: train loss = 4.060428, test loss = 12134.385108\n",
            "Epoch 7982: train loss = 4.060405, test loss = 12134.358747\n",
            "Epoch 7983: train loss = 4.060409, test loss = 12134.326839\n",
            "Epoch 7984: train loss = 4.060404, test loss = 12134.306873\n",
            "Epoch 7985: train loss = 4.060381, test loss = 12134.280834\n",
            "Epoch 7986: train loss = 4.060392, test loss = 12134.247801\n",
            "Epoch 7987: train loss = 4.060380, test loss = 12134.229159\n",
            "Epoch 7988: train loss = 4.060358, test loss = 12134.213686\n",
            "Epoch 7989: train loss = 4.060356, test loss = 12134.189578\n",
            "Epoch 7990: train loss = 4.060357, test loss = 12134.158659\n",
            "Epoch 7991: train loss = 4.060353, test loss = 12134.138867\n",
            "Epoch 7992: train loss = 4.060331, test loss = 12134.112793\n",
            "Epoch 7993: train loss = 4.060339, test loss = 12134.079921\n",
            "Epoch 7994: train loss = 4.060329, test loss = 12134.061717\n",
            "Epoch 7995: train loss = 4.060307, test loss = 12134.035699\n",
            "Epoch 7996: train loss = 4.060322, test loss = 12134.001573\n",
            "Epoch 7997: train loss = 4.060305, test loss = 12133.983674\n",
            "Epoch 7998: train loss = 4.060285, test loss = 12133.968119\n",
            "Epoch 7999: train loss = 4.060281, test loss = 12133.944475\n",
            "Epoch 8000: train loss = 4.060287, test loss = 12133.913041\n",
            "Epoch 8001: train loss = 4.060279, test loss = 12133.893851\n",
            "Epoch 8002: train loss = 4.060256, test loss = 12133.868051\n",
            "Epoch 8003: train loss = 4.060270, test loss = 12133.833995\n",
            "Epoch 8004: train loss = 4.060255, test loss = 12133.816059\n",
            "Epoch 8005: train loss = 4.060232, test loss = 12133.791261\n",
            "Epoch 8006: train loss = 4.060252, test loss = 12133.755753\n",
            "Epoch 8007: train loss = 4.060231, test loss = 12133.738701\n",
            "Epoch 8008: train loss = 4.060214, test loss = 12133.714583\n",
            "Epoch 8009: train loss = 4.060228, test loss = 12133.693271\n",
            "Epoch 8010: train loss = 4.060206, test loss = 12133.665971\n",
            "Epoch 8011: train loss = 4.060198, test loss = 12133.636843\n",
            "Epoch 8012: train loss = 4.060204, test loss = 12133.614810\n",
            "Epoch 8013: train loss = 4.060182, test loss = 12133.587636\n",
            "Epoch 8014: train loss = 4.060181, test loss = 12133.556531\n",
            "Epoch 8015: train loss = 4.060180, test loss = 12133.535911\n",
            "Epoch 8016: train loss = 4.060158, test loss = 12133.509488\n",
            "Epoch 8017: train loss = 4.060164, test loss = 12133.477573\n",
            "Epoch 8018: train loss = 4.060156, test loss = 12133.458090\n",
            "Epoch 8019: train loss = 4.060134, test loss = 12133.431919\n",
            "Epoch 8020: train loss = 4.060147, test loss = 12133.398454\n",
            "Epoch 8021: train loss = 4.060132, test loss = 12133.380082\n",
            "Epoch 8022: train loss = 4.060112, test loss = 12133.364247\n",
            "Epoch 8023: train loss = 4.060108, test loss = 12133.341060\n",
            "Epoch 8024: train loss = 4.060112, test loss = 12133.309370\n",
            "Epoch 8025: train loss = 4.060106, test loss = 12133.290052\n",
            "Epoch 8026: train loss = 4.060083, test loss = 12133.264003\n",
            "Epoch 8027: train loss = 4.060095, test loss = 12133.230805\n",
            "Epoch 8028: train loss = 4.060082, test loss = 12133.212736\n",
            "Epoch 8029: train loss = 4.060060, test loss = 12133.196873\n",
            "Epoch 8030: train loss = 4.060058, test loss = 12133.172761\n",
            "Epoch 8031: train loss = 4.060060, test loss = 12133.141447\n",
            "Epoch 8032: train loss = 4.060055, test loss = 12133.122042\n",
            "Epoch 8033: train loss = 4.060033, test loss = 12133.096002\n",
            "Epoch 8034: train loss = 4.060043, test loss = 12133.063323\n",
            "Epoch 8035: train loss = 4.060032, test loss = 12133.044407\n",
            "Epoch 8036: train loss = 4.060009, test loss = 12133.018685\n",
            "Epoch 8037: train loss = 4.060025, test loss = 12132.984234\n",
            "Epoch 8038: train loss = 4.060008, test loss = 12132.966735\n",
            "Epoch 8039: train loss = 4.059987, test loss = 12132.943208\n",
            "Epoch 8040: train loss = 4.060005, test loss = 12132.921757\n",
            "Epoch 8041: train loss = 4.059982, test loss = 12132.893923\n",
            "Epoch 8042: train loss = 4.059971, test loss = 12132.864975\n",
            "Epoch 8043: train loss = 4.059981, test loss = 12132.842614\n",
            "Epoch 8044: train loss = 4.059958, test loss = 12132.815305\n",
            "Epoch 8045: train loss = 4.059954, test loss = 12132.784805\n",
            "Epoch 8046: train loss = 4.059957, test loss = 12132.764308\n",
            "Epoch 8047: train loss = 4.059934, test loss = 12132.737392\n",
            "Epoch 8048: train loss = 4.059938, test loss = 12132.705545\n",
            "Epoch 8049: train loss = 4.059933, test loss = 12132.685810\n",
            "Epoch 8050: train loss = 4.059910, test loss = 12132.659583\n",
            "Epoch 8051: train loss = 4.059920, test loss = 12132.627103\n",
            "Epoch 8052: train loss = 4.059909, test loss = 12132.608164\n",
            "Epoch 8053: train loss = 4.059887, test loss = 12132.592206\n",
            "Epoch 8054: train loss = 4.059885, test loss = 12132.568172\n",
            "Epoch 8055: train loss = 4.059885, test loss = 12132.537561\n",
            "Epoch 8056: train loss = 4.059882, test loss = 12132.517751\n",
            "Epoch 8057: train loss = 4.059860, test loss = 12132.492083\n",
            "Epoch 8058: train loss = 4.059868, test loss = 12132.459114\n",
            "Epoch 8059: train loss = 4.059858, test loss = 12132.440201\n",
            "Epoch 8060: train loss = 4.059836, test loss = 12132.414402\n",
            "Epoch 8061: train loss = 4.059851, test loss = 12132.380547\n",
            "Epoch 8062: train loss = 4.059834, test loss = 12132.362622\n",
            "Epoch 8063: train loss = 4.059814, test loss = 12132.347411\n",
            "Epoch 8064: train loss = 4.059810, test loss = 12132.323635\n",
            "Epoch 8065: train loss = 4.059816, test loss = 12132.291627\n",
            "Epoch 8066: train loss = 4.059808, test loss = 12132.272641\n",
            "Epoch 8067: train loss = 4.059786, test loss = 12132.246991\n",
            "Epoch 8068: train loss = 4.059799, test loss = 12132.213125\n",
            "Epoch 8069: train loss = 4.059784, test loss = 12132.195480\n",
            "Epoch 8070: train loss = 4.059762, test loss = 12132.170058\n",
            "Epoch 8071: train loss = 4.059781, test loss = 12132.134742\n",
            "Epoch 8072: train loss = 4.059760, test loss = 12132.117618\n",
            "Epoch 8073: train loss = 4.059743, test loss = 12132.093731\n",
            "Epoch 8074: train loss = 4.059757, test loss = 12132.072797\n",
            "Epoch 8075: train loss = 4.059735, test loss = 12132.045192\n",
            "Epoch 8076: train loss = 4.059727, test loss = 12132.015653\n",
            "Epoch 8077: train loss = 4.059733, test loss = 12131.993808\n",
            "Epoch 8078: train loss = 4.059711, test loss = 12131.966557\n",
            "Epoch 8079: train loss = 4.059710, test loss = 12131.935604\n",
            "Epoch 8080: train loss = 4.059709, test loss = 12131.915533\n",
            "Epoch 8081: train loss = 4.059687, test loss = 12131.888699\n",
            "Epoch 8082: train loss = 4.059693, test loss = 12131.856494\n",
            "Epoch 8083: train loss = 4.059685, test loss = 12131.836943\n",
            "Epoch 8084: train loss = 4.059663, test loss = 12131.811070\n",
            "Epoch 8085: train loss = 4.059676, test loss = 12131.777551\n",
            "Epoch 8086: train loss = 4.059662, test loss = 12131.759748\n",
            "Epoch 8087: train loss = 4.059642, test loss = 12131.743508\n",
            "Epoch 8088: train loss = 4.059637, test loss = 12131.719775\n",
            "Epoch 8089: train loss = 4.059641, test loss = 12131.688500\n",
            "Epoch 8090: train loss = 4.059635, test loss = 12131.669123\n",
            "Epoch 8091: train loss = 4.059613, test loss = 12131.643372\n",
            "Epoch 8092: train loss = 4.059624, test loss = 12131.610412\n",
            "Epoch 8093: train loss = 4.059611, test loss = 12131.591759\n",
            "Epoch 8094: train loss = 4.059589, test loss = 12131.575950\n",
            "Epoch 8095: train loss = 4.059587, test loss = 12131.551992\n",
            "Epoch 8096: train loss = 4.059589, test loss = 12131.520667\n",
            "Epoch 8097: train loss = 4.059585, test loss = 12131.501801\n",
            "Epoch 8098: train loss = 4.059562, test loss = 12131.475457\n",
            "Epoch 8099: train loss = 4.059572, test loss = 12131.442177\n",
            "Epoch 8100: train loss = 4.059561, test loss = 12131.423486\n",
            "Epoch 8101: train loss = 4.059538, test loss = 12131.398022\n",
            "Epoch 8102: train loss = 4.059554, test loss = 12131.363506\n",
            "Epoch 8103: train loss = 4.059537, test loss = 12131.346551\n",
            "Epoch 8104: train loss = 4.059516, test loss = 12131.322785\n",
            "Epoch 8105: train loss = 4.059534, test loss = 12131.300718\n",
            "Epoch 8106: train loss = 4.059512, test loss = 12131.273079\n",
            "Epoch 8107: train loss = 4.059500, test loss = 12131.244218\n",
            "Epoch 8108: train loss = 4.059510, test loss = 12131.222070\n",
            "Epoch 8109: train loss = 4.059488, test loss = 12131.195041\n",
            "Epoch 8110: train loss = 4.059484, test loss = 12131.164472\n",
            "Epoch 8111: train loss = 4.059486, test loss = 12131.143304\n",
            "Epoch 8112: train loss = 4.059464, test loss = 12131.116636\n",
            "Epoch 8113: train loss = 4.059467, test loss = 12131.084932\n",
            "Epoch 8114: train loss = 4.059462, test loss = 12131.065119\n",
            "Epoch 8115: train loss = 4.059440, test loss = 12131.039384\n",
            "Epoch 8116: train loss = 4.059450, test loss = 12131.006367\n",
            "Epoch 8117: train loss = 4.059438, test loss = 12130.987525\n",
            "Epoch 8118: train loss = 4.059417, test loss = 12130.971557\n",
            "Epoch 8119: train loss = 4.059414, test loss = 12130.947649\n",
            "Epoch 8120: train loss = 4.059415, test loss = 12130.917374\n",
            "Epoch 8121: train loss = 4.059412, test loss = 12130.897515\n",
            "Epoch 8122: train loss = 4.059390, test loss = 12130.871203\n",
            "Epoch 8123: train loss = 4.059398, test loss = 12130.838499\n",
            "Epoch 8124: train loss = 4.059388, test loss = 12130.819546\n",
            "Epoch 8125: train loss = 4.059365, test loss = 12130.793973\n",
            "Epoch 8126: train loss = 4.059381, test loss = 12130.760500\n",
            "Epoch 8127: train loss = 4.059364, test loss = 12130.742314\n",
            "Epoch 8128: train loss = 4.059344, test loss = 12130.726668\n",
            "Epoch 8129: train loss = 4.059340, test loss = 12130.702927\n",
            "Epoch 8130: train loss = 4.059345, test loss = 12130.671191\n",
            "Epoch 8131: train loss = 4.059338, test loss = 12130.652197\n",
            "Epoch 8132: train loss = 4.059315, test loss = 12130.627002\n",
            "Epoch 8133: train loss = 4.059328, test loss = 12130.592823\n",
            "Epoch 8134: train loss = 4.059314, test loss = 12130.574725\n",
            "Epoch 8135: train loss = 4.059291, test loss = 12130.549458\n",
            "Epoch 8136: train loss = 4.059311, test loss = 12130.514282\n",
            "Epoch 8137: train loss = 4.059290, test loss = 12130.497739\n",
            "Epoch 8138: train loss = 4.059273, test loss = 12130.473513\n",
            "Epoch 8139: train loss = 4.059287, test loss = 12130.452077\n",
            "Epoch 8140: train loss = 4.059265, test loss = 12130.424654\n",
            "Epoch 8141: train loss = 4.059257, test loss = 12130.395190\n",
            "Epoch 8142: train loss = 4.059263, test loss = 12130.373404\n",
            "Epoch 8143: train loss = 4.059241, test loss = 12130.346732\n",
            "Epoch 8144: train loss = 4.059240, test loss = 12130.315445\n",
            "Epoch 8145: train loss = 4.059239, test loss = 12130.294934\n",
            "Epoch 8146: train loss = 4.059217, test loss = 12130.268224\n",
            "Epoch 8147: train loss = 4.059223, test loss = 12130.236089\n",
            "Epoch 8148: train loss = 4.059215, test loss = 12130.216592\n",
            "Epoch 8149: train loss = 4.059193, test loss = 12130.191186\n",
            "Epoch 8150: train loss = 4.059206, test loss = 12130.157573\n",
            "Epoch 8151: train loss = 4.059191, test loss = 12130.139039\n",
            "Epoch 8152: train loss = 4.059172, test loss = 12130.123166\n",
            "Epoch 8153: train loss = 4.059167, test loss = 12130.099371\n",
            "Epoch 8154: train loss = 4.059171, test loss = 12130.068317\n",
            "Epoch 8155: train loss = 4.059165, test loss = 12130.049352\n",
            "Epoch 8156: train loss = 4.059143, test loss = 12130.023239\n",
            "Epoch 8157: train loss = 4.059154, test loss = 12129.989802\n",
            "Epoch 8158: train loss = 4.059141, test loss = 12129.971346\n",
            "Epoch 8159: train loss = 4.059119, test loss = 12129.955733\n",
            "Epoch 8160: train loss = 4.059117, test loss = 12129.931699\n",
            "Epoch 8161: train loss = 4.059119, test loss = 12129.901032\n",
            "Epoch 8162: train loss = 4.059115, test loss = 12129.881283\n",
            "Epoch 8163: train loss = 4.059092, test loss = 12129.855274\n",
            "Epoch 8164: train loss = 4.059102, test loss = 12129.821968\n",
            "Epoch 8165: train loss = 4.059091, test loss = 12129.803404\n",
            "Epoch 8166: train loss = 4.059068, test loss = 12129.778264\n",
            "Epoch 8167: train loss = 4.059085, test loss = 12129.743655\n",
            "Epoch 8168: train loss = 4.059067, test loss = 12129.725999\n",
            "Epoch 8169: train loss = 4.059046, test loss = 12129.702571\n",
            "Epoch 8170: train loss = 4.059064, test loss = 12129.680532\n",
            "Epoch 8171: train loss = 4.059042, test loss = 12129.652942\n",
            "Epoch 8172: train loss = 4.059030, test loss = 12129.624683\n",
            "Epoch 8173: train loss = 4.059040, test loss = 12129.602101\n",
            "Epoch 8174: train loss = 4.059018, test loss = 12129.574625\n",
            "Epoch 8175: train loss = 4.059014, test loss = 12129.544191\n",
            "Epoch 8176: train loss = 4.059016, test loss = 12129.523225\n",
            "Epoch 8177: train loss = 4.058994, test loss = 12129.496500\n",
            "Epoch 8178: train loss = 4.058997, test loss = 12129.465341\n",
            "Epoch 8179: train loss = 4.058992, test loss = 12129.445394\n",
            "Epoch 8180: train loss = 4.058970, test loss = 12129.418990\n",
            "Epoch 8181: train loss = 4.058980, test loss = 12129.386123\n",
            "Epoch 8182: train loss = 4.058969, test loss = 12129.367387\n",
            "Epoch 8183: train loss = 4.058947, test loss = 12129.351567\n",
            "Epoch 8184: train loss = 4.058944, test loss = 12129.328011\n",
            "Epoch 8185: train loss = 4.058945, test loss = 12129.297287\n",
            "Epoch 8186: train loss = 4.058942, test loss = 12129.277370\n",
            "Epoch 8187: train loss = 4.058920, test loss = 12129.251130\n",
            "Epoch 8188: train loss = 4.058928, test loss = 12129.218525\n",
            "Epoch 8189: train loss = 4.058918, test loss = 12129.200129\n",
            "Epoch 8190: train loss = 4.058896, test loss = 12129.174144\n",
            "Epoch 8191: train loss = 4.058911, test loss = 12129.140244\n",
            "Epoch 8192: train loss = 4.058894, test loss = 12129.122226\n",
            "Epoch 8193: train loss = 4.058874, test loss = 12129.106558\n",
            "Epoch 8194: train loss = 4.058870, test loss = 12129.083015\n",
            "Epoch 8195: train loss = 4.058876, test loss = 12129.051708\n",
            "Epoch 8196: train loss = 4.058868, test loss = 12129.032520\n",
            "Epoch 8197: train loss = 4.058846, test loss = 12129.006699\n",
            "Epoch 8198: train loss = 4.058858, test loss = 12128.972891\n",
            "Epoch 8199: train loss = 4.058844, test loss = 12128.954733\n",
            "Epoch 8200: train loss = 4.058822, test loss = 12128.939477\n",
            "Epoch 8201: train loss = 4.058820, test loss = 12128.915931\n",
            "Epoch 8202: train loss = 4.058823, test loss = 12128.883845\n",
            "Epoch 8203: train loss = 4.058818, test loss = 12128.864731\n",
            "Epoch 8204: train loss = 4.058795, test loss = 12128.838862\n",
            "Epoch 8205: train loss = 4.058806, test loss = 12128.805092\n",
            "Epoch 8206: train loss = 4.058794, test loss = 12128.787006\n",
            "Epoch 8207: train loss = 4.058772, test loss = 12128.762006\n",
            "Epoch 8208: train loss = 4.058789, test loss = 12128.726784\n",
            "Epoch 8209: train loss = 4.058770, test loss = 12128.709519\n",
            "Epoch 8210: train loss = 4.058751, test loss = 12128.685805\n",
            "Epoch 8211: train loss = 4.058767, test loss = 12128.664030\n",
            "Epoch 8212: train loss = 4.058745, test loss = 12128.637276\n",
            "Epoch 8213: train loss = 4.058735, test loss = 12128.607612\n",
            "Epoch 8214: train loss = 4.058744, test loss = 12128.585617\n",
            "Epoch 8215: train loss = 4.058721, test loss = 12128.558241\n",
            "Epoch 8216: train loss = 4.058718, test loss = 12128.527490\n",
            "Epoch 8217: train loss = 4.058720, test loss = 12128.506739\n",
            "Epoch 8218: train loss = 4.058697, test loss = 12128.480725\n",
            "Epoch 8219: train loss = 4.058702, test loss = 12128.448357\n",
            "Epoch 8220: train loss = 4.058696, test loss = 12128.428779\n",
            "Epoch 8221: train loss = 4.058673, test loss = 12128.402629\n",
            "Epoch 8222: train loss = 4.058685, test loss = 12128.369457\n",
            "Epoch 8223: train loss = 4.058672, test loss = 12128.350917\n",
            "Epoch 8224: train loss = 4.058650, test loss = 12128.335868\n",
            "Epoch 8225: train loss = 4.058648, test loss = 12128.311585\n",
            "Epoch 8226: train loss = 4.058650, test loss = 12128.280412\n",
            "Epoch 8227: train loss = 4.058646, test loss = 12128.260870\n",
            "Epoch 8228: train loss = 4.058623, test loss = 12128.234897\n",
            "Epoch 8229: train loss = 4.058632, test loss = 12128.201844\n",
            "Epoch 8230: train loss = 4.058622, test loss = 12128.183674\n",
            "Epoch 8231: train loss = 4.058599, test loss = 12128.157908\n",
            "Epoch 8232: train loss = 4.058615, test loss = 12128.123382\n",
            "Epoch 8233: train loss = 4.058598, test loss = 12128.105895\n",
            "Epoch 8234: train loss = 4.058577, test loss = 12128.090384\n",
            "Epoch 8235: train loss = 4.058574, test loss = 12128.067279\n",
            "Epoch 8236: train loss = 4.058580, test loss = 12128.034666\n",
            "Epoch 8237: train loss = 4.058572, test loss = 12128.016002\n",
            "Epoch 8238: train loss = 4.058549, test loss = 12127.990348\n",
            "Epoch 8239: train loss = 4.058563, test loss = 12127.956057\n",
            "Epoch 8240: train loss = 4.058548, test loss = 12127.938317\n",
            "Epoch 8241: train loss = 4.058526, test loss = 12127.905589\n",
            "Epoch 8242: train loss = 4.058525, test loss = 12127.879702\n",
            "Epoch 8243: train loss = 4.058526, test loss = 12127.848461\n",
            "Epoch 8244: train loss = 4.058523, test loss = 12127.828108\n",
            "Epoch 8245: train loss = 4.058501, test loss = 12127.801387\n",
            "Epoch 8246: train loss = 4.058510, test loss = 12127.768667\n",
            "Epoch 8247: train loss = 4.058500, test loss = 12127.749902\n",
            "Epoch 8248: train loss = 4.058478, test loss = 12127.733344\n",
            "Epoch 8249: train loss = 4.058476, test loss = 12127.709064\n",
            "Epoch 8250: train loss = 4.058475, test loss = 12127.678461\n",
            "Epoch 8251: train loss = 4.058473, test loss = 12127.658537\n",
            "Epoch 8252: train loss = 4.058451, test loss = 12127.632075\n",
            "Epoch 8253: train loss = 4.058458, test loss = 12127.600089\n",
            "Epoch 8254: train loss = 4.058450, test loss = 12127.580633\n",
            "Epoch 8255: train loss = 4.058427, test loss = 12127.554713\n",
            "Epoch 8256: train loss = 4.058441, test loss = 12127.520966\n",
            "Epoch 8257: train loss = 4.058426, test loss = 12127.502763\n",
            "Epoch 8258: train loss = 4.058406, test loss = 12127.487121\n",
            "Epoch 8259: train loss = 4.058402, test loss = 12127.463796\n",
            "Epoch 8260: train loss = 4.058406, test loss = 12127.432091\n",
            "Epoch 8261: train loss = 4.058400, test loss = 12127.412819\n",
            "Epoch 8262: train loss = 4.058377, test loss = 12127.386964\n",
            "Epoch 8263: train loss = 4.058389, test loss = 12127.353293\n",
            "Epoch 8264: train loss = 4.058376, test loss = 12127.335607\n",
            "Epoch 8265: train loss = 4.058353, test loss = 12127.309867\n",
            "Epoch 8266: train loss = 4.058372, test loss = 12127.275066\n",
            "Epoch 8267: train loss = 4.058352, test loss = 12127.257673\n",
            "Epoch 8268: train loss = 4.058334, test loss = 12127.234071\n",
            "Epoch 8269: train loss = 4.058349, test loss = 12127.212295\n",
            "Epoch 8270: train loss = 4.058327, test loss = 12127.185455\n",
            "Epoch 8271: train loss = 4.058318, test loss = 12127.156020\n",
            "Epoch 8272: train loss = 4.058325, test loss = 12127.133887\n",
            "Epoch 8273: train loss = 4.058303, test loss = 12127.106638\n",
            "Epoch 8274: train loss = 4.058301, test loss = 12127.075836\n",
            "Epoch 8275: train loss = 4.058301, test loss = 12127.055281\n",
            "Epoch 8276: train loss = 4.058279, test loss = 12127.029014\n",
            "Epoch 8277: train loss = 4.058284, test loss = 12126.996873\n",
            "Epoch 8278: train loss = 4.058277, test loss = 12126.977165\n",
            "Epoch 8279: train loss = 4.058255, test loss = 12126.951144\n",
            "Epoch 8280: train loss = 4.058267, test loss = 12126.918016\n",
            "Epoch 8281: train loss = 4.058254, test loss = 12126.899956\n",
            "Epoch 8282: train loss = 4.058234, test loss = 12126.883761\n",
            "Epoch 8283: train loss = 4.058229, test loss = 12126.859847\n",
            "Epoch 8284: train loss = 4.058232, test loss = 12126.828982\n",
            "Epoch 8285: train loss = 4.058227, test loss = 12126.809470\n",
            "Epoch 8286: train loss = 4.058205, test loss = 12126.783519\n",
            "Epoch 8287: train loss = 4.058215, test loss = 12126.750883\n",
            "Epoch 8288: train loss = 4.058203, test loss = 12126.732131\n",
            "Epoch 8289: train loss = 4.058181, test loss = 12126.716316\n",
            "Epoch 8290: train loss = 4.058179, test loss = 12126.692223\n",
            "Epoch 8291: train loss = 4.058180, test loss = 12126.661316\n",
            "Epoch 8292: train loss = 4.058177, test loss = 12126.641705\n",
            "Epoch 8293: train loss = 4.058155, test loss = 12126.616231\n",
            "Epoch 8294: train loss = 4.058163, test loss = 12126.582926\n",
            "Epoch 8295: train loss = 4.058153, test loss = 12126.564197\n",
            "Epoch 8296: train loss = 4.058131, test loss = 12126.538461\n",
            "Epoch 8297: train loss = 4.058146, test loss = 12126.504316\n",
            "Epoch 8298: train loss = 4.058129, test loss = 12126.486614\n",
            "Epoch 8299: train loss = 4.058109, test loss = 12126.471731\n",
            "Epoch 8300: train loss = 4.058105, test loss = 12126.447731\n",
            "Epoch 8301: train loss = 4.058111, test loss = 12126.415542\n",
            "Epoch 8302: train loss = 4.058103, test loss = 12126.396709\n",
            "Epoch 8303: train loss = 4.058081, test loss = 12126.371064\n",
            "Epoch 8304: train loss = 4.058094, test loss = 12126.337508\n",
            "Epoch 8305: train loss = 4.058080, test loss = 12126.319313\n",
            "Epoch 8306: train loss = 4.058057, test loss = 12126.294006\n",
            "Epoch 8307: train loss = 4.058077, test loss = 12126.258609\n",
            "Epoch 8308: train loss = 4.058056, test loss = 12126.241829\n",
            "Epoch 8309: train loss = 4.058039, test loss = 12126.217726\n",
            "Epoch 8310: train loss = 4.058053, test loss = 12126.196891\n",
            "Epoch 8311: train loss = 4.058031, test loss = 12126.169371\n",
            "Epoch 8312: train loss = 4.058023, test loss = 12126.139668\n",
            "Epoch 8313: train loss = 4.058029, test loss = 12126.118035\n",
            "Epoch 8314: train loss = 4.058007, test loss = 12126.090828\n",
            "Epoch 8315: train loss = 4.058006, test loss = 12126.059872\n",
            "Epoch 8316: train loss = 4.058005, test loss = 12126.039765\n",
            "Epoch 8317: train loss = 4.057983, test loss = 12126.012970\n",
            "Epoch 8318: train loss = 4.057990, test loss = 12125.980558\n",
            "Epoch 8319: train loss = 4.057982, test loss = 12125.961318\n",
            "Epoch 8320: train loss = 4.057959, test loss = 12125.935327\n",
            "Epoch 8321: train loss = 4.057972, test loss = 12125.901820\n",
            "Epoch 8322: train loss = 4.057958, test loss = 12125.884163\n",
            "Epoch 8323: train loss = 4.057937, test loss = 12125.868056\n",
            "Epoch 8324: train loss = 4.057934, test loss = 12125.844356\n",
            "Epoch 8325: train loss = 4.057937, test loss = 12125.812774\n",
            "Epoch 8326: train loss = 4.057931, test loss = 12125.793561\n",
            "Epoch 8327: train loss = 4.057909, test loss = 12125.768193\n",
            "Epoch 8328: train loss = 4.057920, test loss = 12125.734547\n",
            "Epoch 8329: train loss = 4.057908, test loss = 12125.716065\n",
            "Epoch 8330: train loss = 4.057885, test loss = 12125.690717\n",
            "Epoch 8331: train loss = 4.057903, test loss = 12125.655925\n",
            "Epoch 8332: train loss = 4.057884, test loss = 12125.638601\n",
            "Epoch 8333: train loss = 4.057865, test loss = 12125.615568\n",
            "Epoch 8334: train loss = 4.057881, test loss = 12125.593545\n",
            "Epoch 8335: train loss = 4.057859, test loss = 12125.565950\n",
            "Epoch 8336: train loss = 4.057849, test loss = 12125.536975\n",
            "Epoch 8337: train loss = 4.057857, test loss = 12125.514830\n",
            "Epoch 8338: train loss = 4.057835, test loss = 12125.487492\n",
            "Epoch 8339: train loss = 4.057833, test loss = 12125.457493\n",
            "Epoch 8340: train loss = 4.057833, test loss = 12125.436441\n",
            "Epoch 8341: train loss = 4.057811, test loss = 12125.409599\n",
            "Epoch 8342: train loss = 4.057816, test loss = 12125.377895\n",
            "Epoch 8343: train loss = 4.057810, test loss = 12125.358168\n",
            "Epoch 8344: train loss = 4.057787, test loss = 12125.332060\n",
            "Epoch 8345: train loss = 4.057799, test loss = 12125.299566\n",
            "Epoch 8346: train loss = 4.057786, test loss = 12125.280839\n",
            "Epoch 8347: train loss = 4.057766, test loss = 12125.264648\n",
            "Epoch 8348: train loss = 4.057762, test loss = 12125.240917\n",
            "Epoch 8349: train loss = 4.057764, test loss = 12125.210176\n",
            "Epoch 8350: train loss = 4.057759, test loss = 12125.191033\n",
            "Epoch 8351: train loss = 4.057737, test loss = 12125.164880\n",
            "Epoch 8352: train loss = 4.057747, test loss = 12125.131748\n",
            "Epoch 8353: train loss = 4.057736, test loss = 12125.113023\n",
            "Epoch 8354: train loss = 4.057714, test loss = 12125.097322\n",
            "Epoch 8355: train loss = 4.057711, test loss = 12125.073393\n",
            "Epoch 8356: train loss = 4.057712, test loss = 12125.043020\n",
            "Epoch 8357: train loss = 4.057709, test loss = 12125.023230\n",
            "Epoch 8358: train loss = 4.057687, test loss = 12124.996907\n",
            "Epoch 8359: train loss = 4.057695, test loss = 12124.963986\n",
            "Epoch 8360: train loss = 4.057686, test loss = 12124.945295\n",
            "Epoch 8361: train loss = 4.057663, test loss = 12124.919699\n",
            "Epoch 8362: train loss = 4.057678, test loss = 12124.886015\n",
            "Epoch 8363: train loss = 4.057662, test loss = 12124.868182\n",
            "Epoch 8364: train loss = 4.057641, test loss = 12124.852467\n",
            "Epoch 8365: train loss = 4.057638, test loss = 12124.828824\n",
            "Epoch 8366: train loss = 4.057643, test loss = 12124.796792\n",
            "Epoch 8367: train loss = 4.057636, test loss = 12124.778026\n",
            "Epoch 8368: train loss = 4.057613, test loss = 12124.752711\n",
            "Epoch 8369: train loss = 4.057626, test loss = 12124.718652\n",
            "Epoch 8370: train loss = 4.057612, test loss = 12124.700518\n",
            "Epoch 8371: train loss = 4.057589, test loss = 12124.675255\n",
            "Epoch 8372: train loss = 4.057609, test loss = 12124.640002\n",
            "Epoch 8373: train loss = 4.057588, test loss = 12124.623147\n",
            "Epoch 8374: train loss = 4.057571, test loss = 12124.599682\n",
            "Epoch 8375: train loss = 4.057585, test loss = 12124.577932\n",
            "Epoch 8376: train loss = 4.057563, test loss = 12124.550653\n",
            "Epoch 8377: train loss = 4.057555, test loss = 12124.520997\n",
            "Epoch 8378: train loss = 4.057561, test loss = 12124.499445\n",
            "Epoch 8379: train loss = 4.057539, test loss = 12124.472661\n",
            "Epoch 8380: train loss = 4.057538, test loss = 12124.441446\n",
            "Epoch 8381: train loss = 4.057538, test loss = 12124.420748\n",
            "Epoch 8382: train loss = 4.057515, test loss = 12124.394255\n",
            "Epoch 8383: train loss = 4.057522, test loss = 12124.362076\n",
            "Epoch 8384: train loss = 4.057514, test loss = 12124.342652\n",
            "Epoch 8385: train loss = 4.057492, test loss = 12124.317249\n",
            "Epoch 8386: train loss = 4.057505, test loss = 12124.283450\n",
            "Epoch 8387: train loss = 4.057490, test loss = 12124.265265\n",
            "Epoch 8388: train loss = 4.057470, test loss = 12124.249332\n",
            "Epoch 8389: train loss = 4.057466, test loss = 12124.225639\n",
            "Epoch 8390: train loss = 4.057470, test loss = 12124.194313\n",
            "Epoch 8391: train loss = 4.057464, test loss = 12124.175576\n",
            "Epoch 8392: train loss = 4.057442, test loss = 12124.149448\n",
            "Epoch 8393: train loss = 4.057453, test loss = 12124.115979\n",
            "Epoch 8394: train loss = 4.057440, test loss = 12124.097589\n",
            "Epoch 8395: train loss = 4.057418, test loss = 12124.072051\n",
            "Epoch 8396: train loss = 4.057436, test loss = 12124.037621\n",
            "Epoch 8397: train loss = 4.057416, test loss = 12124.020640\n",
            "Epoch 8398: train loss = 4.057398, test loss = 12123.996955\n",
            "Epoch 8399: train loss = 4.057414, test loss = 12123.974910\n",
            "Epoch 8400: train loss = 4.057391, test loss = 12123.947555\n",
            "Epoch 8401: train loss = 4.057382, test loss = 12123.918553\n",
            "Epoch 8402: train loss = 4.057390, test loss = 12123.896854\n",
            "Epoch 8403: train loss = 4.057367, test loss = 12123.869330\n",
            "Epoch 8404: train loss = 4.057365, test loss = 12123.838707\n",
            "Epoch 8405: train loss = 4.057366, test loss = 12123.817922\n",
            "Epoch 8406: train loss = 4.057344, test loss = 12123.791138\n",
            "Epoch 8407: train loss = 4.057348, test loss = 12123.759540\n",
            "Epoch 8408: train loss = 4.057342, test loss = 12123.740222\n",
            "Epoch 8409: train loss = 4.057320, test loss = 12123.713945\n",
            "Epoch 8410: train loss = 4.057332, test loss = 12123.680886\n",
            "Epoch 8411: train loss = 4.057318, test loss = 12123.662367\n",
            "Epoch 8412: train loss = 4.057299, test loss = 12123.646237\n",
            "Epoch 8413: train loss = 4.057294, test loss = 12123.622546\n",
            "Epoch 8414: train loss = 4.057297, test loss = 12123.592264\n",
            "Epoch 8415: train loss = 4.057292, test loss = 12123.572503\n",
            "Epoch 8416: train loss = 4.057270, test loss = 12123.546383\n",
            "Epoch 8417: train loss = 4.057280, test loss = 12123.513498\n",
            "Epoch 8418: train loss = 4.057268, test loss = 12123.494818\n",
            "Epoch 8419: train loss = 4.057246, test loss = 12123.478992\n",
            "Epoch 8420: train loss = 4.057244, test loss = 12123.455612\n",
            "Epoch 8421: train loss = 4.057245, test loss = 12123.424579\n",
            "Epoch 8422: train loss = 4.057242, test loss = 12123.404808\n",
            "Epoch 8423: train loss = 4.057220, test loss = 12123.378578\n",
            "Epoch 8424: train loss = 4.057228, test loss = 12123.345944\n",
            "Epoch 8425: train loss = 4.057218, test loss = 12123.327597\n",
            "Epoch 8426: train loss = 4.057196, test loss = 12123.301598\n",
            "Epoch 8427: train loss = 4.057211, test loss = 12123.267597\n",
            "Epoch 8428: train loss = 4.057195, test loss = 12123.249671\n",
            "Epoch 8429: train loss = 4.057174, test loss = 12123.234290\n",
            "Epoch 8430: train loss = 4.057171, test loss = 12123.210541\n",
            "Epoch 8431: train loss = 4.057176, test loss = 12123.179198\n",
            "Epoch 8432: train loss = 4.057169, test loss = 12123.159998\n",
            "Epoch 8433: train loss = 4.057146, test loss = 12123.134217\n",
            "Epoch 8434: train loss = 4.057159, test loss = 12123.100403\n",
            "Epoch 8435: train loss = 4.057145, test loss = 12123.082300\n",
            "Epoch 8436: train loss = 4.057122, test loss = 12123.057169\n",
            "Epoch 8437: train loss = 4.057142, test loss = 12123.022424\n",
            "Epoch 8438: train loss = 4.057121, test loss = 12123.005149\n",
            "Epoch 8439: train loss = 4.057104, test loss = 12122.981212\n",
            "Epoch 8440: train loss = 4.057118, test loss = 12122.959752\n",
            "Epoch 8441: train loss = 4.057096, test loss = 12122.932478\n",
            "Epoch 8442: train loss = 4.057088, test loss = 12122.903023\n",
            "Epoch 8443: train loss = 4.057094, test loss = 12122.881797\n",
            "Epoch 8444: train loss = 4.057072, test loss = 12122.854357\n",
            "Epoch 8445: train loss = 4.057071, test loss = 12122.823405\n",
            "Epoch 8446: train loss = 4.057071, test loss = 12122.802703\n",
            "Epoch 8447: train loss = 4.057048, test loss = 12122.776117\n",
            "Epoch 8448: train loss = 4.057055, test loss = 12122.744504\n",
            "Epoch 8449: train loss = 4.057047, test loss = 12122.724900\n",
            "Epoch 8450: train loss = 4.057025, test loss = 12122.698776\n",
            "Epoch 8451: train loss = 4.057038, test loss = 12122.665523\n",
            "Epoch 8452: train loss = 4.057023, test loss = 12122.647103\n",
            "Epoch 8453: train loss = 4.057003, test loss = 12122.631258\n",
            "Epoch 8454: train loss = 4.056999, test loss = 12122.608058\n",
            "Epoch 8455: train loss = 4.057003, test loss = 12122.576651\n",
            "Epoch 8456: train loss = 4.056997, test loss = 12122.557183\n",
            "Epoch 8457: train loss = 4.056975, test loss = 12122.531366\n",
            "Epoch 8458: train loss = 4.056986, test loss = 12122.498036\n",
            "Epoch 8459: train loss = 4.056973, test loss = 12122.479563\n",
            "Epoch 8460: train loss = 4.056951, test loss = 12122.454619\n",
            "Epoch 8461: train loss = 4.056969, test loss = 12122.419944\n",
            "Epoch 8462: train loss = 4.056950, test loss = 12122.402337\n",
            "Epoch 8463: train loss = 4.056931, test loss = 12122.386802\n",
            "Epoch 8464: train loss = 4.056925, test loss = 12122.363400\n",
            "Epoch 8465: train loss = 4.056934, test loss = 12122.330988\n",
            "Epoch 8466: train loss = 4.056924, test loss = 12122.313107\n",
            "Epoch 8467: train loss = 4.056901, test loss = 12122.287192\n",
            "Epoch 8468: train loss = 4.056916, test loss = 12122.252731\n",
            "Epoch 8469: train loss = 4.056900, test loss = 12122.235197\n",
            "Epoch 8470: train loss = 4.056879, test loss = 12122.211768\n",
            "Epoch 8471: train loss = 4.056897, test loss = 12122.190143\n",
            "Epoch 8472: train loss = 4.056875, test loss = 12122.162293\n",
            "Epoch 8473: train loss = 4.056863, test loss = 12122.133422\n",
            "Epoch 8474: train loss = 4.056873, test loss = 12122.111013\n",
            "Epoch 8475: train loss = 4.056851, test loss = 12122.083686\n",
            "Epoch 8476: train loss = 4.056846, test loss = 12122.053459\n",
            "Epoch 8477: train loss = 4.056849, test loss = 12122.032755\n",
            "Epoch 8478: train loss = 4.056827, test loss = 12122.005919\n",
            "Epoch 8479: train loss = 4.056830, test loss = 12121.974201\n",
            "Epoch 8480: train loss = 4.056826, test loss = 12121.954304\n",
            "Epoch 8481: train loss = 4.056803, test loss = 12121.928046\n",
            "Epoch 8482: train loss = 4.056813, test loss = 12121.895441\n",
            "Epoch 8483: train loss = 4.056802, test loss = 12121.877036\n",
            "Epoch 8484: train loss = 4.056780, test loss = 12121.861138\n",
            "Epoch 8485: train loss = 4.056778, test loss = 12121.836994\n",
            "Epoch 8486: train loss = 4.056778, test loss = 12121.806419\n",
            "Epoch 8487: train loss = 4.056776, test loss = 12121.786568\n",
            "Epoch 8488: train loss = 4.056753, test loss = 12121.760495\n",
            "Epoch 8489: train loss = 4.056761, test loss = 12121.728331\n",
            "Epoch 8490: train loss = 4.056752, test loss = 12121.709323\n",
            "Epoch 8491: train loss = 4.056730, test loss = 12121.683432\n",
            "Epoch 8492: train loss = 4.056744, test loss = 12121.649615\n",
            "Epoch 8493: train loss = 4.056728, test loss = 12121.631663\n",
            "Epoch 8494: train loss = 4.056708, test loss = 12121.616656\n",
            "Epoch 8495: train loss = 4.056704, test loss = 12121.592834\n",
            "Epoch 8496: train loss = 4.056709, test loss = 12121.560853\n",
            "Epoch 8497: train loss = 4.056702, test loss = 12121.541945\n",
            "Epoch 8498: train loss = 4.056680, test loss = 12121.516123\n",
            "Epoch 8499: train loss = 4.056692, test loss = 12121.482573\n",
            "Epoch 8500: train loss = 4.056679, test loss = 12121.464866\n",
            "Epoch 8501: train loss = 4.056656, test loss = 12121.439363\n",
            "Epoch 8502: train loss = 4.056675, test loss = 12121.404241\n",
            "Epoch 8503: train loss = 4.056655, test loss = 12121.387187\n",
            "Epoch 8504: train loss = 4.056637, test loss = 12121.363418\n",
            "Epoch 8505: train loss = 4.056652, test loss = 12121.341821\n",
            "Epoch 8506: train loss = 4.056630, test loss = 12121.315128\n",
            "Epoch 8507: train loss = 4.056621, test loss = 12121.285390\n",
            "Epoch 8508: train loss = 4.056628, test loss = 12121.263649\n",
            "Epoch 8509: train loss = 4.056606, test loss = 12121.236378\n",
            "Epoch 8510: train loss = 4.056605, test loss = 12121.205542\n",
            "Epoch 8511: train loss = 4.056605, test loss = 12121.184880\n",
            "Epoch 8512: train loss = 4.056582, test loss = 12121.158914\n",
            "Epoch 8513: train loss = 4.056588, test loss = 12121.126601\n",
            "Epoch 8514: train loss = 4.056581, test loss = 12121.106981\n",
            "Epoch 8515: train loss = 4.056558, test loss = 12121.081040\n",
            "Epoch 8516: train loss = 4.056571, test loss = 12121.047704\n",
            "Epoch 8517: train loss = 4.056557, test loss = 12121.029958\n",
            "Epoch 8518: train loss = 4.056537, test loss = 12121.013778\n",
            "Epoch 8519: train loss = 4.056533, test loss = 12120.990038\n",
            "Epoch 8520: train loss = 4.056536, test loss = 12120.958786\n",
            "Epoch 8521: train loss = 4.056531, test loss = 12120.939511\n",
            "Epoch 8522: train loss = 4.056509, test loss = 12120.913571\n",
            "Epoch 8523: train loss = 4.056519, test loss = 12120.881006\n",
            "Epoch 8524: train loss = 4.056507, test loss = 12120.862170\n",
            "Epoch 8525: train loss = 4.056485, test loss = 12120.836612\n",
            "Epoch 8526: train loss = 4.056502, test loss = 12120.802116\n",
            "Epoch 8527: train loss = 4.056484, test loss = 12120.784703\n",
            "Epoch 8528: train loss = 4.056465, test loss = 12120.769186\n",
            "Epoch 8529: train loss = 4.056459, test loss = 12120.746201\n",
            "Epoch 8530: train loss = 4.056467, test loss = 12120.713705\n",
            "Epoch 8531: train loss = 4.056458, test loss = 12120.695012\n",
            "Epoch 8532: train loss = 4.056435, test loss = 12120.669543\n",
            "Epoch 8533: train loss = 4.056450, test loss = 12120.635210\n",
            "Epoch 8534: train loss = 4.056434, test loss = 12120.617585\n",
            "Epoch 8535: train loss = 4.056412, test loss = 12120.602618\n",
            "Epoch 8536: train loss = 4.056410, test loss = 12120.578758\n",
            "Epoch 8537: train loss = 4.056415, test loss = 12120.546453\n",
            "Epoch 8538: train loss = 4.056408, test loss = 12120.527577\n",
            "Epoch 8539: train loss = 4.056385, test loss = 12120.501992\n",
            "Epoch 8540: train loss = 4.056398, test loss = 12120.468256\n",
            "Epoch 8541: train loss = 4.056384, test loss = 12120.450264\n",
            "Epoch 8542: train loss = 4.056362, test loss = 12120.416809\n",
            "Epoch 8543: train loss = 4.056361, test loss = 12120.391094\n",
            "Epoch 8544: train loss = 4.056362, test loss = 12120.360079\n",
            "Epoch 8545: train loss = 4.056360, test loss = 12120.339692\n",
            "Epoch 8546: train loss = 4.056338, test loss = 12120.313602\n",
            "Epoch 8547: train loss = 4.056346, test loss = 12120.280553\n",
            "Epoch 8548: train loss = 4.056336, test loss = 12120.261142\n",
            "Epoch 8549: train loss = 4.056314, test loss = 12120.244939\n",
            "Epoch 8550: train loss = 4.056312, test loss = 12120.220830\n",
            "Epoch 8551: train loss = 4.056311, test loss = 12120.190306\n",
            "Epoch 8552: train loss = 4.056310, test loss = 12120.170671\n",
            "Epoch 8553: train loss = 4.056288, test loss = 12120.144021\n",
            "Epoch 8554: train loss = 4.056295, test loss = 12120.111548\n",
            "Epoch 8555: train loss = 4.056287, test loss = 12120.092331\n",
            "Epoch 8556: train loss = 4.056264, test loss = 12120.066431\n",
            "Epoch 8557: train loss = 4.056278, test loss = 12120.032831\n",
            "Epoch 8558: train loss = 4.056263, test loss = 12120.015088\n",
            "Epoch 8559: train loss = 4.056242, test loss = 12119.999351\n",
            "Epoch 8560: train loss = 4.056239, test loss = 12119.975416\n",
            "Epoch 8561: train loss = 4.056243, test loss = 12119.943888\n",
            "Epoch 8562: train loss = 4.056237, test loss = 12119.924662\n",
            "Epoch 8563: train loss = 4.056214, test loss = 12119.898920\n",
            "Epoch 8564: train loss = 4.056226, test loss = 12119.865805\n",
            "Epoch 8565: train loss = 4.056213, test loss = 12119.847420\n",
            "Epoch 8566: train loss = 4.056191, test loss = 12119.821802\n",
            "Epoch 8567: train loss = 4.056209, test loss = 12119.787105\n",
            "Epoch 8568: train loss = 4.056190, test loss = 12119.769766\n",
            "Epoch 8569: train loss = 4.056171, test loss = 12119.746676\n",
            "Epoch 8570: train loss = 4.056187, test loss = 12119.724779\n",
            "Epoch 8571: train loss = 4.056164, test loss = 12119.697227\n",
            "Epoch 8572: train loss = 4.056155, test loss = 12119.668139\n",
            "Epoch 8573: train loss = 4.056163, test loss = 12119.646120\n",
            "Epoch 8574: train loss = 4.056141, test loss = 12119.618816\n",
            "Epoch 8575: train loss = 4.056139, test loss = 12119.588697\n",
            "Epoch 8576: train loss = 4.056139, test loss = 12119.567720\n",
            "Epoch 8577: train loss = 4.056117, test loss = 12119.540968\n",
            "Epoch 8578: train loss = 4.056122, test loss = 12119.509196\n",
            "Epoch 8579: train loss = 4.056116, test loss = 12119.489499\n",
            "Epoch 8580: train loss = 4.056093, test loss = 12119.463491\n",
            "Epoch 8581: train loss = 4.056105, test loss = 12119.430923\n",
            "Epoch 8582: train loss = 4.056092, test loss = 12119.412222\n",
            "Epoch 8583: train loss = 4.056072, test loss = 12119.396185\n",
            "Epoch 8584: train loss = 4.056068, test loss = 12119.372476\n",
            "Epoch 8585: train loss = 4.056070, test loss = 12119.341587\n",
            "Epoch 8586: train loss = 4.056066, test loss = 12119.322063\n",
            "Epoch 8587: train loss = 4.056043, test loss = 12119.296728\n",
            "Epoch 8588: train loss = 4.056054, test loss = 12119.263387\n",
            "Epoch 8589: train loss = 4.056042, test loss = 12119.244625\n",
            "Epoch 8590: train loss = 4.056020, test loss = 12119.219157\n",
            "Epoch 8591: train loss = 4.056037, test loss = 12119.184955\n",
            "Epoch 8592: train loss = 4.056018, test loss = 12119.167752\n",
            "Epoch 8593: train loss = 4.055999, test loss = 12119.152040\n",
            "Epoch 8594: train loss = 4.055994, test loss = 12119.128408\n",
            "Epoch 8595: train loss = 4.056002, test loss = 12119.096219\n",
            "Epoch 8596: train loss = 4.055992, test loss = 12119.077642\n",
            "Epoch 8597: train loss = 4.055970, test loss = 12119.052129\n",
            "Epoch 8598: train loss = 4.055985, test loss = 12119.018435\n",
            "Epoch 8599: train loss = 4.055969, test loss = 12119.000523\n",
            "Epoch 8600: train loss = 4.055947, test loss = 12118.984917\n",
            "Epoch 8601: train loss = 4.055945, test loss = 12118.961127\n",
            "Epoch 8602: train loss = 4.055950, test loss = 12118.929140\n",
            "Epoch 8603: train loss = 4.055943, test loss = 12118.910331\n",
            "Epoch 8604: train loss = 4.055920, test loss = 12118.885046\n",
            "Epoch 8605: train loss = 4.055933, test loss = 12118.850976\n",
            "Epoch 8606: train loss = 4.055919, test loss = 12118.832785\n",
            "Epoch 8607: train loss = 4.055897, test loss = 12118.807579\n",
            "Epoch 8608: train loss = 4.055916, test loss = 12118.772312\n",
            "Epoch 8609: train loss = 4.055895, test loss = 12118.755408\n",
            "Epoch 8610: train loss = 4.055878, test loss = 12118.731853\n",
            "Epoch 8611: train loss = 4.055893, test loss = 12118.710294\n",
            "Epoch 8612: train loss = 4.055870, test loss = 12118.683007\n",
            "Epoch 8613: train loss = 4.055862, test loss = 12118.653304\n",
            "Epoch 8614: train loss = 4.055869, test loss = 12118.631813\n",
            "Epoch 8615: train loss = 4.055847, test loss = 12118.605032\n",
            "Epoch 8616: train loss = 4.055846, test loss = 12118.573772\n",
            "Epoch 8617: train loss = 4.055845, test loss = 12118.553087\n",
            "Epoch 8618: train loss = 4.055823, test loss = 12118.526658\n",
            "Epoch 8619: train loss = 4.055829, test loss = 12118.494330\n",
            "Epoch 8620: train loss = 4.055822, test loss = 12118.475159\n",
            "Epoch 8621: train loss = 4.055799, test loss = 12118.449672\n",
            "Epoch 8622: train loss = 4.055812, test loss = 12118.415992\n",
            "Epoch 8623: train loss = 4.055798, test loss = 12118.397569\n",
            "Epoch 8624: train loss = 4.055777, test loss = 12118.382002\n",
            "Epoch 8625: train loss = 4.055774, test loss = 12118.358240\n",
            "Epoch 8626: train loss = 4.055777, test loss = 12118.326828\n",
            "Epoch 8627: train loss = 4.055772, test loss = 12118.308100\n",
            "Epoch 8628: train loss = 4.055750, test loss = 12118.281931\n",
            "Epoch 8629: train loss = 4.055760, test loss = 12118.248635\n",
            "Epoch 8630: train loss = 4.055748, test loss = 12118.230118\n",
            "Epoch 8631: train loss = 4.055726, test loss = 12118.204773\n",
            "Epoch 8632: train loss = 4.055743, test loss = 12118.170128\n",
            "Epoch 8633: train loss = 4.055725, test loss = 12118.153292\n",
            "Epoch 8634: train loss = 4.055705, test loss = 12118.129610\n",
            "Epoch 8635: train loss = 4.055722, test loss = 12118.107633\n",
            "Epoch 8636: train loss = 4.055700, test loss = 12118.080250\n",
            "Epoch 8637: train loss = 4.055690, test loss = 12118.051160\n",
            "Epoch 8638: train loss = 4.055698, test loss = 12118.029769\n",
            "Epoch 8639: train loss = 4.055676, test loss = 12118.002109\n",
            "Epoch 8640: train loss = 4.055673, test loss = 12117.971562\n",
            "Epoch 8641: train loss = 4.055675, test loss = 12117.950645\n",
            "Epoch 8642: train loss = 4.055652, test loss = 12117.924041\n",
            "Epoch 8643: train loss = 4.055657, test loss = 12117.892279\n",
            "Epoch 8644: train loss = 4.055651, test loss = 12117.873211\n",
            "Epoch 8645: train loss = 4.055629, test loss = 12117.846845\n",
            "Epoch 8646: train loss = 4.055640, test loss = 12117.813847\n",
            "Epoch 8647: train loss = 4.055627, test loss = 12117.795156\n",
            "Epoch 8648: train loss = 4.055607, test loss = 12117.779392\n",
            "Epoch 8649: train loss = 4.055603, test loss = 12117.755649\n",
            "Epoch 8650: train loss = 4.055605, test loss = 12117.725285\n",
            "Epoch 8651: train loss = 4.055601, test loss = 12117.705541\n",
            "Epoch 8652: train loss = 4.055579, test loss = 12117.679387\n",
            "Epoch 8653: train loss = 4.055588, test loss = 12117.646672\n",
            "Epoch 8654: train loss = 4.055578, test loss = 12117.627872\n",
            "Epoch 8655: train loss = 4.055555, test loss = 12117.602404\n",
            "Epoch 8656: train loss = 4.055571, test loss = 12117.568711\n",
            "Epoch 8657: train loss = 4.055554, test loss = 12117.550846\n",
            "Epoch 8658: train loss = 4.055535, test loss = 12117.535217\n",
            "Epoch 8659: train loss = 4.055530, test loss = 12117.511619\n",
            "Epoch 8660: train loss = 4.055536, test loss = 12117.479728\n",
            "Epoch 8661: train loss = 4.055528, test loss = 12117.461407\n",
            "Epoch 8662: train loss = 4.055505, test loss = 12117.435690\n",
            "Epoch 8663: train loss = 4.055520, test loss = 12117.401528\n",
            "Epoch 8664: train loss = 4.055504, test loss = 12117.383660\n",
            "Epoch 8665: train loss = 4.055483, test loss = 12117.368228\n",
            "Epoch 8666: train loss = 4.055480, test loss = 12117.344535\n",
            "Epoch 8667: train loss = 4.055485, test loss = 12117.313149\n",
            "Epoch 8668: train loss = 4.055478, test loss = 12117.293872\n",
            "Epoch 8669: train loss = 4.055456, test loss = 12117.268106\n",
            "Epoch 8670: train loss = 4.055468, test loss = 12117.234181\n",
            "Epoch 8671: train loss = 4.055455, test loss = 12117.216265\n",
            "Epoch 8672: train loss = 4.055432, test loss = 12117.190928\n",
            "Epoch 8673: train loss = 4.055451, test loss = 12117.156398\n",
            "Epoch 8674: train loss = 4.055431, test loss = 12117.139026\n",
            "Epoch 8675: train loss = 4.055413, test loss = 12117.115182\n",
            "Epoch 8676: train loss = 4.055428, test loss = 12117.093578\n",
            "Epoch 8677: train loss = 4.055406, test loss = 12117.066469\n",
            "Epoch 8678: train loss = 4.055397, test loss = 12117.036906\n",
            "Epoch 8679: train loss = 4.055405, test loss = 12117.015721\n",
            "Epoch 8680: train loss = 4.055382, test loss = 12116.988235\n",
            "Epoch 8681: train loss = 4.055381, test loss = 12116.957261\n",
            "Epoch 8682: train loss = 4.055381, test loss = 12116.936746\n",
            "Epoch 8683: train loss = 4.055359, test loss = 12116.910135\n",
            "Epoch 8684: train loss = 4.055364, test loss = 12116.878066\n",
            "Epoch 8685: train loss = 4.055357, test loss = 12116.859069\n",
            "Epoch 8686: train loss = 4.055335, test loss = 12116.833077\n",
            "Epoch 8687: train loss = 4.055347, test loss = 12116.799509\n",
            "Epoch 8688: train loss = 4.055334, test loss = 12116.781217\n",
            "Epoch 8689: train loss = 4.055313, test loss = 12116.765535\n",
            "Epoch 8690: train loss = 4.055310, test loss = 12116.742260\n",
            "Epoch 8691: train loss = 4.055313, test loss = 12116.710824\n",
            "Epoch 8692: train loss = 4.055308, test loss = 12116.691380\n",
            "Epoch 8693: train loss = 4.055285, test loss = 12116.665468\n",
            "Epoch 8694: train loss = 4.055296, test loss = 12116.632181\n",
            "Epoch 8695: train loss = 4.055284, test loss = 12116.613891\n",
            "Epoch 8696: train loss = 4.055262, test loss = 12116.588840\n",
            "Epoch 8697: train loss = 4.055279, test loss = 12116.554167\n",
            "Epoch 8698: train loss = 4.055261, test loss = 12116.536569\n",
            "Epoch 8699: train loss = 4.055241, test loss = 12116.513270\n",
            "Epoch 8700: train loss = 4.055258, test loss = 12116.491391\n",
            "Epoch 8701: train loss = 4.055235, test loss = 12116.463896\n",
            "Epoch 8702: train loss = 4.055225, test loss = 12116.435589\n",
            "Epoch 8703: train loss = 4.055234, test loss = 12116.413160\n",
            "Epoch 8704: train loss = 4.055212, test loss = 12116.385684\n",
            "Epoch 8705: train loss = 4.055209, test loss = 12116.355333\n",
            "Epoch 8706: train loss = 4.055210, test loss = 12116.334510\n",
            "Epoch 8707: train loss = 4.055188, test loss = 12116.307771\n",
            "Epoch 8708: train loss = 4.055192, test loss = 12116.276777\n",
            "Epoch 8709: train loss = 4.055187, test loss = 12116.256737\n",
            "Epoch 8710: train loss = 4.055165, test loss = 12116.230495\n",
            "Epoch 8711: train loss = 4.055176, test loss = 12116.197682\n",
            "Epoch 8712: train loss = 4.055163, test loss = 12116.179081\n",
            "Epoch 8713: train loss = 4.055143, test loss = 12116.163630\n",
            "Epoch 8714: train loss = 4.055139, test loss = 12116.139723\n",
            "Epoch 8715: train loss = 4.055141, test loss = 12116.108858\n",
            "Epoch 8716: train loss = 4.055137, test loss = 12116.089226\n",
            "Epoch 8717: train loss = 4.055115, test loss = 12116.063236\n",
            "Epoch 8718: train loss = 4.055124, test loss = 12116.030569\n",
            "Epoch 8719: train loss = 4.055113, test loss = 12116.012215\n",
            "Epoch 8720: train loss = 4.055091, test loss = 12115.986465\n",
            "Epoch 8721: train loss = 4.055107, test loss = 12115.952402\n",
            "Epoch 8722: train loss = 4.055090, test loss = 12115.934566\n",
            "Epoch 8723: train loss = 4.055071, test loss = 12115.919125\n",
            "Epoch 8724: train loss = 4.055066, test loss = 12115.895551\n",
            "Epoch 8725: train loss = 4.055072, test loss = 12115.864132\n",
            "Epoch 8726: train loss = 4.055064, test loss = 12115.845181\n",
            "Epoch 8727: train loss = 4.055041, test loss = 12115.819497\n",
            "Epoch 8728: train loss = 4.055055, test loss = 12115.785531\n",
            "Epoch 8729: train loss = 4.055040, test loss = 12115.767744\n",
            "Epoch 8730: train loss = 4.055019, test loss = 12115.752276\n",
            "Epoch 8731: train loss = 4.055016, test loss = 12115.728932\n",
            "Epoch 8732: train loss = 4.055021, test loss = 12115.696950\n",
            "Epoch 8733: train loss = 4.055014, test loss = 12115.677954\n",
            "Epoch 8734: train loss = 4.054992, test loss = 12115.652060\n",
            "Epoch 8735: train loss = 4.055004, test loss = 12115.618469\n",
            "Epoch 8736: train loss = 4.054991, test loss = 12115.600717\n",
            "Epoch 8737: train loss = 4.054968, test loss = 12115.575140\n",
            "Epoch 8738: train loss = 4.054987, test loss = 12115.540131\n",
            "Epoch 8739: train loss = 4.054967, test loss = 12115.523040\n",
            "Epoch 8740: train loss = 4.054949, test loss = 12115.499244\n",
            "Epoch 8741: train loss = 4.054964, test loss = 12115.477845\n",
            "Epoch 8742: train loss = 4.054942, test loss = 12115.450944\n",
            "Epoch 8743: train loss = 4.054933, test loss = 12115.421355\n",
            "Epoch 8744: train loss = 4.054941, test loss = 12115.399423\n",
            "Epoch 8745: train loss = 4.054919, test loss = 12115.372269\n",
            "Epoch 8746: train loss = 4.054917, test loss = 12115.341362\n",
            "Epoch 8747: train loss = 4.054917, test loss = 12115.320872\n",
            "Epoch 8748: train loss = 4.054895, test loss = 12115.294840\n",
            "Epoch 8749: train loss = 4.054900, test loss = 12115.262458\n",
            "Epoch 8750: train loss = 4.054894, test loss = 12115.243105\n",
            "Epoch 8751: train loss = 4.054871, test loss = 12115.217008\n",
            "Epoch 8752: train loss = 4.054883, test loss = 12115.183781\n",
            "Epoch 8753: train loss = 4.054870, test loss = 12115.165364\n",
            "Epoch 8754: train loss = 4.054849, test loss = 12115.150262\n",
            "Epoch 8755: train loss = 4.054846, test loss = 12115.126156\n",
            "Epoch 8756: train loss = 4.054849, test loss = 12115.095069\n",
            "Epoch 8757: train loss = 4.054844, test loss = 12115.075634\n",
            "Epoch 8758: train loss = 4.054822, test loss = 12115.049742\n",
            "Epoch 8759: train loss = 4.054832, test loss = 12115.016998\n",
            "Epoch 8760: train loss = 4.054820, test loss = 12114.998317\n",
            "Epoch 8761: train loss = 4.054798, test loss = 12114.972811\n",
            "Epoch 8762: train loss = 4.054815, test loss = 12114.938298\n",
            "Epoch 8763: train loss = 4.054797, test loss = 12114.920894\n",
            "Epoch 8764: train loss = 4.054777, test loss = 12114.905473\n",
            "Epoch 8765: train loss = 4.054773, test loss = 12114.882607\n",
            "Epoch 8766: train loss = 4.054780, test loss = 12114.849963\n",
            "Epoch 8767: train loss = 4.054771, test loss = 12114.831426\n",
            "Epoch 8768: train loss = 4.054749, test loss = 12114.805748\n",
            "Epoch 8769: train loss = 4.054763, test loss = 12114.771569\n",
            "Epoch 8770: train loss = 4.054747, test loss = 12114.753933\n",
            "Epoch 8771: train loss = 4.054725, test loss = 12114.731159\n",
            "Epoch 8772: train loss = 4.054745, test loss = 12114.708781\n",
            "Epoch 8773: train loss = 4.054722, test loss = 12114.681048\n",
            "Epoch 8774: train loss = 4.054710, test loss = 12114.652504\n",
            "Epoch 8775: train loss = 4.054721, test loss = 12114.630047\n",
            "Epoch 8776: train loss = 4.054699, test loss = 12114.602686\n",
            "Epoch 8777: train loss = 4.054694, test loss = 12114.572919\n",
            "Epoch 8778: train loss = 4.054698, test loss = 12114.551644\n",
            "Epoch 8779: train loss = 4.054675, test loss = 12114.524705\n",
            "Epoch 8780: train loss = 4.054677, test loss = 12114.493433\n",
            "Epoch 8781: train loss = 4.054674, test loss = 12114.473442\n",
            "Epoch 8782: train loss = 4.054652, test loss = 12114.447788\n",
            "Epoch 8783: train loss = 4.054660, test loss = 12114.414842\n",
            "Epoch 8784: train loss = 4.054650, test loss = 12114.396014\n",
            "Epoch 8785: train loss = 4.054628, test loss = 12114.370378\n",
            "Epoch 8786: train loss = 4.054644, test loss = 12114.336442\n",
            "Epoch 8787: train loss = 4.054627, test loss = 12114.318713\n",
            "Epoch 8788: train loss = 4.054608, test loss = 12114.303521\n",
            "Epoch 8789: train loss = 4.054603, test loss = 12114.279935\n",
            "Epoch 8790: train loss = 4.054609, test loss = 12114.248036\n",
            "Epoch 8791: train loss = 4.054601, test loss = 12114.229272\n",
            "Epoch 8792: train loss = 4.054578, test loss = 12114.203505\n",
            "Epoch 8793: train loss = 4.054592, test loss = 12114.169862\n",
            "Epoch 8794: train loss = 4.054577, test loss = 12114.152370\n",
            "Epoch 8795: train loss = 4.054556, test loss = 12114.136645\n",
            "Epoch 8796: train loss = 4.054553, test loss = 12114.112835\n",
            "Epoch 8797: train loss = 4.054557, test loss = 12114.081080\n",
            "Epoch 8798: train loss = 4.054551, test loss = 12114.062223\n",
            "Epoch 8799: train loss = 4.054529, test loss = 12114.036332\n",
            "Epoch 8800: train loss = 4.054540, test loss = 12114.003253\n",
            "Epoch 8801: train loss = 4.054528, test loss = 12113.984814\n",
            "Epoch 8802: train loss = 4.054505, test loss = 12113.959421\n",
            "Epoch 8803: train loss = 4.054523, test loss = 12113.924581\n",
            "Epoch 8804: train loss = 4.054504, test loss = 12113.907336\n",
            "Epoch 8805: train loss = 4.054485, test loss = 12113.883783\n",
            "Epoch 8806: train loss = 4.054501, test loss = 12113.862565\n",
            "Epoch 8807: train loss = 4.054479, test loss = 12113.835170\n",
            "Epoch 8808: train loss = 4.054470, test loss = 12113.805743\n",
            "Epoch 8809: train loss = 4.054478, test loss = 12113.783895\n",
            "Epoch 8810: train loss = 4.054456, test loss = 12113.756622\n",
            "Epoch 8811: train loss = 4.054453, test loss = 12113.726414\n",
            "Epoch 8812: train loss = 4.054454, test loss = 12113.705570\n",
            "Epoch 8813: train loss = 4.054432, test loss = 12113.678821\n",
            "Epoch 8814: train loss = 4.054437, test loss = 12113.646894\n",
            "Epoch 8815: train loss = 4.054431, test loss = 12113.627381\n",
            "Epoch 8816: train loss = 4.054408, test loss = 12113.601568\n",
            "Epoch 8817: train loss = 4.054420, test loss = 12113.568768\n",
            "Epoch 8818: train loss = 4.054407, test loss = 12113.550214\n",
            "Epoch 8819: train loss = 4.054386, test loss = 12113.534333\n",
            "Epoch 8820: train loss = 4.054383, test loss = 12113.510565\n",
            "Epoch 8821: train loss = 4.054385, test loss = 12113.479579\n",
            "Epoch 8822: train loss = 4.054381, test loss = 12113.460165\n",
            "Epoch 8823: train loss = 4.054359, test loss = 12113.434824\n",
            "Epoch 8824: train loss = 4.054369, test loss = 12113.401423\n",
            "Epoch 8825: train loss = 4.054358, test loss = 12113.382789\n",
            "Epoch 8826: train loss = 4.054335, test loss = 12113.357318\n",
            "Epoch 8827: train loss = 4.054352, test loss = 12113.323065\n",
            "Epoch 8828: train loss = 4.054334, test loss = 12113.305940\n",
            "Epoch 8829: train loss = 4.054314, test loss = 12113.290348\n",
            "Epoch 8830: train loss = 4.054310, test loss = 12113.266697\n",
            "Epoch 8831: train loss = 4.054317, test loss = 12113.234623\n",
            "Epoch 8832: train loss = 4.054308, test loss = 12113.215987\n",
            "Epoch 8833: train loss = 4.054286, test loss = 12113.190470\n",
            "Epoch 8834: train loss = 4.054300, test loss = 12113.156732\n",
            "Epoch 8835: train loss = 4.054285, test loss = 12113.138859\n",
            "Epoch 8836: train loss = 4.054262, test loss = 12113.123549\n",
            "Epoch 8837: train loss = 4.054261, test loss = 12113.099662\n",
            "Epoch 8838: train loss = 4.054265, test loss = 12113.067674\n",
            "Epoch 8839: train loss = 4.054259, test loss = 12113.048811\n",
            "Epoch 8840: train loss = 4.054236, test loss = 12113.023534\n",
            "Epoch 8841: train loss = 4.054249, test loss = 12112.989347\n",
            "Epoch 8842: train loss = 4.054235, test loss = 12112.971422\n",
            "Epoch 8843: train loss = 4.054213, test loss = 12112.938057\n",
            "Epoch 8844: train loss = 4.054212, test loss = 12112.912448\n",
            "Epoch 8845: train loss = 4.054212, test loss = 12112.881544\n",
            "Epoch 8846: train loss = 4.054211, test loss = 12112.861524\n",
            "Epoch 8847: train loss = 4.054189, test loss = 12112.834695\n",
            "Epoch 8848: train loss = 4.054196, test loss = 12112.802044\n",
            "Epoch 8849: train loss = 4.054188, test loss = 12112.782592\n",
            "Epoch 8850: train loss = 4.054165, test loss = 12112.756639\n",
            "Epoch 8851: train loss = 4.054180, test loss = 12112.722958\n",
            "Epoch 8852: train loss = 4.054164, test loss = 12112.705127\n",
            "Epoch 8853: train loss = 4.054145, test loss = 12112.689219\n",
            "Epoch 8854: train loss = 4.054140, test loss = 12112.665312\n",
            "Epoch 8855: train loss = 4.054145, test loss = 12112.633747\n",
            "Epoch 8856: train loss = 4.054138, test loss = 12112.614717\n",
            "Epoch 8857: train loss = 4.054116, test loss = 12112.589355\n",
            "Epoch 8858: train loss = 4.054128, test loss = 12112.555529\n",
            "Epoch 8859: train loss = 4.054115, test loss = 12112.537344\n",
            "Epoch 8860: train loss = 4.054093, test loss = 12112.521654\n",
            "Epoch 8861: train loss = 4.054091, test loss = 12112.497718\n",
            "Epoch 8862: train loss = 4.054094, test loss = 12112.466389\n",
            "Epoch 8863: train loss = 4.054089, test loss = 12112.447670\n",
            "Epoch 8864: train loss = 4.054067, test loss = 12112.421424\n",
            "Epoch 8865: train loss = 4.054077, test loss = 12112.388107\n",
            "Epoch 8866: train loss = 4.054066, test loss = 12112.369630\n",
            "Epoch 8867: train loss = 4.054043, test loss = 12112.344128\n",
            "Epoch 8868: train loss = 4.054060, test loss = 12112.309613\n",
            "Epoch 8869: train loss = 4.054042, test loss = 12112.292765\n",
            "Epoch 8870: train loss = 4.054022, test loss = 12112.269014\n",
            "Epoch 8871: train loss = 4.054039, test loss = 12112.247225\n",
            "Epoch 8872: train loss = 4.054017, test loss = 12112.219694\n",
            "Epoch 8873: train loss = 4.054007, test loss = 12112.190660\n",
            "Epoch 8874: train loss = 4.054016, test loss = 12112.168697\n",
            "Epoch 8875: train loss = 4.053993, test loss = 12112.141931\n",
            "Epoch 8876: train loss = 4.053990, test loss = 12112.111161\n",
            "Epoch 8877: train loss = 4.053992, test loss = 12112.090354\n",
            "Epoch 8878: train loss = 4.053970, test loss = 12112.063577\n",
            "Epoch 8879: train loss = 4.053974, test loss = 12112.031906\n",
            "Epoch 8880: train loss = 4.053969, test loss = 12112.012687\n",
            "Epoch 8881: train loss = 4.053946, test loss = 12111.986451\n",
            "Epoch 8882: train loss = 4.053957, test loss = 12111.953338\n",
            "Epoch 8883: train loss = 4.053945, test loss = 12111.934937\n",
            "Epoch 8884: train loss = 4.053924, test loss = 12111.919101\n",
            "Epoch 8885: train loss = 4.053921, test loss = 12111.895330\n",
            "Epoch 8886: train loss = 4.053923, test loss = 12111.864946\n",
            "Epoch 8887: train loss = 4.053919, test loss = 12111.845261\n",
            "Epoch 8888: train loss = 4.053897, test loss = 12111.819179\n",
            "Epoch 8889: train loss = 4.053906, test loss = 12111.786242\n",
            "Epoch 8890: train loss = 4.053896, test loss = 12111.767676\n",
            "Epoch 8891: train loss = 4.053873, test loss = 12111.742066\n",
            "Epoch 8892: train loss = 4.053889, test loss = 12111.708601\n",
            "Epoch 8893: train loss = 4.053872, test loss = 12111.690651\n",
            "Epoch 8894: train loss = 4.053852, test loss = 12111.675123\n",
            "Epoch 8895: train loss = 4.053848, test loss = 12111.651498\n",
            "Epoch 8896: train loss = 4.053854, test loss = 12111.619580\n",
            "Epoch 8897: train loss = 4.053846, test loss = 12111.600974\n",
            "Epoch 8898: train loss = 4.053824, test loss = 12111.575732\n",
            "Epoch 8899: train loss = 4.053838, test loss = 12111.541597\n",
            "Epoch 8900: train loss = 4.053823, test loss = 12111.523625\n",
            "Epoch 8901: train loss = 4.053800, test loss = 12111.508471\n",
            "Epoch 8902: train loss = 4.053799, test loss = 12111.484564\n",
            "Epoch 8903: train loss = 4.053803, test loss = 12111.453160\n",
            "Epoch 8904: train loss = 4.053797, test loss = 12111.433946\n",
            "Epoch 8905: train loss = 4.053774, test loss = 12111.408153\n",
            "Epoch 8906: train loss = 4.053786, test loss = 12111.374340\n",
            "Epoch 8907: train loss = 4.053773, test loss = 12111.356276\n",
            "Epoch 8908: train loss = 4.053751, test loss = 12111.331072\n",
            "Epoch 8909: train loss = 4.053769, test loss = 12111.296440\n",
            "Epoch 8910: train loss = 4.053750, test loss = 12111.279363\n",
            "Epoch 8911: train loss = 4.053731, test loss = 12111.255315\n",
            "Epoch 8912: train loss = 4.053747, test loss = 12111.233863\n",
            "Epoch 8913: train loss = 4.053725, test loss = 12111.206564\n",
            "Epoch 8914: train loss = 4.053716, test loss = 12111.177225\n",
            "Epoch 8915: train loss = 4.053724, test loss = 12111.155909\n",
            "Epoch 8916: train loss = 4.053701, test loss = 12111.128674\n",
            "Epoch 8917: train loss = 4.053700, test loss = 12111.097592\n",
            "Epoch 8918: train loss = 4.053700, test loss = 12111.077064\n",
            "Epoch 8919: train loss = 4.053678, test loss = 12111.050496\n",
            "Epoch 8920: train loss = 4.053683, test loss = 12111.018434\n",
            "Epoch 8921: train loss = 4.053677, test loss = 12110.999622\n",
            "Epoch 8922: train loss = 4.053654, test loss = 12110.973391\n",
            "Epoch 8923: train loss = 4.053666, test loss = 12110.939994\n",
            "Epoch 8924: train loss = 4.053653, test loss = 12110.921667\n",
            "Epoch 8925: train loss = 4.053631, test loss = 12110.906297\n",
            "Epoch 8926: train loss = 4.053629, test loss = 12110.882832\n",
            "Epoch 8927: train loss = 4.053632, test loss = 12110.851434\n",
            "Epoch 8928: train loss = 4.053627, test loss = 12110.831955\n",
            "Epoch 8929: train loss = 4.053605, test loss = 12110.806076\n",
            "Epoch 8930: train loss = 4.053615, test loss = 12110.772893\n",
            "Epoch 8931: train loss = 4.053604, test loss = 12110.754463\n",
            "Epoch 8932: train loss = 4.053581, test loss = 12110.729554\n",
            "Epoch 8933: train loss = 4.053598, test loss = 12110.694777\n",
            "Epoch 8934: train loss = 4.053580, test loss = 12110.677476\n",
            "Epoch 8935: train loss = 4.053560, test loss = 12110.653977\n",
            "Epoch 8936: train loss = 4.053578, test loss = 12110.632152\n",
            "Epoch 8937: train loss = 4.053555, test loss = 12110.604693\n",
            "Epoch 8938: train loss = 4.053545, test loss = 12110.576364\n",
            "Epoch 8939: train loss = 4.053554, test loss = 12110.554070\n",
            "Epoch 8940: train loss = 4.053532, test loss = 12110.526599\n",
            "Epoch 8941: train loss = 4.053529, test loss = 12110.496292\n",
            "Epoch 8942: train loss = 4.053531, test loss = 12110.475340\n",
            "Epoch 8943: train loss = 4.053508, test loss = 12110.448859\n",
            "Epoch 8944: train loss = 4.053512, test loss = 12110.417676\n",
            "Epoch 8945: train loss = 4.053507, test loss = 12110.397770\n",
            "Epoch 8946: train loss = 4.053485, test loss = 12110.371545\n",
            "Epoch 8947: train loss = 4.053495, test loss = 12110.338729\n",
            "Epoch 8948: train loss = 4.053483, test loss = 12110.320208\n",
            "Epoch 8949: train loss = 4.053462, test loss = 12110.304401\n",
            "Epoch 8950: train loss = 4.053460, test loss = 12110.281106\n",
            "Epoch 8951: train loss = 4.053461, test loss = 12110.250173\n",
            "Epoch 8952: train loss = 4.053458, test loss = 12110.230631\n",
            "Epoch 8953: train loss = 4.053435, test loss = 12110.204470\n",
            "Epoch 8954: train loss = 4.053444, test loss = 12110.171800\n",
            "Epoch 8955: train loss = 4.053434, test loss = 12110.153523\n",
            "Epoch 8956: train loss = 4.053412, test loss = 12110.127755\n",
            "Epoch 8957: train loss = 4.053427, test loss = 12110.093602\n",
            "Epoch 8958: train loss = 4.053411, test loss = 12110.076067\n",
            "Epoch 8959: train loss = 4.053391, test loss = 12110.060477\n",
            "Epoch 8960: train loss = 4.053387, test loss = 12110.037036\n",
            "Epoch 8961: train loss = 4.053393, test loss = 12110.005632\n",
            "Epoch 8962: train loss = 4.053385, test loss = 12109.986684\n",
            "Epoch 8963: train loss = 4.053362, test loss = 12109.960974\n",
            "Epoch 8964: train loss = 4.053376, test loss = 12109.927008\n",
            "Epoch 8965: train loss = 4.053361, test loss = 12109.909294\n",
            "Epoch 8966: train loss = 4.053339, test loss = 12109.893919\n",
            "Epoch 8967: train loss = 4.053337, test loss = 12109.870547\n",
            "Epoch 8968: train loss = 4.053341, test loss = 12109.838601\n",
            "Epoch 8969: train loss = 4.053336, test loss = 12109.819564\n",
            "Epoch 8970: train loss = 4.053313, test loss = 12109.793698\n",
            "Epoch 8971: train loss = 4.053324, test loss = 12109.760031\n",
            "Epoch 8972: train loss = 4.053312, test loss = 12109.742052\n",
            "Epoch 8973: train loss = 4.053290, test loss = 12109.717154\n",
            "Epoch 8974: train loss = 4.053308, test loss = 12109.682103\n",
            "Epoch 8975: train loss = 4.053289, test loss = 12109.664872\n",
            "Epoch 8976: train loss = 4.053270, test loss = 12109.641036\n",
            "Epoch 8977: train loss = 4.053286, test loss = 12109.619584\n",
            "Epoch 8978: train loss = 4.053264, test loss = 12109.592910\n",
            "Epoch 8979: train loss = 4.053254, test loss = 12109.563201\n",
            "Epoch 8980: train loss = 4.053262, test loss = 12109.541468\n",
            "Epoch 8981: train loss = 4.053240, test loss = 12109.514167\n",
            "Epoch 8982: train loss = 4.053238, test loss = 12109.483329\n",
            "Epoch 8983: train loss = 4.053239, test loss = 12109.462823\n",
            "Epoch 8984: train loss = 4.053217, test loss = 12109.436834\n",
            "Epoch 8985: train loss = 4.053222, test loss = 12109.404513\n",
            "Epoch 8986: train loss = 4.053215, test loss = 12109.385137\n",
            "Epoch 8987: train loss = 4.053193, test loss = 12109.359077\n",
            "Epoch 8988: train loss = 4.053205, test loss = 12109.325758\n",
            "Epoch 8989: train loss = 4.053192, test loss = 12109.307562\n",
            "Epoch 8990: train loss = 4.053170, test loss = 12109.292548\n",
            "Epoch 8991: train loss = 4.053168, test loss = 12109.268403\n",
            "Epoch 8992: train loss = 4.053170, test loss = 12109.237348\n",
            "Epoch 8993: train loss = 4.053166, test loss = 12109.217871\n",
            "Epoch 8994: train loss = 4.053144, test loss = 12109.191907\n",
            "Epoch 8995: train loss = 4.053154, test loss = 12109.158910\n",
            "Epoch 8996: train loss = 4.053143, test loss = 12109.140962\n",
            "Epoch 8997: train loss = 4.053120, test loss = 12109.115190\n",
            "Epoch 8998: train loss = 4.053137, test loss = 12109.080757\n",
            "Epoch 8999: train loss = 4.053119, test loss = 12109.063374\n",
            "Epoch 9000: train loss = 4.053099, test loss = 12109.040006\n",
            "Epoch 9001: train loss = 4.053116, test loss = 12109.018702\n",
            "Epoch 9002: train loss = 4.053094, test loss = 12108.990975\n",
            "Epoch 9003: train loss = 4.053083, test loss = 12108.961979\n",
            "Epoch 9004: train loss = 4.053093, test loss = 12108.939890\n",
            "Epoch 9005: train loss = 4.053071, test loss = 12108.912626\n",
            "Epoch 9006: train loss = 4.053067, test loss = 12108.882309\n",
            "Epoch 9007: train loss = 4.053069, test loss = 12108.862008\n",
            "Epoch 9008: train loss = 4.053047, test loss = 12108.835000\n",
            "Epoch 9009: train loss = 4.053051, test loss = 12108.803467\n",
            "Epoch 9010: train loss = 4.053046, test loss = 12108.783620\n",
            "Epoch 9011: train loss = 4.053024, test loss = 12108.757622\n",
            "Epoch 9012: train loss = 4.053034, test loss = 12108.724863\n",
            "Epoch 9013: train loss = 4.053022, test loss = 12108.706837\n",
            "Epoch 9014: train loss = 4.053001, test loss = 12108.690728\n",
            "Epoch 9015: train loss = 4.052999, test loss = 12108.666854\n",
            "Epoch 9016: train loss = 4.053000, test loss = 12108.636205\n",
            "Epoch 9017: train loss = 4.052997, test loss = 12108.616653\n",
            "Epoch 9018: train loss = 4.052974, test loss = 12108.590677\n",
            "Epoch 9019: train loss = 4.052983, test loss = 12108.558475\n",
            "Epoch 9020: train loss = 4.052973, test loss = 12108.539530\n",
            "Epoch 9021: train loss = 4.052951, test loss = 12108.513780\n",
            "Epoch 9022: train loss = 4.052966, test loss = 12108.479971\n",
            "Epoch 9023: train loss = 4.052950, test loss = 12108.462187\n",
            "Epoch 9024: train loss = 4.052930, test loss = 12108.447204\n",
            "Epoch 9025: train loss = 4.052926, test loss = 12108.423381\n",
            "Epoch 9026: train loss = 4.052932, test loss = 12108.391601\n",
            "Epoch 9027: train loss = 4.052924, test loss = 12108.372825\n",
            "Epoch 9028: train loss = 4.052901, test loss = 12108.347094\n",
            "Epoch 9029: train loss = 4.052915, test loss = 12108.313439\n",
            "Epoch 9030: train loss = 4.052900, test loss = 12108.295910\n",
            "Epoch 9031: train loss = 4.052878, test loss = 12108.280510\n",
            "Epoch 9032: train loss = 4.052876, test loss = 12108.256512\n",
            "Epoch 9033: train loss = 4.052880, test loss = 12108.224834\n",
            "Epoch 9034: train loss = 4.052875, test loss = 12108.205760\n",
            "Epoch 9035: train loss = 4.052852, test loss = 12108.180074\n",
            "Epoch 9036: train loss = 4.052864, test loss = 12108.146882\n",
            "Epoch 9037: train loss = 4.052851, test loss = 12108.128667\n",
            "Epoch 9038: train loss = 4.052829, test loss = 12108.103163\n",
            "Epoch 9039: train loss = 4.052847, test loss = 12108.068286\n",
            "Epoch 9040: train loss = 4.052828, test loss = 12108.051165\n",
            "Epoch 9041: train loss = 4.052809, test loss = 12108.027542\n",
            "Epoch 9042: train loss = 4.052825, test loss = 12108.006510\n",
            "Epoch 9043: train loss = 4.052803, test loss = 12107.978985\n",
            "Epoch 9044: train loss = 4.052793, test loss = 12107.949623\n",
            "Epoch 9045: train loss = 4.052802, test loss = 12107.927732\n",
            "Epoch 9046: train loss = 4.052779, test loss = 12107.900772\n",
            "Epoch 9047: train loss = 4.052777, test loss = 12107.870354\n",
            "Epoch 9048: train loss = 4.052778, test loss = 12107.849541\n",
            "Epoch 9049: train loss = 4.052756, test loss = 12107.822842\n",
            "Epoch 9050: train loss = 4.052761, test loss = 12107.790916\n",
            "Epoch 9051: train loss = 4.052755, test loss = 12107.771519\n",
            "Epoch 9052: train loss = 4.052732, test loss = 12107.745534\n",
            "Epoch 9053: train loss = 4.052744, test loss = 12107.712906\n",
            "Epoch 9054: train loss = 4.052731, test loss = 12107.694245\n",
            "Epoch 9055: train loss = 4.052710, test loss = 12107.678739\n",
            "Epoch 9056: train loss = 4.052707, test loss = 12107.654839\n",
            "Epoch 9057: train loss = 4.052710, test loss = 12107.623795\n",
            "Epoch 9058: train loss = 4.052706, test loss = 12107.604391\n",
            "Epoch 9059: train loss = 4.052683, test loss = 12107.579006\n",
            "Epoch 9060: train loss = 4.052693, test loss = 12107.545655\n",
            "Epoch 9061: train loss = 4.052682, test loss = 12107.527224\n",
            "Epoch 9062: train loss = 4.052660, test loss = 12107.501633\n",
            "Epoch 9063: train loss = 4.052676, test loss = 12107.467402\n",
            "Epoch 9064: train loss = 4.052659, test loss = 12107.449892\n",
            "Epoch 9065: train loss = 4.052638, test loss = 12107.427178\n",
            "Epoch 9066: train loss = 4.052656, test loss = 12107.405029\n",
            "Epoch 9067: train loss = 4.052634, test loss = 12107.377473\n",
            "Epoch 9068: train loss = 4.052623, test loss = 12107.348705\n",
            "Epoch 9069: train loss = 4.052632, test loss = 12107.326508\n",
            "Epoch 9070: train loss = 4.052610, test loss = 12107.299416\n",
            "Epoch 9071: train loss = 4.052607, test loss = 12107.269521\n",
            "Epoch 9072: train loss = 4.052609, test loss = 12107.248393\n",
            "Epoch 9073: train loss = 4.052587, test loss = 12107.221612\n",
            "Epoch 9074: train loss = 4.052590, test loss = 12107.190140\n",
            "Epoch 9075: train loss = 4.052585, test loss = 12107.170428\n",
            "Epoch 9076: train loss = 4.052563, test loss = 12107.144753\n",
            "Epoch 9077: train loss = 4.052574, test loss = 12107.111875\n",
            "Epoch 9078: train loss = 4.052562, test loss = 12107.093052\n",
            "Epoch 9079: train loss = 4.052541, test loss = 12107.077386\n",
            "Epoch 9080: train loss = 4.052538, test loss = 12107.053532\n",
            "Epoch 9081: train loss = 4.052539, test loss = 12107.023059\n",
            "Epoch 9082: train loss = 4.052536, test loss = 12107.003843\n",
            "Epoch 9083: train loss = 4.052514, test loss = 12106.977616\n",
            "Epoch 9084: train loss = 4.052523, test loss = 12106.944989\n",
            "Epoch 9085: train loss = 4.052513, test loss = 12106.926110\n",
            "Epoch 9086: train loss = 4.052490, test loss = 12106.900586\n",
            "Epoch 9087: train loss = 4.052506, test loss = 12106.866709\n",
            "Epoch 9088: train loss = 4.052489, test loss = 12106.849585\n",
            "Epoch 9089: train loss = 4.052470, test loss = 12106.833717\n",
            "Epoch 9090: train loss = 4.052465, test loss = 12106.810236\n",
            "Epoch 9091: train loss = 4.052471, test loss = 12106.778388\n",
            "Epoch 9092: train loss = 4.052464, test loss = 12106.759662\n",
            "Epoch 9093: train loss = 4.052441, test loss = 12106.734061\n",
            "Epoch 9094: train loss = 4.052455, test loss = 12106.700761\n",
            "Epoch 9095: train loss = 4.052440, test loss = 12106.682710\n",
            "Epoch 9096: train loss = 4.052418, test loss = 12106.667183\n",
            "Epoch 9097: train loss = 4.052416, test loss = 12106.643380\n",
            "Epoch 9098: train loss = 4.052420, test loss = 12106.611750\n",
            "Epoch 9099: train loss = 4.052414, test loss = 12106.593256\n",
            "Epoch 9100: train loss = 4.052392, test loss = 12106.567158\n",
            "Epoch 9101: train loss = 4.052403, test loss = 12106.533622\n",
            "Epoch 9102: train loss = 4.052391, test loss = 12106.515357\n",
            "Epoch 9103: train loss = 4.052369, test loss = 12106.490009\n",
            "Epoch 9104: train loss = 4.052387, test loss = 12106.455290\n",
            "Epoch 9105: train loss = 4.052368, test loss = 12106.438699\n",
            "Epoch 9106: train loss = 4.052349, test loss = 12106.414710\n",
            "Epoch 9107: train loss = 4.052365, test loss = 12106.393157\n",
            "Epoch 9108: train loss = 4.052343, test loss = 12106.365903\n",
            "Epoch 9109: train loss = 4.052333, test loss = 12106.336546\n",
            "Epoch 9110: train loss = 4.052341, test loss = 12106.314895\n",
            "Epoch 9111: train loss = 4.052319, test loss = 12106.288148\n",
            "Epoch 9112: train loss = 4.052317, test loss = 12106.257101\n",
            "Epoch 9113: train loss = 4.052318, test loss = 12106.236449\n",
            "Epoch 9114: train loss = 4.052296, test loss = 12106.209992\n",
            "Epoch 9115: train loss = 4.052301, test loss = 12106.177954\n",
            "Epoch 9116: train loss = 4.052295, test loss = 12106.158671\n",
            "Epoch 9117: train loss = 4.052272, test loss = 12106.133107\n",
            "Epoch 9118: train loss = 4.052284, test loss = 12106.099674\n",
            "Epoch 9119: train loss = 4.052271, test loss = 12106.081284\n",
            "Epoch 9120: train loss = 4.052250, test loss = 12106.065731\n",
            "Epoch 9121: train loss = 4.052247, test loss = 12106.041912\n",
            "Epoch 9122: train loss = 4.052250, test loss = 12106.011487\n",
            "Epoch 9123: train loss = 4.052246, test loss = 12105.991768\n",
            "Epoch 9124: train loss = 4.052223, test loss = 12105.965745\n",
            "Epoch 9125: train loss = 4.052233, test loss = 12105.932723\n",
            "Epoch 9126: train loss = 4.052222, test loss = 12105.914280\n",
            "Epoch 9127: train loss = 4.052200, test loss = 12105.888759\n",
            "Epoch 9128: train loss = 4.052216, test loss = 12105.855130\n",
            "Epoch 9129: train loss = 4.052199, test loss = 12105.837308\n",
            "Epoch 9130: train loss = 4.052178, test loss = 12105.821846\n",
            "Epoch 9131: train loss = 4.052175, test loss = 12105.798444\n",
            "Epoch 9132: train loss = 4.052182, test loss = 12105.766277\n",
            "Epoch 9133: train loss = 4.052173, test loss = 12105.747680\n",
            "Epoch 9134: train loss = 4.052151, test loss = 12105.722666\n",
            "Epoch 9135: train loss = 4.052165, test loss = 12105.688353\n",
            "Epoch 9136: train loss = 4.052150, test loss = 12105.670489\n",
            "Epoch 9137: train loss = 4.052127, test loss = 12105.637493\n",
            "Epoch 9138: train loss = 4.052127, test loss = 12105.611754\n",
            "Epoch 9139: train loss = 4.052129, test loss = 12105.580733\n",
            "Epoch 9140: train loss = 4.052126, test loss = 12105.560992\n",
            "Epoch 9141: train loss = 4.052103, test loss = 12105.534309\n",
            "Epoch 9142: train loss = 4.052113, test loss = 12105.501373\n",
            "Epoch 9143: train loss = 4.052102, test loss = 12105.482300\n",
            "Epoch 9144: train loss = 4.052081, test loss = 12105.466106\n",
            "Epoch 9145: train loss = 4.052079, test loss = 12105.442124\n",
            "Epoch 9146: train loss = 4.052079, test loss = 12105.412094\n",
            "Epoch 9147: train loss = 4.052077, test loss = 12105.391934\n",
            "Epoch 9148: train loss = 4.052054, test loss = 12105.365562\n",
            "Epoch 9149: train loss = 4.052062, test loss = 12105.333214\n",
            "Epoch 9150: train loss = 4.052053, test loss = 12105.314056\n",
            "Epoch 9151: train loss = 4.052031, test loss = 12105.288817\n",
            "Epoch 9152: train loss = 4.052046, test loss = 12105.254831\n",
            "Epoch 9153: train loss = 4.052030, test loss = 12105.236802\n",
            "Epoch 9154: train loss = 4.052010, test loss = 12105.221194\n",
            "Epoch 9155: train loss = 4.052006, test loss = 12105.197573\n",
            "Epoch 9156: train loss = 4.052011, test loss = 12105.166119\n",
            "Epoch 9157: train loss = 4.052004, test loss = 12105.147542\n",
            "Epoch 9158: train loss = 4.051982, test loss = 12105.121733\n",
            "Epoch 9159: train loss = 4.051995, test loss = 12105.087977\n",
            "Epoch 9160: train loss = 4.051981, test loss = 12105.069863\n",
            "Epoch 9161: train loss = 4.051959, test loss = 12105.054415\n",
            "Epoch 9162: train loss = 4.051957, test loss = 12105.030700\n",
            "Epoch 9163: train loss = 4.051960, test loss = 12104.999733\n",
            "Epoch 9164: train loss = 4.051955, test loss = 12104.980237\n",
            "Epoch 9165: train loss = 4.051933, test loss = 12104.954401\n",
            "Epoch 9166: train loss = 4.051943, test loss = 12104.920877\n",
            "Epoch 9167: train loss = 4.051932, test loss = 12104.902750\n",
            "Epoch 9168: train loss = 4.051909, test loss = 12104.877289\n",
            "Epoch 9169: train loss = 4.051927, test loss = 12104.843206\n",
            "Epoch 9170: train loss = 4.051908, test loss = 12104.825633\n",
            "Epoch 9171: train loss = 4.051889, test loss = 12104.802087\n",
            "Epoch 9172: train loss = 4.051906, test loss = 12104.780328\n",
            "Epoch 9173: train loss = 4.051884, test loss = 12104.753148\n",
            "Epoch 9174: train loss = 4.051873, test loss = 12104.724427\n",
            "Epoch 9175: train loss = 4.051882, test loss = 12104.702336\n",
            "Epoch 9176: train loss = 4.051860, test loss = 12104.674931\n",
            "Epoch 9177: train loss = 4.051857, test loss = 12104.644395\n",
            "Epoch 9178: train loss = 4.051859, test loss = 12104.623686\n",
            "Epoch 9179: train loss = 4.051837, test loss = 12104.597097\n",
            "Epoch 9180: train loss = 4.051841, test loss = 12104.565850\n",
            "Epoch 9181: train loss = 4.051836, test loss = 12104.545977\n",
            "Epoch 9182: train loss = 4.051813, test loss = 12104.520094\n",
            "Epoch 9183: train loss = 4.051825, test loss = 12104.486941\n",
            "Epoch 9184: train loss = 4.051812, test loss = 12104.468528\n",
            "Epoch 9185: train loss = 4.051791, test loss = 12104.452877\n",
            "Epoch 9186: train loss = 4.051788, test loss = 12104.429637\n",
            "Epoch 9187: train loss = 4.051790, test loss = 12104.398562\n",
            "Epoch 9188: train loss = 4.051787, test loss = 12104.378926\n",
            "Epoch 9189: train loss = 4.051764, test loss = 12104.353041\n",
            "Epoch 9190: train loss = 4.051773, test loss = 12104.320091\n",
            "Epoch 9191: train loss = 4.051763, test loss = 12104.301670\n",
            "Epoch 9192: train loss = 4.051741, test loss = 12104.276537\n",
            "Epoch 9193: train loss = 4.051757, test loss = 12104.242244\n",
            "Epoch 9194: train loss = 4.051740, test loss = 12104.224510\n",
            "Epoch 9195: train loss = 4.051719, test loss = 12104.209208\n",
            "Epoch 9196: train loss = 4.051716, test loss = 12104.185792\n",
            "Epoch 9197: train loss = 4.051722, test loss = 12104.154145\n",
            "Epoch 9198: train loss = 4.051714, test loss = 12104.135314\n",
            "Epoch 9199: train loss = 4.051692, test loss = 12104.109614\n",
            "Epoch 9200: train loss = 4.051706, test loss = 12104.075723\n",
            "Epoch 9201: train loss = 4.051691, test loss = 12104.057841\n",
            "Epoch 9202: train loss = 4.051668, test loss = 12104.032772\n",
            "Epoch 9203: train loss = 4.051689, test loss = 12103.997995\n",
            "Epoch 9204: train loss = 4.051667, test loss = 12103.981022\n",
            "Epoch 9205: train loss = 4.051651, test loss = 12103.956903\n",
            "Epoch 9206: train loss = 4.051665, test loss = 12103.935856\n",
            "Epoch 9207: train loss = 4.051643, test loss = 12103.908664\n",
            "Epoch 9208: train loss = 4.051635, test loss = 12103.879098\n",
            "Epoch 9209: train loss = 4.051641, test loss = 12103.858003\n",
            "Epoch 9210: train loss = 4.051619, test loss = 12103.830844\n",
            "Epoch 9211: train loss = 4.051619, test loss = 12103.799674\n",
            "Epoch 9212: train loss = 4.051618, test loss = 12103.779242\n",
            "Epoch 9213: train loss = 4.051596, test loss = 12103.752969\n",
            "Epoch 9214: train loss = 4.051603, test loss = 12103.720602\n",
            "Epoch 9215: train loss = 4.051595, test loss = 12103.702067\n",
            "Epoch 9216: train loss = 4.051572, test loss = 12103.675977\n",
            "Epoch 9217: train loss = 4.051586, test loss = 12103.642385\n",
            "Epoch 9218: train loss = 4.051571, test loss = 12103.624209\n",
            "Epoch 9219: train loss = 4.051551, test loss = 12103.608632\n",
            "Epoch 9220: train loss = 4.051547, test loss = 12103.585133\n",
            "Epoch 9221: train loss = 4.051552, test loss = 12103.554172\n",
            "Epoch 9222: train loss = 4.051546, test loss = 12103.534916\n",
            "Epoch 9223: train loss = 4.051523, test loss = 12103.509013\n",
            "Epoch 9224: train loss = 4.051535, test loss = 12103.475739\n",
            "Epoch 9225: train loss = 4.051522, test loss = 12103.457422\n",
            "Epoch 9226: train loss = 4.051500, test loss = 12103.442554\n",
            "Epoch 9227: train loss = 4.051498, test loss = 12103.418423\n",
            "Epoch 9228: train loss = 4.051501, test loss = 12103.387060\n",
            "Epoch 9229: train loss = 4.051497, test loss = 12103.367818\n",
            "Epoch 9230: train loss = 4.051474, test loss = 12103.341917\n",
            "Epoch 9231: train loss = 4.051484, test loss = 12103.308809\n",
            "Epoch 9232: train loss = 4.051473, test loss = 12103.290820\n",
            "Epoch 9233: train loss = 4.051451, test loss = 12103.265170\n",
            "Epoch 9234: train loss = 4.051468, test loss = 12103.230616\n",
            "Epoch 9235: train loss = 4.051450, test loss = 12103.213294\n",
            "Epoch 9236: train loss = 4.051430, test loss = 12103.189828\n",
            "Epoch 9237: train loss = 4.051447, test loss = 12103.168146\n",
            "Epoch 9238: train loss = 4.051425, test loss = 12103.141200\n",
            "Epoch 9239: train loss = 4.051414, test loss = 12103.112145\n",
            "Epoch 9240: train loss = 4.051424, test loss = 12103.089974\n",
            "Epoch 9241: train loss = 4.051402, test loss = 12103.062739\n",
            "Epoch 9242: train loss = 4.051398, test loss = 12103.032246\n",
            "Epoch 9243: train loss = 4.051400, test loss = 12103.011500\n",
            "Epoch 9244: train loss = 4.051378, test loss = 12102.985459\n",
            "Epoch 9245: train loss = 4.051382, test loss = 12102.953484\n",
            "Epoch 9246: train loss = 4.051377, test loss = 12102.933893\n",
            "Epoch 9247: train loss = 4.051355, test loss = 12102.907795\n",
            "Epoch 9248: train loss = 4.051366, test loss = 12102.874866\n",
            "Epoch 9249: train loss = 4.051354, test loss = 12102.856866\n",
            "Epoch 9250: train loss = 4.051332, test loss = 12102.841097\n",
            "Epoch 9251: train loss = 4.051330, test loss = 12102.817075\n",
            "Epoch 9252: train loss = 4.051331, test loss = 12102.786462\n",
            "Epoch 9253: train loss = 4.051328, test loss = 12102.766820\n",
            "Epoch 9254: train loss = 4.051306, test loss = 12102.740846\n",
            "Epoch 9255: train loss = 4.051315, test loss = 12102.708636\n",
            "Epoch 9256: train loss = 4.051305, test loss = 12102.689775\n",
            "Epoch 9257: train loss = 4.051282, test loss = 12102.664119\n",
            "Epoch 9258: train loss = 4.051298, test loss = 12102.630206\n",
            "Epoch 9259: train loss = 4.051281, test loss = 12102.612469\n",
            "Epoch 9260: train loss = 4.051261, test loss = 12102.597079\n",
            "Epoch 9261: train loss = 4.051257, test loss = 12102.574157\n",
            "Epoch 9262: train loss = 4.051263, test loss = 12102.542040\n",
            "Epoch 9263: train loss = 4.051256, test loss = 12102.523171\n",
            "Epoch 9264: train loss = 4.051233, test loss = 12102.497641\n",
            "Epoch 9265: train loss = 4.051247, test loss = 12102.463801\n",
            "Epoch 9266: train loss = 4.051232, test loss = 12102.446355\n",
            "Epoch 9267: train loss = 4.051210, test loss = 12102.421138\n",
            "Epoch 9268: train loss = 4.051230, test loss = 12102.385797\n",
            "Epoch 9269: train loss = 4.051209, test loss = 12102.368867\n",
            "Epoch 9270: train loss = 4.051192, test loss = 12102.345072\n",
            "Epoch 9271: train loss = 4.051206, test loss = 12102.323899\n",
            "Epoch 9272: train loss = 4.051184, test loss = 12102.297187\n",
            "Epoch 9273: train loss = 4.051177, test loss = 12102.267557\n",
            "Epoch 9274: train loss = 4.051183, test loss = 12102.245838\n",
            "Epoch 9275: train loss = 4.051161, test loss = 12102.218709\n",
            "Epoch 9276: train loss = 4.051161, test loss = 12102.187781\n",
            "Epoch 9277: train loss = 4.051160, test loss = 12102.167454\n",
            "Epoch 9278: train loss = 4.051137, test loss = 12102.141503\n",
            "Epoch 9279: train loss = 4.051144, test loss = 12102.109186\n",
            "Epoch 9280: train loss = 4.051136, test loss = 12102.089765\n",
            "Epoch 9281: train loss = 4.051114, test loss = 12102.063918\n",
            "Epoch 9282: train loss = 4.051128, test loss = 12102.030553\n",
            "Epoch 9283: train loss = 4.051113, test loss = 12102.012484\n",
            "Epoch 9284: train loss = 4.051093, test loss = 12101.997235\n",
            "Epoch 9285: train loss = 4.051089, test loss = 12101.973484\n",
            "Epoch 9286: train loss = 4.051093, test loss = 12101.942180\n",
            "Epoch 9287: train loss = 4.051087, test loss = 12101.922950\n",
            "Epoch 9288: train loss = 4.051065, test loss = 12101.897337\n",
            "Epoch 9289: train loss = 4.051077, test loss = 12101.863966\n",
            "Epoch 9290: train loss = 4.051064, test loss = 12101.846121\n",
            "Epoch 9291: train loss = 4.051042, test loss = 12101.830586\n",
            "Epoch 9292: train loss = 4.051040, test loss = 12101.806668\n",
            "Epoch 9293: train loss = 4.051042, test loss = 12101.775356\n",
            "Epoch 9294: train loss = 4.051038, test loss = 12101.756196\n",
            "Epoch 9295: train loss = 4.051016, test loss = 12101.730718\n",
            "Epoch 9296: train loss = 4.051026, test loss = 12101.697344\n",
            "Epoch 9297: train loss = 4.051015, test loss = 12101.678758\n",
            "Epoch 9298: train loss = 4.050993, test loss = 12101.653413\n",
            "Epoch 9299: train loss = 4.051009, test loss = 12101.618933\n",
            "Epoch 9300: train loss = 4.050992, test loss = 12101.601712\n",
            "Epoch 9301: train loss = 4.050971, test loss = 12101.578784\n",
            "Epoch 9302: train loss = 4.050989, test loss = 12101.556767\n",
            "Epoch 9303: train loss = 4.050967, test loss = 12101.529211\n",
            "Epoch 9304: train loss = 4.050956, test loss = 12101.500383\n",
            "Epoch 9305: train loss = 4.050966, test loss = 12101.478403\n",
            "Epoch 9306: train loss = 4.050944, test loss = 12101.451070\n",
            "Epoch 9307: train loss = 4.050940, test loss = 12101.421280\n",
            "Epoch 9308: train loss = 4.050943, test loss = 12101.400149\n",
            "Epoch 9309: train loss = 4.050920, test loss = 12101.373566\n",
            "Epoch 9310: train loss = 4.050924, test loss = 12101.341869\n",
            "Epoch 9311: train loss = 4.050919, test loss = 12101.322234\n",
            "Epoch 9312: train loss = 4.050897, test loss = 12101.296204\n",
            "Epoch 9313: train loss = 4.050907, test loss = 12101.263951\n",
            "Epoch 9314: train loss = 4.050896, test loss = 12101.245160\n",
            "Epoch 9315: train loss = 4.050874, test loss = 12101.229398\n",
            "Epoch 9316: train loss = 4.050872, test loss = 12101.205589\n",
            "Epoch 9317: train loss = 4.050873, test loss = 12101.174897\n",
            "Epoch 9318: train loss = 4.050870, test loss = 12101.155946\n",
            "Epoch 9319: train loss = 4.050848, test loss = 12101.129633\n",
            "Epoch 9320: train loss = 4.050857, test loss = 12101.096907\n",
            "Epoch 9321: train loss = 4.050847, test loss = 12101.078105\n",
            "Epoch 9322: train loss = 4.050824, test loss = 12101.052673\n",
            "Epoch 9323: train loss = 4.050840, test loss = 12101.018686\n",
            "Epoch 9324: train loss = 4.050823, test loss = 12101.001642\n",
            "Epoch 9325: train loss = 4.050803, test loss = 12100.985972\n",
            "Epoch 9326: train loss = 4.050800, test loss = 12100.962406\n",
            "Epoch 9327: train loss = 4.050805, test loss = 12100.930480\n",
            "Epoch 9328: train loss = 4.050798, test loss = 12100.911802\n",
            "Epoch 9329: train loss = 4.050775, test loss = 12100.886289\n",
            "Epoch 9330: train loss = 4.050789, test loss = 12100.852889\n",
            "Epoch 9331: train loss = 4.050775, test loss = 12100.834819\n",
            "Epoch 9332: train loss = 4.050752, test loss = 12100.809635\n",
            "Epoch 9333: train loss = 4.050772, test loss = 12100.774473\n",
            "Epoch 9334: train loss = 4.050751, test loss = 12100.757652\n",
            "Epoch 9335: train loss = 4.050734, test loss = 12100.733808\n",
            "Epoch 9336: train loss = 4.050749, test loss = 12100.713156\n",
            "Epoch 9337: train loss = 4.050727, test loss = 12100.685676\n",
            "Epoch 9338: train loss = 4.050719, test loss = 12100.656174\n",
            "Epoch 9339: train loss = 4.050725, test loss = 12100.634524\n",
            "Epoch 9340: train loss = 4.050703, test loss = 12100.607530\n",
            "Epoch 9341: train loss = 4.050703, test loss = 12100.576561\n",
            "Epoch 9342: train loss = 4.050702, test loss = 12100.556817\n",
            "Epoch 9343: train loss = 4.050680, test loss = 12100.530047\n",
            "Epoch 9344: train loss = 4.050687, test loss = 12100.497854\n",
            "Epoch 9345: train loss = 4.050679, test loss = 12100.478499\n",
            "Epoch 9346: train loss = 4.050656, test loss = 12100.452781\n",
            "Epoch 9347: train loss = 4.050670, test loss = 12100.419930\n",
            "Epoch 9348: train loss = 4.050655, test loss = 12100.401438\n",
            "Epoch 9349: train loss = 4.050636, test loss = 12100.385772\n",
            "Epoch 9350: train loss = 4.050632, test loss = 12100.362073\n",
            "Epoch 9351: train loss = 4.050636, test loss = 12100.331054\n",
            "Epoch 9352: train loss = 4.050630, test loss = 12100.311815\n",
            "Epoch 9353: train loss = 4.050607, test loss = 12100.286577\n",
            "Epoch 9354: train loss = 4.050619, test loss = 12100.253040\n",
            "Epoch 9355: train loss = 4.050606, test loss = 12100.234701\n",
            "Epoch 9356: train loss = 4.050584, test loss = 12100.219335\n",
            "Epoch 9357: train loss = 4.050583, test loss = 12100.195409\n",
            "Epoch 9358: train loss = 4.050585, test loss = 12100.164355\n",
            "Epoch 9359: train loss = 4.050581, test loss = 12100.145439\n",
            "Epoch 9360: train loss = 4.050559, test loss = 12100.119483\n",
            "Epoch 9361: train loss = 4.050568, test loss = 12100.086171\n",
            "Epoch 9362: train loss = 4.050558, test loss = 12100.067757\n",
            "Epoch 9363: train loss = 4.050535, test loss = 12100.042305\n",
            "Epoch 9364: train loss = 4.050552, test loss = 12100.008029\n",
            "Epoch 9365: train loss = 4.050534, test loss = 12099.991131\n",
            "Epoch 9366: train loss = 4.050514, test loss = 12099.967607\n",
            "Epoch 9367: train loss = 4.050532, test loss = 12099.945751\n",
            "Epoch 9368: train loss = 4.050510, test loss = 12099.918216\n",
            "Epoch 9369: train loss = 4.050499, test loss = 12099.889363\n",
            "Epoch 9370: train loss = 4.050508, test loss = 12099.867853\n",
            "Epoch 9371: train loss = 4.050486, test loss = 12099.840364\n",
            "Epoch 9372: train loss = 4.050483, test loss = 12099.809912\n",
            "Epoch 9373: train loss = 4.050485, test loss = 12099.789179\n",
            "Epoch 9374: train loss = 4.050463, test loss = 12099.762436\n",
            "Epoch 9375: train loss = 4.050466, test loss = 12099.730906\n",
            "Epoch 9376: train loss = 4.050462, test loss = 12099.711739\n",
            "Epoch 9377: train loss = 4.050440, test loss = 12099.685550\n",
            "Epoch 9378: train loss = 4.050450, test loss = 12099.652638\n",
            "Epoch 9379: train loss = 4.050438, test loss = 12099.634144\n",
            "Epoch 9380: train loss = 4.050417, test loss = 12099.618440\n",
            "Epoch 9381: train loss = 4.050415, test loss = 12099.594586\n",
            "Epoch 9382: train loss = 4.050416, test loss = 12099.564572\n",
            "Epoch 9383: train loss = 4.050413, test loss = 12099.544829\n",
            "Epoch 9384: train loss = 4.050391, test loss = 12099.518638\n",
            "Epoch 9385: train loss = 4.050399, test loss = 12099.486134\n",
            "Epoch 9386: train loss = 4.050390, test loss = 12099.467301\n",
            "Epoch 9387: train loss = 4.050367, test loss = 12099.441763\n",
            "Epoch 9388: train loss = 4.050383, test loss = 12099.408421\n",
            "Epoch 9389: train loss = 4.050366, test loss = 12099.390524\n",
            "Epoch 9390: train loss = 4.050346, test loss = 12099.375011\n",
            "Epoch 9391: train loss = 4.050342, test loss = 12099.351533\n",
            "Epoch 9392: train loss = 4.050348, test loss = 12099.319815\n",
            "Epoch 9393: train loss = 4.050341, test loss = 12099.301455\n",
            "Epoch 9394: train loss = 4.050318, test loss = 12099.275768\n",
            "Epoch 9395: train loss = 4.050332, test loss = 12099.241806\n",
            "Epoch 9396: train loss = 4.050317, test loss = 12099.223823\n",
            "Epoch 9397: train loss = 4.050295, test loss = 12099.198762\n",
            "Epoch 9398: train loss = 4.050315, test loss = 12099.163832\n",
            "Epoch 9399: train loss = 4.050294, test loss = 12099.147334\n",
            "Epoch 9400: train loss = 4.050277, test loss = 12099.123533\n",
            "Epoch 9401: train loss = 4.050292, test loss = 12099.101970\n",
            "Epoch 9402: train loss = 4.050269, test loss = 12099.074750\n",
            "Epoch 9403: train loss = 4.050262, test loss = 12099.045411\n",
            "Epoch 9404: train loss = 4.050268, test loss = 12099.023898\n",
            "Epoch 9405: train loss = 4.050246, test loss = 12098.997242\n",
            "Epoch 9406: train loss = 4.050246, test loss = 12098.966265\n",
            "Epoch 9407: train loss = 4.050245, test loss = 12098.945669\n",
            "Epoch 9408: train loss = 4.050223, test loss = 12098.919261\n",
            "Epoch 9409: train loss = 4.050229, test loss = 12098.887099\n",
            "Epoch 9410: train loss = 4.050222, test loss = 12098.867906\n",
            "Epoch 9411: train loss = 4.050199, test loss = 12098.842535\n",
            "Epoch 9412: train loss = 4.050213, test loss = 12098.809035\n",
            "Epoch 9413: train loss = 4.050198, test loss = 12098.790795\n",
            "Epoch 9414: train loss = 4.050179, test loss = 12098.775054\n",
            "Epoch 9415: train loss = 4.050175, test loss = 12098.751610\n",
            "Epoch 9416: train loss = 4.050179, test loss = 12098.720876\n",
            "Epoch 9417: train loss = 4.050173, test loss = 12098.701555\n",
            "Epoch 9418: train loss = 4.050151, test loss = 12098.675546\n",
            "Epoch 9419: train loss = 4.050162, test loss = 12098.642411\n",
            "Epoch 9420: train loss = 4.050150, test loss = 12098.624023\n",
            "Epoch 9421: train loss = 4.050128, test loss = 12098.608792\n",
            "Epoch 9422: train loss = 4.050126, test loss = 12098.585333\n",
            "Epoch 9423: train loss = 4.050128, test loss = 12098.554065\n",
            "Epoch 9424: train loss = 4.050124, test loss = 12098.534597\n",
            "Epoch 9425: train loss = 4.050102, test loss = 12098.508716\n",
            "Epoch 9426: train loss = 4.050111, test loss = 12098.475705\n",
            "Epoch 9427: train loss = 4.050101, test loss = 12098.457180\n",
            "Epoch 9428: train loss = 4.050078, test loss = 12098.432327\n",
            "Epoch 9429: train loss = 4.050095, test loss = 12098.397707\n",
            "Epoch 9430: train loss = 4.050078, test loss = 12098.380321\n",
            "Epoch 9431: train loss = 4.050057, test loss = 12098.357033\n",
            "Epoch 9432: train loss = 4.050075, test loss = 12098.335163\n",
            "Epoch 9433: train loss = 4.050053, test loss = 12098.307711\n",
            "Epoch 9434: train loss = 4.050042, test loss = 12098.279553\n",
            "Epoch 9435: train loss = 4.050052, test loss = 12098.257117\n",
            "Epoch 9436: train loss = 4.050030, test loss = 12098.229877\n",
            "Epoch 9437: train loss = 4.050026, test loss = 12098.199511\n",
            "Epoch 9438: train loss = 4.050028, test loss = 12098.178695\n",
            "Epoch 9439: train loss = 4.050006, test loss = 12098.152461\n",
            "Epoch 9440: train loss = 4.050010, test loss = 12098.120816\n",
            "Epoch 9441: train loss = 4.050005, test loss = 12098.101074\n",
            "Epoch 9442: train loss = 4.049983, test loss = 12098.074919\n",
            "Epoch 9443: train loss = 4.049993, test loss = 12098.042293\n",
            "Epoch 9444: train loss = 4.049982, test loss = 12098.023616\n",
            "Epoch 9445: train loss = 4.049961, test loss = 12098.008626\n",
            "Epoch 9446: train loss = 4.049958, test loss = 12097.984464\n",
            "Epoch 9447: train loss = 4.049959, test loss = 12097.953908\n",
            "Epoch 9448: train loss = 4.049956, test loss = 12097.934250\n",
            "Epoch 9449: train loss = 4.049934, test loss = 12097.908297\n",
            "Epoch 9450: train loss = 4.049943, test loss = 12097.875788\n",
            "Epoch 9451: train loss = 4.049933, test loss = 12097.857499\n",
            "Epoch 9452: train loss = 4.049911, test loss = 12097.831746\n",
            "Epoch 9453: train loss = 4.049926, test loss = 12097.797738\n",
            "Epoch 9454: train loss = 4.049910, test loss = 12097.780135\n",
            "Epoch 9455: train loss = 4.049890, test loss = 12097.764675\n",
            "Epoch 9456: train loss = 4.049886, test loss = 12097.741257\n",
            "Epoch 9457: train loss = 4.049892, test loss = 12097.709965\n",
            "Epoch 9458: train loss = 4.049884, test loss = 12097.691061\n",
            "Epoch 9459: train loss = 4.049862, test loss = 12097.665367\n",
            "Epoch 9460: train loss = 4.049875, test loss = 12097.631554\n",
            "Epoch 9461: train loss = 4.049861, test loss = 12097.613690\n",
            "Epoch 9462: train loss = 4.049838, test loss = 12097.588508\n",
            "Epoch 9463: train loss = 4.049858, test loss = 12097.554188\n",
            "Epoch 9464: train loss = 4.049838, test loss = 12097.536919\n",
            "Epoch 9465: train loss = 4.049821, test loss = 12097.513212\n",
            "Epoch 9466: train loss = 4.049835, test loss = 12097.491738\n",
            "Epoch 9467: train loss = 4.049813, test loss = 12097.464659\n",
            "Epoch 9468: train loss = 4.049805, test loss = 12097.435708\n",
            "Epoch 9469: train loss = 4.049812, test loss = 12097.414011\n",
            "Epoch 9470: train loss = 4.049790, test loss = 12097.386738\n",
            "Epoch 9471: train loss = 4.049789, test loss = 12097.355925\n",
            "Epoch 9472: train loss = 4.049789, test loss = 12097.335452\n",
            "Epoch 9473: train loss = 4.049766, test loss = 12097.309101\n",
            "Epoch 9474: train loss = 4.049773, test loss = 12097.277573\n",
            "Epoch 9475: train loss = 4.049765, test loss = 12097.258015\n",
            "Epoch 9476: train loss = 4.049743, test loss = 12097.232128\n",
            "Epoch 9477: train loss = 4.049757, test loss = 12097.198753\n",
            "Epoch 9478: train loss = 4.049742, test loss = 12097.180703\n",
            "Epoch 9479: train loss = 4.049723, test loss = 12097.164964\n",
            "Epoch 9480: train loss = 4.049718, test loss = 12097.141923\n",
            "Epoch 9481: train loss = 4.049722, test loss = 12097.110546\n",
            "Epoch 9482: train loss = 4.049717, test loss = 12097.091380\n",
            "Epoch 9483: train loss = 4.049694, test loss = 12097.065562\n",
            "Epoch 9484: train loss = 4.049706, test loss = 12097.032360\n",
            "Epoch 9485: train loss = 4.049693, test loss = 12097.014101\n",
            "Epoch 9486: train loss = 4.049671, test loss = 12096.999105\n",
            "Epoch 9487: train loss = 4.049670, test loss = 12096.975185\n",
            "Epoch 9488: train loss = 4.049672, test loss = 12096.943955\n",
            "Epoch 9489: train loss = 4.049668, test loss = 12096.924673\n",
            "Epoch 9490: train loss = 4.049645, test loss = 12096.898695\n",
            "Epoch 9491: train loss = 4.049655, test loss = 12096.866215\n",
            "Epoch 9492: train loss = 4.049645, test loss = 12096.847581\n",
            "Epoch 9493: train loss = 4.049622, test loss = 12096.821948\n",
            "Epoch 9494: train loss = 4.049639, test loss = 12096.787788\n",
            "Epoch 9495: train loss = 4.049621, test loss = 12096.770229\n",
            "Epoch 9496: train loss = 4.049601, test loss = 12096.747067\n",
            "Epoch 9497: train loss = 4.049619, test loss = 12096.725685\n",
            "Epoch 9498: train loss = 4.049597, test loss = 12096.698082\n",
            "Epoch 9499: train loss = 4.049586, test loss = 12096.669233\n",
            "Epoch 9500: train loss = 4.049596, test loss = 12096.647127\n",
            "Epoch 9501: train loss = 4.049573, test loss = 12096.619884\n",
            "Epoch 9502: train loss = 4.049570, test loss = 12096.589625\n",
            "Epoch 9503: train loss = 4.049572, test loss = 12096.569375\n",
            "Epoch 9504: train loss = 4.049550, test loss = 12096.542379\n",
            "Epoch 9505: train loss = 4.049554, test loss = 12096.510805\n",
            "Epoch 9506: train loss = 4.049549, test loss = 12096.491158\n",
            "Epoch 9507: train loss = 4.049527, test loss = 12096.465165\n",
            "Epoch 9508: train loss = 4.049537, test loss = 12096.432449\n",
            "Epoch 9509: train loss = 4.049526, test loss = 12096.414491\n",
            "Epoch 9510: train loss = 4.049505, test loss = 12096.398449\n",
            "Epoch 9511: train loss = 4.049502, test loss = 12096.374508\n",
            "Epoch 9512: train loss = 4.049503, test loss = 12096.344070\n",
            "Epoch 9513: train loss = 4.049500, test loss = 12096.324554\n",
            "Epoch 9514: train loss = 4.049478, test loss = 12096.298942\n",
            "Epoch 9515: train loss = 4.049487, test loss = 12096.266295\n",
            "Epoch 9516: train loss = 4.049477, test loss = 12096.247387\n",
            "Epoch 9517: train loss = 4.049455, test loss = 12096.221741\n",
            "Epoch 9518: train loss = 4.049470, test loss = 12096.188000\n",
            "Epoch 9519: train loss = 4.049454, test loss = 12096.170339\n",
            "Epoch 9520: train loss = 4.049434, test loss = 12096.155373\n",
            "Epoch 9521: train loss = 4.049430, test loss = 12096.131799\n",
            "Epoch 9522: train loss = 4.049436, test loss = 12096.099925\n",
            "Epoch 9523: train loss = 4.049428, test loss = 12096.081122\n",
            "Epoch 9524: train loss = 4.049406, test loss = 12096.055561\n",
            "Epoch 9525: train loss = 4.049419, test loss = 12096.021955\n",
            "Epoch 9526: train loss = 4.049405, test loss = 12096.004486\n",
            "Epoch 9527: train loss = 4.049383, test loss = 12095.989075\n",
            "Epoch 9528: train loss = 4.049381, test loss = 12095.965254\n",
            "Epoch 9529: train loss = 4.049385, test loss = 12095.933520\n",
            "Epoch 9530: train loss = 4.049380, test loss = 12095.914715\n",
            "Epoch 9531: train loss = 4.049357, test loss = 12095.888883\n",
            "Epoch 9532: train loss = 4.049369, test loss = 12095.855772\n",
            "Epoch 9533: train loss = 4.049356, test loss = 12095.837628\n",
            "Epoch 9534: train loss = 4.049334, test loss = 12095.812150\n",
            "Epoch 9535: train loss = 4.049352, test loss = 12095.777390\n",
            "Epoch 9536: train loss = 4.049333, test loss = 12095.760230\n",
            "Epoch 9537: train loss = 4.049314, test loss = 12095.736775\n",
            "Epoch 9538: train loss = 4.049331, test loss = 12095.715749\n",
            "Epoch 9539: train loss = 4.049309, test loss = 12095.688205\n",
            "Epoch 9540: train loss = 4.049299, test loss = 12095.659014\n",
            "Epoch 9541: train loss = 4.049308, test loss = 12095.637128\n",
            "Epoch 9542: train loss = 4.049285, test loss = 12095.610150\n",
            "Epoch 9543: train loss = 4.049283, test loss = 12095.579848\n",
            "Epoch 9544: train loss = 4.049284, test loss = 12095.559094\n",
            "Epoch 9545: train loss = 4.049262, test loss = 12095.532430\n",
            "Epoch 9546: train loss = 4.049267, test loss = 12095.500571\n",
            "Epoch 9547: train loss = 4.049261, test loss = 12095.481142\n",
            "Epoch 9548: train loss = 4.049239, test loss = 12095.455415\n",
            "Epoch 9549: train loss = 4.049251, test loss = 12095.422680\n",
            "Epoch 9550: train loss = 4.049238, test loss = 12095.404209\n",
            "Epoch 9551: train loss = 4.049216, test loss = 12095.388566\n",
            "Epoch 9552: train loss = 4.049214, test loss = 12095.364817\n",
            "Epoch 9553: train loss = 4.049216, test loss = 12095.333880\n",
            "Epoch 9554: train loss = 4.049212, test loss = 12095.314531\n",
            "Epoch 9555: train loss = 4.049190, test loss = 12095.289182\n",
            "Epoch 9556: train loss = 4.049200, test loss = 12095.255893\n",
            "Epoch 9557: train loss = 4.049189, test loss = 12095.237533\n",
            "Epoch 9558: train loss = 4.049167, test loss = 12095.211970\n",
            "Epoch 9559: train loss = 4.049183, test loss = 12095.177791\n",
            "Epoch 9560: train loss = 4.049166, test loss = 12095.160302\n",
            "Epoch 9561: train loss = 4.049146, test loss = 12095.137749\n",
            "Epoch 9562: train loss = 4.049163, test loss = 12095.115621\n",
            "Epoch 9563: train loss = 4.049141, test loss = 12095.088054\n",
            "Epoch 9564: train loss = 4.049130, test loss = 12095.059445\n",
            "Epoch 9565: train loss = 4.049140, test loss = 12095.037261\n",
            "Epoch 9566: train loss = 4.049118, test loss = 12095.010613\n",
            "Epoch 9567: train loss = 4.049115, test loss = 12094.980141\n",
            "Epoch 9568: train loss = 4.049117, test loss = 12094.959167\n",
            "Epoch 9569: train loss = 4.049095, test loss = 12094.932435\n",
            "Epoch 9570: train loss = 4.049098, test loss = 12094.901102\n",
            "Epoch 9571: train loss = 4.049094, test loss = 12094.881476\n",
            "Epoch 9572: train loss = 4.049071, test loss = 12094.855849\n",
            "Epoch 9573: train loss = 4.049082, test loss = 12094.823031\n",
            "Epoch 9574: train loss = 4.049070, test loss = 12094.804287\n",
            "Epoch 9575: train loss = 4.049050, test loss = 12094.788706\n",
            "Epoch 9576: train loss = 4.049047, test loss = 12094.764842\n",
            "Epoch 9577: train loss = 4.049048, test loss = 12094.734480\n",
            "Epoch 9578: train loss = 4.049045, test loss = 12094.715333\n",
            "Epoch 9579: train loss = 4.049023, test loss = 12094.689144\n",
            "Epoch 9580: train loss = 4.049031, test loss = 12094.656473\n",
            "Epoch 9581: train loss = 4.049022, test loss = 12094.637894\n",
            "Epoch 9582: train loss = 4.048999, test loss = 12094.612240\n",
            "Epoch 9583: train loss = 4.049015, test loss = 12094.578528\n",
            "Epoch 9584: train loss = 4.048998, test loss = 12094.561271\n",
            "Epoch 9585: train loss = 4.048979, test loss = 12094.545644\n",
            "Epoch 9586: train loss = 4.048975, test loss = 12094.522140\n",
            "Epoch 9587: train loss = 4.048981, test loss = 12094.490394\n",
            "Epoch 9588: train loss = 4.048973, test loss = 12094.471733\n",
            "Epoch 9589: train loss = 4.048951, test loss = 12094.446525\n",
            "Epoch 9590: train loss = 4.048964, test loss = 12094.412776\n",
            "Epoch 9591: train loss = 4.048950, test loss = 12094.394694\n",
            "Epoch 9592: train loss = 4.048928, test loss = 12094.379479\n",
            "Epoch 9593: train loss = 4.048926, test loss = 12094.355676\n",
            "Epoch 9594: train loss = 4.048930, test loss = 12094.324169\n",
            "Epoch 9595: train loss = 4.048925, test loss = 12094.305744\n",
            "Epoch 9596: train loss = 4.048902, test loss = 12094.279682\n",
            "Epoch 9597: train loss = 4.048913, test loss = 12094.246123\n",
            "Epoch 9598: train loss = 4.048901, test loss = 12094.227975\n",
            "Epoch 9599: train loss = 4.048879, test loss = 12094.202854\n",
            "Epoch 9600: train loss = 4.048897, test loss = 12094.168013\n",
            "Epoch 9601: train loss = 4.048878, test loss = 12094.151455\n",
            "Epoch 9602: train loss = 4.048859, test loss = 12094.127625\n",
            "Epoch 9603: train loss = 4.048876, test loss = 12094.106042\n",
            "Epoch 9604: train loss = 4.048853, test loss = 12094.078836\n",
            "Epoch 9605: train loss = 4.048844, test loss = 12094.049636\n",
            "Epoch 9606: train loss = 4.048852, test loss = 12094.027921\n",
            "Epoch 9607: train loss = 4.048830, test loss = 12094.001212\n",
            "Epoch 9608: train loss = 4.048828, test loss = 12093.970518\n",
            "Epoch 9609: train loss = 4.048829, test loss = 12093.949708\n",
            "Epoch 9610: train loss = 4.048807, test loss = 12093.923245\n",
            "Epoch 9611: train loss = 4.048812, test loss = 12093.891307\n",
            "Epoch 9612: train loss = 4.048806, test loss = 12093.872011\n",
            "Epoch 9613: train loss = 4.048784, test loss = 12093.846536\n",
            "Epoch 9614: train loss = 4.048796, test loss = 12093.813350\n",
            "Epoch 9615: train loss = 4.048783, test loss = 12093.794871\n",
            "Epoch 9616: train loss = 4.048761, test loss = 12093.779409\n",
            "Epoch 9617: train loss = 4.048759, test loss = 12093.755584\n",
            "Epoch 9618: train loss = 4.048761, test loss = 12093.725239\n",
            "Epoch 9619: train loss = 4.048758, test loss = 12093.705680\n",
            "Epoch 9620: train loss = 4.048735, test loss = 12093.679612\n",
            "Epoch 9621: train loss = 4.048745, test loss = 12093.646681\n",
            "Epoch 9622: train loss = 4.048734, test loss = 12093.628205\n",
            "Epoch 9623: train loss = 4.048712, test loss = 12093.602943\n",
            "Epoch 9624: train loss = 4.048729, test loss = 12093.569117\n",
            "Epoch 9625: train loss = 4.048711, test loss = 12093.551535\n",
            "Epoch 9626: train loss = 4.048691, test loss = 12093.536134\n",
            "Epoch 9627: train loss = 4.048687, test loss = 12093.512719\n",
            "Epoch 9628: train loss = 4.048694, test loss = 12093.480658\n",
            "Epoch 9629: train loss = 4.048686, test loss = 12093.462122\n",
            "Epoch 9630: train loss = 4.048663, test loss = 12093.437152\n",
            "Epoch 9631: train loss = 4.048678, test loss = 12093.402791\n",
            "Epoch 9632: train loss = 4.048663, test loss = 12093.385225\n",
            "Epoch 9633: train loss = 4.048640, test loss = 12093.352035\n",
            "Epoch 9634: train loss = 4.048640, test loss = 12093.326431\n",
            "Epoch 9635: train loss = 4.048642, test loss = 12093.295473\n",
            "Epoch 9636: train loss = 4.048639, test loss = 12093.275893\n",
            "Epoch 9637: train loss = 4.048617, test loss = 12093.249045\n",
            "Epoch 9638: train loss = 4.048626, test loss = 12093.216229\n",
            "Epoch 9639: train loss = 4.048616, test loss = 12093.197166\n",
            "Epoch 9640: train loss = 4.048595, test loss = 12093.181215\n",
            "Epoch 9641: train loss = 4.048592, test loss = 12093.157563\n",
            "Epoch 9642: train loss = 4.048592, test loss = 12093.127088\n",
            "Epoch 9643: train loss = 4.048591, test loss = 12093.107066\n",
            "Epoch 9644: train loss = 4.048568, test loss = 12093.080731\n",
            "Epoch 9645: train loss = 4.048576, test loss = 12093.048509\n",
            "Epoch 9646: train loss = 4.048567, test loss = 12093.029434\n",
            "Epoch 9647: train loss = 4.048545, test loss = 12093.004142\n",
            "Epoch 9648: train loss = 4.048560, test loss = 12092.970349\n",
            "Epoch 9649: train loss = 4.048544, test loss = 12092.952388\n",
            "Epoch 9650: train loss = 4.048524, test loss = 12092.936747\n",
            "Epoch 9651: train loss = 4.048520, test loss = 12092.913347\n",
            "Epoch 9652: train loss = 4.048525, test loss = 12092.881825\n",
            "Epoch 9653: train loss = 4.048519, test loss = 12092.863337\n",
            "Epoch 9654: train loss = 4.048497, test loss = 12092.837435\n",
            "Epoch 9655: train loss = 4.048509, test loss = 12092.803932\n",
            "Epoch 9656: train loss = 4.048496, test loss = 12092.785771\n",
            "Epoch 9657: train loss = 4.048473, test loss = 12092.770631\n",
            "Epoch 9658: train loss = 4.048472, test loss = 12092.746744\n",
            "Epoch 9659: train loss = 4.048475, test loss = 12092.715849\n",
            "Epoch 9660: train loss = 4.048470, test loss = 12092.696513\n",
            "Epoch 9661: train loss = 4.048448, test loss = 12092.670646\n",
            "Epoch 9662: train loss = 4.048459, test loss = 12092.637210\n",
            "Epoch 9663: train loss = 4.048447, test loss = 12092.619153\n",
            "Epoch 9664: train loss = 4.048425, test loss = 12092.594185\n",
            "Epoch 9665: train loss = 4.048442, test loss = 12092.559419\n",
            "Epoch 9666: train loss = 4.048424, test loss = 12092.542066\n",
            "Epoch 9667: train loss = 4.048404, test loss = 12092.518690\n",
            "Epoch 9668: train loss = 4.048422, test loss = 12092.496936\n",
            "Epoch 9669: train loss = 4.048399, test loss = 12092.469727\n",
            "Epoch 9670: train loss = 4.048389, test loss = 12092.441304\n",
            "Epoch 9671: train loss = 4.048398, test loss = 12092.419061\n",
            "Epoch 9672: train loss = 4.048376, test loss = 12092.391923\n",
            "Epoch 9673: train loss = 4.048373, test loss = 12092.361364\n",
            "Epoch 9674: train loss = 4.048375, test loss = 12092.340596\n",
            "Epoch 9675: train loss = 4.048353, test loss = 12092.314148\n",
            "Epoch 9676: train loss = 4.048357, test loss = 12092.283035\n",
            "Epoch 9677: train loss = 4.048352, test loss = 12092.263172\n",
            "Epoch 9678: train loss = 4.048330, test loss = 12092.237278\n",
            "Epoch 9679: train loss = 4.048341, test loss = 12092.204208\n",
            "Epoch 9680: train loss = 4.048329, test loss = 12092.185875\n",
            "Epoch 9681: train loss = 4.048307, test loss = 12092.170313\n",
            "Epoch 9682: train loss = 4.048305, test loss = 12092.147078\n",
            "Epoch 9683: train loss = 4.048307, test loss = 12092.116053\n",
            "Epoch 9684: train loss = 4.048304, test loss = 12092.096663\n",
            "Epoch 9685: train loss = 4.048281, test loss = 12092.070607\n",
            "Epoch 9686: train loss = 4.048291, test loss = 12092.037867\n",
            "Epoch 9687: train loss = 4.048280, test loss = 12092.019303\n",
            "Epoch 9688: train loss = 4.048258, test loss = 12091.994378\n",
            "Epoch 9689: train loss = 4.048274, test loss = 12091.960119\n",
            "Epoch 9690: train loss = 4.048257, test loss = 12091.942461\n",
            "Epoch 9691: train loss = 4.048237, test loss = 12091.927240\n",
            "Epoch 9692: train loss = 4.048233, test loss = 12091.903718\n",
            "Epoch 9693: train loss = 4.048240, test loss = 12091.872456\n",
            "Epoch 9694: train loss = 4.048232, test loss = 12091.853479\n",
            "Epoch 9695: train loss = 4.048210, test loss = 12091.827883\n",
            "Epoch 9696: train loss = 4.048223, test loss = 12091.793866\n",
            "Epoch 9697: train loss = 4.048209, test loss = 12091.776224\n",
            "Epoch 9698: train loss = 4.048186, test loss = 12091.751187\n",
            "Epoch 9699: train loss = 4.048207, test loss = 12091.716449\n",
            "Epoch 9700: train loss = 4.048186, test loss = 12091.699559\n",
            "Epoch 9701: train loss = 4.048169, test loss = 12091.675533\n",
            "Epoch 9702: train loss = 4.048183, test loss = 12091.654468\n",
            "Epoch 9703: train loss = 4.048161, test loss = 12091.627317\n",
            "Epoch 9704: train loss = 4.048154, test loss = 12091.597889\n",
            "Epoch 9705: train loss = 4.048160, test loss = 12091.576827\n",
            "Epoch 9706: train loss = 4.048138, test loss = 12091.549668\n",
            "Epoch 9707: train loss = 4.048138, test loss = 12091.518534\n",
            "Epoch 9708: train loss = 4.048137, test loss = 12091.498355\n",
            "Epoch 9709: train loss = 4.048115, test loss = 12091.471916\n",
            "Epoch 9710: train loss = 4.048122, test loss = 12091.439804\n",
            "Epoch 9711: train loss = 4.048114, test loss = 12091.421081\n",
            "Epoch 9712: train loss = 4.048091, test loss = 12091.395146\n",
            "Epoch 9713: train loss = 4.048106, test loss = 12091.361625\n",
            "Epoch 9714: train loss = 4.048091, test loss = 12091.343526\n",
            "Epoch 9715: train loss = 4.048071, test loss = 12091.328041\n",
            "Epoch 9716: train loss = 4.048067, test loss = 12091.304901\n",
            "Epoch 9717: train loss = 4.048071, test loss = 12091.273583\n",
            "Epoch 9718: train loss = 4.048065, test loss = 12091.254330\n",
            "Epoch 9719: train loss = 4.048043, test loss = 12091.228602\n",
            "Epoch 9720: train loss = 4.048055, test loss = 12091.195233\n",
            "Epoch 9721: train loss = 4.048042, test loss = 12091.177174\n",
            "Epoch 9722: train loss = 4.048020, test loss = 12091.162395\n",
            "Epoch 9723: train loss = 4.048018, test loss = 12091.138264\n",
            "Epoch 9724: train loss = 4.048021, test loss = 12091.107054\n",
            "Epoch 9725: train loss = 4.048017, test loss = 12091.087730\n",
            "Epoch 9726: train loss = 4.047994, test loss = 12091.062046\n",
            "Epoch 9727: train loss = 4.048005, test loss = 12091.028780\n",
            "Epoch 9728: train loss = 4.047994, test loss = 12091.011031\n",
            "Epoch 9729: train loss = 4.047971, test loss = 12090.985350\n",
            "Epoch 9730: train loss = 4.047988, test loss = 12090.950888\n",
            "Epoch 9731: train loss = 4.047971, test loss = 12090.933644\n",
            "Epoch 9732: train loss = 4.047950, test loss = 12090.910280\n",
            "Epoch 9733: train loss = 4.047968, test loss = 12090.888583\n",
            "Epoch 9734: train loss = 4.047946, test loss = 12090.861735\n",
            "Epoch 9735: train loss = 4.047935, test loss = 12090.832765\n",
            "Epoch 9736: train loss = 4.047945, test loss = 12090.810570\n",
            "Epoch 9737: train loss = 4.047923, test loss = 12090.783377\n",
            "Epoch 9738: train loss = 4.047920, test loss = 12090.753015\n",
            "Epoch 9739: train loss = 4.047922, test loss = 12090.732761\n",
            "Epoch 9740: train loss = 4.047900, test loss = 12090.705887\n",
            "Epoch 9741: train loss = 4.047904, test loss = 12090.674416\n",
            "Epoch 9742: train loss = 4.047899, test loss = 12090.654672\n",
            "Epoch 9743: train loss = 4.047876, test loss = 12090.628765\n",
            "Epoch 9744: train loss = 4.047887, test loss = 12090.595910\n",
            "Epoch 9745: train loss = 4.047876, test loss = 12090.577996\n",
            "Epoch 9746: train loss = 4.047854, test loss = 12090.562266\n",
            "Epoch 9747: train loss = 4.047852, test loss = 12090.538302\n",
            "Epoch 9748: train loss = 4.047853, test loss = 12090.507747\n",
            "Epoch 9749: train loss = 4.047850, test loss = 12090.488187\n",
            "Epoch 9750: train loss = 4.047828, test loss = 12090.462408\n",
            "Epoch 9751: train loss = 4.047837, test loss = 12090.430167\n",
            "Epoch 9752: train loss = 4.047827, test loss = 12090.411342\n",
            "Epoch 9753: train loss = 4.047805, test loss = 12090.385681\n",
            "Epoch 9754: train loss = 4.047820, test loss = 12090.351764\n",
            "Epoch 9755: train loss = 4.047804, test loss = 12090.334259\n",
            "Epoch 9756: train loss = 4.047784, test loss = 12090.318932\n",
            "Epoch 9757: train loss = 4.047780, test loss = 12090.296008\n",
            "Epoch 9758: train loss = 4.047786, test loss = 12090.263929\n",
            "Epoch 9759: train loss = 4.047779, test loss = 12090.245302\n",
            "Epoch 9760: train loss = 4.047756, test loss = 12090.219606\n",
            "Epoch 9761: train loss = 4.047770, test loss = 12090.185867\n",
            "Epoch 9762: train loss = 4.047755, test loss = 12090.168508\n",
            "Epoch 9763: train loss = 4.047733, test loss = 12090.143198\n",
            "Epoch 9764: train loss = 4.047753, test loss = 12090.108101\n",
            "Epoch 9765: train loss = 4.047732, test loss = 12090.091229\n",
            "Epoch 9766: train loss = 4.047715, test loss = 12090.067612\n",
            "Epoch 9767: train loss = 4.047730, test loss = 12090.046275\n",
            "Epoch 9768: train loss = 4.047708, test loss = 12090.019689\n",
            "Epoch 9769: train loss = 4.047700, test loss = 12089.990059\n",
            "Epoch 9770: train loss = 4.047707, test loss = 12089.968475\n",
            "Epoch 9771: train loss = 4.047685, test loss = 12089.941364\n",
            "Epoch 9772: train loss = 4.047685, test loss = 12089.910643\n",
            "Epoch 9773: train loss = 4.047684, test loss = 12089.890202\n",
            "Epoch 9774: train loss = 4.047661, test loss = 12089.864275\n",
            "Epoch 9775: train loss = 4.047668, test loss = 12089.832013\n",
            "Epoch 9776: train loss = 4.047661, test loss = 12089.812776\n",
            "Epoch 9777: train loss = 4.047638, test loss = 12089.786899\n",
            "Epoch 9778: train loss = 4.047652, test loss = 12089.753603\n",
            "Epoch 9779: train loss = 4.047637, test loss = 12089.735619\n",
            "Epoch 9780: train loss = 4.047618, test loss = 12089.720457\n",
            "Epoch 9781: train loss = 4.047614, test loss = 12089.696805\n",
            "Epoch 9782: train loss = 4.047618, test loss = 12089.665488\n",
            "Epoch 9783: train loss = 4.047612, test loss = 12089.646315\n",
            "Epoch 9784: train loss = 4.047590, test loss = 12089.620624\n",
            "Epoch 9785: train loss = 4.047602, test loss = 12089.587541\n",
            "Epoch 9786: train loss = 4.047589, test loss = 12089.569701\n",
            "Epoch 9787: train loss = 4.047567, test loss = 12089.554286\n",
            "Epoch 9788: train loss = 4.047565, test loss = 12089.530265\n",
            "Epoch 9789: train loss = 4.047568, test loss = 12089.499114\n",
            "Epoch 9790: train loss = 4.047564, test loss = 12089.479912\n",
            "Epoch 9791: train loss = 4.047541, test loss = 12089.454586\n",
            "Epoch 9792: train loss = 4.047551, test loss = 12089.421221\n",
            "Epoch 9793: train loss = 4.047541, test loss = 12089.402883\n",
            "Epoch 9794: train loss = 4.047518, test loss = 12089.377363\n",
            "Epoch 9795: train loss = 4.047535, test loss = 12089.342977\n",
            "Epoch 9796: train loss = 4.047518, test loss = 12089.325759\n",
            "Epoch 9797: train loss = 4.047497, test loss = 12089.303077\n",
            "Epoch 9798: train loss = 4.047515, test loss = 12089.280931\n",
            "Epoch 9799: train loss = 4.047493, test loss = 12089.253689\n",
            "Epoch 9800: train loss = 4.047482, test loss = 12089.224769\n",
            "Epoch 9801: train loss = 4.047492, test loss = 12089.202790\n",
            "Epoch 9802: train loss = 4.047470, test loss = 12089.175562\n",
            "Epoch 9803: train loss = 4.047466, test loss = 12089.145847\n",
            "Epoch 9804: train loss = 4.047469, test loss = 12089.124704\n",
            "Epoch 9805: train loss = 4.047447, test loss = 12089.098172\n",
            "Epoch 9806: train loss = 4.047450, test loss = 12089.066596\n",
            "Epoch 9807: train loss = 4.047446, test loss = 12089.047005\n",
            "Epoch 9808: train loss = 4.047423, test loss = 12089.020979\n",
            "Epoch 9809: train loss = 4.047434, test loss = 12088.988856\n",
            "Epoch 9810: train loss = 4.047423, test loss = 12088.970002\n",
            "Epoch 9811: train loss = 4.047401, test loss = 12088.954509\n",
            "Epoch 9812: train loss = 4.047399, test loss = 12088.930591\n",
            "Epoch 9813: train loss = 4.047400, test loss = 12088.900144\n",
            "Epoch 9814: train loss = 4.047397, test loss = 12088.881018\n",
            "Epoch 9815: train loss = 4.047375, test loss = 12088.854873\n",
            "Epoch 9816: train loss = 4.047384, test loss = 12088.822262\n",
            "Epoch 9817: train loss = 4.047374, test loss = 12088.803488\n",
            "Epoch 9818: train loss = 4.047352, test loss = 12088.778052\n",
            "Epoch 9819: train loss = 4.047367, test loss = 12088.744191\n",
            "Epoch 9820: train loss = 4.047351, test loss = 12088.727185\n",
            "Epoch 9821: train loss = 4.047331, test loss = 12088.711554\n",
            "Epoch 9822: train loss = 4.047327, test loss = 12088.688041\n",
            "Epoch 9823: train loss = 4.047333, test loss = 12088.656247\n",
            "Epoch 9824: train loss = 4.047326, test loss = 12088.637608\n",
            "Epoch 9825: train loss = 4.047303, test loss = 12088.612098\n",
            "Epoch 9826: train loss = 4.047317, test loss = 12088.578833\n",
            "Epoch 9827: train loss = 4.047303, test loss = 12088.560795\n",
            "Epoch 9828: train loss = 4.047280, test loss = 12088.535504\n",
            "Epoch 9829: train loss = 4.047300, test loss = 12088.500650\n",
            "Epoch 9830: train loss = 4.047280, test loss = 12088.483752\n",
            "Epoch 9831: train loss = 4.047263, test loss = 12088.460118\n",
            "Epoch 9832: train loss = 4.047277, test loss = 12088.439249\n",
            "Epoch 9833: train loss = 4.047255, test loss = 12088.412033\n",
            "Epoch 9834: train loss = 4.047247, test loss = 12088.382591\n",
            "Epoch 9835: train loss = 4.047254, test loss = 12088.360925\n",
            "Epoch 9836: train loss = 4.047232, test loss = 12088.334032\n",
            "Epoch 9837: train loss = 4.047232, test loss = 12088.303584\n",
            "Epoch 9838: train loss = 4.047231, test loss = 12088.283101\n",
            "Epoch 9839: train loss = 4.047209, test loss = 12088.256518\n",
            "Epoch 9840: train loss = 4.047216, test loss = 12088.224509\n",
            "Epoch 9841: train loss = 4.047208, test loss = 12088.205233\n",
            "Epoch 9842: train loss = 4.047186, test loss = 12088.179538\n",
            "Epoch 9843: train loss = 4.047199, test loss = 12088.146717\n",
            "Epoch 9844: train loss = 4.047185, test loss = 12088.128497\n",
            "Epoch 9845: train loss = 4.047165, test loss = 12088.112715\n",
            "Epoch 9846: train loss = 4.047161, test loss = 12088.089187\n",
            "Epoch 9847: train loss = 4.047165, test loss = 12088.058075\n",
            "Epoch 9848: train loss = 4.047160, test loss = 12088.039045\n",
            "Epoch 9849: train loss = 4.047137, test loss = 12088.013804\n",
            "Epoch 9850: train loss = 4.047149, test loss = 12087.980382\n",
            "Epoch 9851: train loss = 4.047137, test loss = 12087.962079\n",
            "Epoch 9852: train loss = 4.047114, test loss = 12087.946653\n",
            "Epoch 9853: train loss = 4.047113, test loss = 12087.923060\n",
            "Epoch 9854: train loss = 4.047115, test loss = 12087.891918\n",
            "Epoch 9855: train loss = 4.047111, test loss = 12087.873161\n",
            "Epoch 9856: train loss = 4.047089, test loss = 12087.846985\n",
            "Epoch 9857: train loss = 4.047099, test loss = 12087.813958\n",
            "Epoch 9858: train loss = 4.047088, test loss = 12087.795565\n",
            "Epoch 9859: train loss = 4.047066, test loss = 12087.770105\n",
            "Epoch 9860: train loss = 4.047082, test loss = 12087.735953\n",
            "Epoch 9861: train loss = 4.047065, test loss = 12087.718991\n",
            "Epoch 9862: train loss = 4.047045, test loss = 12087.695730\n",
            "Epoch 9863: train loss = 4.047063, test loss = 12087.673674\n",
            "Epoch 9864: train loss = 4.047041, test loss = 12087.646398\n",
            "Epoch 9865: train loss = 4.047030, test loss = 12087.617602\n",
            "Epoch 9866: train loss = 4.047040, test loss = 12087.596087\n",
            "Epoch 9867: train loss = 4.047018, test loss = 12087.568694\n",
            "Epoch 9868: train loss = 4.047014, test loss = 12087.538303\n",
            "Epoch 9869: train loss = 4.047017, test loss = 12087.517478\n",
            "Epoch 9870: train loss = 4.046994, test loss = 12087.490886\n",
            "Epoch 9871: train loss = 4.046998, test loss = 12087.459612\n",
            "Epoch 9872: train loss = 4.046993, test loss = 12087.440326\n",
            "Epoch 9873: train loss = 4.046971, test loss = 12087.414147\n",
            "Epoch 9874: train loss = 4.046982, test loss = 12087.381346\n",
            "Epoch 9875: train loss = 4.046970, test loss = 12087.362812\n",
            "Epoch 9876: train loss = 4.046949, test loss = 12087.347302\n",
            "Epoch 9877: train loss = 4.046947, test loss = 12087.323527\n",
            "Epoch 9878: train loss = 4.046948, test loss = 12087.293575\n",
            "Epoch 9879: train loss = 4.046945, test loss = 12087.273720\n",
            "Epoch 9880: train loss = 4.046923, test loss = 12087.247801\n",
            "Epoch 9881: train loss = 4.046932, test loss = 12087.215161\n",
            "Epoch 9882: train loss = 4.046922, test loss = 12087.196539\n",
            "Epoch 9883: train loss = 4.046900, test loss = 12087.170988\n",
            "Epoch 9884: train loss = 4.046915, test loss = 12087.137764\n",
            "Epoch 9885: train loss = 4.046899, test loss = 12087.119907\n",
            "Epoch 9886: train loss = 4.046879, test loss = 12087.104430\n",
            "Epoch 9887: train loss = 4.046875, test loss = 12087.081098\n",
            "Epoch 9888: train loss = 4.046881, test loss = 12087.049350\n",
            "Epoch 9889: train loss = 4.046874, test loss = 12087.031064\n",
            "Epoch 9890: train loss = 4.046851, test loss = 12087.005311\n",
            "Epoch 9891: train loss = 4.046865, test loss = 12086.971626\n",
            "Epoch 9892: train loss = 4.046851, test loss = 12086.953653\n",
            "Epoch 9893: train loss = 4.046828, test loss = 12086.928675\n",
            "Epoch 9894: train loss = 4.046848, test loss = 12086.893711\n",
            "Epoch 9895: train loss = 4.046828, test loss = 12086.877278\n",
            "Epoch 9896: train loss = 4.046810, test loss = 12086.853435\n",
            "Epoch 9897: train loss = 4.046825, test loss = 12086.832076\n",
            "Epoch 9898: train loss = 4.046803, test loss = 12086.804926\n",
            "Epoch 9899: train loss = 4.046795, test loss = 12086.775743\n",
            "Epoch 9900: train loss = 4.046802, test loss = 12086.754080\n",
            "Epoch 9901: train loss = 4.046780, test loss = 12086.727553\n",
            "Epoch 9902: train loss = 4.046780, test loss = 12086.696558\n",
            "Epoch 9903: train loss = 4.046779, test loss = 12086.676110\n",
            "Epoch 9904: train loss = 4.046757, test loss = 12086.649627\n",
            "Epoch 9905: train loss = 4.046764, test loss = 12086.617705\n",
            "Epoch 9906: train loss = 4.046756, test loss = 12086.598544\n",
            "Epoch 9907: train loss = 4.046734, test loss = 12086.573168\n",
            "Epoch 9908: train loss = 4.046748, test loss = 12086.539864\n",
            "Epoch 9909: train loss = 4.046733, test loss = 12086.521521\n",
            "Epoch 9910: train loss = 4.046713, test loss = 12086.505847\n",
            "Epoch 9911: train loss = 4.046709, test loss = 12086.482439\n",
            "Epoch 9912: train loss = 4.046713, test loss = 12086.451924\n",
            "Epoch 9913: train loss = 4.046708, test loss = 12086.432470\n",
            "Epoch 9914: train loss = 4.046685, test loss = 12086.406735\n",
            "Epoch 9915: train loss = 4.046697, test loss = 12086.373537\n",
            "Epoch 9916: train loss = 4.046685, test loss = 12086.355213\n",
            "Epoch 9917: train loss = 4.046663, test loss = 12086.339952\n",
            "Epoch 9918: train loss = 4.046661, test loss = 12086.316753\n",
            "Epoch 9919: train loss = 4.046663, test loss = 12086.285425\n",
            "Epoch 9920: train loss = 4.046659, test loss = 12086.266168\n",
            "Epoch 9921: train loss = 4.046637, test loss = 12086.240168\n",
            "Epoch 9922: train loss = 4.046647, test loss = 12086.207179\n",
            "Epoch 9923: train loss = 4.046636, test loss = 12086.188849\n",
            "Epoch 9924: train loss = 4.046614, test loss = 12086.163991\n",
            "Epoch 9925: train loss = 4.046631, test loss = 12086.129478\n",
            "Epoch 9926: train loss = 4.046613, test loss = 12086.112132\n",
            "Epoch 9927: train loss = 4.046593, test loss = 12086.088875\n",
            "Epoch 9928: train loss = 4.046611, test loss = 12086.067111\n",
            "Epoch 9929: train loss = 4.046589, test loss = 12086.039700\n",
            "Epoch 9930: train loss = 4.046578, test loss = 12086.011563\n",
            "Epoch 9931: train loss = 4.046588, test loss = 12085.989176\n",
            "Epoch 9932: train loss = 4.046566, test loss = 12085.962034\n",
            "Epoch 9933: train loss = 4.046562, test loss = 12085.931733\n",
            "Epoch 9934: train loss = 4.046565, test loss = 12085.910923\n",
            "Epoch 9935: train loss = 4.046543, test loss = 12085.884338\n",
            "Epoch 9936: train loss = 4.046546, test loss = 12085.853483\n",
            "Epoch 9937: train loss = 4.046542, test loss = 12085.833601\n",
            "Epoch 9938: train loss = 4.046519, test loss = 12085.807433\n",
            "Epoch 9939: train loss = 4.046530, test loss = 12085.774873\n",
            "Epoch 9940: train loss = 4.046519, test loss = 12085.756238\n",
            "Epoch 9941: train loss = 4.046497, test loss = 12085.741297\n",
            "Epoch 9942: train loss = 4.046495, test loss = 12085.717237\n",
            "Epoch 9943: train loss = 4.046496, test loss = 12085.686739\n",
            "Epoch 9944: train loss = 4.046494, test loss = 12085.667082\n",
            "Epoch 9945: train loss = 4.046471, test loss = 12085.641236\n",
            "Epoch 9946: train loss = 4.046480, test loss = 12085.608675\n",
            "Epoch 9947: train loss = 4.046470, test loss = 12085.590617\n",
            "Epoch 9948: train loss = 4.046448, test loss = 12085.564759\n",
            "Epoch 9949: train loss = 4.046464, test loss = 12085.530969\n",
            "Epoch 9950: train loss = 4.046447, test loss = 12085.513206\n",
            "Epoch 9951: train loss = 4.046427, test loss = 12085.497959\n",
            "Epoch 9952: train loss = 4.046424, test loss = 12085.474641\n",
            "Epoch 9953: train loss = 4.046430, test loss = 12085.443404\n",
            "Epoch 9954: train loss = 4.046422, test loss = 12085.424496\n",
            "Epoch 9955: train loss = 4.046400, test loss = 12085.398753\n",
            "Epoch 9956: train loss = 4.046413, test loss = 12085.365274\n",
            "Epoch 9957: train loss = 4.046399, test loss = 12085.347301\n",
            "Epoch 9958: train loss = 4.046377, test loss = 12085.322245\n",
            "Epoch 9959: train loss = 4.046397, test loss = 12085.287818\n",
            "Epoch 9960: train loss = 4.046376, test loss = 12085.270760\n",
            "Epoch 9961: train loss = 4.046359, test loss = 12085.247065\n",
            "Epoch 9962: train loss = 4.046374, test loss = 12085.225699\n",
            "Epoch 9963: train loss = 4.046352, test loss = 12085.198662\n",
            "Epoch 9964: train loss = 4.046344, test loss = 12085.169776\n",
            "Epoch 9965: train loss = 4.046351, test loss = 12085.148083\n",
            "Epoch 9966: train loss = 4.046329, test loss = 12085.120907\n",
            "Epoch 9967: train loss = 4.046328, test loss = 12085.090143\n",
            "Epoch 9968: train loss = 4.046328, test loss = 12085.069676\n",
            "Epoch 9969: train loss = 4.046305, test loss = 12085.043435\n",
            "Epoch 9970: train loss = 4.046312, test loss = 12085.011956\n",
            "Epoch 9971: train loss = 4.046305, test loss = 12084.992403\n",
            "Epoch 9972: train loss = 4.046282, test loss = 12084.966575\n",
            "Epoch 9973: train loss = 4.046296, test loss = 12084.933295\n",
            "Epoch 9974: train loss = 4.046282, test loss = 12084.915310\n",
            "Epoch 9975: train loss = 4.046262, test loss = 12084.899622\n",
            "Epoch 9976: train loss = 4.046258, test loss = 12084.876700\n",
            "Epoch 9977: train loss = 4.046262, test loss = 12084.845374\n",
            "Epoch 9978: train loss = 4.046256, test loss = 12084.826214\n",
            "Epoch 9979: train loss = 4.046234, test loss = 12084.800506\n",
            "Epoch 9980: train loss = 4.046246, test loss = 12084.767349\n",
            "Epoch 9981: train loss = 4.046233, test loss = 12084.749150\n",
            "Epoch 9982: train loss = 4.046211, test loss = 12084.734200\n",
            "Epoch 9983: train loss = 4.046210, test loss = 12084.710384\n",
            "Epoch 9984: train loss = 4.046212, test loss = 12084.679210\n",
            "Epoch 9985: train loss = 4.046208, test loss = 12084.659931\n",
            "Epoch 9986: train loss = 4.046186, test loss = 12084.634060\n",
            "Epoch 9987: train loss = 4.046196, test loss = 12084.601636\n",
            "Epoch 9988: train loss = 4.046185, test loss = 12084.583003\n",
            "Epoch 9989: train loss = 4.046163, test loss = 12084.557427\n",
            "Epoch 9990: train loss = 4.046180, test loss = 12084.523280\n",
            "Epoch 9991: train loss = 4.046162, test loss = 12084.505826\n",
            "Epoch 9992: train loss = 4.046142, test loss = 12084.482894\n",
            "Epoch 9993: train loss = 4.046160, test loss = 12084.461459\n",
            "Epoch 9994: train loss = 4.046138, test loss = 12084.433911\n",
            "Epoch 9995: train loss = 4.046127, test loss = 12084.405073\n",
            "Epoch 9996: train loss = 4.046137, test loss = 12084.383028\n",
            "Epoch 9997: train loss = 4.046115, test loss = 12084.355782\n",
            "Epoch 9998: train loss = 4.046111, test loss = 12084.325807\n",
            "Epoch 9999: train loss = 4.046114, test loss = 12084.305326\n",
            "Epoch 10000: train loss = 4.046092, test loss = 12084.278600\n"
          ]
        }
      ],
      "source": [
        "## Train the 2-hidden layer neural network (8 nodes, 8 nodes followed by 1 node)\n",
        "## using batch training with batch size = 100\n",
        "learning_rate = 1e-03 # learning rate\n",
        "batch_size = 16 # batch size\n",
        "nepochs = 10000 # number of epochs\n",
        "reg_strength = 0.01 # regularization strength\n",
        "# Create empty array to store training losses over each epoch\n",
        "loss_train_epoch = np.empty(nepochs, dtype = np.float64)\n",
        "# Create empty array to store test losses over each epoch\n",
        "loss_test_epoch = np.empty(nepochs, dtype = np.float64)\n",
        "\n",
        "\n",
        "# Neural network architecture\n",
        "\n",
        "dlayer1 = Dense(num_features, 8, reg_strength) # define dense layer 1\n",
        "alayer1 = ReLU() # ReLU activation layer 1\n",
        "dlayer2 = Dense(8, 1, reg_strength) # define dense layer 2\n",
        "\n",
        "# Steps: run over each sample in the batch, calculate loss, gradient of loss,\n",
        "# and update weights.\n",
        "\n",
        "epoch = 0\n",
        "while epoch < nepochs:\n",
        "  batch_indices = generate_batch_indices(num_samples, batch_size)\n",
        "  loss = 0\n",
        "  for b in range(len(batch_indices)):\n",
        "    # Forward propagation for training data\n",
        "    dlayer1.forward(X_train_transformed[:, batch_indices[b]]) # forward prop dense layer 1 with batch feature added\n",
        "    alayer1.forward(dlayer1.output) # forward prop activation layer 1\n",
        "    dlayer2.forward(alayer1.output) # forward prop dense layer 2\n",
        "    # Calculate training data loss\n",
        "    loss += mse(Y_train[batch_indices[b]], dlayer2.output)\n",
        "    # Add the regularization losses\n",
        "    loss += dlayer1.reg_loss + dlayer2.reg_loss\n",
        "\n",
        "    # Backward prop starts here\n",
        "    grad = mse_gradient(Y_train[batch_indices[b]], dlayer2.output)\n",
        "    grad = dlayer2.backward(grad, learning_rate)\n",
        "    grad = alayer1.backward(grad)\n",
        "    grad = dlayer1.backward(grad, learning_rate)\n",
        "  # Calculate the average training loss for the current epoch\n",
        "  loss_train_epoch[epoch] = loss/len(batch_indices)\n",
        "\n",
        "  # Forward propagation for test data\n",
        "  dlayer1.forward(X_test_transformed)\n",
        "  alayer1.forward(dlayer1.output)\n",
        "  dlayer2.forward(alayer1.output)\n",
        "\n",
        "  # Calculate test data loss plus regularization loss\n",
        "  loss_test_epoch[epoch] =  mse(Y_test,dlayer2.output) + dlayer1.reg_loss + dlayer2.reg_loss\n",
        "\n",
        "  print('Epoch %d: train loss = %f, test loss = %f'%(epoch+1, loss_train_epoch[epoch], loss_test_epoch[epoch]))\n",
        "  epoch = epoch + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhXEFASk-Tkv"
      },
      "source": [
        "---\n",
        "\n",
        "Plot training loss vs. epoch\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Iv3k23SlCqGf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs. Epoch for reg. strength 0.01')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot train and test loss as a function of epoch:\n",
        "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "ax.plot(loss_train_epoch, 'b', label = 'Train')\n",
        "ax.plot(loss_test_epoch, 'r', label = 'Test')\n",
        "ax.set_xlabel('Epoch', fontsize = 12)\n",
        "ax.set_ylabel('Loss value', fontsize = 12)\n",
        "ax.legend()\n",
        "ax.set_title('Loss vs. Epoch for reg. strength 0.01', fontsize = 14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaLoOOWK-WBj"
      },
      "source": [
        "---\n",
        "\n",
        "Test performance on test data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "d7AEbmpcKcPY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 78.  ,  13.25],\n",
              "       [152.  ,  71.77],\n",
              "       [200.  , 357.32],\n",
              "       [ 59.  ,  55.69],\n",
              "       [311.  , 223.85],\n",
              "       [178.  , 179.17],\n",
              "       [332.  , 244.3 ],\n",
              "       [132.  ,  33.72],\n",
              "       [156.  ,  53.48],\n",
              "       [135.  , 127.89],\n",
              "       [220.  , 354.81],\n",
              "       [233.  , 321.54],\n",
              "       [ 91.  ,  14.01],\n",
              "       [ 51.  ,  19.72],\n",
              "       [195.  , 325.9 ],\n",
              "       [109.  , 340.44],\n",
              "       [217.  , 127.  ],\n",
              "       [ 94.  ,  59.07],\n",
              "       [ 89.  , 151.58],\n",
              "       [111.  , 228.39],\n",
              "       [129.  , 275.9 ],\n",
              "       [181.  ,  73.46],\n",
              "       [168.  , 285.51],\n",
              "       [ 97.  ,  72.02],\n",
              "       [115.  ,  72.11],\n",
              "       [202.  , 207.53],\n",
              "       [ 84.  ,  53.89],\n",
              "       [147.  , 263.06],\n",
              "       [253.  , 171.51],\n",
              "       [144.  , 216.85],\n",
              "       [262.  , 262.94],\n",
              "       [115.  , 211.76],\n",
              "       [ 68.  , 288.13],\n",
              "       [ 65.  ,  49.47],\n",
              "       [252.  , 152.7 ],\n",
              "       [212.  , 261.28],\n",
              "       [142.  , 145.07],\n",
              "       [215.  , 365.87],\n",
              "       [180.  , 236.33],\n",
              "       [163.  , 246.35],\n",
              "       [151.  ,  89.69],\n",
              "       [283.  ,   4.55],\n",
              "       [ 66.  ,  13.81],\n",
              "       [ 83.  ,  92.19],\n",
              "       [214.  ,  19.32],\n",
              "       [189.  , 231.7 ],\n",
              "       [302.  , 211.48],\n",
              "       [ 93.  , 213.82],\n",
              "       [178.  , 268.34],\n",
              "       [241.  , 123.77],\n",
              "       [ 52.  ,  22.01],\n",
              "       [144.  , 363.51],\n",
              "       [102.  ,  10.53],\n",
              "       [200.  ,  47.28],\n",
              "       [232.  , 144.8 ],\n",
              "       [ 97.  , 105.31],\n",
              "       [109.  ,  73.15],\n",
              "       [ 55.  ,  43.24],\n",
              "       [ 63.  ,  67.87],\n",
              "       [ 98.  ,  52.16],\n",
              "       [ 88.  ,  14.75],\n",
              "       [233.  , 194.85],\n",
              "       [235.  , 260.61],\n",
              "       [ 97.  ,  31.12],\n",
              "       [243.  , 446.34],\n",
              "       [ 59.  ,  57.55],\n",
              "       [138.  ,  35.4 ],\n",
              "       [220.  , 275.43],\n",
              "       [137.  , 379.13],\n",
              "       [ 72.  ,  39.26],\n",
              "       [109.  , 158.9 ],\n",
              "       [ 71.  ,  60.12],\n",
              "       [ 74.  ,  87.08],\n",
              "       [219.  ,  19.49],\n",
              "       [196.  , 195.58],\n",
              "       [170.  ,  32.23],\n",
              "       [199.  ,  19.46],\n",
              "       [ 71.  ,  49.03],\n",
              "       [155.  , 435.25],\n",
              "       [ 52.  , 254.44],\n",
              "       [ 63.  ,  18.78],\n",
              "       [ 88.  ,  20.48],\n",
              "       [ 97.  , 302.36],\n",
              "       [100.  , 288.63],\n",
              "       [ 64.  ,  49.58],\n",
              "       [107.  ,  20.71],\n",
              "       [ 49.  ,  74.44],\n",
              "       [ 60.  ,  54.38],\n",
              "       [346.  , 380.72]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dlayer1.forward(X_test_transformed)\n",
        "alayer1.forward(dlayer1.output)\n",
        "dlayer2.forward(alayer1.output)\n",
        "ypred = dlayer2.output.flatten()\n",
        "ytrue = Y_test\n",
        "np.column_stack((ytrue, ypred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
